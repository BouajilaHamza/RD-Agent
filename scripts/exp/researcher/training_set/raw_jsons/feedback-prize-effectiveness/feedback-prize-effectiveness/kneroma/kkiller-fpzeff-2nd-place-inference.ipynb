{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os, re\nv_transformers = !pip show transformers\nv_transformers = \"\\n\".join(v_transformers)\nv_transformers = re.search(r\"version\\:\\s*([\\d\\.]+)\", v_transformers.lower()).group(1).strip()\nprint(\"initial transformers version:\", v_transformers)\nif v_transformers != \"4.20.1\":\n#     os.system('pip show transformers')\n    os.system('pip uninstall -y transformers')\n    os.system('pip uninstall -y tokenizers')\n    os.system('python -m pip install --no-index --find-links=../input/pip-wheels-transformers-4-20-1/ transformers')\n    os.system('python -m pip install --no-index --find-links=../input/pip-wheels-transformers-4-20-1/ tokenizers')\n    import tokenizers\n    import transformers\n    print(f\"tokenizers.__version__: {tokenizers.__version__}\")\n    print(f\"transformers.__version__: {transformers.__version__}\")\nelse:\n    print(\"transformers is already up to date\")","metadata":{"papermill":{"duration":9.301678,"end_time":"2022-08-23T00:21:51.143425","exception":false,"start_time":"2022-08-23T00:21:41.841747","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-09-04T16:46:30.38115Z","iopub.execute_input":"2022-09-04T16:46:30.381554Z","iopub.status.idle":"2022-09-04T16:46:38.542547Z","shell.execute_reply.started":"2022-09-04T16:46:30.381517Z","shell.execute_reply":"2022-09-04T16:46:38.54088Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"papermill":{"duration":0.004929,"end_time":"2022-08-23T00:21:51.154264","exception":false,"start_time":"2022-08-23T00:21:51.149335","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os, sys\nsys.path.insert(0, \"../input/kkillerfpzeff2ndplace/fpzeff/src\")","metadata":{"papermill":{"duration":0.013533,"end_time":"2022-08-23T00:21:51.172378","exception":false,"start_time":"2022-08-23T00:21:51.158845","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-09-04T16:46:38.545433Z","iopub.execute_input":"2022-09-04T16:46:38.545866Z","iopub.status.idle":"2022-09-04T16:46:38.550681Z","shell.execute_reply.started":"2022-09-04T16:46:38.545822Z","shell.execute_reply":"2022-09-04T16:46:38.549652Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd, numpy as np\nimport torch\n\nfrom tqdm.auto import tqdm\nfrom pathlib import Path\nfrom  datetime import datetime\n\n\nimport configs\nimport dataset\nimport inference\n\nimport gc","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","papermill":{"duration":3.266585,"end_time":"2022-08-23T00:21:54.443827","exception":false,"start_time":"2022-08-23T00:21:51.177242","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-09-04T16:46:38.552477Z","iopub.execute_input":"2022-09-04T16:46:38.553277Z","iopub.status.idle":"2022-09-04T16:46:41.235168Z","shell.execute_reply.started":"2022-09-04T16:46:38.55324Z","shell.execute_reply":"2022-09-04T16:46:41.23419Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"IS_DEBUG = False\n\nos.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n\n# configs.TRAIN_ROOT = \"../input/feedback-prize-effectiveness/train\"\n# configs.TRAIN_CSV_PATH = \"../input/feedback-prize-effectiveness/train.csv\"\n# configs.SAMPLE_SUB_CSV_PATH = None\n\nconfigs.TRAIN_ROOT = \"../input/feedback-prize-effectiveness/test\"\nconfigs.TRAIN_CSV_PATH = \"../input/feedback-prize-effectiveness/test.csv\"\nconfigs.SAMPLE_SUB_CSV_PATH = \"../input/feedback-prize-effectiveness/sample_submission.csv\"\n\nDEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\nprint(DEVICE)","metadata":{"papermill":{"duration":0.08591,"end_time":"2022-08-23T00:21:54.537053","exception":false,"start_time":"2022-08-23T00:21:54.451143","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-09-04T16:46:41.237929Z","iopub.execute_input":"2022-09-04T16:46:41.238591Z","iopub.status.idle":"2022-09-04T16:46:41.305756Z","shell.execute_reply.started":"2022-09-04T16:46:41.238537Z","shell.execute_reply":"2022-09-04T16:46:41.304763Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"papermill":{"duration":0.00456,"end_time":"2022-08-23T00:21:54.547469","exception":false,"start_time":"2022-08-23T00:21:54.542909","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# WEIGHTS","metadata":{"papermill":{"duration":0.004987,"end_time":"2022-08-23T00:21:54.557411","exception":false,"start_time":"2022-08-23T00:21:54.552424","status":"completed"},"tags":[]}},{"cell_type":"code","source":"import re\ndef get_fold(path):\n    return int(re.search(r\"_fold(\\d+)_\", str(path)).group(1))","metadata":{"papermill":{"duration":0.013667,"end_time":"2022-08-23T00:21:54.575991","exception":false,"start_time":"2022-08-23T00:21:54.562324","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-09-04T16:46:41.30934Z","iopub.execute_input":"2022-09-04T16:46:41.309745Z","iopub.status.idle":"2022-09-04T16:46:41.316947Z","shell.execute_reply.started":"2022-09-04T16:46:41.309694Z","shell.execute_reply":"2022-09-04T16:46:41.315959Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"params = [\n    \n    inference.get_params(\n        \n        model_name=\"microsoft/deberta-v2-xlarge\",\n        use_mixup=False,\n        forward_type=\"forward_full_oof\",\n        use_token_types=True,\n        use_layer_norm=True,\n        batch_size=4,\n        maxlen=1792,\n        num_workers=0,\n        weight=.15,\n        \n        config_path=\"../input/kkillerfpzeff2ndplace/kkiller-transformers-data/microsoft_deberta-v2-xlarge-mnli\",\n        tokenizer_path=\"../input/kkillerfpzeff2ndplace/kkiller-transformers-data/microsoft_deberta-v2-xlarge-mnli\",\n        \n        is_pickle=False,\n        device=DEVICE,\n        \n        model_paths=[\n            \"../input/fpzeff-db2xl-psl-1span-notune-v3-1-m1152-weights/db2xl_psl_1span_v3_1_m1152/fpeff_microsoft_deberta-v2-xlarge_fold0_epoch_02_loss_v2_val_0.5704_20220820152247.pth\",\n            \"../input/fpzeff-db2xl-psl-1span-notune-v3-1-m1152-weights/db2xl_psl_1span_v3_1_m1152/fpeff_microsoft_deberta-v2-xlarge_fold1_epoch_02_loss_v2_val_0.6005_20220820194712.pth\",\n        ],\n        \n        oof_name=\"oof_db2xl_fgp_psl_v3_1_1152_220823\",\n        \n        dataset_module=dataset,\n        inference_module=inference,\n    ),\n    \n    \n    inference.get_params(\n        model_name=\"microsoft/deberta-xlarge\",\n        use_mixup=False,\n        forward_type=\"forward_full_oof\",\n        use_token_types=True,\n        use_layer_norm=True,\n        batch_size=4,\n        maxlen=1792,\n        num_workers=0,\n        weight=.25,\n        config_path=\"../input/kkillerfpzeff2ndplace/kkiller-transformers-data/microsoft_deberta-xlarge\",\n        tokenizer_path=\"../input/kkillerfpzeff2ndplace/kkiller-transformers-data/microsoft_deberta-xlarge\",\n        is_pickle=False,\n        device=DEVICE,\n        model_paths=list(Path(\"../input/fpzeff-db1xl-psl-1span-notune-v3-1-m864-weights/db1xl_psl_1span_v3_1_m864/\").glob(\"*.pth\")),\n        \n        oof_name=\"oof_db1xl_fgp_psl_v3_1_864_220823\",\n        \n        dataset_module=dataset,\n        inference_module=inference,\n    ),\n    \n    \n    inference.get_params(\n        model_name=\"microsoft/deberta-large\",\n        use_mixup=False,\n        forward_type=\"forward_full_oof\",\n        use_token_types=True,\n        use_layer_norm=True,\n        batch_size=8,\n        maxlen=1792,\n        num_workers=0,\n        weight=.25,\n        config_path=\"../input/kkillerfpzeff2ndplace/kkiller-transformers-data/microsoft_deberta-large\",\n        tokenizer_path=\"../input/kkillerfpzeff2ndplace/kkiller-transformers-data/microsoft_deberta-large\",\n        is_pickle=False,\n        device=DEVICE,\n        model_paths=list(Path(\"../input/fpzeff-db1l-psl-1span-notune-v3-1-m1152-weights/db1l_psl_1span_v3_1_m1152/\").glob(\"*.pth\")),\n        \n        oof_name=\"oof_db1l_fgp_psl_v3_1_1152_220823\",\n        \n        dataset_module=dataset,\n        inference_module=inference,\n    ),\n    \n    \n    inference.get_params(\n        model_name=\"microsoft/deberta-v3-large\",\n        use_mixup=False,\n        forward_type=\"forward_full_oof\",\n        use_token_types=True,\n        use_layer_norm=True,\n        batch_size=8,\n        maxlen=1792,\n        num_workers=0,\n        weight=.35,\n        config_path=\"../input/kkillerfpzeff2ndplace/kkiller-transformers-data/microsoft_deberta-v3-large\",\n        tokenizer_path=\"../input/kkillerfpzeff2ndplace/kkiller-transformers-data/microsoft_deberta-v3-large\",\n        is_pickle=False,\n        device=DEVICE,\n        model_paths=list(Path(\"../input/fpzeff-db3l-psl-1span-notune-v3-1-m1152-weights/db3l_psl_1span_v3_1_m1152/\").glob(\"*.pth\")),\n        \n        oof_name=\"oof_full_db3l_fgp_psl_v3_1_1152_220822\",\n        \n        dataset_module=dataset,\n        inference_module=inference,\n    ),\n    \n]\n\nS = sum([param[\"weight\"] for param in params])\nassert abs(S- 1.0) < 1e-3, S\n\nprint(\"TOTAL UNIQUE MODELS:\", len(params))\nprint(\"TOTAL  CHECKPOINTS:\", sum([len(param[\"model_paths\"]) for param in params]))\nprint(\"MODELS PER CHKPT;\", [len(param[\"model_paths\"]) for param in params])","metadata":{"papermill":{"duration":2.443214,"end_time":"2022-08-23T00:21:57.023864","exception":false,"start_time":"2022-08-23T00:21:54.58065","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-09-04T16:46:41.318779Z","iopub.execute_input":"2022-09-04T16:46:41.319811Z","iopub.status.idle":"2022-09-04T16:46:43.690656Z","shell.execute_reply.started":"2022-09-04T16:46:41.319708Z","shell.execute_reply":"2022-09-04T16:46:43.68967Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"papermill":{"duration":0.004966,"end_time":"2022-08-23T00:21:57.034186","exception":false,"start_time":"2022-08-23T00:21:57.02922","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"papermill":{"duration":0.004856,"end_time":"2022-08-23T00:21:57.044028","exception":false,"start_time":"2022-08-23T00:21:57.039172","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = dataset.read_train_csv(configs.TRAIN_CSV_PATH, nrows=None, is_test=True)\ndf[\"train_root\"] = configs.TRAIN_ROOT\n\ntrain_roots = dict(zip(df[\"id\"], df[\"train_root\"]))  \nessays = {uuid: dataset.read_from_id(uuid, root=train_roots[uuid]) for uuid in tqdm(df[\"id\"].unique(), desc=\"reading essays\")}\n\ndf[\"nchars\"] = df[\"id\"].map({uuid: len(essays[uuid].split()) for uuid in tqdm(df[\"id\"].unique(), desc=\"nchars\")})\ndf[\"is_true_obs\"] = True\n\nuuids = dict(zip(df[\"id\"], -df[\"nchars\"]))\nuuids = sorted(list(uuids.keys()), key=lambda uuid: uuids[uuid])\n\nif IS_DEBUG:\n    uuids = uuids[:100]\n    df = df[df[\"id\"].isin(uuids)].reset_index(drop=True)\n\nprint(\"nuuids\", len(uuids))\n\nprint(f\"len(uuids): {len(uuids)}\")\n\nprint(df.shape)\ndf[df[\"id\"].isin(uuids[:3])]","metadata":{"papermill":{"duration":0.125912,"end_time":"2022-08-23T00:21:57.174929","exception":false,"start_time":"2022-08-23T00:21:57.049017","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-09-04T16:46:43.692426Z","iopub.execute_input":"2022-09-04T16:46:43.693407Z","iopub.status.idle":"2022-09-04T16:46:43.819256Z","shell.execute_reply.started":"2022-09-04T16:46:43.693367Z","shell.execute_reply":"2022-09-04T16:46:43.818276Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"papermill":{"duration":0.005492,"end_time":"2022-08-23T00:21:57.185921","exception":false,"start_time":"2022-08-23T00:21:57.180429","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"get_fold(params[0][\"model_paths\"][0])","metadata":{"papermill":{"duration":0.015076,"end_time":"2022-08-23T00:21:57.206264","exception":false,"start_time":"2022-08-23T00:21:57.191188","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-09-04T16:46:43.820784Z","iopub.execute_input":"2022-09-04T16:46:43.821458Z","iopub.status.idle":"2022-09-04T16:46:43.829106Z","shell.execute_reply.started":"2022-09-04T16:46:43.821414Z","shell.execute_reply":"2022-09-04T16:46:43.827912Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"papermill":{"duration":0.005396,"end_time":"2022-08-23T00:21:57.21693","exception":false,"start_time":"2022-08-23T00:21:57.211534","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def expand_oof(full_oof):\n    full_oof_list = []\n    for (essay_id, discourse_ids, preds) in full_oof[\"preds\"]:\n\n        temp = {}\n        for discourse_id, pred in zip(discourse_ids, preds):\n            if discourse_id in temp:\n                temp[discourse_id].append(pred)\n            else:\n                temp[discourse_id] = [pred]\n\n\n        for discourse_id, pred in temp.items():\n            pred = np.stack(pred)\n\n            full_oof_list.append(\n                {\n                    \"essay_id\": essay_id,\n                    \"discourse_id\": discourse_id,\n                    \"preds\": pred,\n                    \"fold\": full_oof[\"info\"][\"fold\"],\n                }\n\n            )\n\n    full_oof = pd.DataFrame(full_oof_list)\n        \n    return full_oof","metadata":{"papermill":{"duration":0.016869,"end_time":"2022-08-23T00:21:57.239303","exception":false,"start_time":"2022-08-23T00:21:57.222434","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-09-04T16:46:43.830271Z","iopub.execute_input":"2022-09-04T16:46:43.832373Z","iopub.status.idle":"2022-09-04T16:46:43.841041Z","shell.execute_reply.started":"2022-09-04T16:46:43.832299Z","shell.execute_reply":"2022-09-04T16:46:43.839984Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"papermill":{"duration":0.005114,"end_time":"2022-08-23T00:21:57.249859","exception":false,"start_time":"2022-08-23T00:21:57.244745","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def predict_for_param(param):\n\n    cols = [\"Ineffective\", \"Adequate\", \"Effective\"]\n\n    all_preds = {}\n    \n    model_paths = {get_fold(path): path for path in param[\"model_paths\"]}\n    inference_module = param.get(\"inference_module\", inference)\n    \n    model_name = Path(param[\"model_paths\"][0]).parent.stem\n    \n    print(f\"model: {model_name}  num_folds: {len(model_paths)}\")\n    \n    folds_bar = tqdm(sorted(model_paths), desc=model_name)\n    \n    data = inference_module.load_data(\n        uuids=uuids,\n        param=param,\n        df=df,\n        essays=essays,\n        bar_for_data=True,\n    )\n    \n    for fold in folds_bar:\n        model_path = Path(model_paths[fold])\n        \n        print(f\"model: {model_name}  fold: {fold}\")\n        \n        ckpt = model_path.stem\n        \n        param[\"model_paths\"] = [model_path]\n        \n        preds  = inference_module.predict_from_param(\n            uuids=uuids,\n            param=param,\n            data=data,\n            df=df,\n            essays=essays,\n#             bar_for_models=IS_DEBUG,\n            bar_for_models=True,\n    #         bar_for_data=IS_DEBUG,\n            bar_for_data=False,\n            bar=False,\n            do_full_oof=True,\n        )\n        \n        res = {\n            \"preds\": preds,\n            \"info\": {\n                \"fold\": fold,\n                \"weight\": param[\"weight\"],\n                \"fold_name\": configs.FOLD_COL_NAME,\n                \"model_name\": model_name,\n                \"ckpt\": ckpt,\n            }\n        }\n        \n        all_preds[fold] = expand_oof(res)\n        \n        del res\n        gc.collect()\n        torch.cuda.empty_cache()\n    \n    del data\n    gc.collect()\n    torch.cuda.empty_cache()\n        \n    return all_preds","metadata":{"papermill":{"duration":0.01811,"end_time":"2022-08-23T00:21:57.273501","exception":false,"start_time":"2022-08-23T00:21:57.255391","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-09-04T16:46:43.845032Z","iopub.execute_input":"2022-09-04T16:46:43.845367Z","iopub.status.idle":"2022-09-04T16:46:43.858263Z","shell.execute_reply.started":"2022-09-04T16:46:43.845342Z","shell.execute_reply":"2022-09-04T16:46:43.856711Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def sorted_quantile(array, q):\n    array = np.array(array)\n    n = len(array)\n    index = (n - 1) * q\n    left = np.floor(index).astype(int)\n    fraction = index - left\n    right = left\n    right = right + (fraction > 0).astype(int)\n    i, j = array[left], array[right]\n    return i + (j - i) * fraction\n\nfrom scipy.stats import entropy\n#make features\ndef get_xgb_features(train_df,prob_sequences):\n    features2calculate=[f\"instability_{i}\" for i in range(4)]+\\\n    [f\"begin_{i}\" for i in range(3)]+\\\n    [f\"end_{i}\" for i in range(3)]#+\\\n    #[\"entropy\"]\n\n    calculated_features=[]\n    for i,prob_seq in tqdm(enumerate(prob_sequences)):\n\n        tmp=[]\n        #quants = np.linspace(0,1,n_quan)\n        prob_seq=np.array(prob_seq)\n        instability = []\n        #all_quants=[] \n        tmp.append(np.diff(prob_seq[:,:],0).mean(0))\n        tmp.append([(np.diff(prob_seq[:,[1,2]].sum(1))**2).mean()])\n\n        tmp.append(prob_seq[:5,:].mean(0))\n        tmp.append(prob_seq[-5:,:].mean(0))\n\n        calculated_features.append(np.concatenate(tmp))\n\n\n    train_df[features2calculate]=calculated_features\n    train_df['len']=[len(s) for s in prob_sequences]\n\n    calculated_features=np.array(calculated_features)\n    calculated_features.shape\n\n    p_features=[]\n    n_features=[]\n    neighbor_features=['Ineffective','Adequate','Effective','discourse_type']\n    neighbor_features_values=train_df[neighbor_features].values\n    for i in tqdm(range(len(train_df))):\n        if i>1 and train_df['essay_id'].iloc[i]==train_df['essay_id'].iloc[i-1]:\n            p_features.append(neighbor_features_values[i-1])\n        else:\n            p_features.append(neighbor_features_values[i])\n\n        if i<(len(train_df)-1) and train_df['essay_id'].iloc[i]==train_df['essay_id'].iloc[i+1]:\n            n_features.append(neighbor_features_values[i+1])\n        else:\n            n_features.append(neighbor_features_values[i])\n\n    train_df[[f+\"_previous\" for f in neighbor_features]]=p_features\n    train_df[[f+\"_next\" for f in neighbor_features]]=n_features\n\n    train_df['mean_Ineffective']=train_df.groupby(\"essay_id\")[\"Ineffective\"].transform(\"mean\")\n    train_df['mean_Adequate']=train_df.groupby(\"essay_id\")[\"Adequate\"].transform(\"mean\")\n    train_df['mean_Effective']=train_df.groupby(\"essay_id\")[\"Effective\"].transform(\"mean\")\n\n    train_df['std_Ineffective']=train_df.groupby(\"essay_id\")[\"Ineffective\"].transform(\"std\")\n    train_df['std_Adequate']=train_df.groupby(\"essay_id\")[\"Adequate\"].transform(\"std\")\n    train_df['std_Effective']=train_df.groupby(\"essay_id\")[\"Effective\"].transform(\"std\")\n\n    train_df['discourse_count']=train_df.groupby(\"essay_id\")['discourse_type'].transform(\"count\")\n\n    cnts=train_df.groupby('essay_id')['discourse_type'].apply(lambda x: x.value_counts())\n\n    #new_df=[]\n    discourse_types=['Claim','Evidence','Concluding Statement','Lead','Position','Counterclaim','Rebuttal']\n    value_count_hash={}\n    for t in discourse_types:\n        value_count_hash[t]={}\n    for key in cnts.keys():\n        value_count_hash[key[1]][key[0]]=cnts[key]\n\n    discourse_cnts=[]    \n    for essay_id in train_df['essay_id'].unique():\n        row=[essay_id]\n        for d in discourse_types:\n            try:\n                row.append(value_count_hash[d][essay_id])\n            except:\n                row.append(0)\n        discourse_cnts.append(row)\n\n    discourse_cnts=pd.DataFrame(discourse_cnts,columns=['essay_id']+[f'{d}_count' for d in discourse_types])    \n    #discourse_cnts\n\n    train_df=train_df.merge(discourse_cnts,how='left',on='essay_id')\n    train_df\n\n    #train_df\n\n    return train_df\n\nneighbor_features=['Ineffective','Adequate','Effective','discourse_type']\ndiscourse_types=['Claim','Evidence','Concluding Statement','Lead','Position','Counterclaim','Rebuttal']\n\nfeatures=[\"Ineffective\",\"Adequate\",\"Effective\",\n          \"instability_0\",\"instability_1\",\"instability_2\",\"instability_3\",\n          \"len\",\"discourse_type\"]\nfeatures+=[f\"begin_{i}\" for i in range(3)]\nfeatures+=[f\"end_{i}\" for i in range(3)]\n\nfeatures=features+[f+\"_previous\" for f in neighbor_features]+[f+\"_next\" for f in neighbor_features]+\\\n['mean_Ineffective','mean_Adequate','mean_Effective']+['std_Ineffective','std_Adequate','std_Effective']+\\\n['discourse_count']+[f'{d}_count' for d in discourse_types]","metadata":{"papermill":{"duration":0.031478,"end_time":"2022-08-23T00:21:57.310457","exception":false,"start_time":"2022-08-23T00:21:57.278979","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-09-04T16:46:43.859978Z","iopub.execute_input":"2022-09-04T16:46:43.860524Z","iopub.status.idle":"2022-09-04T16:46:43.884948Z","shell.execute_reply.started":"2022-09-04T16:46:43.860487Z","shell.execute_reply":"2022-09-04T16:46:43.884039Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import xgboost as xgb\nsubs=[]\nweights=[]\nfor param in tqdm(params):\n    all_preds = predict_for_param(param)\n    weights.append(param['weight'])\n    N_XGB_FOLDS=6\n    TOKEN_START_POS=2\n    #XGB_PATH=\"../input/kkiller-stacking-final/kkiller_stacking/oof_db1l_fgp_psl_v3_1_1152_220823/gbm_models\"\n    XGB_PATH=f\"../input/kkiller-stacking-final/kkiller_stacking/{param['oof_name']}/gbm_models\"\n    label_mapping={'Ineffective': 0, 'Adequate': 1, 'Effective': 2}\n    test=pd.read_csv(\"../input/feedback-prize-effectiveness/test.csv\")\n    xgb_preds=[]\n    \n    \n    for key in all_preds.keys():\n    #for key in [3]:\n        pred_df=all_preds[key]\n        sub=pd.DataFrame(columns=['discourse_id']+list(label_mapping.keys()))\n        sub['discourse_id']=pred_df['discourse_id']\n        \n        preds=[s[1] for s in pred_df['preds']]\n        sub[list(label_mapping.keys())]=preds\n        sub=sub.merge(test[['discourse_id','discourse_type','essay_id']],how='left',on='discourse_id')\n        prob_sequences=[s[TOKEN_START_POS:] for s in pred_df['preds']]\n        sub=get_xgb_features(sub,prob_sequences)\n\n        for f in features:\n                if f not in ['discourse_type_previous','discourse_type_next','discourse_type']:\n                    sub[f]= sub[f].astype('float')\n                else:    \n                    sub[f]= sub[f].astype('category')\n\n        d_test = xgb.DMatrix(sub[features],enable_categorical=True)\n\n        for xgb_fold in range(N_XGB_FOLDS):\n            #xgb_model_loaded = pickle.load(open(f\"{exp.XGB_PATH}/xgb_{xgb_fold}.p\", \"rb\"))\n            xgb_model_loaded = xgb.Booster()\n            xgb_model_loaded.load_model(f\"{XGB_PATH}/xgb_{xgb_fold}.json\")\n            xgb_preds.append(xgb_model_loaded.predict(d_test))\n    xgb_preds=np.stack(xgb_preds)\n    print(xgb_preds.shape)\n    xgb_preds=xgb_preds.mean(0)\n\n\n    submission=pd.read_csv(\"../input/feedback-prize-effectiveness/sample_submission.csv\")\n\n    discourse_ids=list(submission['discourse_id'])\n    for i in range(len(sub)):\n        index=discourse_ids.index(sub['discourse_id'].iloc[i])\n        submission[\"Ineffective\"].iloc[index]=xgb_preds[i,0]\n        submission[\"Adequate\"].iloc[index]=xgb_preds[i,1]\n        submission[\"Effective\"].iloc[index]=xgb_preds[i,2]\n\n    #submission.to_csv(\"submission.csv\",index=False)\n    subs.append(submission)\n    print(submission)\n    # Call Stacker here","metadata":{"papermill":{"duration":597.421427,"end_time":"2022-08-23T00:31:54.737447","exception":false,"start_time":"2022-08-23T00:21:57.31602","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-09-04T16:46:43.888343Z","iopub.execute_input":"2022-09-04T16:46:43.888764Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# import os\n# for param in tqdm(params):\n#     #print(param['oof_name'])\n#     XGB_PATH=f\"../input/kkiller-stacking-final/kkiller_stacking/{param['oof_name']}/gbm_models\"\n#     os.system(f\"ls {XGB_PATH}\")\n#     #os.system()\n\n","metadata":{"papermill":{"duration":0.023535,"end_time":"2022-08-23T00:31:54.777062","exception":false,"start_time":"2022-08-23T00:31:54.753527","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"assert len(subs)==len(weights)\n\nprint(weights)\n\nweights=np.array(weights)\nweights=weights/weights.sum()\nsubmission=subs[0].copy()\nsubmission[\"Ineffective\"]=submission[\"Ineffective\"].values*weights[0]\nsubmission[\"Adequate\"]=submission[\"Adequate\"].values*weights[0]\nsubmission[\"Effective\"]=submission[\"Effective\"].values*weights[0]\n\n\nfor sub,weight in zip(subs[1:],weights[1:]):\n    submission[\"Ineffective\"]=submission[\"Ineffective\"].values+sub[\"Ineffective\"].values*weight\n    submission[\"Adequate\"]=submission[\"Adequate\"].values+sub[\"Adequate\"].values*weight\n    submission[\"Effective\"]=submission[\"Effective\"].values+sub[\"Effective\"].values*weight\n\nsubmission.to_csv(\"submission.csv\",index=False)","metadata":{"papermill":{"duration":0.033432,"end_time":"2022-08-23T00:31:54.824528","exception":false,"start_time":"2022-08-23T00:31:54.791096","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]}]}