{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"**Can we approach this as a regression problem instead of classification?**\n\nFor any metric other than ROC-AUC, the answer would be NO, as we have two discreet classes to predict. But *roc_auc_score* cares only about the order of predictions, so it will work. Specifically, I will use Lasso regression because its L1 penalty squeezes out some features by setting their coefficients to zeros, thus performing feature selection. None of the features will be eliminated in this case, but we will get their relative importance at the end.","metadata":{}},{"cell_type":"code","source":"from datetime import datetime\nimport pandas as pd\nimport numpy as np\nfrom sklearn.linear_model import LassoCV\nfrom sklearn.model_selection import RepeatedKFold\nfrom sklearn.metrics import mean_squared_error, roc_auc_score\nimport joblib\nimport matplotlib.pyplot as plt\nfrom category_encoders.leave_one_out import LeaveOneOutEncoder\nfrom sklearn.preprocessing import StandardScaler\nfrom scipy import special\n\n\ndef timer(start_time=None):\n    if not start_time:\n        start_time = datetime.now()\n        return start_time\n    elif start_time:\n        tmin, tsec = divmod((datetime.now() - start_time).total_seconds(), 60)\n        print(\" Time taken: %i minutes and %s seconds.\" % (tmin, round(tsec, 2)))\n\n\nDATA_TRAIN_PATH = \"/kaggle/input/playground-series-s3e2/train.csv\"\nDATA_TEST_PATH = \"/kaggle/input/playground-series-s3e2/test.csv\"\n\n\ndef load_data(path_train=DATA_TRAIN_PATH, path_test=DATA_TEST_PATH):\n    train_loader = pd.read_csv(path_train)\n    train = train_loader.drop([\"stroke\", \"id\"], axis=1)\n    features = train.columns.tolist()\n    print(\"\\n Train dataset shape:\", train.shape)\n    train_labels = train_loader[\"stroke\"].values\n    train_ids = train_loader[\"id\"].values\n\n    test_loader = pd.read_csv(path_test)\n    test = test_loader[features]\n    print(\" Whole test dataset shape:\", test.shape)\n    test_ids = test_loader[\"id\"].values\n\n    return train, train_labels, train_ids, features, test, test_ids\n\n\nif __name__ == \"__main__\":\n\n    # We will do repeated K-fold cross-validation\n    folds = 10\n    repeats = 10\n    # For historic reasons I use one of these 3 seeds\n    seeds = [6772, 6659, 7622]\n\n    # Load data set and target values\n    start_time = timer(None)\n    print(\"\\n# Reading and Processing Data\")\n    X_train, y, train_ids, features, X_test, test_ids = load_data()\n\n    all_cols = features\n    cols_cat = [\n        \"gender\",\n        \"ever_married\",\n        \"work_type\",\n        \"Residence_type\",\n        \"smoking_status\",\n    ]\n    num_features = [col for col in all_cols if col not in cols_cat]","metadata":{"execution":{"iopub.status.busy":"2023-01-11T00:09:40.944474Z","iopub.execute_input":"2023-01-11T00:09:40.944963Z","iopub.status.idle":"2023-01-11T00:09:42.343557Z","shell.execute_reply.started":"2023-01-11T00:09:40.944875Z","shell.execute_reply":"2023-01-11T00:09:42.342227Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Like most generalized linear models, Lasso works only with numerical features and does not tolerate missing values. That means we have to toss out the categorical features, or convert them to numbers. We will do the latter. Didn't check whether features are normally distributed, but it doesn't hurt to standardize them.","metadata":{}},{"cell_type":"code","source":"print(\"\\n Encoding categorical variables ...\")\n# sigma=0.05 injects a bit of noise so we don't overfit\nce = LeaveOneOutEncoder(cols=cols_cat, random_state=2022, sigma=0.05, verbose=1)\nX_train = ce.fit_transform(X_train, y)\nX_test = ce.transform(X_test)\nprint(\"\\n Train Set Matrix Dimensions: %d x %d\" % (X_train.shape[0], X_train.shape[1]))\nprint(\" Test Set Matrix Dimensions: %d x %d\" % (X_test.shape[0], X_test.shape[1]))\n\nprint(\n    \" Potential NaN or Inf values in train data:  \",\n    np.isnan(X_train[features].values).any(),\n    \"  \",\n    np.isinf(X_train[features].values).any(),\n)\nprint(\n    \" Potential NaN or Inf values in test data:  \",\n    np.isnan(X_test[features].values).any(),\n    \"  \",\n    np.isinf(X_test[features].values).any(),\n)\ntimer(start_time)\n\nscaler = StandardScaler()\nscaler.fit(X_train[features].values)\nX_train[features] = scaler.transform(X_train[features].values)\njoblib.dump(scaler, \"StandardScaler_Lasso-01-v1.joblib\")\n# scaler = joblib.load('StandardScaler_Lasso-01-v1.joblib')\nX_test[features] = scaler.transform(X_test[features].values)","metadata":{"execution":{"iopub.status.busy":"2023-01-11T00:09:42.346043Z","iopub.execute_input":"2023-01-11T00:09:42.346961Z","iopub.status.idle":"2023-01-11T00:09:42.507369Z","shell.execute_reply.started":"2023-01-11T00:09:42.346928Z","shell.execute_reply":"2023-01-11T00:09:42.506275Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"All rigth, now we have all-numerical data. Time to set up cross-validation and let Lasso rip.","metadata":{}},{"cell_type":"code","source":"rkf_grid = list(\n    RepeatedKFold(n_splits=folds, n_repeats=repeats, random_state=seeds[0]).split(\n        X_train, y\n    )\n)\nstart_time = timer(None)\n# Run Lasso cross-validation to determine coefficient alpha and the intercept\n# Doing repeated CV to test many different folds and avoid overfitting\nprint(\"\\n Running Lasso:\")\nmodel_llcv = LassoCV(\n    precompute=\"auto\",\n    fit_intercept=True,\n    normalize=False,\n    max_iter=1000,\n    verbose=False,\n    eps=1e-04,\n    cv=rkf_grid,\n    n_alphas=1000,\n    n_jobs=8,\n)\nmodel_llcv.fit(X_train, y)\njoblib.dump(model_llcv, \"Stroke_Lasso-01-v1.joblib\")\n#    model_llcv = joblib.load('Stroke_Lasso-01-v1.joblib')\nprint(\" Best alpha value: %.10f\" % model_llcv.alpha_)\nprint(\" Intercept: %.10f\" % model_llcv.intercept_)\nprint(\" LassoCV score: %.10f\" % model_llcv.score(X_train, y))\n","metadata":{"execution":{"iopub.status.busy":"2023-01-11T00:09:42.508721Z","iopub.execute_input":"2023-01-11T00:09:42.509109Z","iopub.status.idle":"2023-01-11T00:09:59.945286Z","shell.execute_reply.started":"2023-01-11T00:09:42.509077Z","shell.execute_reply":"2023-01-11T00:09:59.944519Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We have our model parameters. The value of alpha is critical, as we don't want to over- or under-fit the model. Large alpha values will make most feature coefficents be zero, and the model will be very simple and likely under-fitted. When alpha is 0, we have linear regression which means no regularization and stronger potential for over-fitting.\n\nLet's do a quick test to see what kind of score we can expect.","metadata":{}},{"cell_type":"code","source":"RMSE_nocv = np.sqrt(mean_squared_error(y, model_llcv.predict(X_train)))\nAUC_nocv = roc_auc_score(y, model_llcv.predict(X_train))\nprint(\"\\n Non cross-validated LassoCV RMSE: %.6f\" % RMSE_nocv)\nprint(\" Non cross-validated AUC: %.6f\" % AUC_nocv)\n","metadata":{"execution":{"iopub.status.busy":"2023-01-11T00:09:59.947124Z","iopub.execute_input":"2023-01-11T00:09:59.949363Z","iopub.status.idle":"2023-01-11T00:09:59.977196Z","shell.execute_reply.started":"2023-01-11T00:09:59.94932Z","shell.execute_reply":"2023-01-11T00:09:59.976415Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Now we run this on even larger number of different folds (10 folds repeated 10 times). The idea again is to avoid overfitting and guard against uneven data distributions within folds, as we will average every single point 10 times in out-of-fold fashion. We will have to keep track of how many times each point has been predicted and divide its sum by the number of predictions.","metadata":{}},{"cell_type":"code","source":"cv_sum = 0\ncv_sum_auc = 0\npred = []\nfpred = []\navreal = y\navpred = np.zeros(X_train.shape[0])\navpred_count = np.zeros(X_train.shape[0])\nidpred = train_ids\n\ntrain_time = timer(None)\nrepeats = 10\nrkf_grid = list(\n    RepeatedKFold(n_splits=folds, n_repeats=repeats, random_state=seeds[0]).split(\n        X_train, y\n    )\n)\n\nfor i, (train_index, val_index) in enumerate(rkf_grid):\n    fold_time = timer(None)\n    print(\"\\n Fold %02d\" % (i + 1))\n    Xtrain, Xval = X_train.loc[train_index], X_train.loc[val_index]\n    ytrain, yval = y[train_index], y[val_index]\n\n    scores_val = model_llcv.predict(Xval)\n    corr_val = np.sqrt(mean_squared_error(yval, scores_val))\n    corr_val_auc = roc_auc_score(yval, scores_val)\n    print(\" Fold %02d RMSE: %.6f\" % ((i + 1), corr_val))\n    print(\" Fold %02d AUC: %.6f\" % ((i + 1), corr_val_auc))\n    y_pred = model_llcv.predict(X_test)\n    timer(fold_time)\n\n    avpred[val_index] += scores_val\n    avpred_count[val_index] += 1\n    if i > 0:\n        fpred = pred + y_pred\n    else:\n        fpred = y_pred\n    pred = fpred\n    cv_sum = cv_sum + corr_val\n    cv_sum_auc = cv_sum_auc + corr_val_auc\n\ntimer(train_time)\n\ncv_score = cv_sum / (folds * repeats)\ncv_score_auc = cv_sum_auc / (folds * repeats)\navpred = avpred / avpred_count\noof_corr = np.sqrt(mean_squared_error(avreal, avpred))\noof_corr_auc = roc_auc_score(avreal, avpred)\nprint(\"\\n Average RMSE: %.6f\" % cv_score)\nprint(\" Out-of-fold RMSE: %.6f\" % oof_corr)\nprint(\" Average AUC: %.6f\" % cv_score_auc)\nprint(\" Out-of-fold AUC: %.6f\" % oof_corr_auc)\nscore = str(round(oof_corr_auc, 6)).replace(\".\", \"\")\nmpred = pred / (folds * repeats)\n\nnow = datetime.now()\n# Not really necessary, but applying sigmoid function here so all predictions map to [0,1] range\noof_result = pd.DataFrame(avreal, columns=[\"stroke\"])\noof_result[\"prediction\"] = special.expit(avpred)\noof_result[\"id\"] = idpred\noof_result = oof_result[[\"id\", \"stroke\", \"prediction\"]]\nsub_file = (\n    \"train_OOF_10_by_10x-Lasso_\"\n    + score\n    + \"_\"\n    + str(now.strftime(\"%Y-%m-%d-%H-%M\"))\n    + \".csv\"\n)\nprint(\"\\n Writing out-of-fold train file::  %s\" % sub_file)\noof_result.to_csv(sub_file, index=False, float_format=\"%.6f\")\n\n# Not really necessary, but applying sigmoid function here so all predictions map to [0,1] range\nresult = pd.DataFrame(special.expit(mpred), columns=[\"stroke\"])\nresult[\"id\"] = test_ids\nresult = result[[\"id\", \"stroke\"]]\nprint(\"\\n First 10 lines of your prediction:\")\nprint(result.head(10))\nsub_file = (\n    \"test_10_by_10x-Lasso_\" + score + \"_\" + str(now.strftime(\"%Y-%m-%d-%H-%M\")) + \".csv\"\n)\nprint(\"\\n Writing submission file::  %s\" % sub_file)\nresult.to_csv(sub_file, index=False, float_format=\"%.6f\")\nresult.to_csv(\"submission.csv\", index=False, float_format=\"%.6f\")\n","metadata":{"execution":{"iopub.status.busy":"2023-01-11T00:09:59.978444Z","iopub.execute_input":"2023-01-11T00:09:59.979985Z","iopub.status.idle":"2023-01-11T00:10:00.810884Z","shell.execute_reply.started":"2023-01-11T00:09:59.979951Z","shell.execute_reply":"2023-01-11T00:10:00.809996Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We are done with predictions. Without any fancy setup or parameter tuning, this will score ~0.87 on public LB.\n\nLet's see what features Lasso selected from the whole group. Features with low coefficients contribute less to the final prediction. The absolute value of each feature coefficient is roughly proportional to its importance.","metadata":{}},{"cell_type":"code","source":"coef = pd.DataFrame(model_llcv.coef_, columns=[\"LassoCV_score\"])\ncoef[\"Feature\"] = features\ncoef[\"Relative score\"] = coef[\"LassoCV_score\"] / coef[\"LassoCV_score\"].sum()\ncoef = coef.sort_values(\"Relative score\", ascending=False)\ncoef = coef[[\"Feature\", \"LassoCV_score\", \"Relative score\"]]\ncoef.to_csv(\"feature_importance_LassoCV.csv\", index=False, float_format=\"%.6f\")\ncoef.plot(kind=\"barh\", x=\"Feature\", y=\"LassoCV_score\", legend=False, figsize=(6, 12))\nplt.title(\"Features Coefficients\")\nplt.xlabel(\"LassoCV score\")\nplt.savefig(\n    \"feature_importance_Lasso-01-v1.png\",\n    bbox_inches=\"tight\",\n    pad_inches=0.25,\n    dpi=150,\n)\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2023-01-11T00:10:00.812373Z","iopub.execute_input":"2023-01-11T00:10:00.812976Z","iopub.status.idle":"2023-01-11T00:10:01.274201Z","shell.execute_reply.started":"2023-01-11T00:10:00.81294Z","shell.execute_reply":"2023-01-11T00:10:01.273317Z"},"trusted":true},"execution_count":null,"outputs":[]}]}