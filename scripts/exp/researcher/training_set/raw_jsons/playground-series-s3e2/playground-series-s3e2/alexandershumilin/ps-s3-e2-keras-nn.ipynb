{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n!pip install keras-tuner --upgrade\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-01-16T11:00:47.455514Z","iopub.execute_input":"2023-01-16T11:00:47.455943Z","iopub.status.idle":"2023-01-16T11:00:57.692175Z","shell.execute_reply.started":"2023-01-16T11:00:47.455896Z","shell.execute_reply":"2023-01-16T11:00:57.691049Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Downloading data**\n+ adding data from \"stroke prediction dataset\"","metadata":{}},{"cell_type":"code","source":"train_df = pd.read_csv('/kaggle/input/playground-series-s3e2/train.csv')\ntest_df = pd.read_csv('/kaggle/input/playground-series-s3e2/test.csv')\nsubmission = pd.read_csv('/kaggle/input/playground-series-s3e2/sample_submission.csv')\naddition_data = pd.read_csv('/kaggle/input/stroke-prediction-dataset/healthcare-dataset-stroke-data.csv')","metadata":{"execution":{"iopub.status.busy":"2023-01-16T11:00:57.696137Z","iopub.execute_input":"2023-01-16T11:00:57.696459Z","iopub.status.idle":"2023-01-16T11:00:57.746405Z","shell.execute_reply.started":"2023-01-16T11:00:57.696428Z","shell.execute_reply":"2023-01-16T11:00:57.745466Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"addition_data = addition_data[addition_data['stroke']==1]\naddition_data","metadata":{"execution":{"iopub.status.busy":"2023-01-16T11:00:57.747909Z","iopub.execute_input":"2023-01-16T11:00:57.748454Z","iopub.status.idle":"2023-01-16T11:00:57.776668Z","shell.execute_reply.started":"2023-01-16T11:00:57.748416Z","shell.execute_reply":"2023-01-16T11:00:57.775523Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.neighbors import KNeighborsRegressor\n\ndef knn_impute(df, na_target):\n    df = df.copy()\n    \n    numeric_df = df.select_dtypes(np.number)\n    non_na_columns = numeric_df.loc[: ,numeric_df.isna().sum() == 0].columns\n    \n    y_train = numeric_df.loc[numeric_df[na_target].isna() == False, na_target]\n    X_train = numeric_df.loc[numeric_df[na_target].isna() == False, non_na_columns]\n    X_test = numeric_df.loc[numeric_df[na_target].isna() == True, non_na_columns]\n    \n    knn = KNeighborsRegressor()\n    knn.fit(X_train, y_train)\n    \n    y_pred = knn.predict(X_test)\n    \n    df.loc[df[na_target].isna() == True, na_target] = y_pred\n    \n    return df\n\nna_cols = [col for col in addition_data.columns if addition_data[col].isnull().sum()!=0]\n\nfor col in na_cols:  \n    addition_data = knn_impute(addition_data, col)","metadata":{"execution":{"iopub.status.busy":"2023-01-16T11:00:57.779775Z","iopub.execute_input":"2023-01-16T11:00:57.78016Z","iopub.status.idle":"2023-01-16T11:00:57.807301Z","shell.execute_reply.started":"2023-01-16T11:00:57.780123Z","shell.execute_reply":"2023-01-16T11:00:57.80614Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# addition_data.bmi = addition_data.bmi.fillna(np.mean(addition_data.bmi))","metadata":{"execution":{"iopub.status.busy":"2023-01-16T11:00:57.808609Z","iopub.execute_input":"2023-01-16T11:00:57.809765Z","iopub.status.idle":"2023-01-16T11:00:57.814722Z","shell.execute_reply.started":"2023-01-16T11:00:57.80973Z","shell.execute_reply":"2023-01-16T11:00:57.813606Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# train_df['generated'] = 1\n# test_df['generated'] = 1\n# addition_data['generated'] = 0\ntrain_df = pd.concat([train_df, addition_data],axis=0, ignore_index=True)","metadata":{"execution":{"iopub.status.busy":"2023-01-16T11:00:57.816014Z","iopub.execute_input":"2023-01-16T11:00:57.816305Z","iopub.status.idle":"2023-01-16T11:00:57.829714Z","shell.execute_reply.started":"2023-01-16T11:00:57.816253Z","shell.execute_reply":"2023-01-16T11:00:57.828714Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.concat([train_df, test_df], axis=0)\ndf","metadata":{"execution":{"iopub.status.busy":"2023-01-16T11:00:57.830978Z","iopub.execute_input":"2023-01-16T11:00:57.831932Z","iopub.status.idle":"2023-01-16T11:00:57.858297Z","shell.execute_reply.started":"2023-01-16T11:00:57.831889Z","shell.execute_reply":"2023-01-16T11:00:57.857211Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Thanks to @edouardo for feature engineering ideas! https://www.kaggle.com/code/edouardo/my-stroke-of-insight#Feature-engineering\nPlease, upvote his notebook!\n\nwe will put 2 extra features with bmi: (from Brenden Siekman)","metadata":{}},{"cell_type":"code","source":"# df['morbid'] = np.where(df.bmi>40,1,0)\n# df['obese'] = np.where(df.bmi>30,1,0)","metadata":{"execution":{"iopub.status.busy":"2023-01-16T11:00:57.859664Z","iopub.execute_input":"2023-01-16T11:00:57.860517Z","iopub.status.idle":"2023-01-16T11:00:57.864481Z","shell.execute_reply.started":"2023-01-16T11:00:57.860482Z","shell.execute_reply":"2023-01-16T11:00:57.863457Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"from CRAIG THOMAS:","metadata":{}},{"cell_type":"code","source":"# def feature_risk_factors(df):\n#     df[\"risk_factors\"] = df[[\n#         \"avg_glucose_level\", \"age\", \"bmi\", \n#         \"hypertension\", \"heart_disease\", \n#         \"smoking_status\"\n#     ]].apply(\n#         lambda x: \\\n#         0 + (1 if x.avg_glucose_level > 99 else 0) + \\\n#         (1 if x.age > 45 else 0) + (1 if x.bmi > 24.99 else 0) + \\\n#         (1 if x.hypertension == 1 else 0) + \\\n#         (1 if x.heart_disease == 1 else 0) + \\\n#         (1 if x.smoking_status in [\"formerly smoked\", \"smokes\"] else 0),\n#         axis=1\n#     )\n#     return df\n\n# feature_risk_factors(df)","metadata":{"execution":{"iopub.status.busy":"2023-01-16T11:00:57.866056Z","iopub.execute_input":"2023-01-16T11:00:57.866715Z","iopub.status.idle":"2023-01-16T11:00:57.875272Z","shell.execute_reply.started":"2023-01-16T11:00:57.866681Z","shell.execute_reply":"2023-01-16T11:00:57.874234Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.get_dummies(df)\ndf = df.drop('id', axis=1)","metadata":{"execution":{"iopub.status.busy":"2023-01-16T11:00:57.879316Z","iopub.execute_input":"2023-01-16T11:00:57.879927Z","iopub.status.idle":"2023-01-16T11:00:57.911202Z","shell.execute_reply.started":"2023-01-16T11:00:57.87989Z","shell.execute_reply":"2023-01-16T11:00:57.910187Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\n\nscaler = StandardScaler()\n\n# num_cols = ['age', 'avg_glucose_level', 'bmi']\n\ny = df['stroke']\ndf = df.drop('stroke', axis=1)\n\ndf[df.columns] = scaler.fit_transform(df[df.columns])\n\n# df = pd.DataFrame(scaler.fit_transform(df), columns = df.columns)","metadata":{"execution":{"iopub.status.busy":"2023-01-16T11:00:57.912762Z","iopub.execute_input":"2023-01-16T11:00:57.913201Z","iopub.status.idle":"2023-01-16T11:00:57.939658Z","shell.execute_reply.started":"2023-01-16T11:00:57.913163Z","shell.execute_reply":"2023-01-16T11:00:57.938785Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df = df.iloc[:-len(test_df),:]\ntrain_df['stroke'] = y[:-len(test_df)]\ntest_df = df.iloc[-len(test_df):,:].reset_index(drop=True)\n\nX = train_df.drop('stroke', axis=1)\ny = train_df.stroke\nX_test = test_df","metadata":{"execution":{"iopub.status.busy":"2023-01-16T11:00:57.941161Z","iopub.execute_input":"2023-01-16T11:00:57.941528Z","iopub.status.idle":"2023-01-16T11:00:57.955831Z","shell.execute_reply.started":"2023-01-16T11:00:57.941492Z","shell.execute_reply":"2023-01-16T11:00:57.954858Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Keras model**\n- Lots of graet ideas were taken from @kirillka95 notebook: https://www.kaggle.com/code/kirillka95/ps-s3e02-keras-nn-kfold-pub\nPlease upvote it!","metadata":{}},{"cell_type":"code","source":"from tensorflow import keras\nimport tensorflow_addons as tfa\nfrom tensorflow.keras import layers\n\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import Dense, Dropout, Input, Lambda, Concatenate, Add, BatchNormalization, LeakyReLU\n\nfrom sklearn.model_selection import KFold, StratifiedKFold, RepeatedStratifiedKFold\n\nfrom sklearn.metrics import classification_report\n\n# from imblearn.under_sampling import NearMiss\n# from imblearn.keras import balanced_batch_generator\n\nimport keras_tuner\n\nmodels = []\npreds = []\n\n# focal_loss = False\nclass_weight = 10 # 10 > 13\n\nn_folds = 12 #11 < 12 > 13\nrepeats = 5  # 5\ndr = 0.3     # 0.1 > 0.2\n\n# k_fold = StratifiedKFold(n_splits=n_folds, random_state=42, shuffle=True)\nk_fold = RepeatedStratifiedKFold(n_splits=n_folds, n_repeats=repeats, random_state=42)\n\ndef get_model():\n    model = keras.Sequential([\n#     layers.Dense(512), \n#     layers.LeakyReLU(alpha=0.3),\n# #     layers.BatchNormalization(),\n#     layers.Dropout(rate=dr),\n    layers.Dense(256), \n    layers.LeakyReLU(alpha=0.3),\n#     layers.BatchNormalization(),\n    layers.Dropout(rate=dr),\n    layers.Dense(128), \n    layers.LeakyReLU(alpha=0.3),\n#     layers.BatchNormalization(),\n    layers.Dropout(rate=dr),\n    layers.Dense(64), \n    layers.LeakyReLU(alpha=0.3),\n#     layers.BatchNormalization(),\n    layers.Dropout(rate=dr),\n    layers.Dense(32), \n    layers.LeakyReLU(alpha=0.3),\n#     layers.BatchNormalization(),\n    layers.Dropout(rate=dr),\n    layers.Dense(16), \n    layers.LeakyReLU(alpha=0.3),\n#     layers.BatchNormalization(),\n    layers.Dropout(rate=dr),\n    layers.Dense(8), \n#     layers.LeakyReLU(alpha=0.3),\n    layers.BatchNormalization(),\n    layers.Dropout(rate=dr),\n    layers.Dense(4), \n#     layers.LeakyReLU(alpha=0.3),\n    layers.BatchNormalization(),\n#     layers.Dropout(rate=0.3),\n    layers.Dense(2), \n    layers.LeakyReLU(alpha=0.3),\n#     layers.BatchNormalization(),\n#     layers.Dropout(rate=0.3),\n    layers.Dense(1, activation='sigmoid')\n   ])\n\n#     lr_schedule = keras.optimizers.schedules.ExponentialDecay(\n#                     initial_learning_rate=0.001,\n#                     decay_steps=1000,\n#                     decay_rate=0.9)\n    opt = keras.optimizers.Adam(learning_rate=0.00005)\n    \n    model.compile(\n    optimizer=opt,\n    loss=tfa.losses.SigmoidFocalCrossEntropy(\n#                                              alpha=hp.Choice('units', [0.6, 0.7, 0.8, 0.9]), \n                                             alpha=0.8,\n                                             gamma=2.0\n                                             ),   # alpha=0.80, gamma=2.0  > (0.7, 4.0)\n    metrics='AUC',\n)\n    \n    return model\n\nearly_stopping = keras.callbacks.EarlyStopping(\n        monitor=\"val_auc\", \n        mode='max',\n        patience=30,\n        min_delta=0.00001,\n        restore_best_weights=True,\n)\nplat = keras.callbacks.ReduceLROnPlateau(\n        monitor=\"val_auc\", \n        mode='max', \n        patience=3, \n        factor=0.1, \n        min_lr=1e-8, \n        min_delta=0.000001)\n\n# tuner = keras_tuner.RandomSearch(\n#     get_model,\n#     objective='val_loss',\n#     max_trials=5)\n\nfor train_index, test_index in k_fold.split(X, y):\n    X_train, X_valid = X.iloc[train_index], X.iloc[test_index]\n    y_train, y_valid = y.iloc[train_index], y.iloc[test_index]\n    \n#     tuner.search(X_train, y_train, epochs=5, validation_data=(X_valid, y_valid))\n#     best_model = tuner.get_best_models()[0]\n#     model = best_model\n    \n    model = get_model()\n    \n    \n# #     training_generator, steps_per_epoch = balanced_batch_generator(X_train, y_train, \n# #                                                                    sampler = NearMiss(), \n# #                                                                    batch_size = 10, \n# #                                                                    random_state = 42)\n    \n    history = model.fit(\n#           training_generator, \n#           steps_per_epoch = steps_per_epoch,\n          X_train, y_train,\n          validation_data=(X_valid, y_valid),\n          batch_size=64,\n          epochs=500,\n          class_weight = { 0: 1.0, 1: class_weight, },\n          callbacks=[early_stopping, plat],\n          verbose=1,\n         )\n    \n    print(classification_report(y, np.round(model.predict(X))))\n    models.append(model)\n    preds.append(model.predict(X_test))","metadata":{"execution":{"iopub.status.busy":"2023-01-16T11:00:57.959238Z","iopub.execute_input":"2023-01-16T11:00:57.959526Z","iopub.status.idle":"2023-01-16T11:03:47.757578Z","shell.execute_reply.started":"2023-01-16T11:00:57.959501Z","shell.execute_reply":"2023-01-16T11:03:47.756524Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history_df = pd.DataFrame(history.history)\nhistory_df.loc[1:, ['loss', 'val_loss']].plot()\nhistory_df.loc[1:, ['auc', 'val_auc']].plot()","metadata":{"execution":{"iopub.status.busy":"2023-01-16T11:03:47.762242Z","iopub.execute_input":"2023-01-16T11:03:47.763074Z","iopub.status.idle":"2023-01-16T11:03:48.211309Z","shell.execute_reply.started":"2023-01-16T11:03:47.763034Z","shell.execute_reply":"2023-01-16T11:03:48.20933Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"preds_eval = []\nfor model in models:\n    preds_eval.append(model.predict(X))\n    \nprint(classification_report(y, np.round(np.average(np.array(preds_eval),axis=0))))","metadata":{"execution":{"iopub.status.busy":"2023-01-16T11:04:26.314026Z","iopub.execute_input":"2023-01-16T11:04:26.314593Z","iopub.status.idle":"2023-01-16T11:04:27.701473Z","shell.execute_reply.started":"2023-01-16T11:04:26.314554Z","shell.execute_reply":"2023-01-16T11:04:27.700333Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pred = np.average(np.array(preds),axis=0)\npred","metadata":{"execution":{"iopub.status.busy":"2023-01-16T11:03:48.222525Z","iopub.status.idle":"2023-01-16T11:03:48.223286Z","shell.execute_reply.started":"2023-01-16T11:03:48.222981Z","shell.execute_reply":"2023-01-16T11:03:48.223015Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission['stroke'] = pred\nsubmission['stroke'] = submission['stroke'].clip(0,1)\nsubmission","metadata":{"execution":{"iopub.status.busy":"2023-01-16T11:03:48.22473Z","iopub.status.idle":"2023-01-16T11:03:48.225506Z","shell.execute_reply.started":"2023-01-16T11:03:48.225197Z","shell.execute_reply":"2023-01-16T11:03:48.225224Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission.to_csv('submission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2023-01-16T11:03:48.226839Z","iopub.status.idle":"2023-01-16T11:03:48.227936Z","shell.execute_reply.started":"2023-01-16T11:03:48.227673Z","shell.execute_reply":"2023-01-16T11:03:48.227699Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission.stroke.hist()","metadata":{"execution":{"iopub.status.busy":"2023-01-16T11:03:48.229301Z","iopub.status.idle":"2023-01-16T11:03:48.230014Z","shell.execute_reply.started":"2023-01-16T11:03:48.229759Z","shell.execute_reply":"2023-01-16T11:03:48.229784Z"},"trusted":true},"execution_count":null,"outputs":[]}]}