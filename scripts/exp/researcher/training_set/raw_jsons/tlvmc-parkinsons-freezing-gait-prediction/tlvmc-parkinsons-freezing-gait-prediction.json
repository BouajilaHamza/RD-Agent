{"Description": "<h3>Goal of the Competition</h3>\n<p>The goal of this competition is to detect freezing of gait (FOG), a debilitating symptom that afflicts many people with Parkinson\u2019s disease. You will develop a machine learning model trained on data collected from a wearable 3D lower back sensor.</p>\n<p>Your work will help researchers better understand when and why FOG episodes occur. This will improve the ability of medical professionals to optimally evaluate, monitor, and ultimately, prevent FOG events.</p>\n<h3>Context</h3>\n<p>An estimated 7 to 10 million people around the world have Parkinson\u2019s disease, many of whom suffer from freezing of gait (FOG). During a FOG episode, a patient's feet are \u201cglued\u201d to the ground, preventing them from moving forward despite their attempts. FOG has a profound negative impact on health-related quality of life\u2014people who suffer from FOG are often depressed, have an increased risk of falling, are likelier to be confined to wheelchair use, and have restricted independence. </p>\n<p>While researchers have multiple theories to explain when, why, and in whom FOG occurs, there is still no clear understanding of its causes. The ability to objectively and accurately quantify FOG is one of the keys to advancing its understanding and treatment. Collection and analysis of FOG events, such as with your data science skills, could lead to potential treatments.</p>\n<p>There are many methods of evaluating FOG, though most involve FOG-provoking protocols. People with FOG are filmed while performing certain tasks that are likely to increase its occurrence. Experts then review the video to score each frame, indicating when FOG occurred. While scoring in this manner is relatively reliable and sensitive, it is extremely time-consuming and requires specific expertise. Another method involves augmenting FOG-provoking testing with wearable devices. With more sensors, the detection of FOG becomes easier, however, compliance and usability may be reduced. Therefore, a combination of these two methods may be the best approach. When combined with machine learning methods, the accuracy of detecting FOG from a lower back accelerometer is relatively high. However, the datasets used to train and test these algorithms have been relatively small and generalizability is limited to date. Furthermore, the emphasis has been on achieving high levels of accuracy, while precision, for example, has largely been ignored.</p>\n<p>Competition host, the Center for the Study of Movement, Cognition, and Mobility (CMCM), Neurological Institute, Tel Aviv Sourasky Medical Center, aims to improve the personalized treatment of age-related movement, cognition, and mobility disorders and to alleviate the associated burden. They leverage a combination of clinical, engineering, and neuroscience expertise to: 1) Gain new understandings into the physiologic and pathophysiologic mechanisms that contribute to cognitive and motor function, the factors that influence these functions, and their changes with aging and disease (e.g., Parkinson\u2019s disease, Alzheimer\u2019s). 2) Develop new methods and tools for the early detection and tracking of cognitive and motor decline. A major focus is on using leveraging wearable devices and digital technologies; and 3) Develop and evaluate novel methods for the prevention and treatment of gait, falls, and cognitive function.</p>\n<p>Your work will help advance the evaluation, understanding and treatment of FOG, improving the lives of the many people who suffer from this debilitating Parkinson\u2019s disease symptom.</p>\n<h3>Acknowledgments</h3>\n<p>The competition data was collected by three research groups:</p>\n<p>The Center for the Study of Movement, Cognition and Mobility, as indicated above,</p>\n<p>The Neurorehabilitation Research Group at Katholieke Universiteit Leuven in Belgium, and the</p>\n<p>Mobility and Falls Translational Research Center at the Hinda and Arthur Marcus Institute for Aging, affiliated with Harvard Medical School in Boston. </p>\n<p>The Michael J. Fox Foundation for Parkinson\u2019s Research generously supported the data collection and this data competition. </p>\n<p><img src=\"https://storage.googleapis.com/kaggle-media/competitions/Michael%20J%20Fox%20Foundation/3923-desc-image.png\" alt=\"\"></p>\n<p><br></p>\n<blockquote>\n  <p><strong>This is a Code Competition. Refer to <a aria-label=\"Code Requirements (opens in a new tab)\" target=\"_blank\" href=\"https://www.kaggle.com/c/tlvmc-parkinsons-freezing-gait-prediction/overview/code-requirements\">Code Requirements</a> for details.</strong></p>\n</blockquote>", "Evaluation": "<p>Submissions are evaluated by the <strong>Mean Average Precision</strong> of predictions for each event class. We compute the <a rel=\"noreferrer nofollow\" aria-label=\"<strong>average precision</strong> (opens in a new tab)\" target=\"_blank\" href=\"https://scikit-learn.org/stable/modules/generated/sklearn.metrics.average_precision_score.html\"><strong>average precision</strong></a> on predicted confidence scores separately for each of the three event classes (see the <a aria-label=\"Data Description (opens in a new tab)\" target=\"_blank\" href=\"https://www.kaggle.com/competitions/tlvmc-parkinsons-freezing-gait-prediction/data\">Data Description</a> for more details) and take the average of these three scores to get the overall score.</p>\n<p>Note that data series in the DeFOG dataset are annotated with <code>Valid</code> and <code>Task</code> labels (in addition to the event labels). Only the portions of the series where both are <code>true</code> should you consider to be annotated. Though not included in the test set series, the metric is aware of these labels and will ignore predictions on the unannotated portions of these series (where either label is <code>false</code>).</p>\n<h2>Submission File</h2>\n<p>For each <code>Id</code> in the test set, you must predict a confidence score for each of the three event types. In the ground truth, at most one event class has a non-zero value for each <code>Id</code>, but there is no restriction on the values of predicted scores. The predicted scores may, but are not required, to take the form of a probability (to be in the range 0.0 to 1.0, that is).</p>\n<p>The <code>Id</code> values in the submission file should have the form <code>{SeriesId}_{Time}</code> where <code>SeriesId</code> is the identifier of the data series and <code>Time</code> is the time-step in that series of the predictions.</p>\n<p>The file should contain a header and have the following format:</p>\n<pre class=\"uc-code-block\"><code><span class=\"hljs-attribute\">Id</span>,StartHesitation,Turn,Walking\n<span class=\"hljs-attribute\">003f117e14_0</span>,<span class=\"hljs-number\">0</span>,<span class=\"hljs-number\">0</span>,<span class=\"hljs-number\">0</span>\n<span class=\"hljs-attribute\">003f117e14_1</span>,<span class=\"hljs-number\">0</span>,<span class=\"hljs-number\">0</span>,<span class=\"hljs-number\">0</span>\n<span class=\"hljs-attribute\">003f117e14_2</span>,<span class=\"hljs-number\">0</span>,<span class=\"hljs-number\">0</span>,<span class=\"hljs-number\">0</span>\n<span class=\"hljs-attribute\">003f117e14_3</span>,<span class=\"hljs-number\">0</span>,<span class=\"hljs-number\">0</span>,<span class=\"hljs-number\">0</span>\n</code><div class=\"uc-code-block-copy-button-wrapper\"><button class=\"uc-code-block-copy-button google-symbols\" aria-label=\"Copy code\">content_copy</button></div></pre>", "Timeline": "<ul>\n<li><p><strong>March 9, 2023</strong> - Start Date.</p></li>\n<li><p><strong>June 1, 2023</strong> - Entry Deadline. You must accept the competition rules before this date in order to compete.</p></li>\n<li><p><strong>June 1, 2023</strong> - Team Merger Deadline. This is the last day participants may join or merge teams.</p></li>\n<li><p><strong>June 8, 2023</strong> - Final Submission Deadline.</p></li>\n</ul>\n<p>All deadlines are at 11:59 PM UTC on the corresponding day unless otherwise noted. The competition organizers reserve the right to update the contest timeline if they deem it necessary.</p>", "Prizes": "<ul>\n<li>1st Place - $ 40,000</li>\n<li>2nd Place - $ 25,000</li>\n<li>3rd Place - $ 20,000</li>\n<li>4th Place - $ 10,000</li>\n<li>5th Place - $ 5,000</li>\n</ul>\n<p>Teams finishing 6-15th place will receive branded merchandise from the Michael J. Fox Foundation for Parkinson's Research at the end of the competition.</p>\n<p><strong>AWARDS CEREMONY</strong><br>\nA virtual awards ceremony celebrating the competition\u2019s top 5 teams is scheduled to take place at the 2023 World Congress of the <a rel=\"noreferrer nofollow\" aria-label=\"International Society of Posture and Gait Research (ISPGR) (opens in a new tab)\" target=\"_blank\" href=\"https://ispgr.org/2023-congress/\">International Society of Posture and Gait Research (ISPGR)</a>. The congress will be physically held in Brisbane, Australia from July 9 through July 13, 2023 and online remotely (i.e., \"hybrid\"). The top 5 teams will be invited to attend the ceremony virtually in order to be recognized.</p>", "Code Requirements": "<p><img style=\"float:right;width:70px;padding:10px\" src=\"https://storage.googleapis.com/kaggle-media/competitions/general/Kerneler-white-desc2_transparent.png\" alt=\"\"></p>\n<h3>This is a Code Competition</h3>\n<p>Submissions to this competition must be made through Notebooks. In order for the \"Submit\" button to be active after a commit, the following conditions must be met:</p>\n<ul>\n<li>CPU Notebook &lt;= 9 hours run-time</li>\n<li>GPU Notebook &lt;= 9 hours run-time</li>\n<li>Internet access disabled</li>\n<li>Freely &amp; publicly available external data is allowed, including pre-trained models</li>\n<li>Submission file must be named <code>submission.csv</code></li>\n</ul>\n<p>Please see the <a aria-label=\"Code Competition FAQ (opens in a new tab)\" target=\"_blank\" href=\"https://www.kaggle.com/docs/competitions#notebooks-only-FAQ\">Code Competition FAQ</a> for more information on how to submit. And review the <a aria-label=\"code debugging doc (opens in a new tab)\" target=\"_blank\" href=\"https://www.kaggle.com/code-competition-debugging\">code debugging doc</a> if you are encountering submission errors.</p>", "Additional Data Documentation": "<p>This page is a supplement to the documentation on the <a aria-label=\"<strong>Data</strong> (opens in a new tab)\" target=\"_blank\" href=\"https://www.kaggle.com/competitions/tlvmc-parkinsons-freezing-gait-prediction/data\"><strong>Data</strong></a> page. We give video examples of freezing gait events and describe the collection protocols for the three data sources.</p>\n<h1>Video Examples of Freezing Gait Events</h1>\n<ul>\n<li><a rel=\"noreferrer nofollow\" aria-label=\"Parkinsonian Gait Demonstration (opens in a new tab)\" target=\"_blank\" href=\"https://youtu.be/j86omOwx0Hk\">Parkinsonian Gait Demonstration</a> - Short demonstration of FOG events.</li>\n<li><a rel=\"noreferrer nofollow\" aria-label=\"Freezing of gait from The Lancet (opens in a new tab)\" target=\"_blank\" href=\"https://youtu.be/3-wrNhyVTNE\">Freezing of gait from The Lancet</a> - Patient showing FOG events during a test.</li>\n<li><a rel=\"noreferrer nofollow\" aria-label=\"Multitarget tDCS for Freezing of Gait in Parkinson\u2019s Disease (opens in a new tab)\" target=\"_blank\" href=\"https://www.youtube.com/watch?v=RX3dzd8Lkeo\">Multitarget tDCS for Freezing of Gait in Parkinson\u2019s Disease</a> - Example of a FOG provoking test.</li>\n<li><a rel=\"noreferrer nofollow\" aria-label=\"Freezing of Gait &amp; Interventions For Freezing Triggers (opens in a new tab)\" target=\"_blank\" href=\"https://youtu.be/uqgqfLCdhOc\">Freezing of Gait &amp; Interventions For Freezing Triggers</a> - See <a rel=\"noreferrer nofollow\" aria-label=\"7:20 (opens in a new tab)\" target=\"_blank\" href=\"https://youtu.be/uqgqfLCdhOc?t=440\">7:20</a> for descriptions of the event types.</li>\n<li><a rel=\"noreferrer nofollow\" aria-label=\"Gait impairments in Parkinson's disease (opens in a new tab)\" target=\"_blank\" href=\"https://youtu.be/pFLC9C-xH8E\">Gait impairments in Parkinson's disease</a></li>\n<li><a rel=\"noreferrer nofollow\" aria-label=\"Cycling for Freezing Gait in Parkinson's Disease (opens in a new tab)\" target=\"_blank\" href=\"https://youtu.be/aaY3gz5tJSk\">Cycling for Freezing Gait in Parkinson's Disease</a></li>\n<li><a rel=\"noreferrer nofollow\" aria-label=\"Parkinson's Freezing of Gait - Before and After Exercise (opens in a new tab)\" target=\"_blank\" href=\"https://youtube.com/shorts/SnVwWLAh11M?feature=share\">Parkinson's Freezing of Gait - Before and After Exercise</a></li>\n<li><a rel=\"noreferrer nofollow\" aria-label=\"Parkinson's Disease Freezing &amp; Festinating Gait (opens in a new tab)\" target=\"_blank\" href=\"https://youtu.be/EQ0HG16EC3g\">Parkinson's Disease Freezing &amp; Festinating Gait</a></li>\n<li><a rel=\"noreferrer nofollow\" aria-label=\"Parkinson's Disease: Freezing of Gait - Parkinsonism and Related (opens in a new tab)\" target=\"_blank\" href=\"https://youtu.be/FumLR_wAfpk\">Parkinson's Disease: Freezing of Gait - Parkinsonism and Related</a></li>\n</ul>\n<h1>The tDCS FOG Dataset</h1>\n<p>Subjects arrived to the clinic for multiple visits as described in <a rel=\"noreferrer nofollow\" aria-label=\"Reches T, Dagan M. et al., 2021 (opens in a new tab)\" target=\"_blank\" href=\"https://pubmed.ncbi.nlm.nih.gov/32785163/\">Reches T, Dagan M. et al., 2021</a> and <a rel=\"noreferrer nofollow\" aria-label=\"Manor B, Dagan M et al. 2021 (opens in a new tab)\" target=\"_blank\" href=\"https://pubmed.ncbi.nlm.nih.gov/34406695/\">Manor B, Dagan M et al. 2021</a>. At each visit they completed the freezing of gait provoking protocol described by Ziegler et al. 2010 (DOI: 10.1002/mds.22993) both at \"off\" and \"on\" anti-parkinsonian medications while wearing 3D accelerometer on their lower back (Opals by APDM Wearable Technologies, Portland, OR, USA. Sampling rate 128Hz). All FoG provoking trials were videotaped and analyzed offline.</p>\n<p>Data recordings include a short period (~2-3s) of quiet standing before the start of the test protocol.</p>\n<h1>The DeFOG Dataset</h1>\n<p>This project included two visits at the subject's home environment. At each visit, the participants were evaluated at Off and On medication states. During the motor assessment, the subjects wore a 3D accelerometer on their lower back (Ax3 by Axivity) which recorded the data with a sample rate of 100Hz. The acceleration units are provided in [g].</p>\n<h3>PROTOCOL</h3>\n<p>The protocol that was performed at each visit:</p>\n<p>At visit 1:<br>\nDuring Off medication:</p>\n<ol>\n<li>4-meter walk test</li>\n<li>Timed Up &amp; Go (TUG) - Single task</li>\n<li>Timed Up &amp; Go (TUG) \u2013 Dual-task (subtracting numbers while performing the TUG test)</li>\n<li>Turning task with alternating directions- Single task (performing 4 x 360 degrees turns, each time alternating the rotation direction).</li>\n<li>Turning task \u2013 Dual-task (same as before, but with additional number subtraction task).</li>\n<li>Hotspot Door \u2013 A walking trial that involves opening a door, entering another room, turning, and returning to the start point.</li>\n<li>Personalized Hotspot - walking through an area in the house that the subject describes as FoG provoking.</li>\n</ol>\n<p>During On medication:<br>\nThe protocol is repeated again with the addition of a MiniBest test that is added after the 4 meters walk. See at the end of the protocol elaboration about the MiniBest test.</p>\n<p>At visit 2:<br>\nThe same protocol that is described for visit 1 was repeated. In addition, the tasks were also performed with auditory cueing, with the exception of tasks that includes dual task (e.g. \"Timed Up &amp; Go (TUG) \u2013 Dual task\" and \"Turning task \u2013 Dual task\").</p>\n<p>MiniBest test includes the following parts:</p>\n<ol>\n<li>SIT TO STAND.</li>\n<li>RISE TO TOES.</li>\n<li>STAND ON ONE LEG.</li>\n<li>COMPENSATORY STEPPING CORRECTION- FORWARD.</li>\n<li>CSC BACKWARD.</li>\n<li>CSC LATERAL.</li>\n<li>STANCE (FEET TOGETHER) EYES OPEN, FIRM SURFACE.</li>\n<li>STANCE (FEET TOGETHER) EYES CLOSED, FOAM SURFACE.</li>\n<li>INCLINE EYES CLOSED (Shoulder width, arms at your side).</li>\n<li>DYNAMIC GAIT INDEX:<ul>\n<li>CHANGE IN GAIT SPEED.</li>\n<li>WALK WITH HEAD TURNS \u2013 HORIZONTAL.</li>\n<li>WALK WITH PIVOT TURNS.</li>\n<li>STEP OVER OBSTACLES.</li></ul></li>\n</ol>\n<h1>The Daily Living Dataset</h1>\n<p>The Daily-living contains data from 65 people with PD that were recorded using the same device as in the home FoG-provoking dataset (the DeFOG dataset). The daily-living recordings contain ~one week of unlabeled, continuous recordings from an accelerometer device placed on the lower back of the subjects at 100Hz, during their daily living activity.</p>\n<p>The 65 PD subjects are comprised of two groups:</p>\n<ol>\n<li>45 people with PD that suffer from FoG. They also underwent a FoG-provoking protocol at their home and that data is provided in the DeFOG data set. In the metadata file, these subjects have NFOG questionnaire score higher than 0.</li>\n<li>20 people with PD that do not suffer from FoG. In the metadata file, these subjects have NFOG questionnaire score of 0.</li>\n</ol>", "Citation": "Addison Howard, amit salomon, eran gazit, Jeff Hausdorff, Leslie Kirsch, Maggie, Pieter Ginis, Ryan Holbrook, and Yasir F Karim. Parkinson's Freezing of Gait Prediction. https://kaggle.com/competitions/tlvmc-parkinsons-freezing-gait-prediction, 2023. Kaggle.", "Data Description": "<p>This competition dataset comprises lower-back 3D accelerometer data from subjects exhibiting <strong>freezing of gait</strong> episodes, a disabling symptom that is common among people with Parkinson's disease. Freezing of gait (FOG) negatively impacts walking abilities and impinges locomotion and independence.</p>\n<p>Your objective is to detect the start and stop of each freezing episode and the occurrence in these series of three types of freezing of gait events: <strong>Start Hesitation</strong>, <strong>Turn</strong>, and <strong>Walking</strong>.</p>\n<h2>The Datasets</h2>\n<p>The data series include three datasets, collected under distinct circumstances:</p>\n<ul>\n<li>The <strong>tDCS FOG</strong> (<code>tdcsfog</code>) dataset, comprising data series collected in the lab, as subjects completed a FOG-provoking protocol.</li>\n<li>The <strong>DeFOG</strong> (<code>defog</code>) dataset, comprising data series collected in the subject's home, as subjects completed a FOG-provoking protocol</li>\n<li>The <strong>Daily Living</strong> (<code>daily</code>) dataset, comprising one week of continuous 24/7 recordings from sixty-five subjects. Forty-five subjects exhibit FOG symptoms and also have series in the <code>defog</code> dataset, while the other twenty subjects do not exhibit FOG symptoms and do not have series elsewhere in the data.</li>\n</ul>\n<p>Trials from the <code>tdcsfog</code> and <code>defog</code> datasets were videotaped and <em>annotated</em> by expert reviewers documented the freezing of gait episodes. That is, the start, end and type of each episode were marked by the experts. Series in the <code>daily</code> dataset are <em>unannotated</em>. You will be detecting FOG episodes for the <code>tdcsfog</code> and <code>defog</code> series. You may wish to apply unsupervised or semi-supervised methods to the series in the <code>daily</code> dataset to support your detection modelling.</p>\n<p>See this page for more on these datasets as well as video examples of freezing of gait events: <a aria-label=\"<strong>Additional Data Documentation</strong> (opens in a new tab)\" target=\"_blank\" href=\"https://www.kaggle.com/competitions/tlvmc-parkinsons-freezing-gait-prediction/overview/additional-data-documentation\"><strong>Additional Data Documentation</strong></a>.</p>\n<h2>File and Field Descriptions</h2>\n<ul>\n<li><strong>train/</strong> Folder containing the data series in the training set within three subfolders: <strong>tdcsfog/</strong>, <strong>defog/</strong>, and <strong>notype/</strong>. Series in the <em>notype</em> folder are from the <code>defog</code> dataset but lack event-type annotations. The fields present in these series vary by folder.<ul>\n<li><code>Time</code> An integer timestep. Series from the <code>tdcsfog</code> dataset are recorded at 128Hz (128 timesteps per second), while series from the <code>defog</code> and <code>daily</code> series are recorded at 100Hz (100 timesteps per second).</li>\n<li><code>AccV</code>, <code>AccML</code>, and <code>AccAP</code> Acceleration from a lower-back sensor on three axes: V - vertical, ML - mediolateral, AP - anteroposterior. Data is in units of <em>m/s^2</em> for <code>tdcsfog/</code> and <em>g</em> for <code>defog/</code> and <code>notype/</code>.</li>\n<li><code>StartHesitation</code>, <code>Turn</code>, <code>Walking</code> Indicator variables for the occurrence of each of the event types.</li>\n<li><code>Event</code> Indicator variable for the occurrence of <em>any</em> FOG-type event. Present only in the <strong>notype</strong> series, which lack type-level annotations.</li>\n<li><code>Valid</code> There were cases during the video annotation that were hard for the annotator to decide if there was an Akinetic (i.e., essentially no movement) FoG or the subject stopped voluntarily. Only event annotations where the series is marked <code>true</code> should be considered as unambiguous.</li>\n<li><code>Task</code> Series were only annotated where this value is <code>true</code>. Portions marked <code>false</code> should be considered unannotated.</li></ul></li>\n</ul>\n<p>Note that the <code>Valid</code> and <code>Task</code> fields are only present in the <code>defog</code> dataset. They are not relevant for the <code>tdcsfog</code> data.</p>\n<ul>\n<li><p><strong>test/</strong> Only the <code>Time</code>, <code>AccV</code>, <code>AccML</code>, and <code>AccAP</code> fields are provided for the test series. See the <a aria-label=\"<strong>Evaluation</strong> (opens in a new tab)\" target=\"_blank\" href=\"https://www.kaggle.com/competitions/tlvmc-parkinsons-freezing-gait-prediction/overview/evaluation\"><strong>Evaluation</strong></a> for details on how the hidden <code>Valid</code> and <code>Task</code> annotations affect scoring.</p></li>\n<li><p><strong>unlabeled/</strong> Folder containing the unannotated data series from the <code>daily</code> dataset, one series per subject. Forty-five of the subjects also have series in the <code>defog</code> dataset, some in the training split and some in the test split. Accelerometer data has units of <em>g</em>.</p></li>\n<li><p><strong>tdcsfog_metadata.csv</strong> Identifies each series in the <code>tdcsfog</code> dataset by a unique <code>Subject, Visit, Test, Medication</code> condition.</p>\n<ul>\n<li><code>Visit</code> Lab visits consist of a baseline assessment, two post-treatment assessments for different treatment stages, and one follow-up assessment.</li>\n<li><code>Test</code> Which of three test types was performed, with <code>3</code> the most challenging.</li>\n<li><code>Medication</code> Subjects may have been either <code>off</code> or <code>on</code> anti-parkinsonian medication during the recording.</li></ul></li>\n<li><p><strong>defog_metadata.csv</strong> Identifies each series in the <code>defog</code> dataset by a unique <code>Subject, Visit, Medication</code> condition.</p></li>\n<li><p><strong>daily_metadata.csv</strong> Each series in the <code>daily</code> dataset is identified by the <code>Subject</code> id. This file also contains the time of day the recording began.</p></li>\n<li><p><strong>subjects.csv</strong> Metadata for each <code>Subject</code> in the study, including their <code>Age</code> and <code>Sex</code> as well as:</p>\n<ul>\n<li><code>Visit</code> Only available for subjects in the <code>daily</code> and <code>defog</code> datasets.</li>\n<li><code>YearsSinceDx</code> Years since Parkinson's diagnosis.</li>\n<li><code>UPDRSIIIOn</code>/<code>UPDRSIIIOff</code> Unified Parkinson's Disease Rating Scale score during on/off medication respectively.</li>\n<li><code>NFOGQ</code> Self-report FoG questionnaire score. See: <br>\n<a rel=\"noreferrer nofollow\" aria-label=\"https://pubmed.ncbi.nlm.nih.gov/19660949/ (opens in a new tab)\" target=\"_blank\" href=\"https://pubmed.ncbi.nlm.nih.gov/19660949/\">https://pubmed.ncbi.nlm.nih.gov/19660949/</a></li></ul></li>\n<li><p><strong>events.csv</strong> Metadata for each FoG event in all data series. The event times agree with the labels in the data series.</p>\n<ul>\n<li><code>Id</code> The data series the event occured in.</li>\n<li><code>Init</code> Time (s) the event began.</li>\n<li><code>Completion</code> Time (s) the event ended.</li>\n<li><code>Type</code> Whether <code>StartHesitation</code>, <code>Turn</code>, or <code>Walking</code>.</li>\n<li><code>Kinetic</code> Whether the event was <em>kinetic</em> (<code>1</code>) and involved movement, or <em>akinetic</em> (<code>0</code>) and static.</li></ul></li>\n<li><p><strong>tasks.csv</strong> Task metadata for series in the <code>defog</code> dataset. (Not relevant for the series in the <code>tdcsfog</code> or <code>daily</code> datasets.)</p>\n<ul>\n<li><code>Id</code> The data series where the task was measured.</li>\n<li><code>Begin</code> Time (s) the task began.</li>\n<li><code>End</code> Time (s) the task ended.</li>\n<li><code>Task</code> One of seven tasks types in the DeFOG protocol, described on <a aria-label=\"this page (opens in a new tab)\" target=\"_blank\" href=\"https://www.kaggle.com/competitions/tlvmc-parkinsons-freezing-gait-prediction/overview/additional-data-documentation\">this page</a>.</li></ul></li>\n<li><p><strong>sample_submission.csv</strong> A submission file in the correct format. Please see the <a aria-label=\"<strong>Evaluation</strong> (opens in a new tab)\" target=\"_blank\" href=\"https://www.kaggle.com/competitions/tlvmc-parkinsons-freezing-gait-prediction/overview/evaluation\"><strong>Evaluation</strong></a> page for more details.</p></li>\n</ul>\n<h2>Data Splits</h2>\n<p>Please note that this is a <a aria-label=\"<strong>Code Competition</strong> (opens in a new tab)\" target=\"_blank\" href=\"https://www.kaggle.com/competitions/tlvmc-parkinsons-freezing-gait-prediction/overview/code-requirements\"><strong>Code Competition</strong></a>, in which the actual test set is hidden. In this public version, we give some sample data drawn from the training set to help you author your solutions. When your submission is scored, this example test data will be replaced with the full test set.</p>\n<p>The test set contains about 250 data series. The series from the <code>tdcsfog</code> and <code>defog</code> are in a proportion similar to that of the training set. These series have subjects that are entirely distinct from those in the training set. This also holds true for the public / private test split. (In other words, the train / public test / private test splits were formed by grouping on subjects and stratifying on datasets.)</p>\n<p>Most, but not all, subjects in the <code>defog</code> test set have unannotated series in the <code>daily</code> dataset.</p>\n<p>All of the series in the <code>daily</code> dataset are in the public version of the data. There are no additional unannotated series in the hidden dataset.</p>\n<p>The <strong>tdcsfog_metadata.csv</strong>, <strong>defog_metadata.csv</strong>, and <strong>subjects.csv</strong> files in the hidden version of the data contain additional entries for the test set series. The hidden versions of these files are supersets of the public versions.</p>\n<p>The <strong>events.csv</strong>, <strong>tasks.csv</strong>, and <strong>daily_metadata.csv</strong> files are the same in both the public and hidden datasets.</p>"}