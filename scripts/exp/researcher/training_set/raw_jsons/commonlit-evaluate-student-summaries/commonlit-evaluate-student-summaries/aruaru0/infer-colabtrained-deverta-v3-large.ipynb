{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!touch submission.csv","metadata":{"_uuid":"d13eed0c-f3b5-4727-8ad5-69918c7fc411","_cell_guid":"489fec99-0b09-48f1-ac83-b8de02dda0b2","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-10-17T00:16:28.512329Z","iopub.execute_input":"2023-10-17T00:16:28.512766Z","iopub.status.idle":"2023-10-17T00:16:29.489907Z","shell.execute_reply.started":"2023-10-17T00:16:28.512739Z","shell.execute_reply":"2023-10-17T00:16:29.488671Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import sys\nsys.path.append(\"/kaggle/input/pip-install-nlp-mit\")","metadata":{"_uuid":"d96ba867-3847-4894-aa35-fb556342235d","_cell_guid":"d89c20d9-dc09-4bf1-8fab-3185982532c4","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-10-17T00:17:24.918245Z","iopub.execute_input":"2023-10-17T00:17:24.918596Z","iopub.status.idle":"2023-10-17T00:17:24.923864Z","shell.execute_reply.started":"2023-10-17T00:17:24.918568Z","shell.execute_reply":"2023-10-17T00:17:24.922946Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install \"/kaggle/input/worddifficulty/py_readability_metrics-1.4.5-py3-none-any.whl\"","metadata":{"_uuid":"7765d4bb-0ce2-4665-987f-8583a339be12","_cell_guid":"edb6763d-09f9-4d8f-b703-5876b3c21bed","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-10-17T00:17:25.066963Z","iopub.execute_input":"2023-10-17T00:17:25.067809Z","iopub.status.idle":"2023-10-17T00:17:57.719825Z","shell.execute_reply.started":"2023-10-17T00:17:25.067777Z","shell.execute_reply":"2023-10-17T00:17:57.71872Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# !pip install \"/kaggle/input/autocorrect/autocorrect-2.6.1.tar\"\n!pip install \"/kaggle/input/pyspellchecker/pyspellchecker-0.7.2-py3-none-any.whl\"","metadata":{"_uuid":"1f60c41b-eec1-4f77-8afd-7c4b905fbc50","_cell_guid":"10d2565f-1643-42b6-b3a3-8c72c969b22b","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-10-17T00:17:57.721906Z","iopub.execute_input":"2023-10-17T00:17:57.722258Z","iopub.status.idle":"2023-10-17T00:18:29.668373Z","shell.execute_reply.started":"2023-10-17T00:17:57.722226Z","shell.execute_reply":"2023-10-17T00:18:29.667351Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from typing import List\nimport numpy as np\nimport pandas as pd\nimport warnings\nimport logging\nimport os\nimport shutil\nimport json\nimport transformers\nfrom transformers import AutoModel, AutoTokenizer, AutoConfig, AutoModelForSequenceClassification\nfrom transformers import DataCollatorWithPadding\nfrom datasets import Dataset,load_dataset, load_from_disk\nfrom transformers import TrainingArguments, Trainer\nfrom datasets import load_metric, disable_progress_bar\nfrom sklearn.metrics import mean_squared_error\nimport torch\nfrom sklearn.model_selection import KFold, GroupKFold\nfrom tqdm import tqdm\n\nimport nltk\nfrom nltk.corpus import stopwords\nfrom nltk.tokenize import word_tokenize\nfrom nltk.tokenize.treebank import TreebankWordDetokenizer\nfrom collections import Counter\nimport spacy\nimport re\nfrom autocorrect import Speller\nfrom spellchecker import SpellChecker\nimport lightgbm as lgb\n\nwarnings.simplefilter(\"ignore\")\nlogging.disable(logging.ERROR)\nos.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\nos.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \ndisable_progress_bar()\ntqdm.pandas()","metadata":{"_uuid":"3128ecfe-dd5d-40db-a8d8-4fb2085dfee5","_cell_guid":"e65b53c1-f28c-438c-bb80-27a4a27bfcff","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-10-17T00:18:29.670006Z","iopub.execute_input":"2023-10-17T00:18:29.670362Z","iopub.status.idle":"2023-10-17T00:18:45.436371Z","shell.execute_reply.started":"2023-10-17T00:18:29.670326Z","shell.execute_reply":"2023-10-17T00:18:45.435501Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def seed_everything(seed: int):\n    import random, os\n    import numpy as np\n    import torch\n    \n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = True\n    \nseed_everything(seed=42)","metadata":{"_uuid":"c70dab34-2911-44f9-90d1-f8a2e7262481","_cell_guid":"c19314c5-a57e-4534-961f-eabd061add8c","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-10-17T00:18:45.438937Z","iopub.execute_input":"2023-10-17T00:18:45.439488Z","iopub.status.idle":"2023-10-17T00:18:45.448686Z","shell.execute_reply.started":"2023-10-17T00:18:45.439454Z","shell.execute_reply":"2023-10-17T00:18:45.447893Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class CFG:\n    model_name = \"another-bert\"\n    learning_rate=1.5e-5\n    weight_decay=0.02\n    hidden_dropout_prob=0.007\n    attention_probs_dropout_prob=0.007\n    num_train_epochs=5\n    n_splits=4\n    batch_size=12\n    \n    random_seed=42\n    save_steps=20\n    max_length=512","metadata":{"_uuid":"76818156-58ee-460b-8bfe-7767257f1e5b","_cell_guid":"08ec1175-9ebe-49f1-a9ed-ff751be278ec","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-10-17T00:18:45.450144Z","iopub.execute_input":"2023-10-17T00:18:45.450721Z","iopub.status.idle":"2023-10-17T00:18:45.456864Z","shell.execute_reply.started":"2023-10-17T00:18:45.450689Z","shell.execute_reply":"2023-10-17T00:18:45.455805Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"MODEL_DIR = '/kaggle/input/commitlit-deberta-v3-large-masked'\nINIT_MODEL = f\"{MODEL_DIR}/content/{CFG.model_name}/fold_0\"","metadata":{"_uuid":"6307a9c4-34b4-4ab5-bca1-a06f9a017f64","_cell_guid":"a3a81585-c225-424a-b7d2-ad69e0f4dc9a","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-10-17T00:18:45.458113Z","iopub.execute_input":"2023-10-17T00:18:45.458937Z","iopub.status.idle":"2023-10-17T00:18:45.470592Z","shell.execute_reply.started":"2023-10-17T00:18:45.458907Z","shell.execute_reply":"2023-10-17T00:18:45.469723Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Dataload","metadata":{"_uuid":"382a4dda-259e-4e4c-bb72-b2b194e495aa","_cell_guid":"c54a89a6-39b8-41e5-a90c-3e5ca781c1e2","trusted":true}},{"cell_type":"code","source":"DATA_DIR = \"/kaggle/input/commonlit-evaluate-student-summaries/\"\n\nprompts_train = pd.read_csv(DATA_DIR + \"prompts_train.csv\")\nprompts_test = pd.read_csv(DATA_DIR + \"prompts_test.csv\")\nsummaries_train = pd.read_csv(DATA_DIR + \"summaries_train.csv\")\nsummaries_test = pd.read_csv(DATA_DIR + \"summaries_test.csv\")\nsample_submission = pd.read_csv(DATA_DIR + \"sample_submission.csv\")","metadata":{"_uuid":"568ee87e-7f0a-4b7c-b627-77bf6adc51d5","_cell_guid":"9f510acc-ba6b-46c0-a4d9-033e6ad45f6d","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-10-17T00:18:45.471919Z","iopub.execute_input":"2023-10-17T00:18:45.472347Z","iopub.status.idle":"2023-10-17T00:18:45.584093Z","shell.execute_reply.started":"2023-10-17T00:18:45.472317Z","shell.execute_reply":"2023-10-17T00:18:45.583278Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Preprocess\n\n[Using features]\n\n- Text Length\n- Length Ratio\n- Word Overlap\n- N-grams Co-occurrence\n  - count\n  - ratio\n- Quotes Overlap\n- Grammar Check\n  - spelling: pyspellchecker","metadata":{"_uuid":"c6635a38-efcf-4550-a7f4-6ede8b05872a","_cell_guid":"fe0065d2-87f2-48b7-b27b-9c2092042ea5","trusted":true}},{"cell_type":"code","source":"class Preprocessor:\n    def __init__(self, \n                model_name: str,\n                ) -> None:\n        self.tokenizer = AutoTokenizer.from_pretrained(INIT_MODEL)\n        self.twd = TreebankWordDetokenizer()\n        self.STOP_WORDS = set(stopwords.words('english'))\n        \n        self.spacy_ner_model = spacy.load('en_core_web_sm',)\n        self.speller = Speller(lang='en')\n        self.spellchecker = SpellChecker() \n        \n    def word_overlap_count(self, row):\n        \"\"\" intersection(prompt_text, text) \"\"\"        \n        def check_is_stop_word(word):\n            return word in self.STOP_WORDS\n        \n        prompt_words = row['prompt_tokens']\n        summary_words = row['summary_tokens']\n        if self.STOP_WORDS:\n            prompt_words = list(filter(check_is_stop_word, prompt_words))\n            summary_words = list(filter(check_is_stop_word, summary_words))\n        return len(set(prompt_words).intersection(set(summary_words)))\n            \n    def ngrams(self, token, n):\n        # Use the zip function to help us generate n-grams\n        # Concatentate the tokens into ngrams and return\n        ngrams = zip(*[token[i:] for i in range(n)])\n        return [\" \".join(ngram) for ngram in ngrams]\n\n    def ngram_co_occurrence(self, row, n: int) -> int:\n        # Tokenize the original text and summary into words\n        original_tokens = row['prompt_tokens']\n        summary_tokens = row['summary_tokens']\n\n        # Generate n-grams for the original text and summary\n        original_ngrams = set(self.ngrams(original_tokens, n))\n        summary_ngrams = set(self.ngrams(summary_tokens, n))\n\n        # Calculate the number of common n-grams\n        common_ngrams = original_ngrams.intersection(summary_ngrams)\n        return len(common_ngrams)\n    \n    def ner_overlap_count(self, row, mode:str):\n        model = self.spacy_ner_model\n        def clean_ners(ner_list):\n            return set([(ner[0].lower(), ner[1]) for ner in ner_list])\n        prompt = model(row['prompt_text'])\n        summary = model(row['text'])\n\n        if \"spacy\" in str(model):\n            prompt_ner = set([(token.text, token.label_) for token in prompt.ents])\n            summary_ner = set([(token.text, token.label_) for token in summary.ents])\n        elif \"stanza\" in str(model):\n            prompt_ner = set([(token.text, token.type) for token in prompt.ents])\n            summary_ner = set([(token.text, token.type) for token in summary.ents])\n        else:\n            raise Exception(\"Model not supported\")\n\n        prompt_ner = clean_ners(prompt_ner)\n        summary_ner = clean_ners(summary_ner)\n\n        intersecting_ners = prompt_ner.intersection(summary_ner)\n        \n        ner_dict = dict(Counter([ner[1] for ner in intersecting_ners]))\n        \n        if mode == \"train\":\n            return ner_dict\n        elif mode == \"test\":\n            return {key: ner_dict.get(key) for key in self.ner_keys}\n\n    \n    def quotes_count(self, row):\n        summary = row['text']\n        text = row['prompt_text']\n        quotes_from_summary = re.findall(r'\"([^\"]*)\"', summary)\n        if len(quotes_from_summary)>0:\n            return [quote in text for quote in quotes_from_summary].count(True)\n        else:\n            return 0\n\n    def spelling(self, text):\n        \n        wordlist=text.split()\n        amount_miss = len(list(self.spellchecker.unknown(wordlist)))\n\n        return amount_miss\n    \n    def add_spelling_dictionary(self, tokens: List[str]) -> List[str]:\n        \"\"\"dictionary update for pyspell checker and autocorrect\"\"\"\n        self.spellchecker.word_frequency.load_words(tokens)\n        self.speller.nlp_data.update({token:1000 for token in tokens})\n    \n    def run(self, \n            prompts: pd.DataFrame,\n            summaries:pd.DataFrame,\n            mode:str\n        ) -> pd.DataFrame:\n        \n        # before merge preprocess\n        prompts[\"prompt_length\"] = prompts[\"prompt_text\"].apply(\n            lambda x: len(word_tokenize(x))\n        )\n        prompts[\"prompt_tokens\"] = prompts[\"prompt_text\"].apply(\n            lambda x: word_tokenize(x)\n        )\n\n        summaries[\"summary_length\"] = summaries[\"text\"].apply(\n            lambda x: len(word_tokenize(x))\n        )\n        summaries[\"summary_tokens\"] = summaries[\"text\"].apply(\n            lambda x: word_tokenize(x)\n        )\n        \n        # Add prompt tokens into spelling checker dictionary\n        prompts[\"prompt_tokens\"].apply(\n            lambda x: self.add_spelling_dictionary(x)\n        )\n        \n#         from IPython.core.debugger import Pdb; Pdb().set_trace()\n        # fix misspelling\n        summaries[\"fixed_summary_text\"] = summaries[\"text\"].progress_apply(\n            lambda x: self.speller(x)\n        )\n        \n        # count misspelling\n        summaries[\"splling_err_num\"] = summaries[\"text\"].progress_apply(self.spelling)\n        \n        # merge prompts and summaries\n        input_df = summaries.merge(prompts, how=\"left\", on=\"prompt_id\")\n\n        # after merge preprocess\n        input_df['length_ratio'] = input_df['summary_length'] / input_df['prompt_length']\n\n        input_df['word_overlap_count'] = input_df.progress_apply(self.word_overlap_count, axis=1)\n        input_df['bigram_overlap_count'] = input_df.progress_apply(\n            self.ngram_co_occurrence,args=(2,), axis=1 \n        )\n        input_df['bigram_overlap_ratio'] = input_df['bigram_overlap_count'] / (input_df['summary_length'] - 1)\n        \n        input_df['trigram_overlap_count'] = input_df.progress_apply(\n            self.ngram_co_occurrence, args=(3,), axis=1\n        )\n        input_df['trigram_overlap_ratio'] = input_df['trigram_overlap_count'] / (input_df['summary_length'] - 2)\n        \n        input_df['quotes_count'] = input_df.progress_apply(self.quotes_count, axis=1)\n        \n        return input_df.drop(columns=[\"summary_tokens\", \"prompt_tokens\"])\n    \npreprocessor = Preprocessor(model_name=CFG.model_name)","metadata":{"_uuid":"690eb4c3-1029-4745-b210-cf3364e51324","_cell_guid":"899fb338-95ec-4cc7-9fe1-24dcc5ef4f29","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-10-17T00:18:45.585328Z","iopub.execute_input":"2023-10-17T00:18:45.585544Z","iopub.status.idle":"2023-10-17T00:18:46.779845Z","shell.execute_reply.started":"2023-10-17T00:18:45.585515Z","shell.execute_reply":"2023-10-17T00:18:46.77894Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"summaries_train.head()","metadata":{"_uuid":"f965c981-c89d-491b-baa0-31f57e641d70","_cell_guid":"c76d1ebd-a5a8-4f6f-b49c-940385bf5a3f","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-10-17T00:18:46.781373Z","iopub.execute_input":"2023-10-17T00:18:46.781605Z","iopub.status.idle":"2023-10-17T00:18:46.801636Z","shell.execute_reply.started":"2023-10-17T00:18:46.781576Z","shell.execute_reply":"2023-10-17T00:18:46.800654Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pickle\nwith open(MODEL_DIR+'/pickled.pkl', 'rb') as f:\n    train = pickle.load(f)\n    test = pickle.load(f)\n\n# train = preprocessor.run(prompts_train, summaries_train, mode=\"train\")\ntest = preprocessor.run(prompts_test, summaries_test, mode=\"test\")\n\n# train.head()","metadata":{"_uuid":"0bab10e3-b2c4-450c-ba20-da8a362408e5","_cell_guid":"fcb5f857-0f88-4a4e-bc36-67664e3468f2","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-10-17T00:18:46.805448Z","iopub.execute_input":"2023-10-17T00:18:46.805649Z","iopub.status.idle":"2023-10-17T00:18:46.962212Z","shell.execute_reply.started":"2023-10-17T00:18:46.805627Z","shell.execute_reply":"2023-10-17T00:18:46.961273Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# train","metadata":{"_uuid":"a02eb23a-a34b-40f0-86c6-b12e4aa86c66","_cell_guid":"3a6bf606-b8ea-46b6-b6f2-92bd01968506","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-10-17T00:18:46.964081Z","iopub.execute_input":"2023-10-17T00:18:46.964712Z","iopub.status.idle":"2023-10-17T00:18:46.969402Z","shell.execute_reply.started":"2023-10-17T00:18:46.964655Z","shell.execute_reply":"2023-10-17T00:18:46.968379Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = train.drop(columns = ['length_ratio'])\ntest = test.drop(columns = ['length_ratio'])","metadata":{"_uuid":"7a36914d-744c-42b9-9973-4650cf7fbc1c","_cell_guid":"f3f25a04-8939-4944-932f-a701c744972b","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-10-17T00:18:46.970988Z","iopub.execute_input":"2023-10-17T00:18:46.972103Z","iopub.status.idle":"2023-10-17T00:18:46.981398Z","shell.execute_reply.started":"2023-10-17T00:18:46.972067Z","shell.execute_reply":"2023-10-17T00:18:46.980425Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"gkf = GroupKFold(n_splits=CFG.n_splits)\n\nfor i, (_, val_index) in enumerate(gkf.split(train, groups=train[\"prompt_id\"])):\n    train.loc[val_index, \"fold\"] = i\n\ntrain.head()","metadata":{"_uuid":"6bbd69c9-3ce6-488f-a2ef-5ccf472aba5d","_cell_guid":"b8730f96-479f-4f2a-a526-db1c6ff9821b","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-10-17T00:18:46.983075Z","iopub.execute_input":"2023-10-17T00:18:46.983615Z","iopub.status.idle":"2023-10-17T00:18:47.012073Z","shell.execute_reply.started":"2023-10-17T00:18:46.983571Z","shell.execute_reply":"2023-10-17T00:18:47.011111Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Model Function Definition","metadata":{"_uuid":"5e896f99-66e5-4525-9791-76417b84dcb4","_cell_guid":"a26316fa-0a2b-4000-80fb-f499a6fb37f5","trusted":true}},{"cell_type":"code","source":"import shutil\n\ndef compute_metrics(eval_pred):\n    predictions, labels = eval_pred\n    rmse = mean_squared_error(labels, predictions, squared=False)\n    return {\"rmse\": rmse}\n\ndef compute_mcrmse(eval_pred):\n    \"\"\"\n    Calculates mean columnwise root mean squared error\n    https://www.kaggle.com/competitions/commonlit-evaluate-student-summaries/overview/evaluation\n    \"\"\"\n    preds, labels = eval_pred\n\n    col_rmse = np.sqrt(np.mean((preds - labels) ** 2, axis=0))\n    mcrmse = np.mean(col_rmse)\n\n    return {\n        \"content_rmse\": col_rmse[0],\n        \"wording_rmse\": col_rmse[1],\n        \"mcrmse\": mcrmse,\n    }\n\ndef compt_score(content_true, content_pred, wording_true, wording_pred):\n    content_score = mean_squared_error(content_true, content_pred)**(1/2)\n    wording_score = mean_squared_error(wording_true, wording_pred)**(1/2)\n    \n    return (content_score + wording_score)/2","metadata":{"_uuid":"5e456ecd-2bcc-4529-8dbf-bef16348f0ff","_cell_guid":"669d92b8-961b-423d-8e34-b6cd4609ee77","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-10-17T00:18:47.013352Z","iopub.execute_input":"2023-10-17T00:18:47.013848Z","iopub.status.idle":"2023-10-17T00:18:47.021985Z","shell.execute_reply.started":"2023-10-17T00:18:47.013816Z","shell.execute_reply":"2023-10-17T00:18:47.020934Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Deberta Regressor","metadata":{"_uuid":"d0789d32-b0bc-4798-86c5-9d1b441b14f3","_cell_guid":"bec3a592-0eb8-4a4e-89f2-a474f769ab8e","trusted":true}},{"cell_type":"code","source":"class ContentScoreRegressor:\n    def __init__(self, \n                model_name: str,\n                model_dir: str,\n                target: str,\n                hidden_dropout_prob: float,\n                attention_probs_dropout_prob: float,\n                max_length: int,\n                ):\n        self.inputs = [\"prompt_text\", \"prompt_title\", \"prompt_question\", \"fixed_summary_text\"]\n        self.input_col = \"input\"\n        \n        self.text_cols = [self.input_col] \n        self.target = target\n        self.target_cols = [target]\n\n        self.model_name = model_name\n        self.model_dir = model_dir\n        self.max_length = max_length\n        \n        self.tokenizer = AutoTokenizer.from_pretrained(INIT_MODEL)\n        self.model_config = AutoConfig.from_pretrained(INIT_MODEL)\n        \n        self.model_config.update({\n            \"hidden_dropout_prob\": hidden_dropout_prob,\n            \"attention_probs_dropout_prob\": attention_probs_dropout_prob,\n            \"num_labels\": 1,\n            \"problem_type\": \"regression\",\n        })\n        \n        seed_everything(seed=42)\n\n        self.data_collator = DataCollatorWithPadding(\n            tokenizer=self.tokenizer\n        )\n\n\n    def tokenize_function(self, examples: pd.DataFrame):\n        labels = [examples[self.target]]\n        tokenized_dict  = self.tokenizer(examples[self.input_col],\n                            padding=False,\n                            truncation=True,\n                            max_length=self.max_length)\n        input_ids = tokenized_dict.input_ids\n        attention_mask = tokenized_dict.attention_mask \n\n        head_mask = []\n        use_full = False\n        for token in tokenized_dict.input_ids:            \n            if token == self.tokenizer.sep_token_id:\n                use_full = not use_full  \n\n            head_mask.append(1 if use_full else .0) \n\n\n\n        # 'input_ids', 'token_type_ids', 'attention_mask'\n\n        # from IPython.core.debugger import Pdb; Pdb().set_trace()\n\n\n        return {\n            'input_ids' : input_ids, \n            'attension_mask': attention_mask,\n            'head_mask': head_mask, \n            \"labels\": labels,\n        }\n    \n    def tokenize_function_test(self, examples: pd.DataFrame):\n        tokenized_dict = self.tokenizer(examples[self.input_col],\n                         padding=False,\n                         truncation=True,\n                         max_length=self.max_length)\n        input_ids = tokenized_dict.input_ids\n        attention_mask = tokenized_dict.attention_mask \n\n        head_mask = []\n        use_full = False\n        for token in tokenized_dict.input_ids:            \n            if token == self.tokenizer.sep_token_id:\n                use_full = not use_full  \n\n            head_mask.append(1 if use_full else .0) \n\n\n\n        # 'input_ids', 'token_type_ids', 'attention_mask'\n\n        # from IPython.core.debugger import Pdb; Pdb().set_trace()\n\n\n        return {\n            'input_ids' : input_ids, \n            'attension_mask': attention_mask,\n            'head_mask': head_mask, \n        }\n        \n    def train(self, \n            fold: int,\n            train_df: pd.DataFrame,\n            valid_df: pd.DataFrame,\n            batch_size: int,\n            learning_rate: float,\n            weight_decay: float,\n            num_train_epochs: float,\n            save_steps: int,\n        ) -> None:\n        \"\"\"fine-tuning\"\"\"\n        \n        sep = self.tokenizer.sep_token\n        train_df[self.input_col] = (\n                    train_df[\"prompt_question\"] + sep\n                    + train_df[\"text\"] + sep\n                    + train_df[\"prompt_text\"]\n                  )\n\n        valid_df[self.input_col] = (\n                    valid_df[\"prompt_question\"] + sep\n                    + valid_df[\"text\"] + sep\n                    + valid_df[\"prompt_text\"]\n                  )\n\n        \n        train_df = train_df[[self.input_col] + self.target_cols]\n        valid_df = valid_df[[self.input_col] + self.target_cols]\n        \n        model_content = AutoModelForSequenceClassification.from_pretrained(\n            f\"/kaggle/input/{self.model_name}\", \n            config=self.model_config,\n            ignore_mismatched_sizes=True\n        )\n\n        train_dataset = Dataset.from_pandas(train_df, preserve_index=False) \n        val_dataset = Dataset.from_pandas(valid_df, preserve_index=False) \n    \n        train_tokenized_datasets = train_dataset.map(self.tokenize_function, batched=False)\n        val_tokenized_datasets = val_dataset.map(self.tokenize_function, batched=False)\n\n        # eg. \"bert/fold_0/\"\n        model_fold_dir = os.path.join(self.model_dir, str(fold)) \n        \n        training_args = TrainingArguments(\n            output_dir=model_fold_dir,\n            load_best_model_at_end=True, # select best model\n            learning_rate=learning_rate,\n            per_device_train_batch_size=batch_size,\n            per_device_eval_batch_size=8,\n            num_train_epochs=num_train_epochs,\n            weight_decay=weight_decay,\n            report_to='none',\n            greater_is_better=False,\n            save_strategy=\"steps\",\n            evaluation_strategy=\"steps\",\n            eval_steps=save_steps,\n            save_steps=save_steps,\n            metric_for_best_model=\"rmse\",\n            save_total_limit=1\n        )\n\n        trainer = Trainer(\n            model=model_content,\n            args=training_args,\n            train_dataset=train_tokenized_datasets,\n            eval_dataset=val_tokenized_datasets,\n            tokenizer=self.tokenizer,\n            compute_metrics=compute_metrics,\n            data_collator=self.data_collator\n        )\n\n        trainer.train()\n        \n        shutil.rmtree(self.model_dir)\n        \n        model_content.save_pretrained(self.model_dir)\n        self.tokenizer.save_pretrained(self.model_dir)\n\n        \n    def predict(self, \n                test_df: pd.DataFrame,\n                fold: int,\n               ):\n        \"\"\"predict content score\"\"\"\n        \n        sep = self.tokenizer.sep_token\n        in_text = (\n                    test_df[\"prompt_question\"] + sep\n                    + test_df[\"text\"] + sep\n                    + test_df[\"prompt_text\"]\n                  )\n        test_df[self.input_col] = in_text\n\n        test_ = test_df[[self.input_col]]\n    \n        test_dataset = Dataset.from_pandas(test_, preserve_index=False) \n        test_tokenized_dataset = test_dataset.map(self.tokenize_function_test, batched=False)\n\n        model_content = AutoModelForSequenceClassification.from_pretrained(f\"{self.model_dir}\")\n        model_content.eval()\n        \n        # e.g. \"bert/fold_0/\"\n        model_fold_dir = os.path.join(self.model_dir, str(fold)) \n        model_fold_dir = \"valid_log\" #f\"bert-{fold}\"\n#         print(\"model_fold_dir\", model_fold_dir)\n        \n        test_args = TrainingArguments(\n            output_dir=model_fold_dir,\n            do_train = False,\n            do_predict = True,\n            per_device_eval_batch_size = 4,   \n            dataloader_drop_last = False,\n        )\n\n        # init trainer\n        infer_content = Trainer(\n                      model = model_content, \n                      tokenizer=self.tokenizer,\n                      data_collator=self.data_collator,\n                      args = test_args)\n\n        preds = infer_content.predict(test_tokenized_dataset)[0]\n\n        return preds","metadata":{"_uuid":"3c72aec7-5dd9-40d0-b0d3-08f804a95dce","_cell_guid":"03ff3b0c-430d-45c3-b902-402b05101c32","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-10-17T00:19:18.815437Z","iopub.execute_input":"2023-10-17T00:19:18.815786Z","iopub.status.idle":"2023-10-17T00:19:18.849124Z","shell.execute_reply.started":"2023-10-17T00:19:18.815749Z","shell.execute_reply":"2023-10-17T00:19:18.848226Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train_by_fold(\n        train_df: pd.DataFrame,\n        model_name: str,\n        target:str,\n        save_each_model: bool,\n        n_splits: int,\n        batch_size: int,\n        learning_rate: int,\n        hidden_dropout_prob: float,\n        attention_probs_dropout_prob: float,\n        weight_decay: float,\n        num_train_epochs: int,\n        save_steps: int,\n        max_length:int\n    ):\n\n    # delete old model files\n    if os.path.exists(model_name):\n        shutil.rmtree(model_name)\n    \n    os.mkdir(model_name)\n        \n    for fold in range(CFG.n_splits):\n        print(f\"fold {fold}:\")\n        \n        train_data = train_df[train_df[\"fold\"] != fold]\n        valid_data = train_df[train_df[\"fold\"] == fold]\n        \n        if save_each_model == True:\n            model_dir =  f\"{target}/{model_name}/fold_{fold}\"\n        else: \n            model_dir =  f\"{model_name}/fold_{fold}\"\n\n        csr = ContentScoreRegressor(\n            model_name=model_name,\n            target=target,\n            model_dir = model_dir, \n            hidden_dropout_prob=hidden_dropout_prob,\n            attention_probs_dropout_prob=attention_probs_dropout_prob,\n            max_length=max_length,\n           )\n        \n        csr.train(\n            fold=fold,\n            train_df=train_data,\n            valid_df=valid_data, \n            batch_size=batch_size,\n            learning_rate=learning_rate,\n            weight_decay=weight_decay,\n            num_train_epochs=num_train_epochs,\n            save_steps=save_steps,\n        )\n\ndef validate(\n    train_df: pd.DataFrame,\n    target:str,\n    save_each_model: bool,\n    model_name: str,\n    hidden_dropout_prob: float,\n    attention_probs_dropout_prob: float,\n    max_length : int\n    ) -> pd.DataFrame:\n    \"\"\"predict oof data\"\"\"\n    for fold in range(CFG.n_splits):\n        print(f\"fold {fold}:\")\n        \n        valid_data = train_df[train_df[\"fold\"] == fold]\n        \n        if save_each_model == True:\n            model_dir =  f\"{MODEL_DIR}/{target}/{model_name}/fold_{fold}\"\n        else: \n            model_dir =  f\"{MODEL_DIR}/{model_name}/fold_{fold}\"\n        \n#         print(model_dir, model_name)\n        csr = ContentScoreRegressor(\n            model_name=model_name,\n            target=target,\n            model_dir = model_dir,\n            hidden_dropout_prob=hidden_dropout_prob,\n            attention_probs_dropout_prob=attention_probs_dropout_prob,\n            max_length=max_length,\n           )\n        \n        pred = csr.predict(\n            test_df=valid_data, \n            fold=fold\n        )\n        \n        train_df.loc[valid_data.index, f\"{target}_pred\"] = pred\n\n    return train_df\n    \ndef predict(\n    test_df: pd.DataFrame,\n    target:str,\n    save_each_model: bool,\n    model_name: str,\n    hidden_dropout_prob: float,\n    attention_probs_dropout_prob: float,\n    max_length : int\n    ):\n    \"\"\"predict using mean folds\"\"\"\n\n    for fold in range(CFG.n_splits):\n        print(f\"fold {fold}:\")\n        \n        if save_each_model == True:\n            model_dir =  f\"{MODEL_DIR}/{target}/{model_name}/fold_{fold}\"\n        else: \n            model_dir =  f\"{MODEL_DIR}/{model_name}/fold_{fold}\"\n\n        csr = ContentScoreRegressor(\n            model_name=model_name,\n            target=target,\n            model_dir = model_dir, \n            hidden_dropout_prob=hidden_dropout_prob,\n            attention_probs_dropout_prob=attention_probs_dropout_prob,\n            max_length=max_length,\n           )\n        \n        pred = csr.predict(\n            test_df=test_df, \n            fold=fold\n        )\n        \n        test_df[f\"{target}_pred_{fold}\"] = pred\n    \n    test_df[f\"{target}\"] = test_df[[f\"{target}_pred_{fold}\" for fold in range(CFG.n_splits)]].mean(axis=1)\n\n    return test_df","metadata":{"_uuid":"dbd9fb5c-6848-4618-b7a5-7d1200adcb34","_cell_guid":"a2522c2f-fc19-45fc-b576-6824ec6f1482","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-10-17T00:19:19.105801Z","iopub.execute_input":"2023-10-17T00:19:19.106086Z","iopub.status.idle":"2023-10-17T00:19:19.128334Z","shell.execute_reply.started":"2023-10-17T00:19:19.106056Z","shell.execute_reply":"2023-10-17T00:19:19.127297Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for target in [\"content\", \"wording\"]:\n#     train_by_fold(\n#         train,\n#         model_name=CFG.model_name,\n#         save_each_model=True,\n#         target=target,\n#         learning_rate=CFG.learning_rate,\n#         hidden_dropout_prob=CFG.hidden_dropout_prob,\n#         attention_probs_dropout_prob=CFG.attention_probs_dropout_prob,\n#         weight_decay=CFG.weight_decay,\n#         num_train_epochs=CFG.num_train_epochs,\n#         n_splits=CFG.n_splits,\n#         batch_size=CFG.batch_size,\n#         save_steps=CFG.save_steps,\n#         max_length=CFG.max_length\n#     )\n    \n    print(\"[validate]\")\n    train = validate(\n        train,\n        target=target,\n        save_each_model=True,\n        model_name=CFG.model_name,\n        hidden_dropout_prob=CFG.hidden_dropout_prob,\n        attention_probs_dropout_prob=CFG.attention_probs_dropout_prob,\n        max_length=CFG.max_length\n    )\n\n    rmse = mean_squared_error(train[target], train[f\"{target}_pred\"], squared=False)\n    print(f\"cv {target} rmse: {rmse}\")\n\n    print(\"[test]\")\n    test = predict(\n        test,\n        target=target,\n        save_each_model=True,\n        model_name=CFG.model_name,\n        hidden_dropout_prob=CFG.hidden_dropout_prob,\n        attention_probs_dropout_prob=CFG.attention_probs_dropout_prob,\n        max_length=CFG.max_length\n    )","metadata":{"_uuid":"1187ef30-4a5c-4c12-a50f-643e20f88c0e","_cell_guid":"2d9f036c-4e05-424e-9e1b-0a7d170763b4","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-10-17T00:19:19.547277Z","iopub.execute_input":"2023-10-17T00:19:19.547508Z","iopub.status.idle":"2023-10-17T00:45:15.903169Z","shell.execute_reply.started":"2023-10-17T00:19:19.547484Z","shell.execute_reply":"2023-10-17T00:45:15.902202Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# !rm -r wording content","metadata":{"_uuid":"aa383d7b-32ee-49ee-b73f-e30117deec9b","_cell_guid":"90bc0020-acaa-4502-a4ee-9a141c0d849b","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-10-17T00:18:49.565648Z","iopub.status.idle":"2023-10-17T00:18:49.566275Z","shell.execute_reply.started":"2023-10-17T00:18:49.566036Z","shell.execute_reply":"2023-10-17T00:18:49.56606Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.head()","metadata":{"_uuid":"d66ba99f-780c-45b3-af70-33c3922152a5","_cell_guid":"ae564c85-2daf-43ac-8cd6-5aa23cc121cc","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-10-17T01:04:21.135874Z","iopub.execute_input":"2023-10-17T01:04:21.136134Z","iopub.status.idle":"2023-10-17T01:04:21.168905Z","shell.execute_reply.started":"2023-10-17T01:04:21.136108Z","shell.execute_reply":"2023-10-17T01:04:21.167851Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Add Features","metadata":{"_uuid":"a3f765ca-588b-4dc8-85b2-fc16370d4d1c","_cell_guid":"2ae2546d-4638-4f97-aa36-be2d833d293b","trusted":true}},{"cell_type":"code","source":"wd = pd.read_csv('/kaggle/input/worddifficulty/WordDifficulty.csv')\ndic = dict(zip(wd['Word'], wd['I_Zscore']))","metadata":{"_uuid":"f9d0371b-b128-4053-8860-fe35af51b402","_cell_guid":"83bd39b1-d572-4ba4-9585-6a9ebf52e185","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-10-17T01:04:22.288348Z","iopub.execute_input":"2023-10-17T01:04:22.289194Z","iopub.status.idle":"2023-10-17T01:04:22.387202Z","shell.execute_reply.started":"2023-10-17T01:04:22.289149Z","shell.execute_reply":"2023-10-17T01:04:22.386337Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def difficulty(data) :\n    words = word_tokenize(data['text'])\n#     s = ['``','\\'\\'','.',',']\n#     stop_words = set(stopwords.words('english') + s)\n#     filtered_words = [word for word in words if word.lower() not in stop_words]\n    filtered_words = words\n    score = 0\n    num = 0\n    sep = 0\n    for e in filtered_words:\n        if e in dic:\n            score += dic[e]\n            num+=1\n        elif e == '.' or e == ',' :\n            sep+=1\n        else:\n            pass\n#             print(e,\"**\")\n\n    nn = max(1, len(filtered_words))\n    sep = max(1, sep)\n    num = max(1, num)\n    return score/num, score/nn, nn/sep, (nn-num)/nn\n\n\n\n#         prompts[\"prompt_tokens\"] = prompts[\"prompt_text\"].apply(\n#             lambda x: word_tokenize(x)\n#         )\nlabels = ['difficulty0', 'difficulty1', 'ave_text_len', 'unknown_words']\ntrain[labels]=train.apply(lambda x:difficulty(x),axis=1, result_type='expand')\ntest[labels]=test.apply(lambda x:difficulty(x),axis=1, result_type='expand')","metadata":{"_uuid":"a9faa6ab-4a3f-4aa6-9ee7-3823e3ba747b","_cell_guid":"d858acfd-1635-4bcf-aa59-d8c2e06be42b","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-10-17T01:04:22.737635Z","iopub.execute_input":"2023-10-17T01:04:22.737906Z","iopub.status.idle":"2023-10-17T01:04:26.674847Z","shell.execute_reply.started":"2023-10-17T01:04:22.737881Z","shell.execute_reply":"2023-10-17T01:04:26.67393Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from readability import Readability","metadata":{"_uuid":"aedc7703-904c-4436-aa3d-460a1e18eb76","_cell_guid":"fedc28f4-d87f-4fd4-8c44-052f3dbb90af","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-10-17T01:04:26.676738Z","iopub.execute_input":"2023-10-17T01:04:26.677487Z","iopub.status.idle":"2023-10-17T01:04:26.689621Z","shell.execute_reply.started":"2023-10-17T01:04:26.677452Z","shell.execute_reply":"2023-10-17T01:04:26.688718Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"no_score = -10000\ndef rscore(data) :\n    txt = data['text']\n    words = word_tokenize(txt)\n    n = len(words) + 1\n    if n == 0 : \n        return no_score, no_score, no_score, no_score, no_score, no_score, no_score, no_score\n    tot = n\n    new = txt\n    while tot < 200 :\n        new += \" \" + txt\n        tot += n\n    r = Readability(new)\n    try :\n        ret = (r.flesch_kincaid().score, r.flesch().score, r.gunning_fog().score,\n               r.coleman_liau().score,r.dale_chall().score, r.ari().score,\n               r.linsear_write().score, r.spache().score)\n    except:\n        return no_score, no_score, no_score, no_score, no_score, no_score, no_score, no_score\n    return ret\n\nlabels = ['flesch_kincaid', 'flesch', 'gunning_fog', 'coleman_liau',\n         'dale_chall','ari','linsear_write','spache']\n\ntrain[labels]=train.progress_apply(lambda x:rscore(x),axis=1, result_type='expand')\ntest[labels]=test.progress_apply(lambda x:rscore(x),axis=1, result_type='expand')","metadata":{"_uuid":"c3a0a7d2-a6d9-4e41-b321-dc1c4e34be69","_cell_guid":"8351cdf8-606c-47ae-90a3-16ab096b9e8f","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-10-17T01:04:26.691292Z","iopub.execute_input":"2023-10-17T01:04:26.691551Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.metrics.pairwise import cosine_similarity\nimport nltk\n\ndic = dict()\nfor i in range(len(prompts_train)) :\n    pid = prompts_train['prompt_id'][i]\n    txt = prompts_train['prompt_text'][i]\n    original_tokens = nltk.word_tokenize(txt)\n    original_text = ' '.join(original_tokens)\n    dic[pid] = original_text\nfor i in range(len(prompts_test)) :\n    pid = prompts_test['prompt_id'][i]\n    txt = prompts_test['prompt_text'][i]\n    original_tokens = nltk.word_tokenize(txt)\n    original_text = ' '.join(original_tokens)\n    dic[pid] = original_text\n    \ndic.keys()\n\ndef cosine_sim(data):\n    original_text = dic[data['prompt_id']]\n    summary = data['fixed_summary_text']\n#     original_tokens = nltk.word_tokenize(original_text)\n    summary_tokens = nltk.word_tokenize(summary)\n\n    # トークンを結合して文に戻す\n#     original_text = ' '.join(original_tokens)\n    summary = ' '.join(summary_tokens)\n\n    # CountVectorizerを使用して文をベクトル化\n    vectorizer = CountVectorizer().fit_transform([original_text, summary])\n\n    # コサイン類似度を計算\n    cosine_scores = cosine_similarity(vectorizer)\n\n    # 要約と元の文章の類似度を表示\n    similarity_score = cosine_scores[0][1]\n    \n    return similarity_score","metadata":{"_uuid":"7a794a97-7bda-4932-98f2-b44033f77ad3","_cell_guid":"0af12943-d9eb-419a-902d-609a27b0be16","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# cosine_sim(train.iloc[0])\ntrain['cos_sim']=train.progress_apply(lambda x:cosine_sim(x),axis=1, result_type='expand')\ntest['cos_sim']=test.progress_apply(lambda x:cosine_sim(x),axis=1, result_type='expand')","metadata":{"_uuid":"b7260189-2419-4844-98db-0c23fe5b9ef6","_cell_guid":"6c75dfd0-48dc-40c2-808d-358cd4d943dd","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import textstat\ndef txts(data):\n    text = data['text']\n    return (\n        textstat.flesch_reading_ease(text),\n        textstat.flesch_kincaid_grade(text),\n        textstat.gunning_fog(text),\n        textstat.smog_index(text),\n        textstat.automated_readability_index(text),\n        textstat.coleman_liau_index(text),\n        textstat.linsear_write_formula(text),\n        textstat.dale_chall_readability_score(text),\n        textstat.text_standard(text, float_output=True),\n        textstat.reading_time(text, ms_per_char=14.69),\n        textstat.syllable_count(text),\n        textstat.lexicon_count(text, removepunct=True),\n        textstat.sentence_count(text),\n        textstat.char_count(text, ignore_spaces=True),\n        textstat.letter_count(text, ignore_spaces=True),\n        textstat.monosyllabcount(text)\n    )\n\nsample = txts(train.iloc[1])\nprint(sample)\nlabels = [f'f{i}' for i in range(len(sample))]\ntrain[labels]=train.progress_apply(lambda x:txts(x),axis=1, result_type='expand')\ntest[labels]=test.progress_apply(lambda x:txts(x),axis=1, result_type='expand')","metadata":{"_uuid":"2be96bef-c53b-4307-b0a7-ab21c8fbb72f","_cell_guid":"d035a9ec-93ee-4558-b30f-8e5de772f26a","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"_uuid":"8445c862-c969-4d80-acff-c73d7a7fa8a9","_cell_guid":"c2201319-a6d5-4435-9662-a792179e1c14","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Predict","metadata":{"_uuid":"66e9682a-11df-43ed-abdf-8cad73266988","_cell_guid":"d5238020-2b7d-4851-aa03-3a9a49916714","trusted":true}},{"cell_type":"code","source":"targets = ['content','wording']\nfor target in targets:\n    test[target] = test[[f\"{target}_pred_{fold}\" for fold in range(CFG.n_splits)]].mean(axis=1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Create Submission file","metadata":{"_uuid":"3fe874a9-90bd-40e0-b0d0-4d85bd47396c","_cell_guid":"16e85908-b5a0-4754-b836-d9f38a832f05","trusted":true}},{"cell_type":"code","source":"sample_submission","metadata":{"_uuid":"48b0b722-807e-427b-8649-ac6351732a60","_cell_guid":"076e28e0-311b-4be6-9db7-338638da5da2","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test[[\"student_id\", \"content\", \"wording\"]]","metadata":{"_uuid":"d71d67e4-fa4d-4a3a-bdfc-50ed4d60dba1","_cell_guid":"3bc9ad4c-0016-4778-aad2-34db8fc11493","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test[[\"student_id\", \"content\", \"wording\"]].to_csv(\"submission.csv\", index=False)","metadata":{"_uuid":"ba27c17f-8172-40bf-9acf-56072a107038","_cell_guid":"260a8049-951f-498e-9fe7-590f58df92b7","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Summary\n\nCV result is like this.\n\n| | content rmse |wording rmse | mcrmse | LB| |\n| -- | -- | -- | -- | -- | -- |\n|baseline| 0.494 | 0.630 | 0.562 | 0.509 | [link](https://www.kaggle.com/code/tsunotsuno/debertav3-baseline-content-and-wording-models)|\n| use title and question field | 0.476| 0.619 | 0.548 | 0.508 | [link](https://www.kaggle.com/code/tsunotsuno/debertav3-w-prompt-title-question-fields) |\n| Debertav3 + LGBM | 0.451 | 0.591 | 0.521 | 0.461 | [link](https://www.kaggle.com/code/tsunotsuno/debertav3-lgbm-with-feature-engineering) |\n| Debertav3 + LGBM with spell autocorrect | 0.448 | 0.581 | 0.514 | 0.459 |nogawanogawa's original code\n| Debertav3 + LGBM with spell autocorrect and tuning | 0.442 | 0.566 | 0.504 | 0.453 | this notebook |\n\nThe CV values improved slightly, and the LB value is improved.","metadata":{"_uuid":"f8acee29-6365-4fe0-bd38-cbbd80c7c50b","_cell_guid":"474d77ea-7273-46d0-a052-e4ec28273e71","trusted":true}},{"cell_type":"code","source":"","metadata":{"_uuid":"8cf59da0-9ee9-4886-b183-b74f477e4250","_cell_guid":"65688c7f-a1ac-42d0-898c-9ad1bbcb2556","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"_uuid":"aeba6ddd-e504-4ce0-b622-5297b455c986","_cell_guid":"4ede3da4-14bc-4550-8e82-bd925041d9f1","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"_uuid":"31175760-2d24-491c-99a5-63855882681d","_cell_guid":"57d6d3ae-3422-4352-9b54-a6427191fb6f","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]}]}