{"cells":[{"metadata":{},"cell_type":"markdown","source":"# EXPLAINING THE LEAKS\n\n\nAs I wrote previously, the first version of sample_submission.csv had 2 leaks (current version has it fixed!). However, this doesn't mean we cannot use it for the fun of the stage1 leaderboard:)\n\nSo, let's get started!"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# read the data first\nlibrary(data.table)\nlibrary(dplyr)\nlibrary(xgboost)\n\ntrain = fread('../input/siimoldsamplesubmission/train-rle.csv', data.table = F, header = T)  \nunet_submission = fread('../input/siimoldsamplesubmission/submission.csv', data.table = F, header = T) # https://www.kaggle.com/meaninglesslives/unet-with-efficientnet-encoder-in-keras?scriptVersionId=17180595\nsample_submission = fread('../input/siimoldsamplesubmission/sample_submission.csv', data.table = F, header = T)  # the original one\ndicom_metadata = fread('../input/siimoldsamplesubmission/dicom_metadata.csv', data.table = F, header = T)  # some extra metadata from dicoms :)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# build  both leaks\n# leak #1 - if more than 1 row is present for ImageId - there is definetly pneumothorax in the image\n# leak #2 - the order in train file matters - ImageId in first thousand rows are more likely to have pneumothorax\ntrain$ptx = ifelse(train$EncodedPixels==-1,0,1)\ntrain$rank = 1:nrow(train)/nrow(train)\ntrain = train %>% group_by(ImageId) %>% summarise(N=n(), ptx = max(ptx), rank = min(rank)) %>% arrange(rank)\ntrain = left_join(train, dicom_metadata, by = c('ImageId' = 'File'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Let's see if I am right about leak #1\ntable(train$N, train$ptx==TRUE)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# let's see if I am right about leak #2\nhist(train$rank[train$ptx==1],breaks=100)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Why these findings are so important? Well, it seems old sample_submission.csv file had the same distribution! So, we can build models on that!"},{"metadata":{},"cell_type":"markdown","source":"# GOOD OLD XGBOOST"},{"metadata":{"trusted":true},"cell_type":"code","source":"features = c('rank','N','View','Age','Sex')\ndtrain = xgb.DMatrix(as.matrix(train[, features]), label = train$ptx)\n\n# define stratified 5-fold split\nN = nrow(train)\nfold5list = c(\n  rep( 1, floor(N/5) ),\n  rep( 2, floor(N/5) ),\n  rep( 3, floor(N/5) ),\n  rep( 4, floor(N/5) ),\n  rep( 5, N - 4*floor(N/5) )\n)\n\nset.seed(420)\nfolds = list()  \nfold_list = sample(fold5list)\nfor (k in 1:5) folds[[k]] = which(fold_list == k)\n\nxgb_parameters = \n  list(\n    objective = 'binary:logistic',\n    eval_metric = \"logloss\",\n    booster = \"gbtree\", \n    eta = 0.1,\n    subsample = 0.7,\n    colsample_bytree = 1,\n    max_depth = 3)\n\n#calculate oof logloss estimate and get optimal number of rounds\nset.seed(120)\nxgb_cv = \n  xgb.cv(\n    params = xgb_parameters,\n    data = dtrain,\n    nrounds = 3000,\n    verbose = 1,\n    nthread = 4,\n    folds = folds,\n    early_stopping_rounds = 30,\n    maximize = FALSE,\n    prediction = TRUE\n  )\ntrain$pred = xgb_cv$pred\n\n# early stopped at\n# [128]\ttrain-logloss:0.211082+0.002224\ttest-logloss:0.226907+0.007627\n\n# use a little more rounds while re-training on full data\nset.seed(420)\n  submission_model = \n    xgb.train(\n      params = xgb_parameters,\n      data = dtrain,\n      nrounds = round(1.05 * xgb_cv$best_iter),\n      verbose = 0,\n      nthread = 4,\n      maximize = FALSE\n)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"log loss of 0.22! seems we are on the right track!\n\nLet's create same features based on old sample_submission.csv:"},{"metadata":{"trusted":true},"cell_type":"code","source":"sample_submission$rank = 1:nrow(sample_submission)/nrow(sample_submission)\nsample_submission = sample_submission %>% group_by(ImageId) %>% summarise(N=n(), rank = min(rank)) %>% arrange(rank)\nsample_submission = left_join(sample_submission, dicom_metadata, by = c('ImageId' = 'File'))\n\ndtest = xgb.DMatrix(as.matrix(sample_submission[, features]))\nsample_submission$pred = predict(submission_model, dtest)\nsample_submission = sample_submission %>% select(ImageId,pred)\n\nfwrite(select(sample_submission, ImageId, pred),'leak_probabilities.csv')\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Finally, join this to the current best public kernel Unet predictions.\nThe idea is to use the leak information to reduce false positives of the predicted pneumothorax."},{"metadata":{"trusted":true},"cell_type":"code","source":"unet_submission = left_join(sample_submission, unet_submission, by = \"ImageId\")\nunet_submission$ptx = ifelse(unet_submission$pred>0.10,1,0)\nunet_submission$ptx[is.na(unet_submission$ptx)]=1\ntable(unet_submission$ptx,unet_submission$EncodedPixels!=\"-1\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The idea is to assume that these 17 cases are false positives, and masks should be dropped from the prediction file. Let's do this:"},{"metadata":{"trusted":true},"cell_type":"code","source":"unet_submission$EncodedPixels = ifelse(unet_submission$ptx==0,\"-1\",unet_submission$EncodedPixels)\nfwrite(select(unet_submission, ImageId, EncodedPixels),'leaky_unet_submission.csv')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# FINAL WORDS\n\nThese leaks only apply to stage1 only, so keep that in mind!\nI noticed that leak exploiting works less as your models get better - but that has to be expected, right?\n\n\nIf you enjoy the content - please don't forget to upvote. This keeps guys like me to work on kernels :)"}],"metadata":{"kernelspec":{"display_name":"R","language":"R","name":"ir"},"language_info":{"mimetype":"text/x-r-source","name":"R","pygments_lexer":"r","version":"3.4.2","file_extension":".r","codemirror_mode":"r"}},"nbformat":4,"nbformat_minor":1}