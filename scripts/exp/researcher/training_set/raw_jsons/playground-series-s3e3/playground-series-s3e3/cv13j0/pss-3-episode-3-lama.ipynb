{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# PSS 3, Episode 3, Light Auto ML ðŸ¦™  ...\n## An Started Model Using Light Auto ML and Multiple New Features...\n\n<img src='https://lightautoml.readthedocs.io/en/latest/_images/LightAutoML_logo_big.png' width = 650>\n\n### Notebook Goals\n* Learn more about LAMA.\n* Develop a competitive model adding more features and playing with the model parameters.\n* Continue learning better aproaches in ML.\n\n### Credits:\nI used this Notebook as inspiration to start my analysis...\n\nIf you like my Code please check this one...\nhttps://www.kaggle.com/code/cv13j0/ps-s3-e3-lightautoml-woe-encoding/edit/run/116989049","metadata":{}},{"cell_type":"markdown","source":"# Installing Requiered Libraries...","metadata":{}},{"cell_type":"code","source":"%%capture\n!pip3 install -U lightautoml\n!pip3 install -U pandas # Install pandas, workoround to solve issues...","metadata":{"execution":{"iopub.status.busy":"2023-01-23T04:46:14.964962Z","iopub.execute_input":"2023-01-23T04:46:14.965304Z","iopub.status.idle":"2023-01-23T04:47:54.730653Z","shell.execute_reply.started":"2023-01-23T04:46:14.965232Z","shell.execute_reply":"2023-01-23T04:47:54.729344Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"---","metadata":{}},{"cell_type":"markdown","source":"# Loading Model Libraries...","metadata":{}},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-01-23T04:47:54.733182Z","iopub.execute_input":"2023-01-23T04:47:54.733864Z","iopub.status.idle":"2023-01-23T04:47:54.74847Z","shell.execute_reply.started":"2023-01-23T04:47:54.733823Z","shell.execute_reply":"2023-01-23T04:47:54.74709Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Importing Auto ML Libraries...\nfrom lightautoml.automl.presets.tabular_presets import TabularAutoML, TabularUtilizedAutoML\nfrom lightautoml.tasks import Task\n\n# Import PyTorch...\nimport torch\n\nimport torch.nn as nn\nimport torch.nn.functional as F","metadata":{"execution":{"iopub.status.busy":"2023-01-23T04:47:54.74974Z","iopub.execute_input":"2023-01-23T04:47:54.750298Z","iopub.status.idle":"2023-01-23T04:47:58.075676Z","shell.execute_reply.started":"2023-01-23T04:47:54.75026Z","shell.execute_reply":"2023-01-23T04:47:58.074616Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\nfrom pathlib import Path # Import OS path libraries\nfrom sklearn.preprocessing import LabelEncoder # Encode things\n\nfrom xgboost import XGBClassifier\nfrom lightgbm import LGBMClassifier\nfrom catboost import CatBoostClassifier\nfrom sklearn.model_selection import KFold, StratifiedKFold\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.preprocessing import StandardScaler\n\nfrom sklearn.metrics import mean_absolute_error as mae\nfrom sklearn.neighbors import KNeighborsRegressor\n\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport optuna\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import cross_val_score\nfrom category_encoders import WOEEncoder","metadata":{"execution":{"iopub.status.busy":"2023-01-23T04:47:58.078319Z","iopub.execute_input":"2023-01-23T04:47:58.078677Z","iopub.status.idle":"2023-01-23T04:47:58.232942Z","shell.execute_reply.started":"2023-01-23T04:47:58.078639Z","shell.execute_reply":"2023-01-23T04:47:58.231648Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"---","metadata":{}},{"cell_type":"markdown","source":"# Configuring the Notebook Paramaters","metadata":{}},{"cell_type":"code","source":"%%time\n# I like to disable my Notebook Warnings.\nimport warnings\nwarnings.filterwarnings('ignore')","metadata":{"execution":{"iopub.status.busy":"2023-01-23T04:47:58.234522Z","iopub.execute_input":"2023-01-23T04:47:58.23497Z","iopub.status.idle":"2023-01-23T04:47:58.242565Z","shell.execute_reply.started":"2023-01-23T04:47:58.234933Z","shell.execute_reply":"2023-01-23T04:47:58.241467Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\n# Notebook Configuration...\n\n# Amount of data we want to load into the Model...\nDATA_ROWS = None\n# Dataframe, the amount of rows and cols to visualize...\nNROWS = 50\nNCOLS = 15\n# Main data location path...\nBASE_PATH = '...'\n\nSEED = 42","metadata":{"execution":{"iopub.status.busy":"2023-01-23T04:47:58.2438Z","iopub.execute_input":"2023-01-23T04:47:58.244619Z","iopub.status.idle":"2023-01-23T04:47:58.252222Z","shell.execute_reply.started":"2023-01-23T04:47:58.244582Z","shell.execute_reply":"2023-01-23T04:47:58.251187Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\n# Configure notebook display settings to only use 2 decimal places, tables look nicer.\npd.options.display.float_format = '{:,.4f}'.format\npd.set_option('display.max_columns', NCOLS) \npd.set_option('display.max_rows', NROWS)","metadata":{"execution":{"iopub.status.busy":"2023-01-23T04:47:58.253504Z","iopub.execute_input":"2023-01-23T04:47:58.254482Z","iopub.status.idle":"2023-01-23T04:47:58.261963Z","shell.execute_reply.started":"2023-01-23T04:47:58.254443Z","shell.execute_reply":"2023-01-23T04:47:58.261028Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"---","metadata":{}},{"cell_type":"markdown","source":"# Loading the Competition Datasets...","metadata":{}},{"cell_type":"code","source":"%%time\n# Load the CSV information into a Pandas DataFrame...\ninput_path = Path('/kaggle/input/playground-series-s3e3')\n\ntrn_df = pd.read_csv(input_path / 'train.csv')\ntst_df = pd.read_csv(input_path / 'test.csv')\n\noriginal = pd.read_csv('/kaggle/input/ibm-hr-analytics-attrition-dataset/WA_Fn-UseC_-HR-Employee-Attrition.csv')\n\nsubmission = pd.read_csv(input_path / 'sample_submission.csv')","metadata":{"execution":{"iopub.status.busy":"2023-01-23T04:47:58.263225Z","iopub.execute_input":"2023-01-23T04:47:58.264142Z","iopub.status.idle":"2023-01-23T04:47:58.324607Z","shell.execute_reply.started":"2023-01-23T04:47:58.264105Z","shell.execute_reply":"2023-01-23T04:47:58.323675Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"original = original.rename(columns = {'EmployeeNumber': 'id'})\noriginal['Attrition'] = (original['Attrition'] == 'Yes').astype(int)\n\noriginal = original[trn_df.columns.tolist()]","metadata":{"execution":{"iopub.status.busy":"2023-01-23T04:47:58.325844Z","iopub.execute_input":"2023-01-23T04:47:58.326291Z","iopub.status.idle":"2023-01-23T04:47:58.348546Z","shell.execute_reply.started":"2023-01-23T04:47:58.326254Z","shell.execute_reply":"2023-01-23T04:47:58.347693Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\ntrn_df['Generated'] = 1\ntst_df['Generated'] = 1\noriginal['Generated'] = 0\n\ntrn_df.drop('id', axis = 1, inplace = True)\noriginal.drop('id', axis = 1, inplace = True)\n\n# original = original[original['Attrition'] == 1] # Only keep the Attrition == 1 for balancing purposes...\n\ntrn_df = pd.concat([trn_df, original], ignore_index = True)\ntst_df.drop('id', axis = 1, inplace = True)","metadata":{"execution":{"iopub.status.busy":"2023-01-23T04:47:58.353057Z","iopub.execute_input":"2023-01-23T04:47:58.354222Z","iopub.status.idle":"2023-01-23T04:47:58.37018Z","shell.execute_reply.started":"2023-01-23T04:47:58.354185Z","shell.execute_reply":"2023-01-23T04:47:58.369081Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"---","metadata":{}},{"cell_type":"markdown","source":"# Auxiliary Functions and Data-Preparation...","metadata":{}},{"cell_type":"code","source":"%%time\ndef identify_neg_cols(df):\n    '''\n    Identify cols with negative values...\n    '''\n    negatives = []\n    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n    tmp = df.select_dtypes(include = numerics)\n    for col in tmp.columns:\n        if tmp[col].min() < 0:\n            negatives.append(col)\n    return negatives\n\nnegative_cols = identify_neg_cols(trn_df)\nprint(negative_cols, '\\n')","metadata":{"execution":{"iopub.status.busy":"2023-01-23T04:47:58.371647Z","iopub.execute_input":"2023-01-23T04:47:58.372108Z","iopub.status.idle":"2023-01-23T04:47:58.387378Z","shell.execute_reply.started":"2023-01-23T04:47:58.372066Z","shell.execute_reply":"2023-01-23T04:47:58.386146Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def identify_outliers(df):\n    '''\n    Identify outliers and flag them...\n    '''\n    factor = 3.0\n    outlier_cols = []\n    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n    tmp = df.select_dtypes(include = numerics)\n    tmp = tmp[tmp.columns[~tmp.columns.isin(['id','Attrition', 'Generated'])]]\n    for col in tmp.columns:\n        lower = tmp[col].quantile(0.25)\n        upper = tmp[col].quantile(0.75)\n        IQR = upper - lower\n        max_value = upper + factor * IQR\n        min_value = lower - factor * IQR\n        \n        print(f'The Variable Analyzed is: {col}, Min: {min_value}, Max: {max_value}')\n        tmp[col + '_Outlier'] = np.where((tmp[col] > max_value) | (tmp[col] < min_value), 1, 0)\n        outlier_cols.append(col + '_Outlier')\n    df['Is_Outlier'] = tmp[outlier_cols].apply(np.sum, axis=1)\n    return df\n\ntrn_df = identify_outliers(trn_df)\ntst_df = identify_outliers(tst_df)\n\nprint('Outliers Identified:', trn_df[trn_df['Is_Outlier'] == 1].shape)","metadata":{"execution":{"iopub.status.busy":"2023-01-23T04:47:58.389435Z","iopub.execute_input":"2023-01-23T04:47:58.389786Z","iopub.status.idle":"2023-01-23T04:47:58.764345Z","shell.execute_reply.started":"2023-01-23T04:47:58.389752Z","shell.execute_reply":"2023-01-23T04:47:58.763069Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"---","metadata":{}},{"cell_type":"markdown","source":"# Feature Engineering...","metadata":{}},{"cell_type":"code","source":"# Creating features...\n\n# Feature 1\ndef is_young(x):\n    '''\n    Binary age separation below age cutoff...\n    '''\n    if x <= 25:\n        return 1\n    else:\n        return 0\n\n# Feature 2\ndef young_and_underpaid(x):\n    '''\n    Calculate if the worker is underpay and younger...\n    '''\n    if x['Age'] <= 25 and x['DailyRate'] < 500:\n        return 1\n    else:\n        return 0\n    \n# Feature 3\ndef work_life(x):\n    '''\n    Calculate Worklife + Stocks Levels\n    '''\n    return x['WorkLifeBalance'] + x['StockOptionLevel']\n    \n\n# Feature 4\ndef overtime_stock(x):\n    '''\n    Calculates a satisfaction score\n    '''\n    \n    if x['OverTime'] == 'Yes':\n        return (x['MonthlyIncome'] * (x['StockOptionLevel'] + 0.05) * x['JobSatisfaction']) / x['Age']\n    else:\n        return (x['MonthlyIncome'] * (x['StockOptionLevel'] + 1.05) * x['JobSatisfaction']) / x['Age']\n    \n\n# Feature 5 \ndef income_satisfaction(x):\n    '''\n    Calculates income and satisfaction combination\n    '''\n    return x['JobSatisfaction'] * x['MonthlyIncome']\n    \n\n# Feature 6   \ndef income_level_enviroment_satisfaction(x):\n    '''\n    Calculates income and satisfaction combination\n    '''\n    return x['EnvironmentSatisfaction']*x['JobSatisfaction'] * (x['MonthlyIncome']/x['JobLevel'])\n    \n    \n# Feature 7\ndef calculate_experience_ratios(df):\n    '''\n    Calculates multiple experience ratios...\n    '''\n    df['Equivalent_Salary'] = df['MonthlyIncome'] / (df['TotalWorkingYears'] + 1)\n    df['Working_Years'] = df['YearsAtCompany'] / (df['TotalWorkingYears'] + 1)\n    df['Avg_Years_Per_Company'] = df['TotalWorkingYears'] / (df['NumCompaniesWorked'] + 1)\n    df['Education_To_Salary'] = df['MonthlyIncome'] / (df['Education'] + 1)\n    df['Manager_Familiarity'] = df['YearsWithCurrManager'] / (df['YearsAtCompany'] + 1)\n    df['Performance_Fairness'] = df['PercentSalaryHike'] / df['PerformanceRating']\n    return df","metadata":{"execution":{"iopub.status.busy":"2023-01-23T04:47:58.766212Z","iopub.execute_input":"2023-01-23T04:47:58.766632Z","iopub.status.idle":"2023-01-23T04:47:58.780369Z","shell.execute_reply.started":"2023-01-23T04:47:58.766592Z","shell.execute_reply":"2023-01-23T04:47:58.777694Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Calculating features for Train...\ntrn_df['Is_young'] = trn_df['Age'].apply(lambda x: is_young(x))\ntrn_df['Young_And_Underpaid'] = trn_df.apply(lambda x: young_and_underpaid(x), axis = 1)\ntrn_df['Worklife_Stock'] = trn_df.apply(lambda x: work_life(x), axis = 1)\n\ntrn_df['Overtime_Stock'] = trn_df.apply(lambda x: overtime_stock(x), axis = 1)\ntrn_df['Income_Satisfaction'] = trn_df.apply(lambda x: income_satisfaction(x), axis = 1)\ntrn_df['Income_Level_Environment_Satisfaction'] = trn_df.apply(lambda x: income_level_enviroment_satisfaction(x), axis = 1)\n\n\n# Calculating features for Test...\ntst_df['Is_young'] = tst_df['Age'].apply(lambda x: is_young(x))\ntst_df['Young_And_Underpaid'] = tst_df.apply(lambda x: young_and_underpaid(x), axis = 1)\ntst_df['Worklife_Stock'] = tst_df.apply(lambda x: work_life(x), axis = 1)\n\ntst_df['Overtime_Stock'] = tst_df.apply(lambda x: overtime_stock(x), axis = 1)\ntst_df['Income_Satisfaction'] = tst_df.apply(lambda x: income_satisfaction(x), axis = 1)\ntst_df['Income_Level_Environment_Satisfaction'] = tst_df.apply(lambda x: income_level_enviroment_satisfaction(x), axis = 1)\n\ntrn_df = calculate_experience_ratios(trn_df)\ntst_df = calculate_experience_ratios(tst_df)","metadata":{"execution":{"iopub.status.busy":"2023-01-23T04:47:58.782443Z","iopub.execute_input":"2023-01-23T04:47:58.782927Z","iopub.status.idle":"2023-01-23T04:47:59.157351Z","shell.execute_reply.started":"2023-01-23T04:47:58.782891Z","shell.execute_reply":"2023-01-23T04:47:59.156384Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"---","metadata":{}},{"cell_type":"markdown","source":"# Data Pre-Processing Before Training...","metadata":{}},{"cell_type":"code","source":"def remove_non_variance(df):\n    '''\n    Remove from the dataframe non-changing features...\n    '''\n    feat_to_drop = [feat for feat in df.columns if df[feat].nunique() == 1]\n    print(f'Dropping {feat_to_drop}')\n    return feat_to_drop\n\nfeat_to_remove = remove_non_variance(trn_df)\ntrn_df = trn_df.drop(columns = feat_to_remove)\ntst_df = tst_df.drop(columns = feat_to_remove)","metadata":{"execution":{"iopub.status.busy":"2023-01-23T04:47:59.15897Z","iopub.execute_input":"2023-01-23T04:47:59.1594Z","iopub.status.idle":"2023-01-23T04:47:59.180826Z","shell.execute_reply.started":"2023-01-23T04:47:59.159366Z","shell.execute_reply":"2023-01-23T04:47:59.179764Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time \n# Creating an Encoding function.\n\n# Fixed list of categotical features...\n#categ_feat_list = ['BusinessTravel', 'Department', 'EducationField', 'Gender', 'JobRole', 'MaritalStatus', 'Over18', 'OverTime']\n#categ_feat = [feat for feat in trn_df.columns if feat in categ_feat_list]\n\n# Dynamic list of categorical features...\ncutoff = 20\ncateg_feat = [feat for feat in trn_df.columns if trn_df[feat].nunique() < cutoff and feat != 'Attrition']\nnumeric_feat = [feat for feat in trn_df.columns if feat not in categ_feat and feat != 'Attrition']\n\n# trn_df[categ_feat] = trn_df[categ_feat].astype('str') # Using the fixed feature list...","metadata":{"execution":{"iopub.status.busy":"2023-01-23T04:47:59.182498Z","iopub.execute_input":"2023-01-23T04:47:59.182845Z","iopub.status.idle":"2023-01-23T04:47:59.199617Z","shell.execute_reply.started":"2023-01-23T04:47:59.182811Z","shell.execute_reply":"2023-01-23T04:47:59.198743Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# features = ['Age', \n#             'BusinessTravel', \n#             'DailyRate', \n#             'Department', \n#             'DistanceFromHome',\n#             'Education', \n#             'EducationField', \n#             'EnvironmentSatisfaction',\n#             'Gender',\n#             'HourlyRate',\n#             'JobInvolvement',\n#             'JobLevel',\n#             'JobRole',\n#             'JobSatisfaction',\n#             'MaritalStatus',\n#             'MonthlyIncome',\n#             'MonthlyRate',\n#             'NumCompaniesWorked',\n#             'OverTime',\n#             'PercentSalaryHike',\n#             'PerformanceRating',\n#             'RelationshipSatisfaction',\n#             'StockOptionLevel',\n#             'TotalWorkingYears',\n#             'TrainingTimesLastYear',\n#             'WorkLifeBalance',\n#             'YearsAtCompany',\n#             'YearsInCurrentRole',\n#             'YearsSinceLastPromotion',\n#             'YearsWithCurrManager',\n#             'is_generated',\n#             'is_young',\n#             'young_and_underpaid',\n#             'worklife_stock',\n#             'income_satisfaction',\n#             'income_level_environ_job_sat',\n#             'overtime_stock'\n#            ]","metadata":{"_kg_hide-output":true,"jupyter":{"source_hidden":true},"execution":{"iopub.status.busy":"2023-01-23T04:47:59.202597Z","iopub.execute_input":"2023-01-23T04:47:59.20285Z","iopub.status.idle":"2023-01-23T04:47:59.207784Z","shell.execute_reply.started":"2023-01-23T04:47:59.202827Z","shell.execute_reply":"2023-01-23T04:47:59.206788Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"categ_feat = ['BusinessTravel',\n              'Department',\n              'Education', \n              'EducationField', \n              'EnvironmentSatisfaction', \n              'Gender',\n              'JobInvolvement', \n              'JobLevel', \n              'JobRole', \n              'JobSatisfaction', \n              'MaritalStatus',\n              'NumCompaniesWorked', \n              'OverTime', \n              'PerformanceRating', \n              'RelationshipSatisfaction', \n              'StockOptionLevel', \n              'TotalWorkingYears', \n              'TrainingTimesLastYear', \n              'WorkLifeBalance', \n              'YearsAtCompany',\n              'Is_young', \n              'Young_And_Underpaid'\n             ]","metadata":{"execution":{"iopub.status.busy":"2023-01-23T04:47:59.209296Z","iopub.execute_input":"2023-01-23T04:47:59.209895Z","iopub.status.idle":"2023-01-23T04:47:59.218334Z","shell.execute_reply.started":"2023-01-23T04:47:59.209831Z","shell.execute_reply":"2023-01-23T04:47:59.217444Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\ndef create_onehot(trn_df, tst_df, list_of_var = categ_feat):\n    '''\n    Onehot encoding multiple features.... \n    '''\n    trn_df['Is_train'] = 1\n    tst_df['Is_train'] = 0\n    df = pd.concat([trn_df, tst_df])\n    df = pd.get_dummies(df, columns = categ_feat)\n    \n    trn_df = df[df['Is_train'] == 1]\n    tst_df = df[df['Is_train'] == 0]\n    \n    trn_df = trn_df.drop(['Is_train'], axis = 1)\n    tst_df = tst_df.drop(['Is_train'], axis = 1)\n    \n    return trn_df,tst_df\n\n# Will not be used in this iteration...\n# trn_df, tst_df = create_onehot(trn_df, tst_df, list_of_var = categ_feat)","metadata":{"execution":{"iopub.status.busy":"2023-01-23T04:47:59.219816Z","iopub.execute_input":"2023-01-23T04:47:59.220226Z","iopub.status.idle":"2023-01-23T04:47:59.233157Z","shell.execute_reply.started":"2023-01-23T04:47:59.220185Z","shell.execute_reply":"2023-01-23T04:47:59.231945Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\ndef feature_encoder(trn, tst, list_of_var = categ_feat):\n    '''\n    Encode multiple features...\n    '''\n    \n    encoded_feat = []\n    trn['Is_train'] = 1\n    tst['Is_train'] = 0\n        \n    df = pd.concat([trn,tst])\n\n    for var in list_of_var:\n        encoder = LabelEncoder()\n        df[var + '_enc'] = encoder.fit_transform(df[var])\n        encoded_feat.append(var + '_enc')\n    \n    trn = df[df['Is_train'] == 1]\n    tst = df[df['Is_train'] == 0]\n    \n    trn = trn.drop(list_of_var, axis=1)\n    tst = tst.drop(list_of_var, axis=1)\n    return trn, tst, encoded_feat\n\n#trn_df, tst_df, enc_feat = feature_encoder(trn_df, tst_df, list_of_var = categ_feat)","metadata":{"execution":{"iopub.status.busy":"2023-01-23T04:47:59.234611Z","iopub.execute_input":"2023-01-23T04:47:59.235066Z","iopub.status.idle":"2023-01-23T04:47:59.245556Z","shell.execute_reply.started":"2023-01-23T04:47:59.234986Z","shell.execute_reply":"2023-01-23T04:47:59.244366Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\ndef adv_feature_encoder(trn, tst, list_of_var = categ_feat):\n    '''\n    Encode multiple features...\n    '''\n    \n    encoded_feat = []\n    trn['Is_train'] = 1\n    tst['Is_train'] = 0\n        \n    #df = pd.concat([trn, tst], ignore_index = True)\n    \n    for var in list_of_var:\n        print(f'Converting >>> {var} ...')\n        encoder = WOEEncoder(drop_invariant = True, randomized = True, verbose = 0)\n        encoder.fit(trn[var].astype('str'), trn['Attrition'])\n        \n        # trn[var + '_enc'] = encoder.transform(trn[var])\n        # tst[var + '_enc'] = encoder.transform(tst[var])\n        # encoded_feat.append(var + '_enc')\n        \n        \n        trn[var] = encoder.transform(trn[var].astype('str'))\n        tst[var] = encoder.transform(tst[var].astype('str'))\n        encoded_feat.append(var)\n        \n    # trn = trn.drop(list_of_var, axis=1)\n    # tst = tst.drop(list_of_var, axis=1)\n\n    return trn, tst, encoded_feat\n\ntrn_df, tst_df, enc_feat = adv_feature_encoder(trn_df, tst_df, list_of_var = categ_feat)","metadata":{"execution":{"iopub.status.busy":"2023-01-23T04:47:59.246989Z","iopub.execute_input":"2023-01-23T04:47:59.247574Z","iopub.status.idle":"2023-01-23T04:47:59.773355Z","shell.execute_reply.started":"2023-01-23T04:47:59.247533Z","shell.execute_reply":"2023-01-23T04:47:59.772247Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"---","metadata":{}},{"cell_type":"markdown","source":"# Feature Selection Before Training...","metadata":{}},{"cell_type":"code","source":"%%time\n# Preprocessing the Information for Training.\nTARGET = 'Attrition'\nfeatures = [feat for feat in trn_df.columns if feat not in [TARGET, 'Is_train', 'id', 'Generated']]","metadata":{"execution":{"iopub.status.busy":"2023-01-23T04:47:59.774844Z","iopub.execute_input":"2023-01-23T04:47:59.77547Z","iopub.status.idle":"2023-01-23T04:47:59.782214Z","shell.execute_reply.started":"2023-01-23T04:47:59.775431Z","shell.execute_reply":"2023-01-23T04:47:59.781039Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\nprint(np.sort(features))","metadata":{"execution":{"iopub.status.busy":"2023-01-23T04:47:59.78396Z","iopub.execute_input":"2023-01-23T04:47:59.784507Z","iopub.status.idle":"2023-01-23T04:47:59.792979Z","shell.execute_reply.started":"2023-01-23T04:47:59.784467Z","shell.execute_reply":"2023-01-23T04:47:59.791865Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\nprint(np.sort(enc_feat))","metadata":{"execution":{"iopub.status.busy":"2023-01-23T04:47:59.794537Z","iopub.execute_input":"2023-01-23T04:47:59.795446Z","iopub.status.idle":"2023-01-23T04:47:59.802327Z","shell.execute_reply.started":"2023-01-23T04:47:59.795412Z","shell.execute_reply":"2023-01-23T04:47:59.801186Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"---","metadata":{}},{"cell_type":"markdown","source":"# Scaling Model Features...","metadata":{}},{"cell_type":"code","source":"%%time\ndef scale_features(train, test, features):\n    '''\n    Scale the features...\n    '''\n    scalar = StandardScaler()\n    train[features] = scalar.fit_transform(train[features])\n    test[features] = scalar.transform(test[features])\n    return train, test\n\ntrn_df, tst_df = scale_features(trn_df, tst_df, features)","metadata":{"execution":{"iopub.status.busy":"2023-01-23T04:47:59.803846Z","iopub.execute_input":"2023-01-23T04:47:59.80449Z","iopub.status.idle":"2023-01-23T04:47:59.833295Z","shell.execute_reply.started":"2023-01-23T04:47:59.804457Z","shell.execute_reply":"2023-01-23T04:47:59.832437Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"---","metadata":{}},{"cell_type":"markdown","source":"# Model Development and Training...","metadata":{}},{"cell_type":"code","source":"%%time\nlgb_params = {'num_iterations'   : 772,\n              'max_depth'        : 3,\n              'learning_rate'    : 0.0293466,\n              'min_child_samples': 36, \n              'num_leaves'       : 128, \n              'colsample_bytree' : 0.80, \n              'subsample'        : 0.90, \n              'subsample_freq'   : 5, \n              'reg_lambda'       : 28,\n              'seed'             : SEED,\n              'objective'        : 'binary',\n              'boosting_type'    : 'gbdt',\n              'device'           : 'cpu', \n              'gpu_platform_id'  : 0,\n              'gpu_device_id'    : 0,\n              'n_jobs'           : -1,\n              'metric'           : 'auc',\n              'verbose'          : -1,\n             }","metadata":{"execution":{"iopub.status.busy":"2023-01-23T04:47:59.836225Z","iopub.execute_input":"2023-01-23T04:47:59.836481Z","iopub.status.idle":"2023-01-23T04:47:59.842958Z","shell.execute_reply.started":"2023-01-23T04:47:59.836457Z","shell.execute_reply":"2023-01-23T04:47:59.842014Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\ncb_params = {'num_boost_round': 1420,\n             'depth': 3,\n             'learning_rate': 0.04895188,\n             'rsm': 0.5,\n             'subsample': 0.931,\n             'l2_leaf_reg': 69,\n             'min_data_in_leaf': 20,\n             'random_strength': 0.175,\n             'random_seed': SEED,\n             'use_best_model': True,\n             'task_type': 'CPU',\n             'bootstrap_type': 'Bernoulli',\n             'grow_policy': 'SymmetricTree',\n             'loss_function': 'Logloss',\n             'eval_metric': 'AUC'\n            }","metadata":{"execution":{"iopub.status.busy":"2023-01-23T04:47:59.844496Z","iopub.execute_input":"2023-01-23T04:47:59.845179Z","iopub.status.idle":"2023-01-23T04:47:59.8542Z","shell.execute_reply.started":"2023-01-23T04:47:59.845145Z","shell.execute_reply":"2023-01-23T04:47:59.853059Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# lgb_params = {\n# #     'metric': 'binary_logloss',\n#     'metric': 'auc',\n# #     'n_estimators': 10000,\n#     'objective': 'binary',\n#     'learning_rate': 0.02,\n#     'min_child_samples': 150,\n#     'reg_alpha': 3e-5,\n#     'reg_lambda': 9e-2,\n#     'num_leaves': 20,\n#     'max_depth': 16,\n#     'colsample_bytree': 0.8,\n#     'subsample': 0.8,\n#     'subsample_freq': 2,\n#     'max_bin': 240\n# }\n\n# cb_params = {\n#     'max_depth':6,\n#     'max_ctr_complexity': 5,\n#     'num_trees': 50000,\n#     'od_wait': 500,\n#     'od_type':'Iter', \n#     'learning_rate': 0.04,\n#     'min_data_in_leaf': 3\n# }","metadata":{"_kg_hide-output":true,"_kg_hide-input":true,"jupyter":{"source_hidden":true},"execution":{"iopub.status.busy":"2023-01-23T04:47:59.860858Z","iopub.execute_input":"2023-01-23T04:47:59.861136Z","iopub.status.idle":"2023-01-23T04:47:59.865721Z","shell.execute_reply.started":"2023-01-23T04:47:59.861112Z","shell.execute_reply":"2023-01-23T04:47:59.864579Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"---","metadata":{}},{"cell_type":"markdown","source":"# Light Auto ML Configuration","metadata":{}},{"cell_type":"code","source":"task = Task('binary', metric = 'auc')\n\nN_THREADS = 4\nN_FOLDS = 5\nRANDOM_STATE = SEED\nTEST_SIZE = 0.20\nTIMEOUT = 60 * 60\nTARGET_NAME = 'Attrition'\n\nnp.random.seed(RANDOM_STATE)\ntorch.set_num_threads(N_THREADS)\n\nnp.random.seed(RANDOM_STATE)\ntorch.set_num_threads(N_THREADS)\n# TabularUtilizedAutoML\n# TabularAutoML\nautoml = TabularAutoML(\n    task = task, \n    timeout = TIMEOUT,\n    cpu_limit = N_THREADS,\n    general_params = {'use_algos': [['linear_l2', 'lgb', 'lgb_tuned', 'cb', 'cb_tuned']]},\n    lgb_params = {'default_params': lgb_params, 'freeze_defaults': True},\n    cb_params = {'default_params': cb_params, 'freeze_defaults': True},\n    #reader_params = {'n_jobs': N_THREADS, 'cv': N_FOLDS, 'random_state': RANDOM_STATE},\n    #general_params = {\"use_algos\": [all_models]},\n    reader_params = {'n_jobs': N_THREADS}\n)","metadata":{"execution":{"iopub.status.busy":"2023-01-23T04:47:59.867302Z","iopub.execute_input":"2023-01-23T04:47:59.867889Z","iopub.status.idle":"2023-01-23T04:48:00.036644Z","shell.execute_reply.started":"2023-01-23T04:47:59.867856Z","shell.execute_reply":"2023-01-23T04:48:00.035644Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# ...\nroles = {'target': TARGET_NAME}","metadata":{"execution":{"iopub.status.busy":"2023-01-23T04:48:00.038092Z","iopub.execute_input":"2023-01-23T04:48:00.038437Z","iopub.status.idle":"2023-01-23T04:48:00.044329Z","shell.execute_reply.started":"2023-01-23T04:48:00.038403Z","shell.execute_reply":"2023-01-23T04:48:00.043191Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"---","metadata":{}},{"cell_type":"markdown","source":"# Light Auto ML Training...","metadata":{}},{"cell_type":"code","source":"# ...\npreds_tr = automl.fit_predict(trn_df, roles = roles, verbose = 1)","metadata":{"execution":{"iopub.status.busy":"2023-01-23T04:48:00.045802Z","iopub.execute_input":"2023-01-23T04:48:00.046987Z","iopub.status.idle":"2023-01-23T04:49:19.733855Z","shell.execute_reply.started":"2023-01-23T04:48:00.046933Z","shell.execute_reply":"2023-01-23T04:49:19.732682Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 0.8714690602300498 ... Baseline\n# 0.8715048088695989 ... Using 1.5 IQR\n# 0.8716365355873238 ... Using 3.0 IQR, Less Filtering...\n# 0.8721769528908104 ... Using 3.0 IQR, Added Additional Features... Best Score >>> \n# 0.8721769528908104 ... Using 3.0 IQR, Added Additional Features + cb_tunned...\n# 0.8769689344490699 ... Using 3.0 IQR, Added Additional Features + cb_tunned + nn + 10 folds...","metadata":{"execution":{"iopub.status.busy":"2023-01-23T04:49:19.735651Z","iopub.execute_input":"2023-01-23T04:49:19.737289Z","iopub.status.idle":"2023-01-23T04:49:19.742845Z","shell.execute_reply.started":"2023-01-23T04:49:19.737247Z","shell.execute_reply":"2023-01-23T04:49:19.741935Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"---","metadata":{}},{"cell_type":"markdown","source":"# Model Interpretability...","metadata":{}},{"cell_type":"code","source":"%%time\n\n# Fast feature importances calculation\nfast_fi = automl.get_feature_scores('fast')\nfast_fi.set_index('Feature')['Importance'].plot.bar(figsize = (15, 10), grid = True)","metadata":{"execution":{"iopub.status.busy":"2023-01-23T04:49:19.744547Z","iopub.execute_input":"2023-01-23T04:49:19.744912Z","iopub.status.idle":"2023-01-23T04:49:20.627606Z","shell.execute_reply.started":"2023-01-23T04:49:19.744872Z","shell.execute_reply":"2023-01-23T04:49:20.626418Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"---","metadata":{}},{"cell_type":"markdown","source":"# Generating Model Predictions...","metadata":{}},{"cell_type":"code","source":"preds = automl.predict(tst_df)\npreds","metadata":{"execution":{"iopub.status.busy":"2023-01-23T04:49:20.62937Z","iopub.execute_input":"2023-01-23T04:49:20.629751Z","iopub.status.idle":"2023-01-23T04:49:20.808259Z","shell.execute_reply.started":"2023-01-23T04:49:20.629717Z","shell.execute_reply":"2023-01-23T04:49:20.807469Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission['Attrition'] = preds.data[:,0]\nsubmission","metadata":{"execution":{"iopub.status.busy":"2023-01-23T04:49:20.809488Z","iopub.execute_input":"2023-01-23T04:49:20.813245Z","iopub.status.idle":"2023-01-23T04:49:20.828963Z","shell.execute_reply.started":"2023-01-23T04:49:20.813211Z","shell.execute_reply":"2023-01-23T04:49:20.827805Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"---","metadata":{}},{"cell_type":"markdown","source":"# Creating a Submission File for Kaggle...","metadata":{}},{"cell_type":"code","source":"submission.to_csv('submission.csv', index = False)","metadata":{"execution":{"iopub.status.busy":"2023-01-23T04:49:20.830193Z","iopub.execute_input":"2023-01-23T04:49:20.830604Z","iopub.status.idle":"2023-01-23T04:49:20.841874Z","shell.execute_reply.started":"2023-01-23T04:49:20.830564Z","shell.execute_reply":"2023-01-23T04:49:20.840694Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"---","metadata":{}},{"cell_type":"markdown","source":"# NN Model...","metadata":{}},{"cell_type":"code","source":"%%time\nimport tensorflow as tf\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.callbacks import ReduceLROnPlateau, LearningRateScheduler, EarlyStopping\nfrom tensorflow.keras.layers import Dense, Input, InputLayer, Add, BatchNormalization, Dropout, Concatenate\n\nfrom sklearn.preprocessing import StandardScaler, RobustScaler, MinMaxScaler\nimport random\n\nfrom sklearn.model_selection import KFold, StratifiedKFold \nfrom sklearn.metrics import roc_auc_score, roc_curve, accuracy_score\nimport datetime\nimport math","metadata":{"execution":{"iopub.status.busy":"2023-01-23T04:55:36.242717Z","iopub.execute_input":"2023-01-23T04:55:36.243146Z","iopub.status.idle":"2023-01-23T04:55:36.250644Z","shell.execute_reply.started":"2023-01-23T04:55:36.243111Z","shell.execute_reply":"2023-01-23T04:55:36.249416Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\ndef nn_model():\n    '''\n    '''\n    \n    activation_func = 'swish'\n    inputs = Input(shape = (len(features)))\n    \n    x = Dense(1024, \n              #use_bias  = True, \n              kernel_regularizer = tf.keras.regularizers.l2(30e-6), \n              activation = activation_func)(inputs)\n    X = Dropout(0.1)\n    x = BatchNormalization()(x)\n    \n    \n    x = Dense(256, \n              #use_bias  = True, \n              kernel_regularizer = tf.keras.regularizers.l2(30e-6), \n              activation = activation_func)(x)\n    X = Dropout(0.1)\n    x = BatchNormalization()(x)\n\n    \n    x = Dense(128, \n              #use_bias  = True, \n              kernel_regularizer = tf.keras.regularizers.l2(30e-6), \n              activation = activation_func)(x)\n    X = Dropout(0.1)\n    x = BatchNormalization()(x)\n    \n    \n    x = Dense(64, \n              #use_bias  = True, \n              kernel_regularizer = tf.keras.regularizers.l2(30e-6), \n              activation = activation_func)(x)\n    X = Dropout(0.1)\n    x = BatchNormalization()(x)    \n\n\n    x = Dense(1 , \n              #use_bias  = True, \n              #kernel_regularizer = tf.keras.regularizers.l2(30e-6),\n              activation = 'sigmoid')(x)\n    \n    model = Model(inputs, x)\n    \n    return model","metadata":{"execution":{"iopub.status.busy":"2023-01-23T04:55:37.210943Z","iopub.execute_input":"2023-01-23T04:55:37.21134Z","iopub.status.idle":"2023-01-23T04:55:37.222593Z","shell.execute_reply.started":"2023-01-23T04:55:37.211308Z","shell.execute_reply":"2023-01-23T04:55:37.22144Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\narchitecture = nn_model()\narchitecture.summary()","metadata":{"execution":{"iopub.status.busy":"2023-01-23T04:55:38.209784Z","iopub.execute_input":"2023-01-23T04:55:38.210163Z","iopub.status.idle":"2023-01-23T04:55:38.305134Z","shell.execute_reply.started":"2023-01-23T04:55:38.210131Z","shell.execute_reply":"2023-01-23T04:55:38.303962Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\n# Defining model parameters...\nBATCH_SIZE         = 64\nEPOCHS             = 512 \nEPOCHS_COSINEDECAY = 512\nDIAGRAMS           = True\nUSE_PLATEAU        = False\nINFERENCE          = False\nVERBOSE            = 0 \nTARGET             = 'Attrition'","metadata":{"execution":{"iopub.status.busy":"2023-01-23T04:55:39.272935Z","iopub.execute_input":"2023-01-23T04:55:39.274083Z","iopub.status.idle":"2023-01-23T04:55:39.281359Z","shell.execute_reply.started":"2023-01-23T04:55:39.274034Z","shell.execute_reply":"2023-01-23T04:55:39.280181Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\n# Defining model training function...\ndef fit_model(X_train, y_train, X_val, y_val, run = 0):\n    '''\n    '''\n    lr_start = 0.2\n    start_time = datetime.datetime.now()\n    \n    #scaler = StandardScaler()\n    #scaler = RobustScaler()\n    #scaler = MinMaxScaler()\n    #numerical = numeric_feat\n    #X_train[numerical] = scaler.fit_transform(X_train[numerical])\n\n    epochs = EPOCHS    \n    lr = ReduceLROnPlateau(monitor = 'val_loss', factor = 0.1, patience = 8, verbose = VERBOSE)\n    es = EarlyStopping(monitor = 'val_loss', patience = 16, verbose = 1, mode = 'min', restore_best_weights = True)\n    tm = tf.keras.callbacks.TerminateOnNaN()\n    callbacks = [lr, es, tm]\n    \n    # Cosine Learning Rate Decay\n    if USE_PLATEAU == False:\n        epochs = EPOCHS_COSINEDECAY\n        lr_end = 0.0002\n\n        def cosine_decay(epoch):\n            if epochs > 1:\n                w = (1 + math.cos(epoch / (epochs - 1) * math.pi)) / 2\n            else:\n                w = 1\n            return w * lr_start + (1 - w) * lr_end\n        \n        lr = LearningRateScheduler(cosine_decay, verbose = 0)\n        callbacks = [lr, tm]\n        \n    model = nn_model()\n    \n    optimizer_func = tf.keras.optimizers.Adam(learning_rate = lr_start)\n    loss_func = tf.keras.losses.BinaryCrossentropy()\n    model.compile(optimizer = optimizer_func, loss = loss_func)\n    \n    #X_val[numerical] = scaler.transform(X_val[numerical])\n    validation_data = (X_val, y_val)\n    \n    history = model.fit(X_train, \n                        y_train, \n                        validation_data = validation_data, \n                        epochs          = epochs,\n                        verbose         = VERBOSE,\n                        batch_size      = BATCH_SIZE,\n                        shuffle         = True,\n                        callbacks       = callbacks\n                       )\n    \n    history_list.append(history.history)\n    print(f'Training loss:{history_list[-1][\"loss\"][-1]:.3f}')\n    callbacks, es, lr, tm, history = None, None, None, None, None\n    \n    \n    y_val_pred = model.predict(X_val, batch_size = BATCH_SIZE, verbose = VERBOSE)\n    \n    score = roc_auc_score(y_val, y_val_pred)\n    print(f'Fold {run}.{fold} | {str(datetime.datetime.now() - start_time)[-12:-7]}'\n          f'| AUC: {score:.5f}')\n    \n    score_list.append(score)\n    \n    X_test = tst_df.copy()\n    X_test = X_test[features]\n    #X_test[numerical] = scaler.transform(X_test[numerical])\n    tst_pred = model.predict(X_test)\n    predictions.append(tst_pred)\n    \n    return model","metadata":{"execution":{"iopub.status.busy":"2023-01-23T04:55:40.353942Z","iopub.execute_input":"2023-01-23T04:55:40.35485Z","iopub.status.idle":"2023-01-23T04:55:40.367978Z","shell.execute_reply.started":"2023-01-23T04:55:40.354805Z","shell.execute_reply":"2023-01-23T04:55:40.367035Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\n# Create empty lists to store NN information...\nhistory_list = []\nscore_list   = []\npredictions  = []\n\n# Define kfolds for training purposes...\n#kf = KFold(n_splits = 5)\nkf = StratifiedKFold(n_splits = 10, random_state = SEED, shuffle = True)\n\nfor fold, (trn_idx, val_idx) in enumerate(kf.split(trn_df[features], trn_df[TARGET])):\n    X_train, X_val = trn_df.iloc[trn_idx][features], trn_df.iloc[val_idx][features]\n    y_train, y_val = trn_df.iloc[trn_idx][TARGET], trn_df.iloc[val_idx][TARGET]\n    \n    fit_model(X_train, y_train, X_val, y_val)\n    \nprint('.'* 15, '\\n')\nprint(f'OOF AUC: {np.mean(score_list):.5f}')","metadata":{"execution":{"iopub.status.busy":"2023-01-23T04:55:42.230824Z","iopub.execute_input":"2023-01-23T04:55:42.231211Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\n# Populated the prediction on the submission dataset and creates an output file\nnn_preds = np.array(predictions).mean(axis=0)\nsubmission['Attrition'] = nn_preds\nsubmission.to_csv('nn_submission.csv', index = False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}