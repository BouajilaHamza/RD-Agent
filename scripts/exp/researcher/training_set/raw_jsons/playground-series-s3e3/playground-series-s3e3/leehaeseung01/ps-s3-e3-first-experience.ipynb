{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"thank for watching and upvote plz","metadata":{}},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"import optuna\nimport numpy as np\nimport pandas as pd\n\nfrom sklearn.decomposition import PCA\n\nfrom category_encoders import WOEEncoder\n\npd.set_option(\"display.max_columns\", None)\n\ntrain = pd.read_csv('/kaggle/input/playground-series-s3e3/train.csv', index_col='id')\ntest = pd.read_csv('/kaggle/input/playground-series-s3e3/test.csv', index_col='id')\nsubmission = pd.read_csv('/kaggle/input/playground-series-s3e3/sample_submission.csv')\noriginal = pd.read_csv('/kaggle/input/ibm-hr-analytics-attrition-dataset/WA_Fn-UseC_-HR-Employee-Attrition.csv')\ntrain['original'] = 0\ntest['original'] = 0\noriginal['original'] = 1\n\n# Remove outliers\ntrain = train.drop(527).drop(1398).reset_index(drop=True)\n\ntarget = 'Attrition'\nfeatures = train.drop(target, axis=1).columns.to_list()\n\n# Format original\noriginal = original.reset_index().rename(columns={'index':'id'}).set_index('id').drop(['EmployeeNumber'], axis=1)\noriginal['Attrition'] = original['Attrition'].apply(lambda x: 1 if x =='Yes' else 0)\n\n# Concatinate train and original dataset\ntrain = pd.concat([train, original],axis=0).reset_index(drop=True)\n\nfloat_features = [f for f in features if train[f].dtype == 'float64']\nint_features = [f for f in features if train[f].dtype == 'int64']\ns = (train.dtypes == 'object')\ncategorical_features = list(s[s].index)\n\n# drop columns with only one value\nfor f in features:\n    if len(train[f].unique()) == 1 and f != 'original':\n        print('Drop', f)\n        for ff in [features, float_features, int_features, categorical_features]:\n            if f in ff:\n                ff.remove(f)\n        for df in [train, test]:\n            df.drop(f, axis=1, inplace=True) \n\n\n# Add features\ndef young_and_low_daily_rate(x):\n    if x['Age'] <= 25 & x['DailyRate'] < 500:\n        return 1\n    else:\n        return 0\n    \ndef overtime_satisfaction(x):\n        if x['OverTime'] == 'Yes':\n            return (x['MonthlyIncome'] * (x['StockOptionLevel'] + 0.05) * x['JobSatisfaction'])/x['Age']\n        else:\n            return (x['MonthlyIncome'] * (x['StockOptionLevel'] + 1.05) * x['JobSatisfaction'])/x['Age']\n        \nfor df in [train, test, original]:    \n    df['is_young'] = df['Age'].le(25).astype(int)\n    df['young_and_underpaid'] = df.apply(lambda x: young_and_low_daily_rate(x), axis = 1)\n    df['worklife_stock'] = df.apply(lambda x: x['WorkLifeBalance'] + x['StockOptionLevel'], axis = 1)\n\n    df['income_satisfaction'] = df.apply(lambda x: x['JobSatisfaction'] * x['MonthlyIncome'], axis = 1)\n    df['income_level_environ_job_sat'] = df.apply(lambda x: x['EnvironmentSatisfaction']*x['JobSatisfaction'] * (x['MonthlyIncome']/x['JobLevel']), axis = 1)\n    df['overtime_stock'] = df.apply(lambda x: overtime_satisfaction(x), axis = 1)\n    \nfeatures = train.drop(target, axis=1).columns.to_list()\n\n# Encode categorical\ncategorical_features = ['BusinessTravel', 'Department','Education', 'EducationField', 'EnvironmentSatisfaction', 'Gender',\n               'JobInvolvement', 'JobLevel', 'JobRole', 'JobSatisfaction', 'MaritalStatus','NumCompaniesWorked', 'OverTime', \n               'PerformanceRating', 'RelationshipSatisfaction', 'StockOptionLevel', 'TotalWorkingYears', 'TrainingTimesLastYear', \n                'WorkLifeBalance', 'YearsAtCompany']\ny = train[target]            \nencoder = WOEEncoder(cols=categorical_features, random_state=42, sigma=0.05, randomized=True, verbose=1)\ntrain = encoder.fit_transform(train[features], train[target])\ntrain[target] = y\ntest = encoder.transform(test)\n\ntest = test.reset_index(drop=True)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-01-23T17:20:24.833157Z","iopub.execute_input":"2023-01-23T17:20:24.833754Z","iopub.status.idle":"2023-01-23T17:20:27.599982Z","shell.execute_reply.started":"2023-01-23T17:20:24.833629Z","shell.execute_reply":"2023-01-23T17:20:27.598739Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test","metadata":{"execution":{"iopub.status.busy":"2023-01-23T17:20:27.602002Z","iopub.execute_input":"2023-01-23T17:20:27.602389Z","iopub.status.idle":"2023-01-23T17:20:27.655715Z","shell.execute_reply.started":"2023-01-23T17:20:27.602354Z","shell.execute_reply":"2023-01-23T17:20:27.654368Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train","metadata":{"execution":{"iopub.status.busy":"2023-01-23T17:20:27.657003Z","iopub.execute_input":"2023-01-23T17:20:27.65739Z","iopub.status.idle":"2023-01-23T17:20:27.704352Z","shell.execute_reply.started":"2023-01-23T17:20:27.657355Z","shell.execute_reply":"2023-01-23T17:20:27.70338Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y = train['Attrition']\ntrain=train.drop('Attrition',axis=1)","metadata":{"execution":{"iopub.status.busy":"2023-01-23T17:20:27.706877Z","iopub.execute_input":"2023-01-23T17:20:27.707277Z","iopub.status.idle":"2023-01-23T17:20:27.714785Z","shell.execute_reply.started":"2023-01-23T17:20:27.707238Z","shell.execute_reply":"2023-01-23T17:20:27.713649Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\n\nscaler = StandardScaler()\n\ntrain[train.columns] = scaler.fit_transform(train[train.columns])\ntest[test.columns] = scaler.transform(test[test.columns])\n","metadata":{"execution":{"iopub.status.busy":"2023-01-23T17:20:27.716498Z","iopub.execute_input":"2023-01-23T17:20:27.717304Z","iopub.status.idle":"2023-01-23T17:20:27.744668Z","shell.execute_reply.started":"2023-01-23T17:20:27.717268Z","shell.execute_reply":"2023-01-23T17:20:27.743627Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X=train\nX_test=test","metadata":{"execution":{"iopub.status.busy":"2023-01-23T17:20:27.746264Z","iopub.execute_input":"2023-01-23T17:20:27.746871Z","iopub.status.idle":"2023-01-23T17:20:27.75122Z","shell.execute_reply.started":"2023-01-23T17:20:27.746837Z","shell.execute_reply":"2023-01-23T17:20:27.750258Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_test","metadata":{"execution":{"iopub.status.busy":"2023-01-23T17:20:27.752813Z","iopub.execute_input":"2023-01-23T17:20:27.753345Z","iopub.status.idle":"2023-01-23T17:20:27.809492Z","shell.execute_reply.started":"2023-01-23T17:20:27.75331Z","shell.execute_reply":"2023-01-23T17:20:27.808664Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import catboost\nfrom sklearn.model_selection import KFold, StratifiedKFold, RepeatedStratifiedKFold\nfrom sklearn.metrics import roc_auc_score\n\nn_folds = 5\nrepeats = 10\n\nMAX_ITER = 15000\nPATIENCE = 1000\nDISPLAY_FREQ = 100\n\nmodelsCB = []\npredsCB = []\n\n\nk_fold = RepeatedStratifiedKFold(n_splits=n_folds, n_repeats=repeats, random_state=42) \n\nMODEL_PARAMS = {\n                'random_seed': 42,             \n                'iterations': MAX_ITER,\n                'early_stopping_rounds': PATIENCE,\n                'use_best_model': True,\n                'eval_metric': 'RMSE',\n                'verbose': 1000,\n    \n                 'depth': 3,\n                 'learning_rate': 0.01,\n                 'rsm': 0.5,\n                 'subsample': 0.931,\n                 'l2_leaf_reg': 69,\n                 'min_data_in_leaf': 20, \n                 'random_strength': 0.175,\n\n               }\nfor train_index, test_index in k_fold.split(X, y):\n    X_train, X_valid = X.iloc[train_index], X.iloc[test_index]\n    y_train, y_valid = y.iloc[train_index], y.iloc[test_index]\n    \n\n    model = catboost.CatBoostRegressor(**MODEL_PARAMS)\n    \n    model.fit(X=X_train, y=y_train,\n          eval_set=[(X_valid, y_valid)],\n          early_stopping_rounds = PATIENCE,\n         )\n    modelsCB.append(model)\n    predsCB.append(model.predict(X_test))\n ","metadata":{"execution":{"iopub.status.busy":"2023-01-23T17:20:27.810779Z","iopub.execute_input":"2023-01-23T17:20:27.811593Z","iopub.status.idle":"2023-01-23T17:21:28.663625Z","shell.execute_reply.started":"2023-01-23T17:20:27.811558Z","shell.execute_reply":"2023-01-23T17:21:28.661283Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"MAX_ITER = 15000\nPATIENCE = 1000\nDISPLAY_FREQ = 100\n\nmodelsCBC = []\npredsCBC = []\n\n\nk_fold = RepeatedStratifiedKFold(n_splits=n_folds, n_repeats=repeats, random_state=42) \n\nMODEL_PARAMS = {\n                'random_seed': 42,             \n                'iterations': MAX_ITER,\n                'early_stopping_rounds': PATIENCE,\n                'use_best_model': True,\n                'eval_metric': 'AUC',\n\n                'verbose': 1000,\n    \n                 'depth': 3,\n                 'learning_rate': 0.01, \n                 'rsm': 0.5,\n                 'subsample': 0.931,\n                 'l2_leaf_reg': 69, #69, 4.445\n                 'min_data_in_leaf': 20, #20, 1\n                 'random_strength': 0.175,\n               }\n\n\nfor train_index, test_index in k_fold.split(X, y):\n    X_train, X_valid = X.iloc[train_index], X.iloc[test_index]\n    y_train, y_valid = y.iloc[train_index], y.iloc[test_index]\n    \n    model = catboost.CatBoostClassifier(**MODEL_PARAMS)\n    \n    model.fit(X=X_train, y=y_train,\n          eval_set=[(X_valid, y_valid)],\n          early_stopping_rounds = PATIENCE,\n         )\n    modelsCBC.append(model)\n    predsCBC.append(model.predict_proba(X_test)[:, 1])","metadata":{"execution":{"iopub.status.busy":"2023-01-23T17:21:28.664839Z","iopub.status.idle":"2023-01-23T17:21:28.665666Z","shell.execute_reply.started":"2023-01-23T17:21:28.665422Z","shell.execute_reply":"2023-01-23T17:21:28.665453Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from xgboost import XGBClassifier, XGBRegressor\n\nk_fold = RepeatedStratifiedKFold(n_splits=n_folds, n_repeats=repeats, random_state=42) \n\nmodelsXB = []\npredsXB = []\n\nPATIENCE = 200\n\nMODEL_PARAMS = {       'n_estimators': 1000, \n                       'learning_rate': 0.01, #0.04625397031701272, 0.06733333333333334\n                       'max_depth': 9, #3, 29\n                       'colsample_bytree': 0.9, #0.9, 0.99\n                       'subsample': 1, #1, 0.99\n                       'reg_lambda': 20,\n#                        'eval_metric': 'auc',\n                       'eval_metric': 'rmse',\n                       'early_stopping_rounds': PATIENCE,\n#                        'tree_method': 'gpu_hist',\n                       'seed': 1\n}\n\nfor train_index, test_index in k_fold.split(X, y):\n    X_train, X_valid = X.iloc[train_index], X.iloc[test_index]\n    y_train, y_valid = y.iloc[train_index], y.iloc[test_index]\n    \n    model = XGBRegressor(**MODEL_PARAMS)\n    \n    model.fit(X=X_train, y=y_train,\n          eval_set=[(X_valid, y_valid)],\n          verbose = 100\n         )\n    modelsXB.append(model)\n    predsXB.append(model.predict(X_test))","metadata":{"execution":{"iopub.status.busy":"2023-01-23T17:21:28.667645Z","iopub.status.idle":"2023-01-23T17:21:28.668297Z","shell.execute_reply.started":"2023-01-23T17:21:28.667987Z","shell.execute_reply":"2023-01-23T17:21:28.668019Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"k_fold = RepeatedStratifiedKFold(n_splits=n_folds, n_repeats=repeats, random_state=42) \n\nmodelsXBC = []\npredsXBC = []\n\nPATIENCE = 200\n\nMODEL_PARAMS = {       'n_estimators': 2000, \n                       'learning_rate': 0.01,\n                       'max_depth': 9, #4, #3, 29\n                       'colsample_bytree': 0.9,\n                       'subsample': 1, #1, 0.99\n                       'reg_lambda': 20,\n                       'eval_metric': 'auc',\n                       'early_stopping_rounds': PATIENCE,\n                       'seed': 1\n}\n\nfor train_index, test_index in k_fold.split(X, y):\n    X_train, X_valid = X.iloc[train_index], X.iloc[test_index]\n    y_train, y_valid = y.iloc[train_index], y.iloc[test_index]\n    \n    model = XGBClassifier(**MODEL_PARAMS)\n    \n    model.fit(X=X_train, y=y_train,\n          eval_set=[(X_valid, y_valid)],\n          verbose = 100\n         )\n    modelsXBC.append(model)\n    predsXBC.append(model.predict_proba(X_test)[:, 1])","metadata":{"execution":{"iopub.status.busy":"2023-01-23T17:21:28.669597Z","iopub.status.idle":"2023-01-23T17:21:28.670021Z","shell.execute_reply.started":"2023-01-23T17:21:28.669826Z","shell.execute_reply":"2023-01-23T17:21:28.669845Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import lightgbm as lgbm\nfrom lightgbm.sklearn import LGBMClassifier, LGBMRegressor\n\nk_fold = RepeatedStratifiedKFold(n_splits=n_folds, n_repeats=repeats, random_state=42) \n\nmodelsLB = []\npredsLB = []\n\nMODEL_PARAMS = {\n                       'learning_rate': 0.01,\n                       'max_depth': 9,\n                       'num_leaves': 90,\n                       'colsample_bytree': 0.8,\n                       'subsample': 0.9,\n                       'subsample_freq': 5,\n                       'min_child_samples': 36,\n                       'reg_lambda': 28,\n                       'n_estimators': 20000,\n                       'metric': 'rmse',\n                       'random_state': 42\n}\n\ncallbacks = [\n             lgbm.early_stopping(30, verbose=1),\n            ]\n\nfor train_index, test_index in k_fold.split(X, y):\n    X_train, X_valid = X.iloc[train_index], X.iloc[test_index]\n    y_train, y_valid = y.iloc[train_index], y.iloc[test_index]\n    \n    model = lgbm.LGBMRegressor(**MODEL_PARAMS)\n    \n    model.fit(X=X_train, y=y_train,\n          eval_set=[(X_valid, y_valid)],\n          callbacks=callbacks\n         )\n    modelsLB.append(model)\n    predsLB.append(model.predict(X_test))","metadata":{"execution":{"iopub.status.busy":"2023-01-23T17:21:28.671317Z","iopub.status.idle":"2023-01-23T17:21:28.671731Z","shell.execute_reply.started":"2023-01-23T17:21:28.671537Z","shell.execute_reply":"2023-01-23T17:21:28.671557Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.linear_model import LassoCV\n\n# n_folds = 20\nk_fold = RepeatedStratifiedKFold(n_splits=n_folds, n_repeats=2*repeats, random_state=42) # 20\n\nmodelsLR = []\npredsLR = []\n\nMODEL_PARAMS = {\n                       'precompute': \"auto\",\n                       'fit_intercept': True,\n                       'normalize': False,\n                       'max_iter': 1000,\n                       'verbose': False,\n                       'eps': 1e-04,\n                       'cv': 5,\n                       'n_alphas': 1000,\n                       'n_jobs': 8,\n}\n\n\nfor train_index, test_index in k_fold.split(X, y):\n    X_train, X_valid = X.iloc[train_index], X.iloc[test_index]\n    y_train, y_valid = y.iloc[train_index], y.iloc[test_index]\n    \n    model = LassoCV(**MODEL_PARAMS)\n    \n    model.fit(X=X_train, y=y_train,\n         )\n    \n    modelsLR.append(model)\n    predsLR.append(model.predict(X_test))","metadata":{"execution":{"iopub.status.busy":"2023-01-23T17:21:28.673521Z","iopub.status.idle":"2023-01-23T17:21:28.67426Z","shell.execute_reply.started":"2023-01-23T17:21:28.674014Z","shell.execute_reply":"2023-01-23T17:21:28.674038Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.linear_model import RidgeCV\n\nk_fold = RepeatedStratifiedKFold(n_splits=n_folds, n_repeats=2*repeats, random_state=42) # 20\n\nmodelsR = []\npredsR = []\n\n\nfor train_index, test_index in k_fold.split(X, y):\n    X_train, X_valid = X.iloc[train_index], X.iloc[test_index]\n    y_train, y_valid = y.iloc[train_index], y.iloc[test_index]\n    \n    model = RidgeCV(alphas=np.linspace(0.0001, 100, 1000)\n                   )\n    \n    model.fit(X=X_train, y=y_train)\n    \n    modelsR.append(model)\n    predsR.append(model.predict(X_test))","metadata":{"execution":{"iopub.status.busy":"2023-01-23T17:21:28.67549Z","iopub.status.idle":"2023-01-23T17:21:28.675963Z","shell.execute_reply.started":"2023-01-23T17:21:28.675717Z","shell.execute_reply":"2023-01-23T17:21:28.675739Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"keras_nn_preds = pd.read_csv('/kaggle/input/keras-nn-submission/submission nn.csv')","metadata":{"execution":{"iopub.status.busy":"2023-01-23T17:21:28.677035Z","iopub.status.idle":"2023-01-23T17:21:28.677462Z","shell.execute_reply.started":"2023-01-23T17:21:28.677262Z","shell.execute_reply":"2023-01-23T17:21:28.677282Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predNN = keras_nn_preds.Attrition","metadata":{"execution":{"iopub.status.busy":"2023-01-23T17:21:28.678875Z","iopub.status.idle":"2023-01-23T17:21:28.679379Z","shell.execute_reply.started":"2023-01-23T17:21:28.679086Z","shell.execute_reply":"2023-01-23T17:21:28.679119Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import roc_auc_score\n\n \ndef coef_objective(trial):\n    a = trial.suggest_float('a', 0, 1)\n    b = trial.suggest_float('b', 0, 1)\n    c = trial.suggest_float('c', 0, 1)\n    d = trial.suggest_float('d', 0, 1)\n    e = trial.suggest_float('e', 0, 1)\n    f = trial.suggest_float('f', 0, 1)\n    g = trial.suggest_float('g', 0, 1)\n    h = trial.suggest_float('h', 0, 1)\n    \n#     X = X1\n#     y = y1\n    \n    preds_eval = []\n    for model in modelsCB:\n        preds_eval.append(model.predict(X))\n    \n    resCB = np.average(np.array(preds_eval),axis=0)\n\n    preds_eval = []\n    for model in modelsXB:\n        preds_eval.append(model.predict(X))\n    \n    resXB = np.average(np.array(preds_eval),axis=0)\n\n    preds_eval = []\n    for model in modelsLB:\n        preds_eval.append(model.predict(X))\n    \n    resLB = np.average(np.array(preds_eval),axis=0)\n    \n    preds_eval = []\n    for model in modelsLR:\n        preds_eval.append(model.predict(X))\n    \n    resLR = np.average(np.array(preds_eval),axis=0)\n    \n    preds_eval = []\n    for model in modelsCBC:\n        preds_eval.append(model.predict_proba(X)[:, 1])\n    \n    resCBC = np.average(np.array(preds_eval),axis=0)\n    \n    preds_eval = []\n    for model in modelsXBC:\n        preds_eval.append(model.predict_proba(X)[:, 1])\n    \n    resXBC = np.average(np.array(preds_eval),axis=0)\n    \n    preds_eval = []\n    for model in modelsR:\n        preds_eval.append(model.predict(X))\n    \n    resR = np.average(np.array(preds_eval),axis=0)\n    \n    k = pd.read_csv('/kaggle/input/keras-nn-test/KerasNNX1.csv')\n    resNN = np.array(k['0'])\n\n    res = roc_auc_score(y, (resCB * a + resXB * b + resLB * c + resLR * d + resNN * e + resCBC * f + resXBC * g + resR * h)/(a + b + c + d + e + f + g + h))\n\n    return res\n\nstudy = optuna.create_study(direction= 'maximize')","metadata":{"execution":{"iopub.status.busy":"2023-01-23T17:21:28.680725Z","iopub.status.idle":"2023-01-23T17:21:28.68169Z","shell.execute_reply.started":"2023-01-23T17:21:28.681472Z","shell.execute_reply":"2023-01-23T17:21:28.681494Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"a = 0.03065532725826637\nb = 0.011578190971283535\nc = 0.019159393835472383\nd = 0.3373901994395983\ne = 0.03422756360477424\nf = 0.21937795907658797\ng = 0.00035405910179546316\nh = 0.3472573067122217","metadata":{"execution":{"iopub.status.busy":"2023-01-23T17:21:28.682906Z","iopub.status.idle":"2023-01-23T17:21:28.683556Z","shell.execute_reply.started":"2023-01-23T17:21:28.683343Z","shell.execute_reply":"2023-01-23T17:21:28.683365Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predCB = np.average(np.array(predsCB),axis=0)\npredXB = np.average(np.array(predsXB),axis=0)\npredLB = np.average(np.array(predsLB),axis=0)\npredLR = np.average(np.array(predsLR),axis=0)\npredCBC = np.average(np.array(predsCBC),axis=0)\npredXBC = np.average(np.array(predsXBC),axis=0)\npredR = np.average(np.array(predsR),axis=0)\n\npred = predCB * a + predXB * b + predLB * c + predLR * d  + predCBC * f + predXBC * g + predR * h  + predNN * e\n\npred","metadata":{"execution":{"iopub.status.busy":"2023-01-23T17:21:28.684607Z","iopub.status.idle":"2023-01-23T17:21:28.685001Z","shell.execute_reply.started":"2023-01-23T17:21:28.684811Z","shell.execute_reply":"2023-01-23T17:21:28.68483Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission['Attrition'] = pred\nsubmission\nsubmission.to_csv('submission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2023-01-23T17:21:28.687153Z","iopub.status.idle":"2023-01-23T17:21:28.689894Z","shell.execute_reply.started":"2023-01-23T17:21:28.689653Z","shell.execute_reply":"2023-01-23T17:21:28.689689Z"},"trusted":true},"execution_count":null,"outputs":[]}]}