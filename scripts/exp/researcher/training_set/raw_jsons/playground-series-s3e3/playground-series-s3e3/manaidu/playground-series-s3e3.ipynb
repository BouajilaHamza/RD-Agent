{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-01-21T14:22:13.515846Z","iopub.execute_input":"2023-01-21T14:22:13.516203Z","iopub.status.idle":"2023-01-21T14:22:13.524934Z","shell.execute_reply.started":"2023-01-21T14:22:13.516173Z","shell.execute_reply":"2023-01-21T14:22:13.523796Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = pd.read_csv('/kaggle/input/playground-series-s3e3/train.csv')\ntest = pd.read_csv('/kaggle/input/playground-series-s3e3/test.csv')\ntrain_add = pd.read_csv('/kaggle/input/ibm-hr-analytics-attrition-dataset/WA_Fn-UseC_-HR-Employee-Attrition.csv')","metadata":{"execution":{"iopub.status.busy":"2023-01-21T14:22:13.53195Z","iopub.execute_input":"2023-01-21T14:22:13.532612Z","iopub.status.idle":"2023-01-21T14:22:13.566198Z","shell.execute_reply.started":"2023-01-21T14:22:13.532584Z","shell.execute_reply":"2023-01-21T14:22:13.56533Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.head()","metadata":{"execution":{"iopub.status.busy":"2023-01-21T14:22:13.568031Z","iopub.execute_input":"2023-01-21T14:22:13.568493Z","iopub.status.idle":"2023-01-21T14:22:13.589197Z","shell.execute_reply.started":"2023-01-21T14:22:13.568457Z","shell.execute_reply":"2023-01-21T14:22:13.587985Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.info()","metadata":{"execution":{"iopub.status.busy":"2023-01-21T14:22:13.590623Z","iopub.execute_input":"2023-01-21T14:22:13.591514Z","iopub.status.idle":"2023-01-21T14:22:13.608603Z","shell.execute_reply.started":"2023-01-21T14:22:13.591476Z","shell.execute_reply":"2023-01-21T14:22:13.607438Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_add['Attrition']","metadata":{"execution":{"iopub.status.busy":"2023-01-21T14:22:13.611016Z","iopub.execute_input":"2023-01-21T14:22:13.611373Z","iopub.status.idle":"2023-01-21T14:22:13.619029Z","shell.execute_reply.started":"2023-01-21T14:22:13.611339Z","shell.execute_reply":"2023-01-21T14:22:13.617814Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cat_cols = ['Age','BusinessTravel','Department','Education','EducationField','EmployeeCount','EnvironmentSatisfaction','Gender','JobInvolvement','JobLevel','JobRole','JobSatisfaction','MaritalStatus','NumCompaniesWorked','Over18','OverTime','PerformanceRating',\n'RelationshipSatisfaction','StandardHours','StockOptionLevel','TrainingTimesLastYear','WorkLifeBalance','PercentSalaryHike','TotalWorkingYears','YearsAtCompany','YearsInCurrentRole','YearsWithCurrManager','YearsSinceLastPromotion']\nfor col in cat_cols:\n    train[col] = train[col].astype('category')\n    test[col] = test[col].astype('category')\ntrain.drop(['id'],axis=1,inplace=True)   \ntest_id = test['id']\ntest.drop(['id'],axis=1,inplace=True)\n\ntrain_add = train_add[train.columns]\nfor i,val in enumerate(train_add['Attrition']):\n    if val=='No':\n        train_add.iloc[i,-1] = 0\n    else:\n        train_add.iloc[i,-1] = 1","metadata":{"execution":{"iopub.status.busy":"2023-01-21T14:22:13.621443Z","iopub.execute_input":"2023-01-21T14:22:13.621792Z","iopub.status.idle":"2023-01-21T14:22:13.990817Z","shell.execute_reply.started":"2023-01-21T14:22:13.62175Z","shell.execute_reply":"2023-01-21T14:22:13.989789Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_add['Attrition']","metadata":{"execution":{"iopub.status.busy":"2023-01-21T14:22:13.994417Z","iopub.execute_input":"2023-01-21T14:22:13.995071Z","iopub.status.idle":"2023-01-21T14:22:14.006648Z","shell.execute_reply.started":"2023-01-21T14:22:13.995041Z","shell.execute_reply":"2023-01-21T14:22:14.005665Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from category_encoders.cat_boost import CatBoostEncoder\nimport tensorflow as tf\nfrom tensorflow.keras.layers import Dense, Dropout, BatchNormalization, Activation,Add, Concatenate\nfrom tensorflow.keras import Model, Input, Sequential\nfrom sklearn.model_selection import train_test_split, KFold\nfrom tensorflow.keras.losses import BinaryCrossentropy\nfrom tensorflow.keras.optimizers import Adam\nfrom sklearn.preprocessing import StandardScaler, OrdinalEncoder\nfrom tensorflow.keras.optimizers.schedules import ExponentialDecay\nfrom tensorflow.keras.regularizers import L2\nfrom category_encoders.backward_difference import BackwardDifferenceEncoder\nimport optuna\nfrom lightgbm import LGBMClassifier, LGBMRegressor\nfrom sklearn.metrics import roc_auc_score, mean_squared_error\n\n","metadata":{"execution":{"iopub.status.busy":"2023-01-21T14:22:14.007999Z","iopub.execute_input":"2023-01-21T14:22:14.009693Z","iopub.status.idle":"2023-01-21T14:22:14.017211Z","shell.execute_reply.started":"2023-01-21T14:22:14.009665Z","shell.execute_reply":"2023-01-21T14:22:14.016191Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nX_train, X_cv, y_train, y_cv = train_test_split(train.iloc[:,:-1],train.iloc[:,-1],shuffle=True, random_state=1, test_size=0.2,stratify=train.iloc[:,-1].values)\n\nencode = CatBoostEncoder(random_state=1)\nX_train = encode.fit_transform(X_train,y_train)\nX_cv = encode.transform(X_cv)\nX_test = encode.transform(test)\nX_train_add = encode.transform(train_add.loc[:,[col for col in train.columns if col!='Attrition']])\n\ntrain_scaler = StandardScaler()\nX_train[X_train.columns] = train_scaler.fit_transform(X_train)\nX_cv[X_train.columns] = train_scaler.transform(X_cv)\nX_train_add[X_train.columns] = train_scaler.transform(X_train_add)\n\ntest_scaler = StandardScaler()\nX_test[X_train.columns] = test_scaler.fit_transform(X_test)\n\n\nX_train = pd.concat([X_train,X_train_add],axis=0)\ny_train = pd.concat([y_train,train_add['Attrition'].astype('bool')],axis=0)","metadata":{"execution":{"iopub.status.busy":"2023-01-21T14:22:14.018773Z","iopub.execute_input":"2023-01-21T14:22:14.019085Z","iopub.status.idle":"2023-01-21T14:22:14.680011Z","shell.execute_reply.started":"2023-01-21T14:22:14.019053Z","shell.execute_reply":"2023-01-21T14:22:14.678943Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_add['Attrition']","metadata":{"execution":{"iopub.status.busy":"2023-01-21T14:22:14.681639Z","iopub.execute_input":"2023-01-21T14:22:14.682275Z","iopub.status.idle":"2023-01-21T14:22:14.69359Z","shell.execute_reply.started":"2023-01-21T14:22:14.682234Z","shell.execute_reply":"2023-01-21T14:22:14.692403Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#0.94\ninputs = Input(shape=(33,))\nX = inputs\nX1, X2, X3, X4, X5, X6 = X, X, X, X, X, X\nfor i in [256,128,64]:\n    X1 = Dense(units=i)(X1)\n    X1 = BatchNormalization()(X1)\n    X1 = Activation('relu')(X1)\n    X1 = Dropout(0.8)(X1)\nfor i in [256,128,64]:\n    X2 = Dense(units=i)(X2)\n    X2 = BatchNormalization()(X2)\n    X2 = Activation('elu')(X2)\n    X2 = Dropout(0.8)(X2)\nfor i in [256,128,64]:\n    X3 = Dense(units=i)(X3)\n    X3 = BatchNormalization()(X3)\n    X3 = Activation('tanh')(X3)\n    X3 = Dropout(0.8)(X3)\nfor i in [256,128,64]:\n    X4 = Dense(units=i)(X4)\n    X4 = BatchNormalization()(X4)\n    X4 = Activation('gelu')(X4)\n    X4 = Dropout(0.8)(X4)\nfor i in [256,128,64]:\n    X5 = Dense(units=i)(X5)\n    X5 = BatchNormalization()(X5)\n    X5 = Activation('selu')(X5)\n    X5 = Dropout(0.5)(X5)\nX1 = Dense(units=1)(X1)\nX1 = BatchNormalization()(X1)\nX1 = Activation('sigmoid')(X1)\nX2 = Dense(units=1)(X2)\nX2 = BatchNormalization()(X2)\nX2 = Activation('sigmoid')(X2)\nX3 = Dense(units=1)(X3)\nX3 = BatchNormalization()(X3)\nX3 = Activation('sigmoid')(X3)\nX4 = Dense(units=1)(X4)\nX4 = BatchNormalization()(X4)\nX4 = Activation('sigmoid')(X4)\nX5 = Dense(units=1)(X5)\nX5 = BatchNormalization()(X5)\nX5 = Activation('sigmoid')(X5)\noutputs= Add()([X1,X2,X3,X4,X5])/5\nmodel2 = Model(inputs=inputs, outputs=outputs)\nmodel2.compile(loss=BinaryCrossentropy(),optimizer=Adam(),metrics=['AUC'])\nmodel2.fit(X_train, y_train, validation_data=(X_cv,y_cv),epochs=100,batch_size=32)","metadata":{"execution":{"iopub.status.busy":"2023-01-21T14:22:14.69729Z","iopub.execute_input":"2023-01-21T14:22:14.697681Z","iopub.status.idle":"2023-01-21T14:24:40.969671Z","shell.execute_reply.started":"2023-01-21T14:22:14.697647Z","shell.execute_reply":"2023-01-21T14:24:40.968702Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#0.94319\nmodel = Sequential()\nmodel.add(Input(shape=(33,)))\nmodel.add(Dense(units=256))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.8))\nmodel.add(Activation('relu'))#ExponentialDecay(0.001,510,0.89)\nmodel.add(Dense(units=128))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.8))\nmodel.add(Activation('relu'))\nmodel.add(Dense(units=64))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.8))\nmodel.add(Activation('relu'))\nmodel.add(Dense(units=1))\nmodel.add(BatchNormalization())\nmodel.add(Activation('sigmoid'))\nmodel.compile(loss=BinaryCrossentropy(), optimizer= Adam(), metrics=['AUC'])\nmodel.fit(X_train,y_train,epochs=120,batch_size=32,validation_data=(X_cv,y_cv))","metadata":{"execution":{"iopub.status.busy":"2023-01-21T14:24:40.972717Z","iopub.execute_input":"2023-01-21T14:24:40.973021Z","iopub.status.idle":"2023-01-21T14:25:48.734286Z","shell.execute_reply.started":"2023-01-21T14:24:40.972994Z","shell.execute_reply":"2023-01-21T14:25:48.733241Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"kf = KFold(n_splits=2)\n\ndef objective(trial):\n    params={\n          'max_depth':trial.suggest_int('max_depth',-1,20),\n           'min_data_in_leaf':trial.suggest_int('min_data_in_leaf',0,1000),\n           'bagging_fraction':trial.suggest_float('bagging_fraction',0.0,1),\n          'pos_bagging_fraction':trial.suggest_float('pos_bagging_fraction',0.0,1),\n          'neg_bagging_fraction':trial.suggest_float('neg_bagging_fraction',0.0,1),\n           'bagging_freq':trial.suggest_int('bagging_freq',0,1000),\n           'lambda_l1':trial.suggest_loguniform('lambda_l1',1e-05,100),\n           'lambda_l2':trial.suggest_loguniform('lambda_l2',1e-05,100),\n          'num_leaves':trial.suggest_int('num_leaves',10,1000),\n            'metrics':'mse',\n            'max_bin':trial.suggest_int('max_bin',5,2000),\n            'learning_rate':trial.suggest_loguniform('learning_rate',0.0001,0.1),\n            'boosting':trial.suggest_categorical('boosting',['dart','gbdt']),\n           'min_child_samples': trial.suggest_int('min_child_samples', 3, 2000),\n             'cat_smooth':trial.suggest_int('cat_smooth', 1, 100)}\n            \n    score_list=[]\n    for fold, (train_indx,cv_indx) in enumerate(kf.split(X_train,y_train)):\n        X_tr = X_train.iloc[train_indx]\n        y_tr = y_train.iloc[train_indx]\n        X_cv = X_train.iloc[cv_indx]\n        y_cv = y_train.iloc[cv_indx]\n        \n        \n        model = LGBMRegressor(**params)\n        model.fit(X_tr, y_tr,eval_set=(X_cv,y_cv), early_stopping_rounds=200,verbose=0)\n        y_pred = model.predict(X_cv)\n        score = mean_squared_error(y_cv,y_pred)\n        score_list.append(score)\n    return sum(score_list)/len(score_list)\n\nstudy = optuna.create_study(direction='minimize')\nstudy.optimize(objective,n_trials=1000)\n\n        ","metadata":{"execution":{"iopub.status.busy":"2023-01-19T14:06:09.420742Z","iopub.execute_input":"2023-01-19T14:06:09.42164Z","iopub.status.idle":"2023-01-19T14:06:31.727429Z","shell.execute_reply.started":"2023-01-19T14:06:09.42155Z","shell.execute_reply":"2023-01-19T14:06:31.725487Z"}}},{"cell_type":"code","source":"\ninputs = Input(shape=(33,))\nX = inputs\nX1, X2, X3, X4, X5 = X, X, X, X, X\nfor i in [500,400,300,200,100]:\n    X1 = Dense(units=i)(X1)\n    X1 = BatchNormalization()(X1)\n    X1 = Activation('relu')(X1)\n    X1 = Dropout(0.8)(X1)\nfor i in [500,400,300,200,100]:\n    X2 = Dense(units=i)(X2)\n    X2 = BatchNormalization()(X2)\n    X2 = Activation('selu')(X2)\n    X2 = Dropout(0.8)(X2)\nfor i in [500,400,300,200,100]:\n    X3 = Dense(units=i)(X3)\n    X3 = BatchNormalization()(X3)\n    X3 = Activation('tanh')(X3) \n    X3 = Dropout(0.8)(X3)\nfor i in [500,400,300,200,100]:\n    X4 = Dense(units=i)(X4)\n    X4 = BatchNormalization()(X4)\n    X4 = Activation('elu')(X4)\n    X4 = Dropout(0.8)(X4)\nfor i in [500,400,300,200,100]:\n    X5 = Dense(units=i)(X5)\n    X5 = BatchNormalization()(X5)\n    X5 = Activation('gelu')(X5)\n    X5 = Dropout(0.8)(X5)\nX = Concatenate(axis=-1)([X1,X2,X3,X4,X5])\nX = Dense(units=5)(X)\nX = BatchNormalization()(X)\nX = Dense(units=1)(X)\nX = BatchNormalization()(X)\noutputs = Activation('sigmoid')(X)\nmodel4 = Model(inputs=inputs, outputs=outputs)\nmodel4.compile(loss=BinaryCrossentropy(), optimizer= Adam(), metrics=['AUC'])\nmodel4.fit(X_train,y_train,epochs=100,batch_size=32,validation_data=(X_cv,y_cv))","metadata":{"execution":{"iopub.status.busy":"2023-01-21T14:25:48.735666Z","iopub.execute_input":"2023-01-21T14:25:48.736023Z","iopub.status.idle":"2023-01-21T14:29:17.725269Z","shell.execute_reply.started":"2023-01-21T14:25:48.735987Z","shell.execute_reply":"2023-01-21T14:29:17.723231Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"preds = ( model4.predict(X_test).reshape(-1,)+model2.predict(X_test).reshape(-1,)+model.predict(X_test).reshape(-1,))*0.333333333333333333","metadata":{"execution":{"iopub.status.busy":"2023-01-21T14:30:32.717113Z","iopub.execute_input":"2023-01-21T14:30:32.717513Z","iopub.status.idle":"2023-01-21T14:30:33.173873Z","shell.execute_reply.started":"2023-01-21T14:30:32.717479Z","shell.execute_reply":"2023-01-21T14:30:33.172755Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission = pd.DataFrame({'id':test_id,'Attrition':preds})\nsubmission.to_csv('submission.csv',index=False)","metadata":{"execution":{"iopub.status.busy":"2023-01-21T14:30:35.226072Z","iopub.execute_input":"2023-01-21T14:30:35.226488Z","iopub.status.idle":"2023-01-21T14:30:35.238374Z","shell.execute_reply.started":"2023-01-21T14:30:35.226453Z","shell.execute_reply":"2023-01-21T14:30:35.237173Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}