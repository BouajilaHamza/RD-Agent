{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\nfrom category_encoders import WOEEncoder\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-01-22T12:35:42.500728Z","iopub.execute_input":"2023-01-22T12:35:42.501044Z","iopub.status.idle":"2023-01-22T12:35:43.502361Z","shell.execute_reply.started":"2023-01-22T12:35:42.500972Z","shell.execute_reply":"2023-01-22T12:35:43.500771Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Downloading data**","metadata":{}},{"cell_type":"code","source":"train_df = pd.read_csv('/kaggle/input/playground-series-s3e3/train.csv')\ntest_df = pd.read_csv('/kaggle/input/playground-series-s3e3/test.csv')\nsubmission = pd.read_csv('/kaggle/input/playground-series-s3e3/sample_submission.csv')\naddition_data = pd.read_csv('/kaggle/input/ibm-hr-analytics-attrition-dataset/WA_Fn-UseC_-HR-Employee-Attrition.csv')\n\ntrain_df['is_generated'] = 1\ntest_df['is_generated'] = 1\naddition_data['is_generated'] = 0","metadata":{"execution":{"iopub.status.busy":"2023-01-22T12:35:43.504743Z","iopub.execute_input":"2023-01-22T12:35:43.505806Z","iopub.status.idle":"2023-01-22T12:35:43.574997Z","shell.execute_reply.started":"2023-01-22T12:35:43.505765Z","shell.execute_reply":"2023-01-22T12:35:43.573979Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df = train_df.drop(527).drop(1398).reset_index(drop=True)","metadata":{"execution":{"iopub.status.busy":"2023-01-22T12:35:43.579765Z","iopub.execute_input":"2023-01-22T12:35:43.581383Z","iopub.status.idle":"2023-01-22T12:35:43.596532Z","shell.execute_reply.started":"2023-01-22T12:35:43.581341Z","shell.execute_reply":"2023-01-22T12:35:43.595456Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df = train_df.drop('id', axis=1)\ntrain_df","metadata":{"execution":{"iopub.status.busy":"2023-01-22T12:35:43.601901Z","iopub.execute_input":"2023-01-22T12:35:43.604623Z","iopub.status.idle":"2023-01-22T12:35:43.656027Z","shell.execute_reply.started":"2023-01-22T12:35:43.60458Z","shell.execute_reply":"2023-01-22T12:35:43.654956Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df.Attrition.hist()","metadata":{"execution":{"iopub.status.busy":"2023-01-22T12:35:43.660479Z","iopub.execute_input":"2023-01-22T12:35:43.662872Z","iopub.status.idle":"2023-01-22T12:35:44.005083Z","shell.execute_reply.started":"2023-01-22T12:35:43.662832Z","shell.execute_reply":"2023-01-22T12:35:44.003978Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df.isna().any()","metadata":{"execution":{"iopub.status.busy":"2023-01-22T12:35:44.01004Z","iopub.execute_input":"2023-01-22T12:35:44.012562Z","iopub.status.idle":"2023-01-22T12:35:44.028106Z","shell.execute_reply.started":"2023-01-22T12:35:44.012518Z","shell.execute_reply":"2023-01-22T12:35:44.027098Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# addition_data['Attrition'] = (addition_data['Attrition'] == 'Yes').astype(int)\naddition_data['Attrition'] = addition_data['Attrition'].map(lambda x: 1 if x == \"Yes\" else 0)\n# addition_data = addition_data[addition_data.Attrition == 1]","metadata":{"execution":{"iopub.status.busy":"2023-01-22T12:35:44.032629Z","iopub.execute_input":"2023-01-22T12:35:44.035165Z","iopub.status.idle":"2023-01-22T12:35:44.043815Z","shell.execute_reply.started":"2023-01-22T12:35:44.035106Z","shell.execute_reply":"2023-01-22T12:35:44.042842Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# addition_data.Attrition.hist()","metadata":{"execution":{"iopub.status.busy":"2023-01-22T12:35:44.048475Z","iopub.execute_input":"2023-01-22T12:35:44.051063Z","iopub.status.idle":"2023-01-22T12:35:44.058622Z","shell.execute_reply.started":"2023-01-22T12:35:44.051022Z","shell.execute_reply":"2023-01-22T12:35:44.056839Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"addition_data.isna().any()","metadata":{"execution":{"iopub.status.busy":"2023-01-22T12:35:44.063191Z","iopub.execute_input":"2023-01-22T12:35:44.063798Z","iopub.status.idle":"2023-01-22T12:35:44.080604Z","shell.execute_reply.started":"2023-01-22T12:35:44.063761Z","shell.execute_reply":"2023-01-22T12:35:44.079677Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df = pd.concat([train_df, addition_data],axis=0, ignore_index=True)\ntrain_df = train_df.drop('EmployeeNumber', axis=1)\ntrain_df","metadata":{"execution":{"iopub.status.busy":"2023-01-22T12:35:44.08826Z","iopub.execute_input":"2023-01-22T12:35:44.090605Z","iopub.status.idle":"2023-01-22T12:35:44.144178Z","shell.execute_reply.started":"2023-01-22T12:35:44.090565Z","shell.execute_reply":"2023-01-22T12:35:44.143193Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df.isna().any()","metadata":{"execution":{"iopub.status.busy":"2023-01-22T12:35:44.148596Z","iopub.execute_input":"2023-01-22T12:35:44.15093Z","iopub.status.idle":"2023-01-22T12:35:44.166015Z","shell.execute_reply.started":"2023-01-22T12:35:44.150888Z","shell.execute_reply":"2023-01-22T12:35:44.165145Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def is_young(x):\n    if x <=25:\n        return 1\n    else:\n        return 0\n    \ndef young_and_low_daily_rate(x):\n    if x['Age'] <= 25 & x['DailyRate'] < 500:\n        return 1\n    else:\n        return 0\n    \ndef overtime_satisfaction(x):\n        if x['OverTime'] == 'Yes':\n            return (x['MonthlyIncome'] * (x['StockOptionLevel'] + 0.05) * x['JobSatisfaction'])/x['Age']\n        else:\n            return (x['MonthlyIncome'] * (x['StockOptionLevel'] + 1.05) * x['JobSatisfaction'])/x['Age']","metadata":{"execution":{"iopub.status.busy":"2023-01-22T12:35:44.170124Z","iopub.execute_input":"2023-01-22T12:35:44.172353Z","iopub.status.idle":"2023-01-22T12:35:44.181636Z","shell.execute_reply.started":"2023-01-22T12:35:44.172316Z","shell.execute_reply":"2023-01-22T12:35:44.180784Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.concat([train_df, test_df], axis=0)\ndf = df.drop([\"EmployeeCount\", \"Over18\", \"StandardHours\"], axis=1)\n\ndf['is_young'] = df['Age'].apply(lambda x: is_young(x))\ndf['young_and_underpaid'] = df.apply(lambda x: young_and_low_daily_rate(x), axis = 1)\ndf['worklife_stock'] = df.apply(lambda x: x['WorkLifeBalance'] + x['StockOptionLevel'], axis = 1)\n\ndf['income_satisfaction'] = df.apply(lambda x: x['JobSatisfaction'] * x['MonthlyIncome'], axis = 1)\ndf['income_level_environ_job_sat'] = df.apply(lambda x: x['EnvironmentSatisfaction']*x['JobSatisfaction'] * (x['MonthlyIncome']/x['JobLevel']), axis = 1)\ndf['overtime_stock'] = df.apply(lambda x: overtime_satisfaction(x), axis = 1)\n\n# df = pd.get_dummies(df)\ndf","metadata":{"execution":{"iopub.status.busy":"2023-01-22T12:35:44.185618Z","iopub.execute_input":"2023-01-22T12:35:44.188065Z","iopub.status.idle":"2023-01-22T12:35:44.79246Z","shell.execute_reply.started":"2023-01-22T12:35:44.188031Z","shell.execute_reply":"2023-01-22T12:35:44.791064Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"features = ['Age', 'BusinessTravel', 'DailyRate', 'Department', 'DistanceFromHome',\n       'Education', 'EducationField', 'EnvironmentSatisfaction', 'Gender',\n       'HourlyRate', 'JobInvolvement', 'JobLevel', 'JobRole',\n       'JobSatisfaction', 'MaritalStatus', 'MonthlyIncome', 'MonthlyRate',\n       'NumCompaniesWorked', 'OverTime', 'PercentSalaryHike',\n       'PerformanceRating', 'RelationshipSatisfaction', 'StockOptionLevel',\n       'TotalWorkingYears', 'TrainingTimesLastYear', 'WorkLifeBalance',\n       'YearsAtCompany', 'YearsInCurrentRole', 'YearsSinceLastPromotion',\n       'YearsWithCurrManager', 'is_generated', 'id', 'is_young',\n       'young_and_underpaid', 'worklife_stock', 'income_satisfaction',\n        'income_level_environ_job_sat', 'overtime_stock']\ncat_features = ['BusinessTravel', 'Department','Education', 'EducationField', 'EnvironmentSatisfaction', 'Gender',\n               'JobInvolvement', 'JobLevel', 'JobRole', 'JobSatisfaction', 'MaritalStatus','NumCompaniesWorked', 'OverTime', \n               'PerformanceRating', 'RelationshipSatisfaction', 'StockOptionLevel', 'TotalWorkingYears', 'TrainingTimesLastYear', \n                'WorkLifeBalance', 'YearsAtCompany','is_young', 'young_and_underpaid']","metadata":{"execution":{"iopub.status.busy":"2023-01-22T12:35:44.79379Z","iopub.execute_input":"2023-01-22T12:35:44.794701Z","iopub.status.idle":"2023-01-22T12:35:44.804021Z","shell.execute_reply.started":"2023-01-22T12:35:44.794647Z","shell.execute_reply":"2023-01-22T12:35:44.802813Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Woe encoder from @faelk8 notebook https://www.kaggle.com/code/faelk8/catboost/notebook","metadata":{}},{"cell_type":"code","source":"woe = WOEEncoder(drop_invariant=True, randomized = True)\nfor col in cat_features:\n    df[col] = df[col].astype(str)\nwoe.fit(df[features][:-len(test_df)], df['Attrition'][:-len(test_df)], cols = cat_features)\nX = woe.transform(df[features])\nX['Attrition'] = df['Attrition']\ndf = X","metadata":{"execution":{"iopub.status.busy":"2023-01-22T12:35:44.807954Z","iopub.execute_input":"2023-01-22T12:35:44.808375Z","iopub.status.idle":"2023-01-22T12:35:45.416601Z","shell.execute_reply.started":"2023-01-22T12:35:44.808349Z","shell.execute_reply":"2023-01-22T12:35:45.415522Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\n\nscaler = StandardScaler()\n\ny = df['Attrition']\ndf = df.drop(['id', 'Attrition'], axis=1)\n\ndf[df.columns] = scaler.fit_transform(df[df.columns])","metadata":{"execution":{"iopub.status.busy":"2023-01-22T12:35:45.418162Z","iopub.execute_input":"2023-01-22T12:35:45.418507Z","iopub.status.idle":"2023-01-22T12:35:45.482811Z","shell.execute_reply.started":"2023-01-22T12:35:45.418472Z","shell.execute_reply":"2023-01-22T12:35:45.481688Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df = df.iloc[:-len(test_df),:]\ntrain_df['Attrition'] = y[:-len(test_df)]\ntest_df = df.iloc[-len(test_df):,:].reset_index(drop=True)\n\nX = train_df.drop('Attrition', axis=1)\ny = train_df.Attrition\nX_test = test_df","metadata":{"execution":{"iopub.status.busy":"2023-01-22T12:35:45.487577Z","iopub.execute_input":"2023-01-22T12:35:45.490443Z","iopub.status.idle":"2023-01-22T12:35:45.509958Z","shell.execute_reply.started":"2023-01-22T12:35:45.490403Z","shell.execute_reply":"2023-01-22T12:35:45.508644Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# X1 = X[:500]\n# y1 = y[:500]\n# X = X[500:]\n# y = y[500:]","metadata":{"execution":{"iopub.status.busy":"2023-01-22T12:35:45.514317Z","iopub.execute_input":"2023-01-22T12:35:45.517145Z","iopub.status.idle":"2023-01-22T12:35:45.525089Z","shell.execute_reply.started":"2023-01-22T12:35:45.51708Z","shell.execute_reply":"2023-01-22T12:35:45.523589Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X","metadata":{"execution":{"iopub.status.busy":"2023-01-22T12:35:45.529635Z","iopub.execute_input":"2023-01-22T12:35:45.530018Z","iopub.status.idle":"2023-01-22T12:35:45.606756Z","shell.execute_reply.started":"2023-01-22T12:35:45.529981Z","shell.execute_reply":"2023-01-22T12:35:45.605174Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Keras NN**","metadata":{}},{"cell_type":"code","source":"from tensorflow import keras\nimport tensorflow_addons as tfa\nfrom tensorflow.keras import layers\n\nfrom tensorflow.keras.models import Model, Sequential\nfrom tensorflow.keras.layers import Dense, Dropout, Input, Lambda, Concatenate, Add, BatchNormalization, LeakyReLU\n\nfrom sklearn.model_selection import KFold, StratifiedKFold, RepeatedStratifiedKFold\n\nfrom sklearn.metrics import classification_report\n\n# import keras_tuner","metadata":{"execution":{"iopub.status.busy":"2023-01-22T12:35:45.608726Z","iopub.execute_input":"2023-01-22T12:35:45.609301Z","iopub.status.idle":"2023-01-22T12:35:50.949538Z","shell.execute_reply.started":"2023-01-22T12:35:45.609265Z","shell.execute_reply":"2023-01-22T12:35:50.948526Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"models = []\npreds = []\n\nclass_weight = 10 \n\nn_folds = 11 #10\nrepeats = 10 #10 \ndr = 0.1     \n\n# k_fold = StratifiedKFold(n_splits=n_folds, random_state=42, shuffle=True)\nk_fold = RepeatedStratifiedKFold(n_splits=n_folds, n_repeats=repeats, random_state=42)\n\ndef get_model():\n    model = keras.Sequential([\n    layers.Dense(512), \n    layers.LeakyReLU(alpha=0.3),\n    layers.Dropout(rate=dr),\n    layers.Dense(256), \n    layers.LeakyReLU(alpha=0.3),\n    layers.Dropout(rate=dr),\n    layers.Dense(128), \n    layers.LeakyReLU(alpha=0.3),\n    layers.Dropout(rate=dr),\n    layers.Dense(64), \n    layers.LeakyReLU(alpha=0.3),\n    layers.Dropout(rate=dr),\n    layers.BatchNormalization(),\n    layers.Dense(32), \n    layers.LeakyReLU(alpha=0.3),\n    layers.Dropout(rate=dr),\n    layers.Dense(16), \n    layers.LeakyReLU(alpha=0.3),\n    layers.Dropout(rate=dr),\n    layers.Dense(8),\n    layers.LeakyReLU(alpha=0.3),\n    layers.Dropout(rate=dr),\n    layers.Dense(4), \n    layers.LeakyReLU(alpha=0.3),\n    layers.Dense(2), \n    layers.LeakyReLU(alpha=0.3),\n    layers.Dense(1, activation='sigmoid')\n   ])\n\n    opt = keras.optimizers.Adam(learning_rate=0.0001)\n    \n    model.compile(\n    optimizer=opt,\n        loss=tfa.losses.SigmoidFocalCrossEntropy(\n                                             alpha=0.8,\n                                             gamma=2.0\n                                             ),\n        metrics='AUC',\n)\n    \n    return model\n\n\n\nearly_stopping = keras.callbacks.EarlyStopping(\n        monitor=\"val_auc\", \n        mode='max',\n        patience=30,\n        min_delta=0.00001,\n        restore_best_weights=True,\n)\nplat = keras.callbacks.ReduceLROnPlateau(\n        monitor=\"val_auc\", \n        mode='max', \n        patience=3, \n        factor=0.1, \n        min_lr=1e-8, \n        min_delta=0.000001)\n\n\nfor train_index, test_index in k_fold.split(X, y):\n    X_train, X_valid = X.iloc[train_index], X.iloc[test_index]\n    y_train, y_valid = y.iloc[train_index], y.iloc[test_index]\n    \n    model = get_model()\n\n    history = model.fit(\n          X_train, y_train,\n          validation_data=(X_valid, y_valid),\n          batch_size=64,\n          epochs=500,\n          class_weight = { 0: 1.0, 1: class_weight, },\n          callbacks=[early_stopping, plat],\n          verbose=0\n         )\n    \n#     print(classification_report(y, np.round(model.predict(X))))\n    models.append(model)\n    preds.append(model.predict(X_test))\n","metadata":{"execution":{"iopub.status.busy":"2023-01-22T12:35:50.952031Z","iopub.execute_input":"2023-01-22T12:35:50.95316Z","iopub.status.idle":"2023-01-22T12:36:58.331937Z","shell.execute_reply.started":"2023-01-22T12:35:50.953086Z","shell.execute_reply":"2023-01-22T12:36:58.330974Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history_df = pd.DataFrame(history.history)\nhistory_df.loc[1:, ['loss', 'val_loss']].plot()\nhistory_df.loc[1:, ['auc', 'val_auc']].plot()","metadata":{"execution":{"iopub.status.busy":"2023-01-22T12:36:58.333322Z","iopub.execute_input":"2023-01-22T12:36:58.333651Z","iopub.status.idle":"2023-01-22T12:36:58.729061Z","shell.execute_reply.started":"2023-01-22T12:36:58.333619Z","shell.execute_reply":"2023-01-22T12:36:58.728109Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# preds_evalX1 = []\n# for model in models:\n#     preds_evalX1.append(model.predict(X1))\n    \n# predsX1 = np.average(np.array(preds_evalX1),axis=0)\n# dfX1 = pd.DataFrame(predsX1)\n# dfX1.to_csv('KerasNNX1.csv')\n# dfX1","metadata":{"execution":{"iopub.status.busy":"2023-01-22T12:36:58.730702Z","iopub.execute_input":"2023-01-22T12:36:58.731369Z","iopub.status.idle":"2023-01-22T12:36:58.737179Z","shell.execute_reply.started":"2023-01-22T12:36:58.731328Z","shell.execute_reply":"2023-01-22T12:36:58.736136Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"preds_eval = []\nfor model in models:\n    preds_eval.append(model.predict(X))\n    \nprint(classification_report(y, np.round(np.average(np.array(preds_eval),axis=0))))","metadata":{"execution":{"iopub.status.busy":"2023-01-22T12:36:58.738497Z","iopub.execute_input":"2023-01-22T12:36:58.739421Z","iopub.status.idle":"2023-01-22T12:36:59.132428Z","shell.execute_reply.started":"2023-01-22T12:36:58.739381Z","shell.execute_reply":"2023-01-22T12:36:59.131372Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pred = np.average(np.array(preds),axis=0)\npred","metadata":{"execution":{"iopub.status.busy":"2023-01-22T12:36:59.133705Z","iopub.execute_input":"2023-01-22T12:36:59.134306Z","iopub.status.idle":"2023-01-22T12:36:59.142164Z","shell.execute_reply.started":"2023-01-22T12:36:59.134268Z","shell.execute_reply":"2023-01-22T12:36:59.140943Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission['Attrition'] = pred\nsubmission['Attrition'] = submission['Attrition'].clip(0,1)\nsubmission","metadata":{"execution":{"iopub.status.busy":"2023-01-22T12:36:59.143865Z","iopub.execute_input":"2023-01-22T12:36:59.145724Z","iopub.status.idle":"2023-01-22T12:36:59.164006Z","shell.execute_reply.started":"2023-01-22T12:36:59.145697Z","shell.execute_reply":"2023-01-22T12:36:59.163169Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission.to_csv('submission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2023-01-22T12:36:59.16535Z","iopub.execute_input":"2023-01-22T12:36:59.165862Z","iopub.status.idle":"2023-01-22T12:36:59.175642Z","shell.execute_reply.started":"2023-01-22T12:36:59.165824Z","shell.execute_reply":"2023-01-22T12:36:59.174668Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission.Attrition.hist()","metadata":{"execution":{"iopub.status.busy":"2023-01-22T12:36:59.180628Z","iopub.execute_input":"2023-01-22T12:36:59.180897Z","iopub.status.idle":"2023-01-22T12:36:59.433822Z","shell.execute_reply.started":"2023-01-22T12:36:59.180872Z","shell.execute_reply":"2023-01-22T12:36:59.426104Z"},"trusted":true},"execution_count":null,"outputs":[]}]}