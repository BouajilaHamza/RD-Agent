{"Description": "<p>Writing is a critical skill for success. However, less than a third of high school seniors are proficient writers, according to the National Assessment of Educational Progress. Unfortunately, low-income, Black, and Hispanic students fare even worse, with less than 15 percent demonstrating writing proficiency. One way to help students improve their writing is via automated feedback tools, which evaluate student writing and provide personalized feedback.</p>\n<p>There are currently numerous  automated writing feedback tools, but they all have limitations. Many often fail to identify writing structures, such as thesis statements and support for claims, in essays or do not do so thoroughly. Additionally, the majority of the available tools are proprietary, with algorithms and feature claims that cannot be independently backed up. More importantly, many of these writing tools are inaccessible to educators because of their cost. This problem is compounded for  under-serviced schools which serve a disproportionate number of students of color and from low-income backgrounds. In short, the field of automated writing feedback is ripe for innovation that could help democratize education.</p>\n<p>Georgia State University (GSU) is an undergraduate and graduate urban public research institution in Atlanta. U.S. News &amp; World Report ranked GSU as one of the most innovative universities in the nation. GSU awards more bachelor\u2019s degrees to African-Americans than any other non-profit college or university in the country. GSU and <a rel=\"noreferrer nofollow\" aria-label=\"The Learning Agency Lab (opens in a new tab)\" target=\"_blank\" href=\"https://the-learning-agency-lab.com/\">The Learning Agency Lab</a>, an independent nonprofit based in Arizona, are focused on developing science of learning-based tools and programs for social good.</p>\n<p>In this competition, you\u2019ll identify elements in student writing. More specifically, you will automatically segment texts and classify argumentative and rhetorical elements in essays written by 6th-12th grade students. You'll have access to the largest dataset of student writing ever released in order to test your skills in natural language processing, a fast-growing area of data science.</p>\n<p><img alt=\"Description Image\" src=\"https://storage.googleapis.com/kaggle-media/competitions/The%20Learning%20Agency/Kaggle%20Description%20Image.png\"></p>\n<p>If successful, you'll make it easier for students to receive feedback on their writing and increase opportunities to improve writing outcomes. Virtual writing tutors  and automated writing systems can leverage these algorithms while teachers may use them to reduce grading time. The open-sourced algorithms you come up with will allow any educational organization to better help young writers develop.</p>\n<h3>Acknowledgements</h3>\n<p>Georgia State University and the Learning Agency Lab would like to thank the Bill &amp; Melinda Gates Foundation, Schmidt Futures and Chan Zuckerberg Initiative for their support in making this work possible. </p>\n<p><a rel=\"noreferrer nofollow\" href=\"https://www.gatesfoundation.org/\"><img style=\"width:200px\" src=\"https://storage.googleapis.com/kaggle-media/competitions/The%20Learning%20Agency/BMGF_logo_black_300dpi%20(1).jpg\" alt=\"\"> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</a><a rel=\"noreferrer nofollow\" href=\"https://schmidtfutures.com/\"><img style=\"width:250px\" src=\"https://storage.googleapis.com/kaggle-media/competitions/The%20Learning%20Agency/Schmidt%20Futures%20Logo.png\" alt=\"\">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</a><a rel=\"noreferrer nofollow\" href=\"https://chanzuckerberg.com/\"><img style=\"width:100px\" src=\"https://storage.googleapis.com/kaggle-media/competitions/The%20Learning%20Agency/1200px-Chan_Zuckerberg_Initiative.svg.png\" alt=\"\">&nbsp;&nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp;&nbsp;</a></p>\n<p><br></p>\n<blockquote>\n  <p><strong>This is a Code Competition. Refer to <a aria-label=\"Code Requirements (opens in a new tab)\" target=\"_blank\" href=\"https://www.kaggle.com/c/feedback-prize-2021/overview/code-requirements\">Code Requirements</a> for details.</strong></p>\n</blockquote>", "Evaluation": "<p>Submissions are evaluated on the overlap between ground truth and predicted word indices.</p>\n<ol>\n<li>For each sample, all ground truths and predictions for a given class are compared.</li>\n<li>If the overlap between the ground truth and prediction is &gt;= 0.5, and the overlap between the prediction and the ground truth &gt;= 0.5, the prediction is a match and considered a <code>true positive</code>. If multiple matches exist, the match with the highest pair of overlaps is taken.</li>\n<li>Any unmatched ground truths are <code>false negatives</code> and any unmatched predictions are <code>false positives</code>.</li>\n</ol>\n<p>Example:</p>\n<p>Ground Truth</p>\n<pre class=\"uc-code-block\"><code>id,<span class=\"hljs-keyword\">class</span>,<span class=\"hljs-symbol\">predictionstring</span>\n<span class=\"hljs-symbol\">1,<span class=\"hljs-symbol\">Claim</span>,<span class=\"hljs-symbol\">1</span></span> <span class=\"hljs-symbol\">2</span> <span class=\"hljs-symbol\">3</span> <span class=\"hljs-symbol\">4</span> <span class=\"hljs-symbol\">5</span>\n<span class=\"hljs-symbol\">1,<span class=\"hljs-symbol\">Claim</span>,<span class=\"hljs-symbol\">6</span></span> <span class=\"hljs-symbol\">7</span> <span class=\"hljs-symbol\">8</span>\n<span class=\"hljs-symbol\">1,<span class=\"hljs-symbol\">Claim</span>,<span class=\"hljs-symbol\">21</span></span> <span class=\"hljs-symbol\">22</span> <span class=\"hljs-symbol\">23</span> <span class=\"hljs-symbol\">24</span> <span class=\"hljs-symbol\">25</span>\n</code><div class=\"uc-code-block-copy-button-wrapper\"><button class=\"uc-code-block-copy-button google-symbols\" aria-label=\"Copy code\">content_copy</button></div></pre>\n<p>Prediction</p>\n<pre class=\"uc-code-block\"><code>id,<span class=\"hljs-keyword\">class</span>,<span class=\"hljs-symbol\">predictionstring</span>\n<span class=\"hljs-symbol\">1,<span class=\"hljs-symbol\">Claim</span>,<span class=\"hljs-symbol\">1</span></span> <span class=\"hljs-symbol\">2</span>\n<span class=\"hljs-symbol\">1,<span class=\"hljs-symbol\">Claim</span>,<span class=\"hljs-symbol\">6</span></span> <span class=\"hljs-symbol\">7</span> <span class=\"hljs-symbol\">8</span>\n</code><div class=\"uc-code-block-copy-button-wrapper\"><button class=\"uc-code-block-copy-button google-symbols\" aria-label=\"Copy code\">content_copy</button></div></pre>\n<p>The first prediction would not have &gt;= 0.5 overlap with either ground truth and would be a <code>false positive</code>. The second prediction would overlap perfectly with the second ground truth and be a <code>true positive</code>. The third ground truth would be unmatched, and would be a <code>false negative</code>.</p>\n<p>The final score is arrived at by calculating TP/FP/FN for each class, then taking the <a rel=\"noreferrer nofollow\" aria-label=\"macro F1 score (opens in a new tab)\" target=\"_blank\" href=\"https://en.wikipedia.org/wiki/F-score\">macro F1 score</a> across all classes.</p>\n<p>The word indices are calculated by using Python's <code>.split()</code> function and taking the indices in the resulting list. The two overlaps are calculated by taking the <code>set()</code> of each list of indices in a ground truth / prediction pair and calculating the intersection between the two sets divided by the length of each set.</p>\n<h2>Submission File</h2>\n<p>For each sample in the test set, you must extract any strings from the document that you feel aligns with a <code>class</code>, then submit the sample <code>id</code>, <code>class</code> and word indices <code>predictionstring</code> of that string. If you have multiple predictions for a class or sample, simply submit multiple rows. The file should contain a header and have the following format:</p>\n<pre class=\"uc-code-block\"><code><span class=\"hljs-attribute\">id</span>,class,predictionstring\n<span class=\"hljs-attribute\">2</span>,Claim,<span class=\"hljs-number\">300</span> <span class=\"hljs-number\">301</span> <span class=\"hljs-number\">302</span> <span class=\"hljs-number\">303</span>\n<span class=\"hljs-attribute\">5</span>,Evidence,<span class=\"hljs-number\">56</span> <span class=\"hljs-number\">57</span> <span class=\"hljs-number\">58</span> <span class=\"hljs-number\">59</span> <span class=\"hljs-number\">60</span> <span class=\"hljs-number\">61</span> <span class=\"hljs-number\">62</span>\n<span class=\"hljs-attribute\">6</span>,Lead,<span class=\"hljs-number\">0</span> <span class=\"hljs-number\">1</span> <span class=\"hljs-number\">2</span> <span class=\"hljs-number\">3</span> <span class=\"hljs-number\">4</span> <span class=\"hljs-number\">5</span> <span class=\"hljs-number\">6</span>\n<span class=\"hljs-attribute\">6</span>,Lead,<span class=\"hljs-number\">9</span> <span class=\"hljs-number\">10</span> <span class=\"hljs-number\">11</span> <span class=\"hljs-number\">12</span>\n<span class=\"hljs-attribute\">etc</span>.\n</code><div class=\"uc-code-block-copy-button-wrapper\"><button class=\"uc-code-block-copy-button google-symbols\" aria-label=\"Copy code\">content_copy</button></div></pre>", "Timeline": "<ul>\n<li><strong>December 14, 2021</strong> - Start Date.</li>\n<li><strong>March 8, 2022</strong> - Entry Deadline. You must accept the competition rules before this date in order to compete.</li>\n<li><strong>March 8, 2022</strong> - Team Merger Deadline. This is the last day participants may join or merge teams.</li>\n<li><strong>March 15, 2022</strong> - Final Submission Deadline.</li>\n</ul>\n<p>All deadlines are at 11:59 PM UTC on the corresponding day unless otherwise noted. The competition organizers reserve the right to update the contest timeline if they deem it necessary.</p>", "Prizes": "<ul>\n<li>1st Place - $40,000</li>\n<li>2nd Place - $35,000</li>\n<li>3rd Place - $25,000</li>\n<li>4th Place - $15,000</li>\n<li>5th Place - $10,000</li>\n<li>6th - 12th Place(s) - $5,000 (each)</li>\n</ul>", "Code Requirements": "<p><img style=\"float:right;width:70px;padding:10px\" src=\"https://storage.googleapis.com/kaggle-media/competitions/general/Kerneler-white-desc2_transparent.png\" alt=\"\"></p>\n<h3>This is a Code Competition</h3>\n<p>Submissions to this competition must be made through Notebooks. In order for the \"Submit\" button to be active after a commit, the following conditions must be met:</p>\n<ul>\n<li>CPU Notebook &lt;= 9 hours run-time</li>\n<li>GPU Notebook &lt;= 9 hours run-time</li>\n<li>Internet access disabled</li>\n<li>Freely &amp; publicly available external data is allowed, including pre-trained models</li>\n<li>Submission file must be named <code>submission.csv</code></li>\n</ul>\n<p>Please see the <a aria-label=\"Code Competition FAQ (opens in a new tab)\" target=\"_blank\" href=\"https://www.kaggle.com/docs/competitions#notebooks-only-FAQ\">Code Competition FAQ</a> for more information on how to submit. And review the <a aria-label=\"code debugging doc (opens in a new tab)\" target=\"_blank\" href=\"https://www.kaggle.com/code-competition-debugging\">code debugging doc</a> if you are encountering submission errors.</p>", "Citation": "Aigner Picou, Alex Franklin, Maggie, Meg Benner, Perpetual Baffour, Phil Culliton, Ryan Holbrook, Scott Crossley, Terry_yutian, and ulrichboser. Feedback Prize - Evaluating Student Writing. https://kaggle.com/competitions/feedback-prize-2021, 2021. Kaggle.", "Data Description": "<hr>\n<p><strong>Update</strong></p>\n<p>You may read more about Feedback Prize 1.0 data from the following publication:</p>\n<ul>\n<li>Crossley, S. A, Baffour, P., Tian, Y., Picou, A., Benner, M., &amp; Boser., U. (2022). The Persuasive Essays for Rating, Selecting, and Understanding Argumentative and Discourse Elements (PERSUADE) corpus 1.0.  <em>Assessing Writing, 54.</em> [<a rel=\"noreferrer nofollow\" aria-label=\"link (opens in a new tab)\" target=\"_blank\" href=\"https://www.sciencedirect.com/science/article/pii/S1075293522000630\">link</a>]</li>\n</ul>\n<hr>\n<p>The dataset contains argumentative essays written by U.S students in grades 6-12. The essays were annotated by expert raters for elements commonly found in argumentative writing.</p>\n<p>Note that this is a code competition, in which you will submit code that will be run against an unseen test set. The unseen test set is approximately 10k documents. A small public test sample has been provided for testing your notebooks.</p>\n<p>Your task is to predict the human annotations. You will first need to segment each essay into discrete rhetorical and argumentative elements (i.e., discourse elements) and then classify each element as one of the following:</p>\n<ul>\n<li><strong>Lead</strong> - an introduction that begins with a statistic, a quotation, a description, or some other device to grab the reader\u2019s attention and point toward the thesis</li>\n<li><strong>Position</strong> - an opinion or conclusion on the main question</li>\n<li><strong>Claim</strong> - a claim that supports the position</li>\n<li><strong>Counterclaim</strong> - a claim that refutes another claim or gives an opposing reason to the position</li>\n<li><strong>Rebuttal</strong> - a claim that refutes a counterclaim</li>\n<li><strong>Evidence</strong> - ideas or examples that support claims, counterclaims, or rebuttals.</li>\n<li><strong>Concluding Statement</strong> - a concluding statement that restates the claims</li>\n</ul>\n<p>The training set will consist of individual essays in a folder of .txt files, as well as a .csv file containing the annotated version of these essays. It is important to note that some parts of the essays will be unannotated (i.e., they do not fit into one of the classifications above).</p>\n<p>Files</p>\n<ul>\n<li><strong>train.zip</strong> - folder of individual .txt files, with each file containing the full text of an essay response in the training set </li>\n<li><strong>train.csv</strong> - a .csv file containing the annotated version of all essays in the training set<ul>\n<li>id - ID code for essay response</li>\n<li>discourse_id - ID code for discourse element</li>\n<li>discourse_start - character position where discourse element begins in the essay response</li>\n<li>discourse_end - character position where discourse element ends in the essay response</li>\n<li>discourse_text - text of discourse element</li>\n<li>discourse_type - classification of discourse element</li>\n<li>discourse_type_num - enumerated class label of discourse element </li>\n<li>predictionstring - the word indices of the training sample, as required for predictions</li></ul></li>\n<li><strong>test.zip</strong>  -  folder of individual .txt files, with each file containing the full text of an essay response in the test set</li>\n<li><strong>sample_submission.csv</strong>  -  file in the required format for making predictions - note that if you are making multiple predictions for a document, submit multiple rows</li>\n</ul>\n<p>Submission File Format</p>\n<p>Competitors will submit a .csv file of their predictions for the essays in the test set with the following format:</p>\n<ul>\n<li>id - the name of the text segment\u2019s source essay, excluding the \u201c.txt\u201d extension</li>\n<li>class - class label of discourse element</li>\n<li>predictionstring - word indices of discourse element</li>\n</ul>\n<p>Please see the Evaluation page for more details.</p>"}