[
    {
        "idea": "Feature Engineering",
        "method": "Create a 'group' feature based on visit month difference to capture the periodicity in patient's data.",
        "context": "The notebook introduces a 'group' column in the training data which is determined by the minimum difference in visit months for each patient. This helps in segregating data based on periodicity of visits.",
        "hypothesis": {
            "problem": "Predicting the progression of Parkinson's disease over time.",
            "data": "Longitudinal clinical data with periodic measurements.",
            "method": "Grouping based on time intervals to capture repeated patterns.",
            "reason": "The clinical progression of diseases like Parkinson's often follows specific temporal patterns, which can be captured by grouping based on consistent time intervals."
        }
    },
    {
        "idea": "Data Imputation Strategy",
        "method": "Use polynomial trends to impute missing values in target variables based on time (visit month).",
        "context": "The notebook uses pre-computed trends to replace NaN values in UPDRS scores, utilizing a trend-based filling strategy that incorporates both linear and quadratic terms.",
        "hypothesis": {
            "problem": "Missing target values due to irregular clinical assessments.",
            "data": "Time-series clinical data with gaps in recorded UPDRS scores.",
            "method": "Imputation using trends that assume regular progression over time.",
            "reason": "In progressive diseases like Parkinson's, changes over time can often be approximated using polynomial trends since the progression is generally gradual and consistent."
        }
    },
    {
        "idea": "Model Training with Temporal Shifts",
        "method": "Create shifted datasets for prediction at multiple future time points and train separate models for each shift.",
        "context": "The notebook creates lagged datasets by shifting the visit month backward by 6, 12, and 24 months and then trains separate LightGBM models for each shift.",
        "hypothesis": {
            "problem": "Forecasting future clinical scores at multiple future intervals.",
            "data": "Time-series data where future predictions are required at specific intervals.",
            "method": "Training models that are specifically tailored for different prediction horizons.",
            "reason": "Using shifted datasets allows each model to focus on the unique temporal dynamics and dependencies relevant to its specific prediction task."
        }
    },
    {
        "idea": "Feature Encoding for Event Flags",
        "method": "Encode presence of specific visit months as binary flags to capture key time points in patient history.",
        "context": "Binary flags such as v6, v12, v18, etc., are introduced to mark whether patients had visits at those specific months, which are used as features in model training.",
        "hypothesis": {
            "problem": "Capturing key events or milestones in patient visits.",
            "data": "Longitudinal patient data with visits at irregular intervals.",
            "method": "Encoding key visits as binary flags to incorporate their impact on disease progression.",
            "reason": "Specific visit months may represent key milestones in a patient's treatment or disease progression, making them critical features for prediction."
        }
    },
    {
        "idea": "Model Selection",
        "method": "Utilize LightGBM with MAE loss for robust regression against outliers in UPDRS scores.",
        "context": "The notebook employs LightGBM with mean absolute error as the objective function, which is less sensitive to outliers compared to MSE.",
        "hypothesis": {
            "problem": "Predicting UPDRS scores that may include outliers due to variability in disease symptoms.",
            "data": "Clinical score data with potential outliers due to variability in patient conditions.",
            "method": "Using a robust regression approach that minimizes the influence of outliers.",
            "reason": "The variability in clinical assessments can introduce outliers; MAE mitigates their impact during model training."
        }
    },
    {
        "idea": "Iterative Prediction with Historical Data Accumulation",
        "method": "Accumulate historical test data iteratively as predictions are made over multiple rounds using a rolling window approach.",
        "context": "During the test phase, the notebook accumulates all historical test data in each iteration and uses it for predictions, ensuring no forward-looking bias.",
        "hypothesis": {
            "problem": "Sequential prediction over multiple time points with limited initial data.",
            "data": "Incremental availability of test data due to the nature of time series API delivery.",
            "method": "Using accumulated historical data to avoid forward-looking bias and improve prediction accuracy.",
            "reason": "Accumulating historical data allows models to utilize all available information for better-informed predictions at each step."
        }
    }
]