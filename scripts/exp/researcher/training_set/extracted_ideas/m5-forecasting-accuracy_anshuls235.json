[
    {
        "idea": "Feature Engineering",
        "method": "Introduce lag features for the target variable to transform time series data into a supervised learning problem.",
        "context": "The notebook introduces lag features for the target variable 'sold' by shifting values by 1, 2, 3, 6, 12, 24, and 36 days.",
        "hypothesis": {
            "problem": "Forecasting future sales based on historical data.",
            "data": "Time series sales data with daily frequency.",
            "method": "Lag features are classical methods for converting time series forecasting into supervised learning.",
            "reason": "Using lag features is beneficial as it allows the model to learn from past patterns and trends in sales data, which are crucial for accurate forecasting."
        }
    },
    {
        "idea": "Feature Engineering",
        "method": "Calculate rolling window statistics to capture short-term trends and patterns in the data.",
        "context": "The notebook calculates the weekly rolling average of items sold to capture recent trends in sales data.",
        "hypothesis": {
            "problem": "Capturing short-term trends and patterns in sales data.",
            "data": "Time series data with daily sales records.",
            "method": "Rolling window statistics help capture short-term trends and patterns.",
            "reason": "Short-term patterns in sales are important for making accurate forecasts, especially in retail scenarios where promotions and events can cause temporary spikes or drops in sales."
        }
    },
    {
        "idea": "Feature Engineering",
        "method": "Mean encoding of categorical features to capture target variable distribution conditioned on feature values.",
        "context": "The notebook employs mean encoding for features such as item_id, state_id, store_id, cat_id, and their combinations.",
        "hypothesis": {
            "problem": "Capturing complex relationships between categorical features and the target variable.",
            "data": "Categorical features like item_id, store_id, and state_id with high cardinality.",
            "method": "Mean encoding captures the conditional distribution of the target variable given each feature value.",
            "reason": "Incorporating information about how different categorical levels relate to sales can provide additional predictive power that simple one-hot encoding might not capture."
        }
    },
    {
        "idea": "Model Training",
        "method": "Use LightGBM, a gradient boosting framework that is efficient for large datasets and capable of handling categorical features directly.",
        "context": "The notebook trains a LightGBM model for each store's sales data with specific hyperparameters tuned for performance.",
        "hypothesis": {
            "problem": "Predicting future sales accurately using historical sales data.",
            "data": "Large dataset with hierarchical categorical features and numerical features from feature engineering.",
            "method": "LightGBM is efficient for large-scale datasets and handles categorical features well.",
            "reason": "LightGBM's ability to handle large datasets efficiently and its built-in support for categorical variables make it suitable for this problem where there are many categorical features and a large amount of data."
        }
    },
    {
        "idea": "Memory Optimization",
        "method": "Downcast numerical and categorical data types to reduce memory usage and improve computational efficiency.",
        "context": "The notebook downcasts numerical columns to smaller integer or float types and converts object columns to categorical types.",
        "hypothesis": {
            "problem": "High memory usage due to large dataset size.",
            "data": "Large datasets with numerous numerical and categorical columns.",
            "method": "Downcasting reduces memory footprint, leading to faster computation times.",
            "reason": "Memory optimization is crucial when working with large datasets as it allows for efficient processing without running into resource limitations."
        }
    },
    {
        "idea": "Data Transformation",
        "method": "Convert wide-formatted time series data into long format using the melt function for flexible data manipulation and merging.",
        "context": "The notebook uses the melt function to transform daily sales data into a long format with day-level granularity.",
        "hypothesis": {
            "problem": "Need to perform detailed time-series analysis and feature engineering on daily sales data.",
            "data": "Sales data recorded in wide format with each column representing a day's sales.",
            "method": "'Melting' allows easier manipulation and merging with other datasets like calendar and price data.",
            "reason": "'Melting' time series data into long format facilitates merging with other datasets (e.g., calendar data) and makes it easier to apply time-window based feature engineering."
        }
    }
]