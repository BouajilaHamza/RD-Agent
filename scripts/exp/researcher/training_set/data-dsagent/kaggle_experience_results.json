[{"content": "High-ranking Kaggle notebooks or competition strategies: (1) The overall design of this code is to predict housing prices in Paris. It uses a combination of data cleaning, preprocessing, ensemble modeling, and cross-validation to achieve high performance. The code first loads the necessary data from CSV files and removes outliers. Then, it performs preprocessing steps such as merging datasets, creating yearly statistics, and splitting the data into different ranges based on the 'made' column. Next, it defines an ensemble model consisting of Random Forest, Gradient Boosting, XGBoost, and CatBoost regressors. The code then predicts the housing prices for each range using the ensemble model. Finally, it evaluates the model performance using train-test split and multi-cross validation, and creates a submission file with the predicted prices.\n\n(2) The overall model architecture consists of an ensemble model that combines the predictions of four different regressors: Random Forest, Gradient Boosting, XGBoost, and CatBoost. The ensemble model is created using the VotingRegressor class from scikit-learn. Each regressor is trained on a specific range of data based on the 'made' column. The ranges are defined using lambda functions and are split into four periods: before 2005, between 2005 and 2007, between 2007 and 2015, and after 2015. The ensemble model then predicts the housing prices for each range.\n\n(3) The important hyperparameters in this code are:\n\n- RandomForestRegressor: The random_state parameter is set to 0.\n- GradientBoostingRegressor: The random_state parameter is set to 0.\n- XGBRegressor: The n_estimators parameter is set to 300 and the gamma parameter is set to 0.1. The random_state parameter is set to 0.\n- CatBoostRegressor: The l2_leaf_reg parameter is set to 1, the depth parameter is set to 6, the verbose parameter is set to False, and the random_state parameter is set to 0.\n- VotingRegressor: No specific hyperparameters are set for the ensemble model.\n\n(4) The optimization objective of this code is to minimize the root mean squared error (RMSE) between the predicted housing prices and the actual prices. The code uses the mean_squared_error function from scikit-learn to calculate the RMSE.\n\n(5) The advanced machine learning technique used in this code is ensemble modeling. The code combines the predictions of multiple regressors (Random Forest, Gradient Boosting, XGBoost, and CatBoost) using the VotingRegressor class. This technique helps to improve the model's performance by leveraging the strengths of different models and reducing the impact of individual model weaknesses.\n\n(6) Some important tricks that play a role in achieving high performance in this code are:\n\n- Removing outliers: The code uses the interquartile range (IQR) method to identify and remove outliers from the training data. This helps to improve the cross-validation results by reducing the impact of outliers on the RMSE metric.\n- Piece-wise model: The code splits the data into different periods based on the 'made' column. This approach allows the models to capture different patterns and trends in the housing prices over time, leading to better predictions.\n- Multi-StratifiedKFold: The code uses the StratifiedKFold cross-validation method multiple times with different random seeds. This helps to obtain more reliable statistics about the model's performance by reducing the impact of random variations in the data splitting process. The data is stratified based on the 'made' column to ensure consistent results for the piece-wise model approach.\n- Low number of estimators: The code uses a relatively low number of estimators for the ensemble model (e.g., 300 for XGBoost). This helps to prevent overfitting to the noise in the data and improves the model's generalization ability.\n- Use of all features (except CityCode): The code includes all the features in the training dataset except for the CityCode column. Although the size of the house (squareMeters column) is the most dominant feature, the code finds that the other features also play some role in predicting the housing prices, especially in edge cases. Including these features helps the model make more informed decisions.\n- No extra features: The code does not use any additional artificial features that were tested but did not improve the cross-validation score. This suggests that the original features are sufficient for predicting the housing prices.\n- Inclusion of original data: The code includes the original data from the ParisHousing.csv file in the training dataset. Although the original data may look different based on adversarial validation, the code finds that including the original data, especially the squareMeters column, improves the results.", "title": "Predicting Housing Prices in Paris", "competition_name": "Paris Housing Prices Prediction", "task_category": "Regression", "field": "Modeling", "ranking": "Not specified", "score": "Not specified"}, {"content": "High-ranking Kaggle notebooks or competition strategies: (1) The overall design of this code is to train a high-performing model for a Kaggle competition on stroke prediction. It combines multiple machine learning models, including CatBoost, XGBoost, LGBM, Lasso regression, and a Keras neural network, to make predictions on the test dataset. The code also includes data preprocessing steps, such as handling missing values and scaling the features, as well as ensembling techniques to combine the predictions from different models.\n\n(2) The overall model architecture consists of multiple machine learning models, each trained separately on the training dataset and used to make predictions on the test dataset. The models used in this code are:\n\n- CatBoost: A gradient boosting model that uses decision trees as base learners. It is trained using the CatBoostClassifier or CatBoostRegressor class from the CatBoost library.\n\n- XGBoost: Another gradient boosting model that uses decision trees as base learners. It is trained using the XGBClassifier or XGBRegressor class from the XGBoost library.\n\n- LGBM: A gradient boosting model similar to CatBoost and XGBoost. It is trained using the LGBMClassifier or LGBMRegressor class from the LightGBM library.\n\n- Lasso regression: A linear regression model that uses L1 regularization to perform feature selection. It is trained using the LassoCV class from the scikit-learn library.\n\n- Keras NN: A neural network model implemented using the Keras library. It consists of multiple dense layers with dropout regularization. It is trained using the fit() function from the Keras library.\n\nEach model is trained using a k-fold cross-validation approach, where the training dataset is split into k subsets (folds), and each model is trained on k-1 folds and evaluated on the remaining fold. This process is repeated multiple times to ensure robustness of the model.\n\n(3) The important hyperparameters in this code are:\n\n- n_folds: The number of folds used in the k-fold cross-validation process. It is set to 11 for CatBoost and 20 for XGBoost, LGBM, Lasso regression, and Keras NN.\n\n- MAX_ITER: The maximum number of iterations for training the CatBoost model. It is set to 15000.\n\n- PATIENCE: The number of iterations to wait for improvement in the CatBoost model before early stopping. It is set to 1000.\n\n- DISPLAY_FREQ: The frequency of displaying the evaluation metrics during training of the CatBoost model. It is set to 100.\n\n- MODEL_PARAMS: A dictionary containing the hyperparameters for each model. The specific hyperparameters for each model are described in the code.\n\n- BATCH_SIZE: The batch size used for training the Keras NN model. It is set to 64.\n\n(4) The optimization objective in this code is to maximize the area under the ROC curve (AUC) for the predictions. This is a common objective for binary classification problems like stroke prediction, where the goal is to accurately classify whether a person will have a stroke or not.\n\n(5) The advanced machine learning technique used in this code is ensemble learning. Ensemble learning combines the predictions of multiple models to make a final prediction. In this code, the predictions from CatBoost, XGBoost, LGBM, Lasso regression, and Keras NN models are combined using weighted averaging. Each model contributes to the final prediction with a specific weight, which is determined based on the performance of the model on the training dataset.\n\n(6) Some important tricks that play a role in achieving high performance in this code include:\n\n- Handling missing data: The code uses a k-nearest neighbors imputation technique to fill in missing values in the additional dataset. This helps to ensure that the models have complete and accurate data for training.\n\n- Feature engineering: The code includes some commented-out code for creating additional features based on risk factors for stroke. While these features are not used in the final model, feature engineering can often improve the performance of machine learning models by providing them with more relevant information.\n\n- Scaling the features: The code uses the StandardScaler from the scikit-learn library to scale the numerical features in the dataset. Scaling the features can help to improve the performance of some machine learning models, especially those that are sensitive to the scale of the input data.\n\n- Cross-validation: The code uses k-fold cross-validation to train and evaluate the models. Cross-validation helps to estimate the performance of the models on unseen data and can prevent overfitting by providing a more robust estimate of the model's performance.\n\n- Early stopping: The code uses early stopping in the training process of the CatBoost and Keras NN models. Early stopping allows the models to stop training if there is no improvement in the evaluation metric (AUC) for a certain number of iterations. This helps to prevent overfitting and can save computational resources.\n\n- Ensemble learning: The code combines the predictions from multiple models using weighted averaging. This ensemble approach can help to improve the overall performance by leveraging the strengths of different models and reducing the impact of individual model's weaknesses.\n\n- Hyperparameter tuning: The code sets the hyperparameters for each model based on some initial values. However, hyperparameter tuning can often further improve the performance of the models. In this code, the hyperparameters are not explicitly tuned, but they can be adjusted to optimize the performance for the specific dataset and problem.", "title": null, "competition_name": "stroke prediction", "task_category": "Classification", "field": "Modeling", "ranking": null, "score": null}, {"content": "High-ranking Kaggle notebooks or competition strategies: (1) The overall design of this code is to train a high-performing model for a Kaggle competition. It uses the LightAutoML library, which is a framework for automated machine learning. The code first installs the necessary packages and imports the required libraries. Then, it reads the training and test data from CSV files and performs some data preprocessing steps. After that, it defines the model architecture, sets the hyperparameters, and trains the model using the training data. Finally, it makes predictions on the test data and generates a submission file.\n\n(2) The overall model architecture is a combination of different algorithms, including linear regression, LightGBM, and CatBoost. The TabularAutoML class from the LightAutoML library is used to create an automated machine learning pipeline. This pipeline consists of multiple steps, such as data preprocessing, feature engineering, algorithm selection, and model training. The pipeline automatically selects the best algorithms and hyperparameters based on the given task (binary classification) and metric (AUC). The model architecture is flexible and can be customized by specifying different algorithms and hyperparameters.\n\n(3) The important hyperparameters in this code are:\n\n- `learning_rate`: The learning rate for the gradient boosting algorithm.\n- `min_child_samples`: The minimum number of samples required to create a new leaf node in the gradient boosting algorithm.\n- `reg_alpha`: The L1 regularization term for the gradient boosting algorithm.\n- `reg_lambda`: The L2 regularization term for the gradient boosting algorithm.\n- `num_leaves`: The maximum number of leaves in each tree of the gradient boosting algorithm.\n- `max_depth`: The maximum depth of each tree in the gradient boosting algorithm.\n- `colsample_bytree`: The fraction of features to consider when building each tree in the gradient boosting algorithm.\n- `subsample`: The fraction of samples to consider when building each tree in the gradient boosting algorithm.\n- `subsample_freq`: The frequency of subsampling for each tree in the gradient boosting algorithm.\n- `max_bin`: The maximum number of bins to use for numerical features in the gradient boosting algorithm.\n- `max_depth`: The maximum depth of the CatBoost algorithm.\n- `max_ctr_complexity`: The maximum complexity of categorical features interactions in the CatBoost algorithm.\n- `num_trees`: The number of trees to train in the CatBoost algorithm.\n- `od_wait`: The number of iterations to wait for the CatBoost algorithm to converge.\n- `od_type`: The type of early stopping criteria to use in the CatBoost algorithm.\n- `learning_rate`: The learning rate for the CatBoost algorithm.\n- `min_data_in_leaf`: The minimum number of samples required to create a new leaf node in the CatBoost algorithm.\n\n(4) The optimization objective is to maximize the AUC (Area Under the ROC Curve) metric. The AUC is a commonly used evaluation metric for binary classification problems, which measures the model's ability to distinguish between positive and negative samples. The higher the AUC, the better the model's performance.\n\n(5) This code uses the LightAutoML library, which is an advanced machine learning technique for automated machine learning. It combines multiple algorithms, such as linear regression, LightGBM, and CatBoost, to create an ensemble model that can achieve high performance on various tasks. The library also provides automated feature engineering and hyperparameter optimization, making it easier to build high-performing models without manual intervention.\n\n(6) Some important tricks that play a role in achieving high performance in this code include:\n\n- Feature engineering: The code performs various feature engineering techniques, such as creating new features based on existing ones, encoding categorical features using the WOE (Weight of Evidence) technique, and scaling numerical features using standardization. These techniques help to extract useful information from the data and improve the model's performance.\n\n- Algorithm selection: The code uses a combination of different algorithms, including linear regression, LightGBM, and CatBoost. This ensemble approach helps to capture different patterns in the data and improve the model's predictive power.\n\n- Hyperparameter optimization: The code sets the hyperparameters of the algorithms based on domain knowledge and previous experience. It also uses the LightAutoML library's automated hyperparameter optimization capabilities to fine-tune the hyperparameters and find the best combination for the given task and metric.\n\n- Cross-validation: The code uses 5-fold cross-validation to evaluate the model's performance and prevent overfitting. This technique helps to estimate the model's generalization ability and select the best model based on the average performance across multiple folds.\n\n- Early stopping: The code uses early stopping criteria in the CatBoost algorithm to stop training if the model's performance does not improve for a certain number of iterations. This technique helps to prevent overfitting and save computational resources.\n\n- Ensemble learning: The code combines the predictions of multiple models trained on different subsets of the data to make the final predictions. This ensemble approach helps to reduce the variance and improve the model's robustness.\n\n- Parallel processing: The code uses multiple threads to parallelize the training process and speed up the computation. This technique helps to reduce the training time and improve the overall efficiency.", "title": null, "competition_name": "Kaggle competition", "task_category": "Binary Classification", "field": "Modeling", "ranking": null, "score": "AUC"}, {"content": "The overall design of this code is to train a high-performing model for a Kaggle competition on stroke prediction. It involves data preprocessing, feature engineering, model training, and generating predictions for the test set. The overall model architecture is a sequential neural network model built using the Keras library. The model consists of several dense layers with leaky ReLU activation functions and dropout regularization. The number of layers and neurons in each layer can be adjusted. The final layer uses a sigmoid activation function to output a probability of stroke occurrence. The model is compiled with the Adam optimizer and a custom loss function called SigmoidFocalCrossEntropy, which is a variant of binary cross-entropy loss that focuses on hard examples. The important hyperparameters in this code are: - `class_weight`: The weight assigned to the positive class in the loss function. It is set to 10, indicating that the positive class (stroke occurrence) is given more importance. - `n_folds`: The number of folds used in the cross-validation process. It is set to 12. - `repeats`: The number of times the cross-validation process is repeated. It is set to 5. - `dr`: The dropout rate used in the dropout layers. It is set to 0.3. The optimization objective is to minimize the SigmoidFocalCrossEntropy loss function and maximize the AUC metric. The model is trained using the Adam optimizer with a learning rate of 0.00005. The advanced machine learning technique used in this code is focal loss. Focal loss is a modification of the binary cross-entropy loss that focuses on hard examples by down-weighting easy examples. It helps to address the issue of class imbalance and improve the model's performance on the minority class (stroke occurrence). Other important tricks that play a role in high performance include: - Data preprocessing: The code performs data preprocessing steps such as imputing missing values using a K-nearest neighbors regressor and scaling the numerical features using standardization. - Feature engineering: The code includes additional features based on BMI and risk factors for stroke. These features are created using logical conditions and transformations on existing features. - Cross-validation: The code uses repeated stratified k-fold cross-validation to evaluate the model's performance and reduce overfitting. - Early stopping: The code uses early stopping with a patience of 30 epochs to stop training if the validation loss does not improve for a certain number of epochs. - Learning rate reduction: The code uses a learning rate reduction callback to reduce the learning rate if the validation loss does not improve for a certain number of epochs. - Model ensembling: The code trains multiple models using different folds of the data and averages their predictions to improve the model's performance.", "title": "", "competition_name": "stroke prediction", "task_category": "Classification", "field": "Modeling", "ranking": "", "score": ""}, {"content": "High-ranking Kaggle notebooks or competition strategies: (1) The overall design of this code is to train a machine learning model on a given dataset and make predictions on a test dataset. The code uses the XGBoost algorithm to build a regression model and predicts the prices of certain items. The predictions are then combined with another dataset to generate the final submission file. (2) The overall model architecture is as follows: - The code starts by importing the necessary libraries and modules. - It then reads the sample submission, train, and test datasets from CSV files. - The 'id' and 'cityCode' columns are dropped from the train and test datasets. - Any rows with missing values are dropped from the train dataset. - The features (X) and target variable (y) are extracted from the train dataset. - The train and test datasets are split into training and testing sets using the train_test_split function from sklearn. - An XGBoost regression model is initialized with hyperparameters such as max_depth, learning_rate, n_estimators, objective, and booster. - The XGBoost model is trained on the training set using the fit method. - Predictions are made on the testing set using the predict method. - The 'id' and 'cityCode' columns are dropped from the test dataset. - Predictions are made on the test dataset using the trained XGBoost model. - Another dataset containing price information is read from a CSV file. - The predicted prices and the prices from the additional dataset are combined to generate the final submission file. - The submission file is saved as 'submission.csv' and then read to display the contents. (3) The important hyperparameters in this code are set as follows: - max_depth: 3 - learning_rate: 0.24 - n_estimators: 80000 - objective: 'reg:linear' - booster: 'gbtree' (4) The optimization objective in this code is to minimize the mean squared error (MSE) between the predicted prices and the actual prices. (5) The advanced machine learning technique used in this code is the XGBoost algorithm. XGBoost is a gradient boosting framework that uses a combination of decision trees to make predictions. It is known for its high performance and ability to handle large datasets. (6) Some important tricks that may play a role in achieving high performance in this code include: - Dropping irrelevant columns ('id' and 'cityCode') from the datasets to reduce noise and improve model performance. - Handling missing values by dropping rows with missing values, which ensures that the model is trained on complete data. - Splitting the dataset into training and testing sets using the train_test_split function, which helps evaluate the model's performance on unseen data. - Setting appropriate hyperparameters for the XGBoost model, such as max_depth, learning_rate, and n_estimators, to optimize the model's performance. - Combining predictions from the XGBoost model with prices from an additional dataset to improve the accuracy of the final predictions. - Saving the submission file as 'submission.csv' for further analysis and evaluation.", "title": "Not provided", "competition_name": "Not provided", "task_category": "Regression", "field": "Modeling", "ranking": "Not provided", "score": "Not provided"}, {"content": "High-ranking Kaggle notebooks or competition strategies: One need to trust the local CV when picking the submissions when they are ranked in the public rank 400-500 :) glad it worked here.\n\nThe best single model was a work with some feature engineering and than tuning it with a XGB model via HPO.\nFor the FE I used the orginal data to the comp. data and first manually removed the outliers below:\ntrain[train['made']!=10000]\ntrain[train['floors']!=6000]\ntrain[train['squareMeters']!=6071330]\ntrain[train['garage']!=9017]\ntrain[train['garage']!=2048]\n\nThen I applied some common FE such as scaling, remove perfect collinearity, cardinality reduction, power transform etc.\nI used a custom created HPO FE for finding the best FE for the data. Binned CV FE HPO on the train data is relevant and treat the val data as the coming test data per fold. After this I used the best CV FE HPO for tuning the XGB in the same way.\n\nThis was the best single model, I also used a ensemble with different models, kernels, versions etc for the second submissions.\n\nThats it!", "title": null, "competition_name": null, "task_category": null, "field": "Feature Engineering, Modeling", "ranking": "400-500 (public rank)", "score": null}, {"content": "High-ranking Kaggle notebooks or competition strategies: (1) The overall design of the code is to preprocess the data, train three different models (LGBM, CatBoost, and XGBoost), and then blend the predictions of these models to generate the final submission.\n\n(2) The overall model architecture consists of three models: LGBM, CatBoost, and XGBoost. Each model is trained using a specific set of hyperparameters and features. The training process involves splitting the data into folds, training the model on each fold, and evaluating the performance using RMSE. The predictions of each model are then blended using a weighted average to generate the final predictions.\n\n(3) The important hyperparameters in this code are:\n\n- LGBM:\n  - max_depth: Maximum depth of the tree.\n  - learning_rate: Learning rate for boosting.\n  - min_data_in_leaf: Minimum number of data points in a leaf.\n  - num_leaves: Maximum number of leaves in a tree.\n  - feature_fraction: Fraction of features to be used in each iteration.\n  - bagging_fraction: Fraction of data points to be used in each iteration.\n  - bagging_freq: Frequency of bagging.\n  - lambda_l2: L2 regularization term.\n  - seed: Random seed for reproducibility.\n  - objective: Objective function for regression.\n  - boosting_type: Type of boosting algorithm.\n  - device: Device to use for training.\n  - gpu_platform_id: GPU platform ID.\n  - gpu_device_id: GPU device ID.\n  - n_jobs: Number of parallel threads to use.\n  - metric: Evaluation metric.\n  - verbose: Verbosity level.\n\n- CatBoost:\n  - depth: Maximum depth of the tree.\n  - learning_rate: Learning rate for boosting.\n  - rsm: Feature fraction for each tree.\n  - subsample: Subsample ratio of the training instances.\n  - l2_leaf_reg: L2 regularization term.\n  - min_data_in_leaf: Minimum number of data points in a leaf.\n  - random_strength: Random strength for feature selection.\n  - use_best_model: Whether to use the best model found during training.\n  - task_type: Type of task to perform (CPU or GPU).\n  - bootstrap_type: Type of bootstrap sampling.\n  - grow_policy: Tree growth policy.\n  - random_seed: Random seed for reproducibility.\n  - loss_function: Loss function for regression.\n  - eval_metric: Evaluation metric.\n\n- XGBoost:\n  - max_depth: Maximum depth of the tree.\n  - eta: Learning rate for boosting.\n  - colsample_bytree: Fraction of features to be used in each tree.\n  - subsample: Subsample ratio of the training instances.\n  - min_child_weight: Minimum sum of instance weight needed in a child.\n  - lambda: L2 regularization term.\n  - gamma: Minimum loss reduction required to make a further partition on a leaf node.\n  - tree_method: Tree construction method.\n  - booster: Booster type.\n  - predictor: Predictor type.\n  - seed: Random seed for reproducibility.\n  - objective: Objective function for regression.\n  - eval_metric: Evaluation metric.\n\n(4) The optimization objective is to minimize the root mean squared error (RMSE) between the predicted and actual values of the target variable (MedHouseVal).\n\n(5) The advanced machine learning technique used in this code is ensemble learning. The predictions of multiple models (LGBM, CatBoost, and XGBoost) are blended together using a weighted average to improve the overall performance.\n\n(6) Some important tricks that play a role in achieving high performance include:\n- Generating additional data by merging the original dataset with the California housing dataset.\n- Encoding latitude and longitude coordinates using a trigonometric trick.\n- Transforming latitude and longitude coordinates using PCA and UMAP.\n- Rotating latitude and longitude coordinates using a rotation matrix.\n- Determining the location of coordinates using reverse geocoding.\n- Calculating distances to cities and coast points using the haversine formula.\n- Using feature importance analysis to identify the most important features.\n- Applying rounding to the final predictions to improve the results.", "title": null, "competition_name": null, "task_category": "Regression", "field": "Modeling", "ranking": null, "score": null}, {"content": "The overall design of this code is to solve a Kaggle competition problem related to predicting the median house value for California districts. The code performs various data preprocessing steps, including data loading, exploratory data analysis, feature engineering, and model training. Finally, it generates a submission file with the predicted house values.\n\nThe overall model architecture consists of three different regression models: XGBoost, LightGBM, and CatBoost. Each model is trained using 10-fold cross-validation. The features used for training include 'MedInc', 'HouseAge', 'AveRooms', 'AveBedrms', 'Population', 'AveOccup', 'Latitude', 'Longitude', 'rot_15_x', 'rot_15_y', 'rot_30_x', 'rot_30_y', 'rot_45_x', and 'rot_45_y'. The models are trained using different hyperparameters, and the predictions from each model are combined using weighted averaging.\n\nThe important hyperparameters in this code are set as follows:\n- XGBoost:\n  - n_estimators: 20000\n  - max_depth: 9\n  - learning_rate: 0.01\n  - colsample_bytree: 0.66\n  - subsample: 0.9\n  - min_child_weight: 22\n  - reg_lambda: 16\n  - tree_method: 'gpu_hist'\n- LightGBM:\n  - learning_rate: 0.01\n  - max_depth: 9\n  - num_leaves: 90\n  - colsample_bytree: 0.8\n  - subsample: 0.9\n  - subsample_freq: 5\n  - min_child_samples: 36\n  - reg_lambda: 28\n  - n_estimators: 20000\n- CatBoost:\n  - iterations: 20000\n  - depth: 9\n  - learning_rate: 0.01\n  - rsm: 0.88\n  - subsample: 0.795\n  - min_data_in_leaf: 35\n  - l2_leaf_reg: 8\n  - random_strength: 0.63\n  - bootstrap_type: 'Bernoulli'\n  - grow_policy: 'SymmetricTree'\n\nThe optimization objective of this code is to minimize the Root Mean Squared Error (RMSE) between the predicted median house values and the actual median house values.\n\nThe advanced machine learning techniques used in this code are ensemble learning and stacking. The code trains multiple regression models (XGBoost, LightGBM, and CatBoost) and combines their predictions using weighted averaging to improve the overall performance.\n\nSome important tricks that play a role in achieving high performance in this code include:\n- Feature engineering: The code creates new features by rotating the coordinates (latitude and longitude) to provide more spatial information.\n- Cross-validation: The code uses 10-fold cross-validation to evaluate the performance of the models and prevent overfitting.\n- Model stacking: The code combines the predictions from multiple regression models using weighted averaging to improve the overall prediction accuracy.\n- Hyperparameter tuning: The code tunes the hyperparameters of each model to find the best combination for achieving high performance.\n- Feature importance analysis: The code analyzes the feature importance of each model to understand the contribution of different features in predicting the median house values.", "title": null, "competition_name": "California Housing Prices", "task_category": "Regression", "field": "Modeling", "ranking": null, "score": null}, {"content": "High-ranking Kaggle notebooks or competition strategies: (1) The overall design of this code is to train and evaluate multiple machine learning models for a Kaggle competition. It starts by importing necessary libraries and setting the random seed. Then, it defines the models to be trained and evaluated, along with their hyperparameters. Next, it loops through each model, performs cross-validation, calculates the AUC score, and saves the predictions. Finally, it generates various plots and outputs the final submission files.\n\n(2) The overall model architecture includes a variety of machine learning models such as CatBoost, XGBoost, LightGBM, Logistic Regression, Ridge Regression, Lasso Regression, MLP, and KNN. Each model is trained using the training data and evaluated using cross-validation. The predictions from each model are then combined using voting or blending techniques to generate the final predictions.\n\n(3) The important hyperparameters in this code are set for each model in the `MODELS` dictionary. For example, the hyperparameters for the CatBoost model are defined in the `catboost_params` dictionary. The hyperparameters for other models such as XGBoost, LightGBM, Logistic Regression, etc. are also defined in a similar manner. These hyperparameters control various aspects of the model such as learning rate, depth, regularization, etc.\n\n(4) The optimization objective in this code is to maximize the AUC (Area Under the Curve) score. The AUC score is a commonly used metric for binary classification problems, which measures the model's ability to distinguish between positive and negative samples.\n\n(5) This code uses advanced machine learning techniques such as ensemble learning, stacking, and blending. Ensemble learning is used to combine the predictions of multiple models to improve overall performance. Stacking is used to train a meta-model that combines the predictions of multiple base models. Blending is used to average the predictions of multiple models to generate the final predictions.\n\n(6) Some important tricks that play a role in high performance include:\n- Cross-validation: The models are evaluated using cross-validation to get a more robust estimate of their performance.\n- Feature scaling: The features are scaled using various scalers such as StandardScaler, MinMaxScaler, etc. to ensure that they are on a similar scale and to improve model performance.\n- Feature selection: The code includes feature selection techniques such as mutual information regression/classification to select the most informative features for training the models.\n- Early stopping: Some models use early stopping to prevent overfitting and improve generalization performance.\n- Hyperparameter tuning: The hyperparameters of each model are tuned using techniques such as grid search or Optuna to find the best combination of hyperparameters for each model.\n- Model comparison: The code includes various plots and metrics to compare the performance of different models and select the best ones for blending or stacking.", "title": "Not provided", "competition_name": "Not provided", "task_category": "Classification", "field": "Modeling", "ranking": "Not provided", "score": "AUC score"}, {"content": "High-ranking Kaggle notebooks or competition strategies: (1) The overall design of the code is to preprocess the data, perform exploratory data analysis (EDA), and then train three different models (LGBM, CatBoost, and XGBoost) on the preprocessed data. Finally, the predictions from these models are blended together to create the final submission.\n\n(2) The overall model architecture consists of three different models: LGBM, CatBoost, and XGBoost. Each model is trained separately on the preprocessed data. The LGBM model uses the LightGBM library, the CatBoost model uses the CatBoost library, and the XGBoost model uses the XGBoost library. Each model is trained using a specific set of hyperparameters and the training process involves creating a dataset, defining the model architecture, training the model, and evaluating the performance.\n\n(3) The important hyperparameters in this code are:\n\n- LGBM hyperparameters:\n  - max_depth: Maximum depth of the tree. Default value is 9.\n  - learning_rate: Learning rate for boosting. Default value is 0.01.\n  - min_data_in_leaf: Minimum number of data points in a leaf. Default value is 36.\n  - num_leaves: Maximum number of leaves in a tree. Default value is 100.\n  - feature_fraction: Fraction of features to be used in each iteration. Default value is 0.8.\n  - bagging_fraction: Fraction of data points to be used in each iteration. Default value is 0.89.\n  - bagging_freq: Frequency of bagging. Default value is 5.\n  - lambda_l2: L2 regularization term. Default value is 28.\n\n- CatBoost hyperparameters:\n  - depth: Maximum depth of the tree. Default value is 9.\n  - learning_rate: Learning rate for boosting. Default value is 0.01.\n  - rsm: Random subspace method. Default value is 0.88.\n  - subsample: Fraction of data points to be used in each iteration. Default value is 0.795.\n  - l2_leaf_reg: L2 regularization term. Default value is 8.\n  - min_data_in_leaf: Minimum number of data points in a leaf. Default value is 35.\n  - random_strength: Random strength for feature selection. Default value is 0.63.\n\n- XGBoost hyperparameters:\n  - max_depth: Maximum depth of the tree. Default value is 9.\n  - eta: Learning rate for boosting. Default value is 0.01.\n  - colsample_bytree: Fraction of features to be used in each iteration. Default value is 0.66.\n  - subsample: Fraction of data points to be used in each iteration. Default value is 0.76.\n  - min_child_weight: Minimum sum of instance weight needed in a child. Default value is 22.\n  - lambda: L2 regularization term. Default value is 16.\n  - gamma: Minimum loss reduction required to make a further partition on a leaf node. Default value is 1.\n\n(4) The optimization objective is to minimize the root mean squared error (RMSE) between the predicted values and the actual target values. The RMSE is calculated using the `rmse` function.\n\n(5) The advanced machine learning techniques used in this code are gradient boosting algorithms, specifically LGBM, CatBoost, and XGBoost. These algorithms are known for their ability to handle large datasets, handle missing values, and handle categorical features.\n\n(6) Some important tricks that play a role in achieving high performance in this code are:\n\n- Data preprocessing: The code performs various preprocessing steps such as generating additional data, encoding tricks, clustering, dimensionality reduction using PCA and UMAP, coordinate rotation, location determination, and distance calculations. These preprocessing steps help in extracting meaningful features from the data and improving the performance of the models.\n\n- Feature importance analysis: The code includes a function `f_importance_plot` that plots the feature importances of the models. This helps in identifying the most important features and understanding their impact on the predictions.\n\n- Model blending: The code blends the predictions from the three models (LGBM, CatBoost, and XGBoost) using a weighted average. This helps in leveraging the strengths of each model and improving the overall prediction accuracy.\n\n- Hyperparameter tuning: The code uses the Optuna library for hyperparameter tuning. Optuna is an automatic hyperparameter optimization framework that helps in finding the best set of hyperparameters for the models. This helps in improving the performance of the models by finding the optimal configuration of hyperparameters.\n\n- Cross-validation: The code uses K-fold cross-validation with 10 folds to evaluate the performance of the models. This helps in obtaining a more robust estimate of the model's performance and reduces the risk of overfitting.\n\n- Early stopping: The code uses early stopping to prevent overfitting and improve the training efficiency of the models. Early stopping stops the training process if the performance on the validation set does not improve for a certain number of iterations.\n\n- Memory management: The code includes memory management techniques such as garbage collection (`gc.collect()`) to free up memory and improve the efficiency of the code.\n\n- Parallel processing: The code uses parallel processing (`n_jobs=-1`) to utilize multiple CPU cores for training the models. This helps in speeding up the training process and improving the overall performance.", "title": null, "competition_name": null, "task_category": "Regression", "field": "Modeling", "ranking": null, "score": null}, {"content": "My brief write-up of the 9th place solution can be found in the attached link. A simple automl approach using autogluon, with the original data included within the training loops, but not the cross-validation, ended up being my highest local cross-validation. - I used a 5-fold StratifiedKFold split, with the classes being the three groups of price/sqm (~10/sqm, ~100/sqm, and ~1000/sqm). - I tried multiclass classification on these three groups, but it ultimately did not improve the modelling. - Feature engineering, oversampling of the minority classes (~10/1000/sqm), and undersampling of the majority classes (~100/sqm) were also not helpful in my experimentation to improve the local cross-validation. In the notebook, I have outlined what worked for me and what did not. Unlike some of the other top scores, I was not able to achieve high local cross-validation using a single model.", "title": "9th place solution write-up", "competition_name": "Not explicitly mentioned", "task_category": "Classification", "field": "Modeling", "ranking": "9th place", "score": "Not explicitly mentioned"}, {"content": "High-ranking Kaggle notebooks or competition strategies: (1) The overall design of this code is to train multiple regression models using different algorithms (XGBoost, LightGBM, CatBoost) and then blend or stack the predictions from these models to make the final submission for a Kaggle competition. The code includes data preprocessing, exploratory data analysis (EDA), model training, feature importance analysis, and submission generation.\n\n(2) The overall model architecture consists of three different regression models: XGBoost, LightGBM, and CatBoost. Each model is trained using a 10-fold cross-validation strategy. The XGBoost model is trained with 10,000 estimators, a maximum depth of 9, a learning rate of 0.001, a column subsample ratio of 0.66, a row subsample ratio of 0.9, a minimum child weight of 20, a regularization lambda of 16, and using GPU acceleration. The LightGBM model is trained with 10,000 estimators, a maximum depth of 9, 100 leaves, a column subsample ratio of 0.8, a row subsample ratio of 0.9, a subsample frequency of 5, a minimum child sample size of 36, a regularization lambda of 28, and using early stopping with a patience of 100. The CatBoost model is trained with 20,000 iterations, a maximum depth of 9, a learning rate of 0.01, a column subsample ratio of 0.88, a row subsample ratio of 0.795, a minimum data in leaf of 35, an L2 regularization lambda of 8, a random strength of 0.63, using Bernoulli bootstrap sampling, symmetric tree growth policy, and early stopping with a patience of 100.\n\n(3) The important hyperparameters in this code are set as follows:\n- XGBoost: n_estimators=10000, max_depth=9, learning_rate=0.001, colsample_bytree=0.66, subsample=0.9, min_child_weight=20, reg_lambda=16, tree_method='gpu_hist', seed=42\n- LightGBM: learning_rate=0.01, max_depth=9, num_leaves=100, colsample_bytree=0.8, subsample=0.9, subsample_freq=5, min_child_samples=36, reg_lambda=28, n_estimators=10000, metric='rmse', random_state=42\n- CatBoost: iterations=20000, depth=9, learning_rate=0.01, rsm=0.88, subsample=0.795, min_data_in_leaf=35, l2_leaf_reg=8, random_strength=0.63, bootstrap_type='Bernoulli', grow_policy='SymmetricTree', loss_function='RMSE', eval_metric='RMSE', task_type=\"CPU\", random_state=42\n\n(4) The optimization objective of this code is to minimize the root mean squared error (RMSE) between the predicted and actual values of the target variable (MedHouseVal).\n\n(5) The advanced machine learning techniques used in this code are ensemble learning and stacking. Ensemble learning is used by training multiple regression models (XGBoost, LightGBM, CatBoost) and combining their predictions to improve the overall performance. Stacking is used by blending the predictions from different models to make the final submission.\n\n(6) Some important tricks that play a role in achieving high performance in this code include:\n- Feature engineering: The code includes the creation of new features by rotating the coordinates (longitude and latitude) to provide more spatial information.\n- Cross-validation: The models are trained using a 10-fold cross-validation strategy to evaluate their performance and reduce overfitting.\n- Early stopping: The LightGBM and CatBoost models use early stopping to prevent overfitting by stopping the training process if the performance on the validation set does not improve for a certain number of iterations.\n- Hyperparameter tuning: The hyperparameters of the models are carefully tuned to optimize their performance.", "title": "Not provided", "competition_name": "Not provided", "task_category": "Regression", "field": "Modeling", "ranking": "Not provided", "score": "Not provided"}, {"content": "High-ranking Kaggle notebooks or competition strategies: (1) The overall design of this code is to train multiple machine learning models on a dataset for a kaggle competition. It uses three original datasets, but only includes data with stroke = 1. It applies data preprocessing techniques such as scaling and encoding to prepare the data. It then trains three different models (LGBMClassifier, CatBoostClassifier, and RandomForestClassifier) using RepeatedKFold cross-validation. Finally, it combines the predictions of these models using an ensemble technique and generates a submission file.\n\n(2) The overall model architecture consists of three different machine learning models: LGBMClassifier, CatBoostClassifier, and RandomForestClassifier. These models are trained using the training data and evaluated using cross-validation. The predictions of these models are then combined using an ensemble technique to generate the final predictions for the test data.\n\n(3) The important hyper-parameters in this code are as follows:\n- `random`: The random seed used for reproducibility.\n- `load_original`: A boolean flag indicating whether to load external data or not.\n- `only_positive`: A boolean flag indicating whether to include only positive stroke cases or not.\n- `folds`: The number of folds to use in cross-validation.\n- `n_estimators`: The number of estimators (trees) to use in the LGBMClassifier and RandomForestClassifier models.\n- `iterations`: The number of iterations to use in the CatBoostClassifier model.\n- `min_samples_leaf`: The minimum number of samples required to be at a leaf node in the RandomForestClassifier model.\n- `max_depth`: The maximum depth of the tree in the RandomForestClassifier model.\n- `max_samples`: The maximum number of samples to use in the RandomForestClassifier model.\n- `class_weight`: The class weights to use in the RandomForestClassifier model.\n\n(4) The optimization objective of this code is to maximize the area under the ROC curve (ROC AUC) for the predictions of the machine learning models. This is measured using the roc_auc_score metric.\n\n(5) The advanced machine learning technique used in this code is ensemble learning. The predictions of multiple machine learning models (LGBMClassifier, CatBoostClassifier, and RandomForestClassifier) are combined using an ensemble technique to improve the overall performance.\n\n(6) Some important tricks that play a role in high performance in this code include:\n- Using three original datasets to increase the amount of training data.\n- Applying data preprocessing techniques such as scaling and encoding to handle different types of features.\n- Using RepeatedKFold cross-validation to evaluate the models and reduce overfitting.\n- Tuning the hyperparameters of the models to optimize performance.\n- Using ensemble learning to combine the predictions of multiple models and improve performance.", "title": "", "competition_name": "", "task_category": "Classification", "field": "Modeling", "ranking": "", "score": "roc_auc_score"}, {"content": "Thanks to all the competitors for another week of informative discussions!  Thanks also to the Kaggle organizers for another interesting episode of the Playground Series.  I was able to garner an 8th place position using my XGBoost + focused CV approach from Episode 2 ([notebook]( and [discussion](\n\nThe notebook I used for this competition can be found [here](\n\n### Influences\n\nThe main influence on this week's competition was the [fantastic EDA notebook]( by @craigmthomas.  I studied this one very closely and made a lot of decisions from this EDA work.  **Give that notebook an upvote!**\n\n### Modeling \n\nAs I did in Episode 2, used tried a variety of techniques (XGBoost, CatBoost, Neural Net, Logistic Regression), and XGBoost consistently gave me the best CVs.  Others came close, but never quite surpassed XGBoost.\n\nI used the same CV strategy as before in that I did 10-fold cross-validation and only used the synthetic dataset for calculation of AUC in each fold.   I added the original dataset (using the whole dataset this time around) to the training set within each fold, but did not measure performance on the original set in any way.  I believe this was a huge factor in this competition particularly given the very unbalanced nature of the target class and the small dataset size.  There were too many opportunities for overtraining to occur. \n\n### Feature Engineering\n\nA big difference for this competition was the way I approached feature engineering.  The data consisted of a number of different types of data, and I approached each type independently.\n\n####  Winsorization\n\nOthers found that there were some data points with overly extreme values.  I chose to reset those extreme values to the maximum value for that particular feature.  Nothing unique here - there are lots of notebooks where others did the same.  There were only 2 Winsorizations, but it did take away their outlier status.\n\n#### Label Encoding\n\nOne variable, `BusinessTravel` was an ordinal variable with text categories, `Non-Travel`, `Travel_Rarely`, `Travel_Frequently`.  These 3 categories have a logical order that can be converted to numerical values [0, 1, 2].  I anticipated high levels of `BusinessTravel` would lead to Attrition, and wanted to maintain the ordinal nature of the variable, rather than converting it to multiple one-hot-encoded files.\n\n#### Ordinal Variables\n\nThere were a number of ordinal variables that were coded numerically.  I left these in their original form as I thought the relative levels could be important, and one-hot encoding would have increased the total number of features substantially.\n\n#### One-hot Encoding\n\nThere were 6 categorical features for which I used one-hot encoding.  I was concerned about the number of additional columns this would create, even when using sparse one-hot encoding, and looked at the various features (in a quick and dirty [notebook](  For this figure, I took all the models for which an average CV of 0.8 or greater was found and calculated variable importances - 100s of models.  The boxplots show those importances (y-axis) by each variable.  \n\n`JobRole` in particular looks like there is high attrition in sales-related roles and lower attrition in other roles - see the far right of the boxplot.  I tried changing this to Sales and Non-sales categories, but it didn't seem to help.  For min 8th place submission, I left all the one-hot encoded columns in place.  I also used this to drop a few columns, but my results didn't improve.\n\n#### Center and Scale\n\nFor the continuous variables, I also centered and scaled them, probably more out of habit.  I'm sure this doesn't matter for XGBoost.\n\n### TPOT\n\nOne very interesting result came from using [TPOT]( an autoML tool.  I ran TPOT multiple times with small, short simulations just to get an idea of what kinds of models it found.  About 90% of the time XGBoost or a GradientBoostingClassifer was the top classifier.", "title": "Not provided", "competition_name": "Playground Series", "task_category": "Classification", "field": "Modeling", "ranking": "8th place", "score": "Not provided"}, {"content": "# Hello, everybody!\n\nI'd like to believe it wasn't just luck.\nMy work here \ntips:\n1. Using the original data (\n2. CV with n_splits = 5, n_repeats =10.\n3. Applying Permutation Importance for each model separately.\n4. Using three models (CAT, XGB, RF) for the first level and LGBM as a metamodel.\n\nFriends, good luck with the books!", "title": "not available", "competition_name": "not available", "task_category": "not available", "field": "Modeling", "ranking": "not available", "score": "not available"}, {"content": "High-ranking Kaggle notebooks or competition strategies: (1) The overall design of this code is to train a machine learning model on a dataset and make predictions on a test dataset. The code uses the XGBoost algorithm to build a regression model and predicts the prices of houses based on various features. The training data is split into training and testing sets, and the model is trained on the training set. The trained model is then used to make predictions on the test set. The final predictions are combined with another dataset to create the submission file for the Kaggle competition.\n\n(2) The overall model architecture is based on the XGBoost algorithm, which is a gradient boosting framework. XGBoost stands for eXtreme Gradient Boosting and is an implementation of the gradient boosting algorithm. Gradient boosting is an ensemble learning method that combines multiple weak models (decision trees in this case) to create a strong predictive model.\n\nIn this code, the XGBRegressor class from the xgboost library is used to create the XGBoost model. The model is initialized with the following hyperparameters:\n- max_depth: The maximum depth of each tree in the boosting process. It controls the complexity of the model and helps prevent overfitting.\n- learning_rate: The learning rate or step size shrinkage used in each boosting iteration. It controls the contribution of each tree to the final prediction.\n- n_estimators: The number of boosting iterations or the number of trees in the model.\n- objective: The loss function to be minimized during training. In this case, it is set to 'reg:linear' for regression.\n- booster: The type of booster to use. It is set to 'gbtree' for tree-based models.\n\nThe XGBRegressor model is then trained on the training data using the fit() method. The trained model is used to make predictions on the test data using the predict() method.\n\n(3) The important hyperparameters in this code are set as follows:\n- max_depth: 3\n- learning_rate: 0.24\n- n_estimators: 2000\n- objective: 'reg:linear'\n- booster: 'gbtree'\n\nThese hyperparameters are set based on the specific problem and dataset. The values chosen for these hyperparameters may have been determined through experimentation or tuning to achieve the best performance.\n\n(4) The optimization objective in this code is to minimize the mean squared error (MSE) between the predicted prices and the actual prices. The XGBoost algorithm uses gradient boosting to iteratively minimize the objective function, which in this case is the MSE.\n\nThe mean_squared_error() function from the sklearn.metrics module is used to calculate the MSE between the predicted prices and the actual prices.\n\n(5) The advanced machine learning technique used in this code is gradient boosting with the XGBoost algorithm. Gradient boosting is an ensemble learning method that combines multiple weak models (decision trees in this case) to create a strong predictive model. XGBoost is an implementation of the gradient boosting algorithm that is known for its efficiency and performance.\n\n(6) Some important tricks that may play a role in achieving high performance in this code include:\n- Data preprocessing: The code drops certain columns from the training and test datasets using the drop() method. This may be done to remove irrelevant or redundant features that do not contribute to the prediction task.\n- Handling missing values: The code uses the dropna() method to remove rows with missing values from the training dataset. This ensures that the model is trained on complete data and avoids potential issues with missing values during training.\n- Train-test split: The code splits the training data into training and testing sets using the train_test_split() function from the sklearn.model_selection module. This allows for evaluation of the model's performance on unseen data and helps prevent overfitting.\n- Ensemble learning: The code combines the predictions from the XGBoost model with another dataset to create the final submission file. This ensemble approach may help improve the overall performance by leveraging the strengths of multiple models or datasets.\n- Hyperparameter tuning: The hyperparameters of the XGBoost model are set based on specific values chosen for max_depth, learning_rate, n_estimators, objective, and booster. These hyperparameters may have been tuned or optimized to achieve the best performance on the given dataset.", "title": null, "competition_name": "House Prices Prediction", "task_category": "Regression", "field": "Modeling", "ranking": null, "score": null}, {"content": "**24th place!**🏅 I recently decided to get back into Kaggle competitions, and I’m very happy with my performance on this one. One year ago, I competed in the Sartorius Cell Instance Segmentation competition and it was one of the most rewarding things I’ve done in the past two years. The amount of information I learned in such a short period of time was astonishing. The same goes for this competition. Prior to this competition I hadn’t competed in any tabular competitions, and I again learned an incredible amount of information. To that end, I want to thank the Kaggle team for putting together these competitions and thank everyone who competed for making the competition enjoyable for noobs like myself. \n\nI would like to especially give a shout out to the following four notebooks and discussions that I continuously referenced throughout the competition, I couldn’t have done it without these (go give them an upvote):\n- @phongnguyen1 - \n- @dmitryuarov - \n- @thedevastator - \n- @tilii7 - \n\n### My Solution:\n- Quite frankly, I didn’t do anything groundbreaking. My solution consisted of an ensemble of XGBoost, LightGBM, and CatBoost using a 10 KFold split. I did some light hyperparameter optimization using Optuna for the XGBoost model, though not on the LightGBM or CatBoost model parameters.\n- **Feature Engineering:**\n- Distance to any California city with over 500,000 population.\n- Encoding trick listed [here](\n- Distance to coastline features as listed in [this discussion](\n- PCA coordinates\n- Rotated coordinates (15, 30, 45)\n- Polar coordinates.\n- **CV:** To compute my CV score, I used an 80/20 split of the training data and excluded the “original” dataset to get more accurate scores. \n- **Trusting local CV:** After playing around a bit with various models and feature engineering ideas, I decided to trust my CV score and determined that the top public leaderboard scores were either doing some crazy feature engineering or were slightly overfit. Trusting my CV was the right choice as I increased my position 24 spots in the private leaderboard :)\n\nThis competition will likely be the first of many for me this year, and hopefully you all will be seeing a lot more of me. I aim to play these tabular series until I land a top 3 position in one of them (I’m coming for you Kaggle merch).\n\nYou can find my solution notebook here: ", "title": "24th place!🏅", "competition_name": "Not explicitly mentioned", "task_category": "Not explicitly mentioned", "field": "Feature Engineering, Modeling", "ranking": "24th place", "score": "Not explicitly mentioned"}, {"content": "High-ranking Kaggle notebooks or competition strategies: (1) The overall design of the code is to train multiple machine learning models (Catboost, XGBoost, and LightGBM) on a dataset and make predictions on a test dataset. The predictions from each model are then combined using weighted averaging to generate the final prediction. The code also includes various data preprocessing steps, such as feature engineering, encoding, and distance calculations.\n\n(2) The overall model architecture consists of three machine learning models: Catboost, XGBoost, and LightGBM. Each model is trained separately on the training dataset and used to make predictions on the test dataset. The predictions from each model are then combined using weighted averaging to generate the final prediction.\n\nThe Catboost model is initialized with the following parameters:\n- random_seed: 1234\n- iterations: 15000\n- early_stopping_rounds: 1000\n- use_best_model: True\n- eval_metric: RMSE\n- verbose: 1000\n\nThe XGBoost model is initialized with the following parameters:\n- n_estimators: 1000\n- max_depth: 4\n- colsample_bytree: 0.9\n- subsample: 1\n- reg_lambda: 20\n\nThe LightGBM model is initialized with the following parameters:\n- learning_rate: 0.01\n- max_depth: 9\n- num_leaves: 90\n- colsample_bytree: 0.8\n- subsample: 0.9\n- subsample_freq: 5\n- min_child_samples: 36\n- reg_lambda: 28\n- n_estimators: 20000\n- metric: rmse\n\n(3) The important hyperparameters in this code are set as follows:\n- For Catboost:\n  - random_seed: 1234\n  - iterations: 15000\n  - early_stopping_rounds: 1000\n  - eval_metric: RMSE\n  - verbose: 1000\n- For XGBoost:\n  - n_estimators: 1000\n  - max_depth: 4\n  - colsample_bytree: 0.9\n  - subsample: 1\n  - reg_lambda: 20\n- For LightGBM:\n  - learning_rate: 0.01\n  - max_depth: 9\n  - num_leaves: 90\n  - colsample_bytree: 0.8\n  - subsample: 0.9\n  - subsample_freq: 5\n  - min_child_samples: 36\n  - reg_lambda: 28\n  - n_estimators: 20000\n\n(4) The optimization objective of this code is to minimize the root mean squared error (RMSE) between the predicted values and the actual values of the target variable (MedHouseVal).\n\n(5) The advanced machine learning technique used in this code is ensemble learning. Multiple machine learning models (Catboost, XGBoost, and LightGBM) are trained separately on the dataset, and their predictions are combined using weighted averaging to generate the final prediction. This ensemble approach helps to improve the overall performance and robustness of the model.\n\n(6) Some important tricks that play a role in achieving high performance in this code include:\n- Feature engineering: The code includes various feature engineering steps, such as calculating distances to cities and coast points, combining latitude and longitude, and creating new features based on PCA and UMAP.\n- Encoding: The code uses encoding techniques to transform categorical variables into numerical representations, such as one-hot encoding for the \"place\" variable.\n- Data preprocessing: The code includes various data preprocessing steps, such as dropping unnecessary columns, handling missing values, and scaling features.\n- Hyperparameter tuning: Although the code does not explicitly mention hyperparameter tuning, it is likely that the hyperparameters of each model have been tuned to achieve the best performance.\n- Ensemble learning: The code combines the predictions from multiple models using weighted averaging, which helps to improve the overall performance and robustness of the model.", "title": null, "competition_name": null, "task_category": "Regression", "field": "Modeling", "ranking": null, "score": "RMSE"}, {"content": "High-ranking Kaggle notebooks or competition strategies: (1) The overall design of the code is to solve a regression task using synthetic data generated from a deep learning model trained with the California housing dataset. The code imports various libraries for data manipulation, model training, and evaluation. It then loads the augmented data with geo places and performs exploratory data analysis (EDA) to understand the data distribution and missing values. The code also includes additional features such as distance to cities, distance to coastlines, clustering, rotation features, and other geo features. It trains multiple models (LGBMRegressor, CatBoostRegressor, XGBRegressor) using k-fold cross-validation and evaluates their performance. Finally, it combines the predictions from different models and generates a submission file.\n\n(2) The overall model architecture is a combination of gradient boosting models (LGBMRegressor, CatBoostRegressor, XGBRegressor). The code uses the LGBMRegressor, CatBoostRegressor, and XGBRegressor classes from the respective libraries to create instances of these models. The models are trained using the `fit` method with the training data and evaluated using the mean squared error (MSE) metric. The code uses k-fold cross-validation to train and evaluate the models on different folds of the data. The predictions from the models are combined to generate the final submission.\n\n(3) The important hyperparameters in this code are set as follows:\n- LGBM_PARAMS: The hyperparameters for the LGBMRegressor model, including `max_depth`, `n_estimators`, `learning_rate`, `device`, and `random_state`.\n- N_SPLITS: The number of splits for k-fold cross-validation.\n- CB: The hyperparameters for the CatBoostRegressor model, including `n_estimators`, `early_stopping_rounds`, and `random_seed`.\n- XGB_PARAMS: The hyperparameters for the XGBRegressor model, including `n_estimators`, `max_depth`, `learning_rate`, `colsample_bytree`, `subsample`, `min_child_weight`, `reg_lambda`, `early_stopping_rounds`, `eval_metric`, and `seed`.\n\n(4) The optimization objective is to minimize the mean squared error (MSE) between the predicted and actual target values. This is calculated using the `mean_squared_error` function from the `sklearn.metrics` module.\n\n(5) The code uses advanced machine learning techniques such as gradient boosting with LGBMRegressor, CatBoostRegressor, and XGBRegressor models. These models are known for their high performance in regression tasks and are widely used in competitions like Kaggle.\n\n(6) Some important tricks that play a role in high performance include:\n- Adding additional geo features such as distance to cities, distance to coastlines, clustering, rotation features, and other geo features.\n- Using k-fold cross-validation to train and evaluate the models, which helps to assess the model's performance on different subsets of the data and reduce overfitting.\n- Combining the predictions from multiple models to generate the final submission, which can help to improve the overall performance by leveraging the strengths of different models.\n- Tuning the hyperparameters of the models to find the best combination that minimizes the mean squared error (MSE).\n- Using advanced libraries such as LGBM, CatBoost, and XGBoost, which are known for their high performance and efficient implementation of gradient boosting algorithms.", "title": "", "competition_name": "California housing dataset", "task_category": "Regression", "field": "Modeling", "ranking": "", "score": ""}, {"content": "High-ranking Kaggle notebooks or competition strategies: (1) The overall design of this code is to train and evaluate multiple machine learning models for a Kaggle competition. It starts by importing necessary libraries and loading the training, testing, and submission data. Then, it performs exploratory data analysis (EDA) to gain insights into the data. After that, it applies feature engineering techniques to create additional features. Finally, it trains and evaluates multiple models using cross-validation and ensembles the predictions for the final submission.\n\n(2) The overall model architecture consists of multiple machine learning models, including CatBoost, LightGBM, and XGBoost. Each model is trained using the training data and evaluated using cross-validation. The models are then ensembled to make the final predictions for the testing data. The CatBoost and LightGBM models use gradient boosting algorithms, while the XGBoost model uses a feedforward neural network architecture.\n\n(3) The important hyperparameters in this code are:\n\n- CatBoostRegressor:\n  - iterations: Number of boosting iterations.\n  - loss_function: Loss function to optimize.\n  - early_stopping_rounds: Number of rounds with no improvement to stop training.\n  - use_best_model: Whether to use the best model found during training.\n\n- LGBMRegressor:\n  - learning_rate: Learning rate for boosting.\n  - n_estimators: Number of boosting iterations.\n  - metric: Evaluation metric.\n  - lambda_l1: L1 regularization term.\n  - num_leaves: Maximum number of leaves in each tree.\n  - feature_fraction: Fraction of features to consider for each tree.\n  - bagging_fraction: Fraction of data to use for each tree.\n  - bagging_freq: Frequency of bagging.\n  - min_data_in_leaf: Minimum number of data points in each leaf.\n  - max_depth: Maximum depth of each tree.\n\n- XGBRegressor:\n  - learning_rate: Learning rate for boosting.\n  - n_estimators: Number of boosting iterations.\n  - eval_metric: Evaluation metric.\n  - max_depth: Maximum depth of each tree.\n  - colsample_bytree: Fraction of features to consider for each tree.\n  - subsample: Fraction of data to use for each tree.\n  - min_child_weight: Minimum sum of instance weight needed in a child.\n  - reg_lambda: L2 regularization term.\n  - tree_method: Method to use for constructing trees.\n\n(4) The optimization objective is to minimize the root mean squared error (RMSE) between the predicted and actual values of the target variable (MedHouseVal).\n\n(5) The advanced machine learning technique used in this code is gradient boosting. It is used in the CatBoost, LightGBM, and XGBoost models to iteratively train weak learners and combine their predictions to make accurate predictions.\n\n(6) Some important tricks that play a role in achieving high performance include:\n\n- Additional training data: The code combines the original training data with additional generated data to increase the size of the training set and improve model performance.\n\n- Feature engineering: The code creates additional features based on latitude and longitude, such as distance to cities and distance to the coastline. These features provide additional information that can help the models make more accurate predictions.\n\n- Categorical feature encoding: The code encodes the categorical feature 'admin2' using the 'astype' method to convert it to a category type. This allows the models to handle categorical features more efficiently.\n\n- Scaling for neural network: The code uses the MinMaxScaler from sklearn.preprocessing to scale the input features for the feedforward neural network. Scaling the features can help improve the convergence and performance of the neural network.\n\n- Ensemble of models: The code ensembles the predictions of multiple models to make the final predictions for the testing data. This can help improve the overall performance by combining the strengths of different models.\n\n- Cross-validation: The code uses KFold cross-validation to evaluate the models. This helps estimate the performance of the models on unseen data and prevents overfitting.\n\n- Early stopping: The code uses early stopping in the training process of the CatBoost and LightGBM models. This allows the models to stop training if there is no improvement in the evaluation metric for a certain number of rounds, preventing overfitting and saving computational resources.\n\n- Hyperparameter tuning: The code manually sets the hyperparameters for the models based on prior knowledge or experimentation. Tuning the hyperparameters can help optimize the performance of the models.\n\n- Feature importance analysis: The code calculates and prints the feature importances of the models. This helps identify the most important features for making predictions and can guide further feature engineering or model selection.", "title": "", "competition_name": "", "task_category": "Regression", "field": "Modeling", "ranking": "", "score": ""}, {"content": "High-ranking Kaggle notebooks or competition strategies: First of all, thanks to the organizers for a fun, short competition. Also thanks to the many notebook contributors in this competition!!!🎉\n\nMy final solution is an ensemble of some public contributions with some of my own personal ideas. \n\n-I felt like the boosting path was well-explored by many public notebooks and designed to base my boosting approach on these methods; as mentiond, distance using coordinates plays a big part.\n\n-I noticed many people added the external data to their dataset and computed their CV score using this data. Since the competition data is an **adaptation** of the original dataset, I think this is why some CV scores weren't very well aligned. Instead, I ran a CV split on the original data, and added the external data to the training set afterwards. This forces validation on the supplied dataset, better representing the LB score. Ensembling this with methods that split on the full merged data seemed to diversify a lot and improve LB.\n\n-Lastly, I also training a NN in keras using [keras_tuner]( on the standard features + coordinate features. Local CV was only 0.59, but this also added significant diversification in the full blend. Model summary can be seen below:\n\n![](", "title": null, "competition_name": null, "task_category": null, "field": "Modeling", "ranking": null, "score": "0.59"}, {"content": "First - thanks for the fun competition, great public solutions and contributions! 👍\n\nThis will be a short summary but still as some maybe are interested in what FE/models etc. included to the solution.\n\nDidn't had much time for this competition while doing other as well but joined the competitions for trying some new frameworks versions in this specific dataset.\n\nI finally picked the AutoGluon framework and its tabular predictor for the task.\n\"AutoGluon-Tabular: Robust and Accurate AutoML for Structured Data\" - \n\nFor the FE part I used a public notebook  ,  credit to author!\n\nThe AG trained solution is an weighted ensemble of many 8 fold trained common architectures as xgb,lgbm,catb,RF,NN etc and it also used bootstrap aggregation and stacking(3 levels for this one).\n\nThe final local CV score was 0.5006.\n\nThat's it! 🙂", "title": "AutoGluon-Tabular: Robust and Accurate AutoML for Structured Data", "competition_name": "Not explicitly mentioned", "task_category": "Not explicitly mentioned, but likely Classification or Regression", "field": "Modeling", "ranking": "Not mentioned", "score": "0.5006 (local CV score)"}, {"content": "High-ranking Kaggle notebooks or competition strategies: (1) The overall design of this code is to predict housing prices in Paris. It starts by reading in the training and test datasets, as well as an additional dataset called 'original'. It then performs some data preprocessing steps, such as filling missing values and transforming variables. Next, it explores the data through visualizations and correlation analysis. After that, it splits the data into three subsets based on the 'made' variable. For each subset, it trains an XGBoost regression model to predict the housing prices. Finally, it combines the predictions from the three subsets and generates a submission file.\n\n(2) The overall model architecture is based on XGBoost, which is a gradient boosting framework. XGBoost is an ensemble learning method that combines multiple weak models (decision trees) to create a strong predictive model. In this code, three separate XGBoost models are trained on different subsets of the data. Each model is trained to predict the housing prices based on a set of numerical features. The models are trained using the XGBRegressor class from the xgboost library. The hyperparameters of the XGBoost models are set as follows: max_depth=3, learning_rate=0.24, n_estimators=2000, objective='reg:linear', booster='gbtree'. These hyperparameters control the complexity of the trees, the learning rate of the model, the number of trees in the ensemble, the loss function to optimize, and the type of booster to use.\n\n(3) The important hyperparameters in this code are set as follows:\n- max_depth: The maximum depth of each tree in the ensemble. It is set to 3, which means each tree can have a maximum of 3 levels of nodes.\n- learning_rate: The learning rate or shrinkage factor of the model. It is set to 0.24, which controls the contribution of each tree to the final prediction.\n- n_estimators: The number of trees in the ensemble. It is set to 2000, which means 2000 trees will be trained.\n- objective: The loss function to optimize during training. It is set to 'reg:linear', which means the model will be trained to minimize the mean squared error.\n- booster: The type of booster to use. It is set to 'gbtree', which means gradient boosting with decision trees will be used.\n\n(4) The optimization objective of this code is to minimize the mean squared error between the predicted housing prices and the actual housing prices. This is achieved by training XGBoost regression models using the training data and evaluating their performance using the mean squared error metric.\n\n(5) The advanced machine learning technique used in this code is gradient boosting with decision trees, implemented through the XGBoost framework. Gradient boosting is an ensemble learning method that combines multiple weak models (decision trees) to create a strong predictive model. It works by iteratively training new models to correct the mistakes made by the previous models. XGBoost is a popular implementation of gradient boosting that is known for its efficiency and performance.\n\n(6) Some important tricks that play a role in achieving high performance in this code include:\n- Data preprocessing: The code performs some data preprocessing steps, such as filling missing values and transforming variables, to ensure that the data is in a suitable format for training the models.\n- Feature engineering: The code explores the data through visualizations and correlation analysis to identify important features for predicting housing prices. It also splits the data into subsets based on the 'made' variable, which may capture different patterns in the data.\n- Hyperparameter tuning: The code sets the hyperparameters of the XGBoost models based on domain knowledge or through a grid search using the GridSearchCV class from the sklearn.model_selection module. This allows for finding the best combination of hyperparameters that optimize the model's performance.\n- Ensemble learning: The code trains multiple XGBoost models on different subsets of the data and combines their predictions to generate the final predictions. This ensemble approach can help improve the model's performance by reducing overfitting and capturing different patterns in the data.", "title": null, "competition_name": "Housing Prices Prediction in Paris", "task_category": "Regression", "field": "Modeling", "ranking": null, "score": null}, {"content": "High-ranking Kaggle notebooks or competition strategies: (1) The overall design of this code is to create Employee Attrition Prediction Models using DNN (Deep Neural Network) with the Employee Attrition Dataset. It performs Exploratory Data Analysis (EDA) to divide the features into categorical and numerical features, selects correlated features, and trains models using StratifiedKFold split strategy with different random seeds. It also uses KerasTuner for hyperparameter tuning and selects the best model based on the validation AUC score. Finally, it generates a submission file with the predicted probabilities for the test data. (2) The overall model architecture is a Deep Neural Network (DNN) with multiple dense layers. The number of layers and units in each layer are hyperparameters that are tuned using KerasTuner. The model takes the input features, applies normalization, and passes them through a series of dense layers with activation functions. The output layer has a sigmoid activation function to predict the probability of attrition. The model is trained using binary cross-entropy loss and optimized using the Adam optimizer. (3) The important hyperparameters in this code are: - `n_folds`: Number of folds for StratifiedKFold cross-validation. - `quick_experiment`: Boolean flag to control whether to perform a quick experiment or not. - `tuning_epochs`: Number of epochs for hyperparameter tuning using KerasTuner. - `max_trials`: Maximum number of hyperparameter search trials. - `epochs`: Number of epochs for training the final model. - `use_correlated_columns`: Boolean flag to control whether to use correlated columns or not. (4) The optimization objective is to maximize the validation AUC (Area Under the Curve) score. The models are trained using binary cross-entropy loss and the Adam optimizer. (5) The advanced machine learning technique used in this code is hyperparameter tuning using KerasTuner. KerasTuner is used to search for the best hyperparameters for the DNN model. It performs a Bayesian optimization search over the hyperparameter space to find the combination of hyperparameters that maximizes the validation AUC score. (6) Some important tricks that play a role in high performance are: - Using StratifiedKFold cross-validation to ensure that each fold has a similar distribution of the target variable. - Performing feature selection by selecting correlated features. - Applying normalization to the input features using the Normalization layer in TensorFlow. - Using a cosine decay learning rate scheduler to adjust the learning rate during training. - Using ModelCheckpoint to save the best model based on the validation AUC score. - Using early stopping based on the validation AUC score to prevent overfitting. - Ensembling the models by averaging the predicted probabilities weighted by their validation AUC scores.", "title": "Employee Attrition Prediction Models using DNN", "competition_name": "Employee Attrition Dataset", "task_category": "Classification", "field": "Modeling", "ranking": "Not provided", "score": "Validation AUC score"}, {"content": "The overall design of this code is to train and evaluate models for a Kaggle competition on stroke prediction. It starts by importing necessary libraries and loading the training, test, and submission data. Then, it performs data preprocessing steps such as filling missing values, creating new features, and scaling numerical features. After that, it trains two models - LassoCV and CatBoost - using cross-validation. Finally, it generates predictions on the test data and creates a submission file.\n\nThe overall model architecture consists of two models - LassoCV and CatBoost.\n\n- LassoCV: LassoCV is a linear regression model with L1 regularization. It is trained using cross-validation with 20 folds. The hyperparameters for LassoCV are set as follows:\n  - precompute: 'auto'\n  - fit_intercept: True\n  - max_iter: 100000\n  - verbose: False\n  - eps: 1e-04\n  - n_alphas: 1000\n  - n_jobs: -1\n\n- CatBoost: CatBoost is a gradient boosting model. It is trained using cross-validation with 10 folds. The hyperparameters for CatBoost are set as follows:\n  - depth: 3\n  - learning_rate: 0.01\n  - rsm: 0.5\n  - subsample: 0.931\n  - l2_leaf_reg: 69\n  - min_data_in_leaf: 20\n  - random_strength: 0.175\n  - use_best_model: True\n  - task_type: 'CPU'\n  - bootstrap_type: 'Bernoulli'\n  - grow_policy: 'SymmetricTree'\n  - loss_function: 'Logloss'\n  - eval_metric: 'AUC'\n  - scale_pos_weight: 5\n\nThe important hyperparameters in this code are set as follows:\n\n- LassoCV:\n  - precompute: 'auto'\n  - fit_intercept: True\n  - max_iter: 100000\n  - verbose: False\n  - eps: 1e-04\n  - n_alphas: 1000\n  - n_jobs: -1\n\n- CatBoost:\n  - depth: 3\n  - learning_rate: 0.01\n  - rsm: 0.5\n  - subsample: 0.931\n  - l2_leaf_reg: 69\n  - min_data_in_leaf: 20\n  - random_strength: 0.175\n  - use_best_model: True\n  - task_type: 'CPU'\n  - bootstrap_type: 'Bernoulli'\n  - grow_policy: 'SymmetricTree'\n  - loss_function: 'Logloss'\n  - eval_metric: 'AUC'\n  - scale_pos_weight: 5\n\nThe optimization objective of this code is to maximize the area under the ROC curve (AUC) for stroke prediction. The models are trained and evaluated using the AUC metric.\n\nThe advanced machine learning technique used in this code is gradient boosting. CatBoost, one of the models used, is a gradient boosting algorithm that can handle categorical features and provides better performance compared to traditional gradient boosting algorithms.\n\nSome important tricks that play a role in high performance in this code include:\n\n- Filling missing values using a DecisionTreeRegressor: The missing values in the 'bmi' feature are filled using a DecisionTreeRegressor trained on the available data.\n\n- Creating new features: Two new features, 'morbid' and 'obese', are created based on the 'bmi' feature. These features indicate whether a person is morbidly obese or obese based on a threshold.\n\n- Feature engineering: The 'risk_factors' feature is created by combining multiple features related to glucose level, age, bmi, hypertension, heart disease, and smoking status. This feature represents the presence of risk factors for stroke.\n\n- Scaling numerical features: The numerical features 'age', 'avg_glucose_level', and 'bmi' are scaled using StandardScaler.\n\n- Cross-validation: Both LassoCV and CatBoost models are trained using cross-validation to ensure robustness and avoid overfitting.\n\n- Ensemble prediction: The predictions from both models are combined using rank averaging to generate the final predictions. This ensemble approach can improve the overall performance.", "title": "Stroke Prediction Model", "competition_name": "Stroke Prediction", "task_category": "Classification", "field": "Modeling", "ranking": null, "score": null}, {"content": "High-ranking Kaggle notebooks or competition strategies: (1) The overall design of this code is to train a high-performing model for a Kaggle competition. It combines multiple datasets, performs feature engineering by adding distance to cities as a feature, and trains both LGBMRegressor and CatBoostRegressor models using 10-fold cross-validation. Finally, it ensembles the predictions from both models and creates a submission file.\n\n(2) The overall model architecture consists of two models: LGBMRegressor and CatBoostRegressor. The LGBMRegressor model is trained using the LightGBM library, while the CatBoostRegressor model is trained using the CatBoost library. Both models are trained using the same set of features and target variable. The training process involves splitting the data into train and validation sets, fitting the models on the train set, and evaluating the performance on the validation set. The models are trained using early stopping to prevent overfitting. The final predictions are obtained by ensembling the predictions from both models.\n\n(3) The important hyperparameters in this code are:\n- `learning_rate`: The learning rate for the LGBMRegressor model.\n- `n_estimators`: The number of boosting iterations for the LGBMRegressor model.\n- `metric`: The evaluation metric used for training the LGBMRegressor model.\n- `lambda_l1`: The L1 regularization term for the LGBMRegressor model.\n- `num_leaves`: The maximum number of leaves for the LGBMRegressor model.\n- `feature_fraction`: The fraction of features to be used for each tree in the LGBMRegressor model.\n- `bagging_fraction`: The fraction of data to be used for each bagging iteration in the LGBMRegressor model.\n- `bagging_freq`: The frequency of bagging for the LGBMRegressor model.\n- `min_data_in_leaf`: The minimum number of data points required in a leaf for the LGBMRegressor model.\n- `max_depth`: The maximum depth of a tree for the LGBMRegressor model.\n- `iterations`: The number of boosting iterations for the CatBoostRegressor model.\n- `loss_function`: The loss function used for training the CatBoostRegressor model.\n- `early_stopping_rounds`: The number of rounds to wait for early stopping in the CatBoostRegressor model.\n\n(4) The optimization objective of this code is to minimize the root mean squared error (RMSE) between the predicted and actual values of the target variable.\n\n(5) The advanced machine learning technique used in this code is ensemble learning. It combines the predictions from two different models, LGBMRegressor and CatBoostRegressor, to improve the overall performance. The predictions from both models are averaged to obtain the final predictions.\n\n(6) Some important tricks that play a role in achieving high performance in this code include:\n- Feature engineering: Adding distance to cities as a feature can provide additional information that may be useful for predicting the target variable.\n- Cross-validation: Using 10-fold cross-validation helps to evaluate the model's performance on different subsets of the data and reduce overfitting.\n- Early stopping: Using early stopping during training helps to prevent overfitting by stopping the training process when the performance on the validation set starts to deteriorate.\n- Hyperparameter tuning: The hyperparameters of the models are tuned to find the best combination that minimizes the RMSE.\n- Ensemble learning: Combining the predictions from multiple models can help to improve the overall performance by reducing bias and variance.", "title": "", "competition_name": "Kaggle competition", "task_category": "Regression", "field": "Modeling", "ranking": "", "score": "Root Mean Squared Error (RMSE)"}, {"content": "High-ranking Kaggle notebooks or competition strategies: (1) The overall design of the code is to solve a Kaggle competition problem of predicting the probability of a person having a stroke. The code includes data exploration, explanatory data analysis (EDA), data preprocessing, and modeling. It uses various machine learning techniques to analyze the dataset and build a predictive model. (2) The overall model architecture includes the following steps: - Data exploration: Loading the dataset, examining the data types, visualizing the ratio of numeric and categorical features, checking for missing values, and performing statistical analysis. - Explanatory Data Analysis (EDA): Analyzing the features individually and exploring the relationships among features and the target variable. - Data preprocessing: Combining the training set with the original dataset, removing irrelevant features, encoding categorical variables, and normalizing numeric features. - Modeling: Training the XGBRFClassifier and CatBoostClassifier models using KFold cross-validation, obtaining out-of-fold predictions for the test set, blending the predictions, and creating a submission file. (3) The important hyperparameters in this code are: - n_estimators: The number of trees in the XGBRFClassifier and CatBoostClassifier models. It is set to 1000. - verbose: The verbosity level of the CatBoostClassifier model. It is set to 0 to suppress the output. (4) The optimization objective is to build a machine learning model that can accurately predict the probability of a person having a stroke based on the given input parameters. (5) The advanced machine learning techniques used in this code are: - XGBRFClassifier: A variant of the XGBoost algorithm specifically designed for random forests. - CatBoostClassifier: A gradient boosting algorithm that handles categorical features automatically. (6) Other important tricks that play a role in high performance include: - Data exploration and EDA: Analyzing the features individually and exploring their relationships with the target variable to gain insights and identify important patterns. - Data preprocessing: Combining datasets, removing irrelevant features, encoding categorical variables, and normalizing numeric features to prepare the data for modeling. - Blending predictions: Combining the predictions from multiple models (XGBRFClassifier and CatBoostClassifier) to improve the overall prediction accuracy. - KFold cross-validation: Splitting the training data into multiple folds and training the models on different subsets of the data to obtain more reliable predictions. - Feature engineering: Creating new features or transforming existing features to capture additional information that may be useful for the prediction task.", "title": null, "competition_name": "Predicting Stroke Probability", "task_category": "Classification", "field": "Modeling", "ranking": null, "score": null}, {"content": "High-ranking Kaggle notebooks or competition strategies: (1) The overall design of this code is to approach a binary classification problem as a regression problem using Lasso regression. The code performs data preprocessing, feature encoding, feature scaling, and then trains a Lasso regression model using repeated K-fold cross-validation. It also evaluates the model performance using root mean squared error (RMSE) and area under the ROC curve (AUC). Finally, it generates predictions for the test set and saves the results.\n\n(2) The overall model architecture is as follows:\n- Load the training and test data.\n- Perform data preprocessing by dropping unnecessary columns.\n- Encode categorical variables using the LeaveOneOutEncoder.\n- Standardize the numerical features using StandardScaler.\n- Split the data into training and validation sets.\n- Train a LassoCV model using repeated K-fold cross-validation.\n- Evaluate the model performance using RMSE and AUC.\n- Generate predictions for the test set.\n- Save the predictions and feature importance.\n\n(3) The important hyperparameters in this code are:\n- `folds`: The number of folds for cross-validation.\n- `repeats`: The number of times to repeat the cross-validation process.\n- `seeds`: A list of random seeds for reproducibility.\n- `sigma`: The amount of noise to inject during encoding of categorical variables.\n- `precompute`: Whether to use precomputed Gram matrix for faster calculations.\n- `fit_intercept`: Whether to calculate the intercept for the model.\n- `normalize`: Whether to normalize the features before fitting the model.\n- `max_iter`: The maximum number of iterations for the LassoCV algorithm.\n- `eps`: The tolerance for stopping criteria.\n- `n_alphas`: The number of alphas along the regularization path.\n- `n_jobs`: The number of parallel jobs to run for cross-validation.\n\n(4) The optimization objective is to minimize the mean squared error (MSE) between the predicted values and the true labels. The LassoCV algorithm finds the optimal alpha value (regularization strength) that minimizes the MSE.\n\n(5) The advanced machine learning technique used in this code is Lasso regression. Lasso regression is a linear regression model with L1 regularization, which performs feature selection by setting some feature coefficients to zero. It is used here to select the most important features for predicting the target variable.\n\n(6) Some important tricks that play a role in high performance are:\n- Encoding categorical variables using the LeaveOneOutEncoder, which injects noise to avoid overfitting.\n- Standardizing the numerical features using StandardScaler to ensure they have zero mean and unit variance.\n- Using repeated K-fold cross-validation to avoid overfitting and account for uneven data distributions within folds.\n- Averaging predictions from multiple folds to improve the stability and accuracy of the final predictions.\n- Applying the sigmoid function to the predictions to map them to the [0, 1] range.\n- Saving the feature importance and visualizing it to understand the relative importance of each feature.", "title": "Not provided", "competition_name": "Not provided", "task_category": "Classification", "field": "Modeling", "ranking": "Not provided", "score": "Not provided"}, {"content": "High-ranking Kaggle notebooks or competition strategies: (1) The overall design of this code is to train a high-performing model for a Kaggle competition. It involves loading the data, performing data preprocessing and feature engineering, training multiple models using cross-validation, blending the predictions of these models, and generating a submission file.\n\n(2) The overall model architecture consists of two main models: CatBoostRegressor and XGBoostRegressor. These models are trained using the features extracted from the dataset. The CatBoostRegressor is trained using the CatBoost library, while the XGBoostRegressor is trained using the XGBoost library. Both models are trained using cross-validation to evaluate their performance.\n\n(3) The important hyperparameters in this code are set as follows:\n- CatBoostRegressor:\n  - iterations: 20000\n  - loss_function: 'RMSE'\n  - random_seed: 0\n- XGBoostRegressor:\n  - n_estimators: 10000\n  - max_depth: 9\n  - learning_rate: 0.01\n  - colsample_bytree: 0.66\n  - subsample: 0.9\n  - min_child_weight: 22\n  - reg_lambda: 16\n  - seed: 1\n\n(4) The optimization objective of this code is to minimize the root mean squared error (RMSE) between the predicted and actual values of the target variable (MedHouseVal).\n\n(5) The advanced machine learning technique used in this code is stacking. Stacking is a technique where multiple models are trained and their predictions are combined using another model (in this case, a weighted average) to improve the overall performance.\n\n(6) Some important tricks that play a role in achieving high performance in this code include:\n- Outlier removal: The code removes outliers from the dataset by filtering out rows with extreme values in certain columns.\n- Feature engineering: The code performs various feature engineering techniques such as adding new features based on geographical data, applying PCA to latitude and longitude coordinates, and creating rotated coordinates.\n- Feature scaling: The code applies feature scaling using the MinMaxScaler to ensure that all features are on a similar scale.\n- Cross-validation: The code uses KFold cross-validation to evaluate the performance of the models and prevent overfitting.\n- Ensemble blending: The code blends the predictions of multiple models (CatBoostRegressor and XGBoostRegressor) using a weighted average to improve the overall prediction accuracy.\n- Post-processing: The code applies post-processing techniques such as adjusting the predicted values for certain conditions (e.g., randomly increasing the predicted values for certain rows) and capping the predicted values to a certain threshold.", "title": "High-ranking Kaggle notebooks or competition strategies", "competition_name": "Not explicitly mentioned", "task_category": "Regression", "field": "Modeling", "ranking": "Not provided", "score": "Not provided"}, {"content": "High-ranking Kaggle notebooks or competition strategies: (1) The overall design of this code is to train and evaluate different machine learning models for a Kaggle competition on stroke prediction. It includes data preprocessing, exploratory data analysis, feature engineering, model training, and blending of predictions.\n\n(2) The overall model architecture consists of three different models: CatBoost, Lasso Regression, and a Neural Network (NN). \n\n- CatBoost: It is a gradient boosting algorithm that uses decision trees. The hyperparameters for CatBoost are set in the `cb_params` dictionary. The model is trained using Stratified K-Fold cross-validation with 10 folds. The predictions from each fold are averaged to obtain the final predictions.\n\n- Lasso Regression: The code uses pre-trained Lasso Regression predictions from a separate file. The predictions are normalized to a range of 0 to 1.\n\n- Neural Network (NN): The NN model architecture consists of three dense layers with dropout regularization. The model is compiled with the Adam optimizer and a custom loss function (Sigmoid Focal Cross Entropy) and trained using Stratified K-Fold cross-validation with 10 folds. The predictions from each fold are averaged to obtain the final predictions.\n\n(3) The important hyperparameters in this code are:\n\n- CatBoost hyperparameters: `depth`, `learning_rate`, `rsm`, `subsample`, `l2_leaf_reg`, `min_data_in_leaf`, `random_strength`, `random_seed`, `use_best_model`, `task_type`, `bootstrap_type`, `grow_policy`, `loss_function`, `eval_metric`.\n\n- Neural Network hyperparameters: `BATCH_SIZE`, `epochs`, `class_weight`, `optimizer`, `loss function`, `metrics`.\n\n(4) The optimization objective is to maximize the area under the ROC curve (AUC) for the stroke prediction task. The AUC is used as the evaluation metric for both CatBoost and the Neural Network models.\n\n(5) The advanced machine learning technique used in this code is gradient boosting with CatBoost. CatBoost is a state-of-the-art gradient boosting algorithm that handles categorical features and provides good performance out of the box.\n\n(6) Some important tricks that play a role in achieving high performance include:\n\n- Handling missing values: The code uses K-Nearest Neighbors (KNN) regression to impute missing values for the 'bmi' feature.\n\n- Feature engineering: The code performs feature engineering by encoding categorical features using LabelEncoder and one-hot encoding. It also creates additional features based on the original dataset.\n\n- Outlier removal: The code removes outliers from the CatBoost training data to improve model performance.\n\n- Model blending: The code blends the predictions from CatBoost, Lasso Regression, and the Neural Network models to obtain the final predictions. The blending weights are manually set.\n\n- Model evaluation: The code uses Stratified K-Fold cross-validation to evaluate the models and calculate the mean AUC score.\n\n- Standardization: The code standardizes numerical features using StandardScaler before training the Neural Network model.\n\n- Early stopping and learning rate reduction: The code uses early stopping and learning rate reduction callbacks in the Neural Network training to prevent overfitting and improve convergence.\n\n- Feature importance analysis: The code calculates and visualizes the feature importances for the CatBoost model.\n\n- Visualization: The code uses various visualization techniques, such as bar plots, heatmaps, scatter plots, and histograms, to analyze the data and model predictions.", "title": "not provided", "competition_name": "stroke prediction", "task_category": "Classification", "field": "Modeling", "ranking": "not provided", "score": "not provided"}, {"content": "High-ranking Kaggle notebooks or competition strategies: (1) The overall design of this code is to train a high-performing model for a Kaggle competition. It involves data preprocessing, exploratory data analysis, feature engineering, model training, and prediction.\n\n(2) The overall model architecture consists of two models: XGBoost and CatBoost. The XGBoost model is trained using the XGBClassifier class from the xgboost library, and the CatBoost model is trained using the CatBoostClassifier class from the catboost library. Both models are trained on the preprocessed data and used for prediction.\n\n(3) The important hyperparameters in this code are set as follows:\n- For Ridge Regression:\n  - alpha: [0.01, 0.1, 1, 10, 100]\n- For XGBoost:\n  - subsample: 0.6\n  - scale_pos_weight: 5\n  - n_estimators: 400\n  - max_depth: 3\n  - learning_rate: 0.03\n  - lambda: 5\n  - colsample_bytree: 0.4\n- For CatBoost:\n  - depth: 3\n  - l2_leaf_reg: 1\n  - iterations: 400\n  - subsample: 0.6\n  - rsm: 0.6\n  - learning_rate: 0.1\n\n(4) The optimization objective is to maximize the ROC-AUC score. This is evaluated using the roc_auc_score function from the sklearn.metrics module.\n\n(5) The advanced machine learning technique used in this code is ensemble learning. It combines the predictions of the XGBoost and CatBoost models using weighted averaging. The weights are manually set as 0.7 for CatBoost, 0.1 for the predictions from the validation set, and 0.2 for XGBoost.\n\n(6) Other important tricks that play a role in high performance include:\n- Data preprocessing: The code performs data preprocessing steps such as dropping unnecessary columns, handling missing values, and encoding categorical variables using one-hot encoding and weight of evidence encoding.\n- Feature engineering: The code selects a set of features based on domain knowledge and drops outliers from the dataset.\n- Model selection: The code uses Ridge Regression, XGBoost, and CatBoost models, which are known for their high performance in various scenarios.\n- Hyperparameter tuning: The code uses GridSearchCV to perform hyperparameter tuning for the Ridge Regression model.\n- Cross-validation: The code uses KFold cross-validation with 10 folds to evaluate the performance of the Ridge Regression model.\n- Evaluation metric: The code uses the ROC-AUC score as the evaluation metric, which is a commonly used metric for binary classification problems.\n- Visualization: The code uses various visualization techniques, such as heatmaps and histograms, to gain insights into the data and model performance.", "title": "Not provided", "competition_name": "Not provided", "task_category": "Classification", "field": "Modeling", "ranking": "Not provided", "score": "Not provided"}, {"content": "High-ranking Kaggle notebooks or competition strategies: (1) Summary of the overall design: The overall design of this code is to train multiple machine learning models on the given dataset to predict the probability of stroke occurrence. The code starts by importing the necessary libraries and configuring the seed for reproducibility. It then reads the training, test, and sample submission data from CSV files. Additional data from another dataset is also read if the `add_extra` flag is set to True. The data is then split into training and validation sets using stratified shuffle split. The code then preprocesses the data using various transformers and pipelines. Finally, it trains different models such as Lasso Regression, Random Forest, Boosting (XGBoost, CatBoost, LightGBM), and Logistic Regression. The trained models are used to make predictions on the validation set and calculate the ROC AUC score. The best models are then used to make predictions on the test set for submission. (2) Overall model architecture: The overall model architecture consists of multiple machine learning models trained on the preprocessed data. The models used in this code are Lasso Regression, Random Forest, Boosting (XGBoost, CatBoost, LightGBM), and Logistic Regression. Each model is trained using different hyperparameters and techniques. The models are then used to make predictions on the validation set and calculate the ROC AUC score. The best models are selected based on their performance and used to make predictions on the test set for submission. (3) Important hyperparameters setting: - `seed`: The seed value used for random number generation to ensure reproducibility. - `add_extra`: A flag indicating whether to add additional data from another dataset. - `test_size`: The proportion of the data to be used as the validation set during the split. - `n_estimators`: The number of trees in the Random Forest model. - `min_samples_leaf`: The minimum number of samples required to be at a leaf node in the Random Forest model. - `max_depth`: The maximum depth of the trees in the Random Forest model. - `class_weight`: The weights associated with classes in the Random Forest model. - `n_alphas`: The number of alphas along the regularization path in LassoCV. - `n_jobs`: The number of parallel jobs to run in LassoCV. - `iterations`: The number of boosting iterations in CatBoostClassifier. - `n_estimators`: The number of boosting iterations in XGBClassifier. - `solver`: The solver algorithm to use in LogisticRegression. - `max_iter`: The maximum number of iterations for the solver in LogisticRegression. (4) Optimization objective: The optimization objective of this code is to maximize the ROC AUC score. The models are trained and evaluated based on their ability to predict the probability of stroke occurrence accurately. The ROC AUC score is used as the evaluation metric to measure the performance of the models. (5) Advanced machine learning technique used: The code uses various advanced machine learning techniques, including: - StratifiedShuffleSplit: It is used to split the data into training and validation sets while maintaining the class distribution. - ColumnTransformer: It is used to apply different transformers to different columns of the data. - LeaveOneOutEncoder: It is used to encode categorical features using leave-one-out encoding. - SimpleImputer: It is used to impute missing values in the data. - StandardScaler: It is used to standardize the numerical features in the data. - Pipeline: It is used to chain multiple transformers and estimators together. - RepeatedStratifiedKFold: It is used to perform repeated stratified k-fold cross-validation. - GridSearchCV: It is used to perform grid search to find the best hyperparameters for the XGBClassifier model. - CalibratedClassifierCV: It is used to calibrate the predicted probabilities of the models. (6) Other important tricks for high performance: - StratifiedShuffleSplit: It helps in maintaining the class distribution while splitting the data, which is important for imbalanced datasets like this one. - Feature engineering: The code adds additional data from another dataset to improve the model's performance. - Preprocessing: The code applies various preprocessing techniques such as encoding categorical features, imputing missing values, and scaling numerical features to prepare the data for training. - Ensemble learning: The code combines the predictions of multiple models using weighted averaging to improve the overall performance. - Hyperparameter tuning: The code uses techniques like LassoCV and GridSearchCV to find the best hyperparameters for the models, which can significantly improve their performance. - Calibration: The code uses CalibratedClassifierCV to calibrate the predicted probabilities of the models, which can improve the reliability of the predictions.", "title": "not provided", "competition_name": "not provided", "task_category": "Classification", "field": "Modeling", "ranking": "not provided", "score": "not provided"}, {"content": "High-ranking Kaggle notebooks or competition strategies: (1) The overall design of this code is to train multiple machine learning models using different algorithms and combine their predictions to make the final prediction. The code starts by importing the necessary libraries and loading the training, test, and submission data. It then performs some data preprocessing steps, such as removing outliers, formatting the original dataset, concatenating the train and original datasets, and encoding categorical features. After preprocessing, the code splits the data into features and target variables. It then scales the features using StandardScaler. Next, the code trains multiple models, including CatBoostRegressor, CatBoostClassifier, XGBRegressor, XGBClassifier, LGBMRegressor, LassoCV, and RidgeCV. Finally, it combines the predictions from these models using weighted averaging and saves the final prediction in a submission file.\n\n(2) The overall model architecture of this code is an ensemble of multiple machine learning models. The code trains several models using different algorithms, including CatBoost, XGBoost, LightGBM, LassoCV, and RidgeCV. Each model is trained on the same set of features and target variable. The models are trained using cross-validation, where the data is split into multiple folds and the models are trained on different combinations of these folds. The predictions from each model are then combined using weighted averaging to make the final prediction.\n\n(3) The important hyperparameters in this code are set as follows:\n- For CatBoostRegressor and CatBoostClassifier:\n    - iterations: 15000\n    - early_stopping_rounds: 1000\n    - eval_metric: 'RMSE' for CatBoostRegressor and 'AUC' for CatBoostClassifier\n    - depth: 3\n    - learning_rate: 0.01\n    - rsm: 0.5\n    - subsample: 0.931\n    - l2_leaf_reg: 69\n    - min_data_in_leaf: 20\n    - random_strength: 0.175\n- For XGBRegressor and XGBClassifier:\n    - n_estimators: 1000\n    - learning_rate: 0.01\n    - max_depth: 9\n    - colsample_bytree: 0.9\n    - subsample: 1\n    - reg_lambda: 20\n    - eval_metric: 'rmse' for XGBRegressor and 'auc' for XGBClassifier\n    - early_stopping_rounds: 200\n- For LGBMRegressor and LGBMClassifier:\n    - learning_rate: 0.01\n    - max_depth: 9\n    - num_leaves: 90\n    - colsample_bytree: 0.8\n    - subsample: 0.9\n    - subsample_freq: 5\n    - min_child_samples: 36\n    - reg_lambda: 28\n    - n_estimators: 20000\n    - metric: 'rmse'\n- For LassoCV:\n    - precompute: \"auto\"\n    - fit_intercept: True\n    - normalize: False\n    - max_iter: 1000\n    - verbose: False\n    - eps: 1e-04\n    - cv: 5\n    - n_alphas: 1000\n    - n_jobs: 8\n- For RidgeCV:\n    - alphas: np.linspace(0.0001, 100, 1000)\n\n(4) The optimization objective of this code is to maximize the ROC AUC score. The objective function used in the optimization process is defined as `coef_objective(trial)`, which takes a set of hyperparameters as input and returns the ROC AUC score based on the weighted averaging of the predictions from different models.\n\n(5) The advanced machine learning technique used in this code is ensemble learning. The code trains multiple machine learning models using different algorithms and combines their predictions to make the final prediction. This ensemble of models helps to improve the overall performance and generalization of the model.\n\n(6) Some important tricks that play an important role in achieving high performance in this code include:\n- Data preprocessing: The code performs various data preprocessing steps, such as removing outliers, formatting the original dataset, concatenating datasets, encoding categorical features, and adding new features. These preprocessing steps help to improve the quality and relevance of the data for training the models.\n- Feature scaling: The code uses StandardScaler to scale the features before training the models. Scaling the features helps to normalize the data and improve the convergence and performance of the models.\n- Cross-validation: The code uses cross-validation to train the models. Cross-validation helps to evaluate the performance of the models on different subsets of the data and provides a more reliable estimate of the model's performance.\n- Model selection: The code trains multiple models using different algorithms. This helps to capture different patterns and relationships in the data and improve the overall performance of the ensemble.\n- Weighted averaging: The code combines the predictions from different models using weighted averaging. This allows the models with higher performance to have a greater influence on the final prediction, improving the overall accuracy and robustness of the model.", "title": "", "competition_name": "", "task_category": "Regression", "field": "Modeling", "ranking": "", "score": ""}, {"content": "High-ranking Kaggle notebooks or competition strategies: Sometimes, proper methodology is useful in these competitions. When the public leaderboard was dominated by notebooks which skipped cross-validation and [trained on subsets of the available data]( I decided to compare different cross-validation strategies. These experiments showed that samples with duplicated `squareMeters` should be treated differently from samples with unseen `squareMeters`: A. When I cross-validated with `GroupKFold(groups=train.squareMeters)`, linear regression gave the best results, better than all tree-based models: ![horizontal bar chart]( B. When I cross-validated with `KFold`, I got the best results by predicting the mean price of all houses with identical `squareMeters`, `made` and sometimes `cityCode` (this is the method I announced in [Quasi-duplicates in the data]( My [final model]( includes the original dataset and uses only three features: `squareMeters`, `made` and `cityCode`. It predicts test prices in three phases: 1. If the training data contains houses with identical `squareMeters`, `made` and `cityCode`, predict the mean price of these houses. 2. If the training data contains houses with identical `squareMeters` and `made` (regardless of `cityCode`), predict the mean price of these houses. 3. Otherwise do a linear regression.", "title": null, "competition_name": null, "task_category": "Regression", "field": "Modeling", "ranking": null, "score": null}, {"content": "High-ranking Kaggle notebooks or competition strategies: (1) The overall design of this code is to develop a high-performing solution for a Kaggle competition using the Light AutoML library. It involves loading the necessary libraries, loading the competition datasets, performing data preprocessing and feature engineering, training the model using Light AutoML, interpreting the model, and generating predictions for submission.\n\n(2) The overall model architecture is a combination of multiple models, including linear regression, LightGBM, CatBoost, and a neural network. The TabularAutoML class from the Light AutoML library is used to automatically select and combine the best models for the given task. The neural network model is defined using the Keras library and consists of multiple dense layers with dropout and batch normalization.\n\n(3) The important hyperparameters in this code are set as follows:\n- LightGBM parameters:\n  - num_iterations: 772\n  - max_depth: 3\n  - learning_rate: 0.0293466\n  - min_child_samples: 36\n  - num_leaves: 128\n  - colsample_bytree: 0.80\n  - subsample: 0.90\n  - subsample_freq: 5\n  - reg_lambda: 28\n- CatBoost parameters:\n  - num_boost_round: 1420\n  - depth: 3\n  - learning_rate: 0.04895188\n  - rsm: 0.5\n  - subsample: 0.931\n  - l2_leaf_reg: 69\n  - min_data_in_leaf: 20\n  - random_strength: 0.175\n- Neural network parameters:\n  - Batch size: 64\n  - Number of epochs: 512\n  - Learning rate: 0.2\n  - Activation function: Swish\n  - Number of hidden layers: 4\n  - Number of neurons in each hidden layer: 1024, 256, 128, 64\n\n(4) The optimization objective is to maximize the area under the ROC curve (AUC) for the binary classification task of predicting employee attrition.\n\n(5) The advanced machine learning technique used in this code is the Light AutoML library, which automates the process of feature engineering, model selection, and model stacking. It combines multiple models and optimizes their performance using a variety of techniques, such as feature importance analysis and hyperparameter tuning.\n\n(6) Some important tricks that play a role in achieving high performance in this code include:\n- Feature engineering: Creating new features based on domain knowledge and combining existing features to capture important patterns and relationships in the data.\n- Outlier detection: Identifying and flagging outliers in the numerical features to prevent them from affecting the model's performance.\n- Feature encoding: Encoding categorical features using techniques such as one-hot encoding and weight of evidence encoding to convert them into numerical representations that can be used by the models.\n- Feature selection: Removing non-variance features that do not provide any useful information for the task.\n- Scaling: Scaling the numerical features to a similar range to prevent them from dominating the model's learning process.\n- Model stacking: Combining the predictions of multiple models, including linear regression, LightGBM, CatBoost, and a neural network, to improve the overall performance.\n- Model interpretation: Analyzing the feature importances of the models to gain insights into the important factors influencing the prediction.\n- Neural network training: Training a neural network model with multiple hidden layers and regularization techniques, such as dropout and batch normalization, to improve its generalization and prevent overfitting.", "title": null, "competition_name": null, "task_category": "Classification", "field": "Modeling", "ranking": null, "score": null}, {"content": "High-ranking Kaggle notebooks or competition strategies: (1) The overall design of this code is to solve a Kaggle competition problem using machine learning techniques. It starts with importing necessary libraries and loading the data. Then, it performs exploratory data analysis (EDA) to understand the data and identify any missing values or outliers. After that, it proceeds to the machine learning phase, where it preprocesses the data, selects features, and trains multiple regression models using different algorithms. Finally, it evaluates the models using cross-validation and selects the best performing model for making predictions on the test set.\n\n(2) The overall model architecture consists of several steps:\n- Importing necessary libraries and loading the data.\n- Performing exploratory data analysis (EDA) to understand the data and identify any missing values or outliers.\n- Preprocessing the data using standard scaling, power transformation, and robust scaling.\n- Selecting the best features using the SelectKBest algorithm with the f_regression scoring function.\n- Training multiple regression models, including Linear Regression, Decision Tree Regression, XGBoost Regression, Random Forest Regression, Gradient Boosting Regression, Support Vector Regression, K-Nearest Neighbors Regression, and AdaBoost Regression.\n- Using GridSearchCV to tune the hyperparameters of each model.\n- Evaluating the models using negative mean squared error as the scoring metric.\n- Building a StackingRegressor and a VotingRegressor using the best performing models.\n- Fitting the StackingRegressor and VotingRegressor on the training data.\n- Evaluating the performance of the StackingRegressor and VotingRegressor on the validation data.\n\n(3) The important hyperparameters in this code are:\n- `random_state`: The random seed used for reproducibility.\n- `test_size`: The proportion of the data to be used as the validation set during the train-test split.\n- `quantile_range`: The range of quantiles to be used for robust scaling.\n- `score_func`: The scoring function used for feature selection.\n- `n_estimators`: The number of estimators (trees) in the ensemble models.\n- `base_estimator__max_depth`: The maximum depth of the decision tree base estimator in AdaBoost.\n- `estimator__learning_rate`: The learning rate of the ensemble models.\n- `estimator__loss`: The loss function used in AdaBoost.\n- `early_stopping_rounds`: The number of rounds without improvement before early stopping in XGBoost.\n\n(4) The optimization objective of this code is to minimize the negative mean squared error (MSE) during model training and evaluation. The negative MSE is used as the scoring metric in GridSearchCV, where the models are tuned to find the best hyperparameters that minimize the MSE.\n\n(5) The advanced machine learning technique used in this code is stacking. Stacking is an ensemble learning method that combines multiple regression models by training a meta-model on their predictions. In this code, a StackingRegressor is built using multiple regression models as base estimators, and a meta-model (XGBoost Regressor) is trained on their predictions. This allows the StackingRegressor to learn from the strengths of each base estimator and improve overall prediction performance.\n\n(6) Some important tricks that play a role in achieving high performance in this code include:\n- Data preprocessing techniques such as standard scaling, power transformation, and robust scaling to normalize and transform the data.\n- Feature selection using the SelectKBest algorithm to select the most relevant features for prediction.\n- Hyperparameter tuning using GridSearchCV to find the best combination of hyperparameters for each model.\n- Ensemble learning techniques such as stacking and voting to combine the predictions of multiple models and improve overall performance.\n- Evaluation of models using cross-validation to get a more robust estimate of their performance.\n- Early stopping in XGBoost to prevent overfitting and improve generalization.", "title": null, "competition_name": null, "task_category": "Regression", "field": "Modeling", "ranking": null, "score": null}, {"content": "High-ranking Kaggle notebooks or competition strategies: Hey kagglers 👋!!\n\nMy first attempt in open Kaggle competition is end with great results!\nI trust 98% my cross validation (CV) and I took the 5th place, and If I trust it 100% I would take the 3rd place, but this should be a lesson for me! **DON'T TRUST THE PUBLIC LEADERBOARD**!!\n\n**My solution notebook is here:** \n\n## Things that worked 🔥\n* **Remove outliers** - Run IQR for each column and remove the rows with the outliers (just 20 records). The outlier removal was not so important for the final model performance but it was important for the CV, because the RMSE metric is very sensitive to outliers and can lead to missleading results.\n* **Piece-Wise model** (I like the terminology from @PRASAD)- Split the models based on different periods (based on made column). The best score was by spliting the data in 4 periods.\n* **Multi-StratifiedKFold** - Run StratifiedKFold many times with different SEEDS. This give me the confidence to have good statistics about model performance (MeanScore +/- SD). The second key point is the selection of the \"Statified\" CV. Due to \"Piece-Wise model\" approach I had to stratify the data based on the \"made\" column in order to have consistent results.\n* **Ensemble Model** - From CV I observed that different models (e.g Random Forest, XGBoost) had case that were good and others are not, so an ensemble model created a more stable solution.\n* **Low number of estimators** - I used few estimators because with more estimators the models were overfitting in data noise\n* **Use all the features (except CityCode)** - The most dominant feature was the size of the house (squareMeters column). It was the only feature with significan correlation (~ =53%) with the target and feature importance (~ =99%), all the others were look to be noise. But the CV show me that the other features were play some role and maybe in edge cases were helping the model to take the right decision, so I keep them!\n* **No extra features** - After searching for artificial features that would probably help the model performance, I couldn;t find features which improve the CV score, so I didn't use any extra features.\n* **Include original data** - The original data were looked different (based on Adversarial validation) but If we keep only the squareMeters columns the dataset were approximately the same, so I tried to include them in the training dataset and the results were better.", "title": "My first attempt in open Kaggle competition is end with great results!", "competition_name": "Not explicitly mentioned", "task_category": "Regression", "field": "Modeling", "ranking": "5th place", "score": "Not explicitly mentioned"}, {"content": "High-ranking Kaggle notebooks or competition strategies: (1) The overall design of this code is to develop a high-performing solution for a Kaggle competition using the XGBoost algorithm. The code starts by importing necessary libraries and reading the input data files. It then performs data preprocessing steps such as outlier detection and handling, visualization, and dropping unnecessary columns. After that, it splits the data into training and testing sets, creates an XGBoost regression model, trains the model on the training data, and makes predictions on the testing data. Finally, it saves the predictions in a submission file.\n\n(2) The overall model architecture is based on the XGBoost algorithm, which is a gradient boosting framework. XGBoost stands for eXtreme Gradient Boosting and is known for its high performance and efficiency. The XGBoost model used in this code is a regression model, as indicated by the objective parameter set to 'reg:linear'. The model architecture consists of multiple decision trees, where each tree is built sequentially to correct the mistakes made by the previous trees. The trees are added to the model in an additive manner, with each tree trying to minimize the loss function. The final prediction is obtained by summing the predictions of all the trees.\n\n(3) The important hyperparameters set in this code are as follows:\n- max_depth: The maximum depth of each tree. It is set to 3, which means each tree can have a maximum depth of 3 levels.\n- learning_rate: The learning rate or shrinkage factor, which controls the contribution of each tree to the final prediction. It is set to 0.25.\n- n_estimators: The number of trees in the model. It is set to 500, which means the model will have 500 trees.\n- objective: The objective function to be minimized during training. It is set to 'reg:linear', indicating that the model is a regression model.\n- booster: The type of booster to use. It is set to 'gbtree', indicating that the model uses tree-based models as the base learners.\n\n(4) The optimization objective of this code is to minimize the mean squared error (MSE) between the predicted prices and the actual prices. The MSE is calculated using the mean_squared_error function from the sklearn.metrics module. The lower the MSE, the better the model performance.\n\n(5) The advanced machine learning technique used in this code is gradient boosting. Gradient boosting is an ensemble learning method that combines multiple weak models (decision trees in this case) to create a strong predictive model. It works by iteratively adding new models to the ensemble, with each new model trying to correct the mistakes made by the previous models. This technique is known for its high performance and ability to handle complex datasets.\n\n(6) Some important tricks that play a role in achieving high performance in this code include:\n- Outlier detection and handling: The code uses the interquartile range (IQR) method to detect outliers in the numerical features and replaces them with appropriate values.\n- Feature selection: The code drops unnecessary columns from the dataset to reduce noise and improve model performance.\n- Data visualization: The code uses box plots to visualize the distribution of numerical features and identify outliers.\n- Data preprocessing: The code performs necessary preprocessing steps such as dropping missing values and converting categorical variables to numerical format.\n- Model hyperparameter tuning: The code sets appropriate values for hyperparameters such as max_depth, learning_rate, and n_estimators to optimize the model performance.\n- Model evaluation: The code calculates the mean squared error (MSE) to evaluate the performance of the model and make improvements if necessary.", "title": null, "competition_name": null, "task_category": "Regression", "field": "Modeling", "ranking": null, "score": null}, {"content": "High-ranking Kaggle notebooks or competition strategies: (1) The overall design of the code is to train and evaluate multiple machine learning models for the Kaggle competition on stroke prediction. The code starts by loading the necessary libraries and setting up the notebook configuration. Then, it reads the input datasets and performs some data preprocessing steps such as filling missing values using KNN, merging datasets, and separating features. After that, it trains a Lasso Regression model using cross-validation and evaluates its performance. Next, it trains XGBoost, LightGBM, and CatBoost models using stratified k-fold cross-validation and evaluates their performance. Finally, it blends the predictions from all the models and generates the final submission file.\n\n(2) The overall model architecture consists of multiple machine learning models trained on the stroke prediction dataset. The models used in this code are Lasso Regression, XGBoost, LightGBM, and CatBoost.\n\n- Lasso Regression: It is a linear regression model with L1 regularization. It is trained using cross-validation and the LassoCV function from scikit-learn. The model parameters are set to precompute='auto', fit_intercept=True, normalize=False, max_iter=1000, verbose=False, eps=1e-04, cv=rkf_grid (repeated k-fold cross-validation strategy), n_alphas=1000, and n_jobs=-1.\n\n- XGBoost: It is a gradient boosting model that uses decision trees as base learners. It is trained using stratified k-fold cross-validation and the XGBClassifier function from the XGBoost library. The model parameters are set to n_estimators=16384, min_child_weight=96, max_depth=8, learning_rate=0.01, subsample=0.95, colsample_bytree=0.95, reg_lambda=1.50, reg_alpha=1.50, gamma=1.50, max_bin=512, random_state=SEED, objective='binary:logistic', tree_method='hist', and eval_metric='auc'.\n\n- LightGBM: It is another gradient boosting model that uses decision trees as base learners. It is trained using stratified k-fold cross-validation and the LGBMClassifier function from the LightGBM library. The model parameters are set to num_iterations=16384, max_depth=9, learning_rate=0.01, min_child_samples=36, num_leaves=128, colsample_bytree=0.80, subsample=0.90, subsample_freq=5, reg_lambda=28, seed=SEED, objective='binary', boosting_type='gbdt', device='cpu', gpu_platform_id=0, gpu_device_id=0, n_jobs=-1, metric='auc', and verbose=-1.\n\n- CatBoost: It is a gradient boosting model that uses decision trees as base learners. It is trained using stratified k-fold cross-validation and the CatBoostClassifier function from the CatBoost library. The model parameters are set to num_boost_round=10000, depth=3, learning_rate=0.01, rsm=0.5, subsample=0.931, l2_leaf_reg=69, min_data_in_leaf=20, random_strength=0.175, random_seed=SEED, use_best_model=True, task_type='CPU', bootstrap_type='Bernoulli', grow_policy='SymmetricTree', loss_function='Logloss', and eval_metric='AUC'.\n\n(3) The important hyperparameters in this code are:\n\n- Lasso Regression: The hyperparameters for Lasso Regression are set in the lasso_params dictionary. The important hyperparameters are precompute, fit_intercept, normalize, max_iter, verbose, eps, cv, n_alphas, and n_jobs.\n\n- XGBoost: The hyperparameters for XGBoost are set in the xgb_params dictionary. The important hyperparameters are n_estimators, min_child_weight, max_depth, learning_rate, subsample, colsample_bytree, reg_lambda, reg_alpha, gamma, max_bin, random_state, objective, tree_method, and eval_metric.\n\n- LightGBM: The hyperparameters for LightGBM are set in the lgb_params dictionary. The important hyperparameters are num_iterations, max_depth, learning_rate, min_child_samples, num_leaves, colsample_bytree, subsample, subsample_freq, reg_lambda, seed, objective, boosting_type, device, gpu_platform_id, gpu_device_id, n_jobs, metric, and verbose.\n\n- CatBoost: The hyperparameters for CatBoost are set in the cb_params dictionary. The important hyperparameters are num_boost_round, depth, learning_rate, rsm, subsample, l2_leaf_reg, min_data_in_leaf, random_strength, random_seed, use_best_model, task_type, bootstrap_type, grow_policy, loss_function, and eval_metric.\n\n(4) The optimization objective in this code is to maximize the area under the ROC curve (AUC) for the stroke prediction task. The AUC is a common evaluation metric for binary classification problems, and it measures the model's ability to distinguish between positive and negative samples.\n\n(5) The advanced machine learning techniques used in this code are:\n\n- Lasso Regression: Lasso Regression is a linear regression model with L1 regularization. It is used to select the most important features and perform feature selection.\n\n- XGBoost: XGBoost is a gradient boosting model that uses decision trees as base learners. It is an advanced ensemble learning technique that combines multiple weak models to create a strong predictive model.\n\n- LightGBM: LightGBM is another gradient boosting model that uses decision trees as base learners. It is designed to be efficient and scalable, making it suitable for large datasets.\n\n- CatBoost: CatBoost is a gradient boosting model that uses decision trees as base learners. It is designed to handle categorical features efficiently and has built-in support for handling missing values.\n\n(6) Some important tricks that play a role in achieving high performance in this code are:\n\n- Filling missing values using KNN: The code uses K-nearest neighbors (KNN) regression to fill missing values in the 'bmi' feature. This helps to ensure that the dataset is complete and ready for training.\n\n- Label encoding and standard scaling: The code uses label encoding to convert categorical features into numerical representations. It also uses standard scaling to normalize the numerical features. These preprocessing steps help to ensure that the features are in a suitable range for training the models.\n\n- Cross-validation: The code uses cross-validation techniques (repeated k-fold and stratified k-fold) to evaluate the performance of the models. This helps to estimate the model's performance on unseen data and avoid overfitting.\n\n- Blending predictions: The code blends the predictions from multiple models (Lasso Regression, XGBoost, LightGBM, and CatBoost) to create a final prediction. This ensemble technique helps to improve the overall performance by combining the strengths of different models.\n\n- Hyperparameter tuning: The code sets the hyperparameters for each model based on prior knowledge and experimentation. Fine-tuning the hyperparameters can significantly improve the model's performance.\n\n- Feature selection: The code uses Lasso Regression to perform feature selection and select the most important features for training the models. This helps to reduce the dimensionality of the dataset and improve the model's performance.", "title": null, "competition_name": "stroke prediction", "task_category": "Classification", "field": "Modeling", "ranking": null, "score": "AUC"}, {"content": "High-ranking Kaggle notebooks or competition strategies: (1) The overall design of this code is to train multiple models on a dataset for a Kaggle competition on stroke prediction. The code imports necessary libraries, loads the data, performs data preprocessing and feature engineering, trains the models using different algorithms, and generates predictions for the test dataset.\n\n(2) The overall model architecture includes three different models: Lasso regression, CatBoost classifier, and a neural network. The Lasso regression model is trained using LassoCV, which performs cross-validation to select the best regularization parameter. The CatBoost classifier is trained using the CatBoost library, which is a gradient boosting algorithm. The neural network is implemented using Keras and consists of multiple dense layers with dropout regularization.\n\n(3) The important hyperparameters in this code are:\n- LassoCV: 'max_iter' (maximum number of iterations), 'eps' (tolerance for convergence), 'n_alphas' (number of alphas along the regularization path)\n- CatBoost: 'depth' (depth of the trees), 'learning_rate' (learning rate), 'rsm' (random subspace method), 'subsample' (subsample ratio of the training instances), 'l2_leaf_reg' (L2 regularization coefficient), 'min_data_in_leaf' (minimum number of samples in a leaf), 'random_strength' (random strength), 'bootstrap_type' (type of bootstrap), 'grow_policy' (tree growth policy)\n- Neural Network: 'batch_size' (number of samples per gradient update), 'epochs' (number of epochs), 'callbacks' (list of callbacks), 'class_weight' (weights associated with classes)\n\n(4) The optimization objective is to maximize the area under the ROC curve (AUC) for the prediction of stroke. The models are trained to minimize the binary cross-entropy loss and maximize the AUC metric.\n\n(5) The advanced machine learning techniques used in this code are:\n- Lasso regression: LassoCV is used to perform cross-validation and select the best regularization parameter. Lasso regression is a linear model with L1 regularization, which can perform feature selection by shrinking some coefficients to zero.\n- CatBoost classifier: CatBoost is a gradient boosting algorithm that can handle categorical features and automatically handle missing values. It uses a symmetric tree structure and applies various techniques to prevent overfitting, such as random subspace method and bootstrap type.\n- Neural network: A neural network with multiple dense layers and dropout regularization is used for binary classification. The network is trained using the Adam optimizer and early stopping to prevent overfitting.\n\n(6) Other important tricks that play a role in high performance include:\n- Data preprocessing: The code performs data preprocessing steps such as handling missing values in the BMI feature using a decision tree regressor, replacing unknown values in the smoking status feature, and creating additional features based on BMI categories and risk factors.\n- Feature engineering: The code creates additional features based on gender, BMI categories, and risk factors. These features are derived from domain knowledge and can provide additional information for the models to learn from.\n- Model ensembling: The code combines the predictions from multiple models by averaging the predicted probabilities or ranking the predictions. This can help improve the overall performance by leveraging the strengths of different models.\n- Model evaluation: The code uses stratified k-fold cross-validation to evaluate the models and compute the AUC metric. This helps to assess the generalization performance of the models and prevent overfitting.\n- Class imbalance handling: The code handles the class imbalance issue in the dataset by using class weights in the neural network model and oversampling techniques such as SMOTE. This helps to improve the performance on the minority class (stroke) by giving it more importance during training.", "title": null, "competition_name": "stroke prediction", "task_category": "Classification", "field": "Modeling", "ranking": null, "score": null}, {"content": "High-ranking Kaggle notebooks or competition strategies: (1) The overall design of this code is to predict housing prices in Paris. It uses a dataset of housing information, including features such as square meters, number of rooms, and location. The code preprocesses the data, performs exploratory data analysis, trains three separate XGBoost regression models on different subsets of the data, and generates a submission file with the predicted prices.\n\n(2) The overall model architecture consists of three separate XGBoost regression models. Each model is trained on a different subset of the data based on the \"made\" feature. The subsets are divided into three categories: made <= 2000, 2001 <= made <= 2007, and made > 2007. For each subset, the model is trained using the features in the \"num_cols\" list, which includes all numerical columns except for \"id\" and \"price\". The target variable is the \"price\" column. The XGBoost models are configured with a maximum depth of 3, learning rate of 0.24, 2000 estimators, and a linear regression objective.\n\n(3) The important hyper-parameters in this code are set as follows:\n- `max_depth`: The maximum depth of each tree in the XGBoost models. It is set to 3.\n- `learning_rate`: The learning rate or step size shrinkage used in each boosting iteration. It is set to 0.24.\n- `n_estimators`: The number of boosting iterations or trees to build. It is set to 2000.\n- `objective`: The optimization objective for the XGBoost models. It is set to 'reg:linear', indicating linear regression.\n- `booster`: The type of booster to use. It is set to 'gbtree', indicating tree-based boosting.\n\n(4) The optimization objective of this code is to minimize the mean squared error between the predicted housing prices and the actual prices. This is achieved by training XGBoost regression models that learn to predict the prices based on the given features.\n\n(5) The advanced machine learning technique used in this code is XGBoost, which is an optimized gradient boosting framework. XGBoost is known for its high performance and ability to handle large datasets with high-dimensional features. It combines the strengths of both gradient boosting and regularization techniques to improve model accuracy and generalization.\n\n(6) Some important tricks that play a role in achieving high performance in this code include:\n- Data preprocessing: The code uses various data preprocessing techniques such as scaling and encoding to prepare the data for modeling.\n- Feature selection: The code selects a subset of numerical features for training the XGBoost models, which helps to reduce dimensionality and focus on the most relevant features.\n- Subset training: The code divides the data into three subsets based on the \"made\" feature and trains separate models on each subset. This allows the models to capture different patterns and relationships within each subset.\n- Hyperparameter tuning: The code sets the hyperparameters of the XGBoost models to optimal values, which are determined through experimentation or grid search using the GridSearchCV function.\n- Cross-validation: The code uses StratifiedKFold for cross-validation during hyperparameter tuning to ensure that the models are evaluated on different subsets of the data and to prevent overfitting.\n- Ensemble prediction: The code combines the predictions from the three XGBoost models to generate the final submission. This ensemble approach can help to improve the overall prediction accuracy.", "title": "Predicting Housing Prices in Paris", "competition_name": "Unknown", "task_category": "Regression", "field": "Modeling", "ranking": "Unknown", "score": "Unknown"}, {"content": "High-ranking Kaggle notebooks or competition strategies: (1) The overall design of this code is to train a high-performing model for a Kaggle competition. It includes several steps such as EDA, preprocessing, model selection, model hyperparameter tuning, and submission.\n\n(2) The overall model architecture is a pipeline that consists of a scaler (StandardScaler) and an estimator (LogisticRegression). The scaler is used to standardize the features, and the logistic regression model is used for classification. The logistic regression model is trained using the training data and then used to make predictions on the test data.\n\n(3) The important hyperparameters in this code are tuned using Optuna, an automatic hyperparameter optimization framework. The hyperparameters that are tuned include 'tol' (tolerance for stopping criteria), 'C' (inverse of regularization strength), 'fit_intercept' (whether to calculate the intercept for this model), and 'solver' (algorithm to use in the optimization problem).\n\n(4) The optimization objective is to maximize the area under the ROC curve (AUC) for the logistic regression model. The AUC is a common evaluation metric for binary classification models, and a higher AUC indicates better performance.\n\n(5) The advanced machine learning technique used in this code is Optuna, which is used for automatic hyperparameter optimization. Optuna uses a combination of different search algorithms to find the best set of hyperparameters that maximize the objective function.\n\n(6) Some important tricks that play a role in high performance include:\n- Feature scaling: The features are scaled using the StandardScaler before training the model. This helps to normalize the features and improve the convergence of the optimization algorithm.\n- Stratified K-fold cross-validation: The training data is split into multiple folds using StratifiedKFold, which ensures that each fold has a similar distribution of the target variable. This helps to reduce the bias in the evaluation of the model's performance.\n- Calibration: The calibration of the model's predicted probabilities is checked using the CalibrationDisplay. This helps to assess the reliability of the predicted probabilities and can be used to calibrate the model if necessary.\n- ROC curve analysis: The ROC curve is plotted using the RocCurveDisplay to visualize the trade-off between the true positive rate and the false positive rate. This helps to assess the overall performance of the model and choose an appropriate threshold for classification.\n- Ensemble methods: The code includes the use of ensemble methods such as VotingClassifier, StackingClassifier, and BaggingClassifier. These methods combine the predictions of multiple models to improve the overall performance and reduce overfitting.", "title": null, "competition_name": null, "task_category": "Classification", "field": "Modeling", "ranking": null, "score": null}, {"content": "High-ranking Kaggle notebooks or competition strategies: (1) The overall design of this code is to train a high-performing model for a Kaggle competition. It involves data preprocessing, feature engineering, model training using a neural network, and generating predictions for the test dataset.\n\n(2) The overall model architecture is a sequential neural network with multiple hidden layers. The model architecture is as follows:\n- Input layer: The input layer takes the preprocessed and scaled features as input.\n- Hidden layers: The model has multiple hidden layers with different numbers of neurons. Each hidden layer is followed by a LeakyReLU activation function and a dropout layer to prevent overfitting.\n- Batch normalization: A batch normalization layer is added after the fourth hidden layer to normalize the activations of the previous layer.\n- Output layer: The output layer consists of a single neuron with a sigmoid activation function, which outputs the probability of attrition.\n\n(3) The important hyperparameters in this code are:\n- class_weight: The weight assigned to the positive class in the loss function. It is set to 10, indicating that the positive class (attrition) is given more importance during training.\n- n_folds: The number of folds used in cross-validation. It is set to 11.\n- repeats: The number of times the cross-validation process is repeated. It is set to 10.\n- dr: The dropout rate used in the dropout layers. It is set to 0.1.\n- learning_rate: The learning rate used in the Adam optimizer. It is set to 0.0001.\n- alpha: The alpha parameter used in the SigmoidFocalCrossEntropy loss function. It is set to 0.8.\n- gamma: The gamma parameter used in the SigmoidFocalCrossEntropy loss function. It is set to 2.0.\n- patience: The number of epochs with no improvement after which training will be stopped during early stopping. It is set to 30.\n- min_delta: The minimum change in the monitored quantity to qualify as an improvement during early stopping. It is set to 0.00001.\n- factor: The factor by which the learning rate will be reduced during plateau-based learning rate reduction. It is set to 0.1.\n- min_lr: The minimum learning rate during plateau-based learning rate reduction. It is set to 1e-8.\n\n(4) The optimization objective is to minimize the SigmoidFocalCrossEntropy loss function, which is a modified version of the binary cross-entropy loss function. It takes into account the imbalance in the dataset by assigning a higher weight to the positive class (attrition). The model is trained to maximize the AUC (Area Under the ROC Curve) metric, which is a common evaluation metric for binary classification problems.\n\n(5) This code uses the SigmoidFocalCrossEntropy loss function, which is an advanced machine learning technique for handling imbalanced datasets. It assigns a higher weight to the positive class (attrition) during training, which helps the model to focus more on correctly predicting the positive class.\n\n(6) Some important tricks that play a role in high performance are:\n- Feature engineering: The code performs feature engineering by creating new features based on the existing ones. These new features capture important patterns and relationships in the data, which can improve the model's performance.\n- Weighted loss function: The code assigns a higher weight to the positive class (attrition) in the loss function. This helps the model to pay more attention to correctly predicting the positive class, which is often the minority class in imbalanced datasets.\n- Dropout regularization: The code uses dropout layers in the neural network architecture. Dropout randomly sets a fraction of input units to 0 during training, which helps to prevent overfitting and improve generalization.\n- Batch normalization: The code includes a batch normalization layer in the neural network architecture. Batch normalization normalizes the activations of the previous layer, which helps to stabilize and speed up the training process.\n- Early stopping: The code uses early stopping to stop training if the validation loss does not improve for a certain number of epochs. This helps to prevent overfitting and find the optimal number of epochs for training.\n- Learning rate reduction: The code reduces the learning rate during training if the validation loss does not improve for a certain number of epochs. This helps to fine-tune the model and improve its performance.", "title": "High-ranking Kaggle notebooks or competition strategies", "competition_name": "Not explicitly mentioned", "task_category": "Classification", "field": "Modeling", "ranking": "Not provided", "score": "Not provided"}, {"content": "I hadn't even selected any submissions because I wasn't expecting to do well as I watched my public LB score slip. 😄\n\nMany thanks to [Khawaja Abaid]( whose notebook [Starting Strong - XGBoost + LightGBM + CatBoost]( was the basis of [my own]( Please go upvote Khawaja's notebook if you haven't already. My only big change was to add some feature engineering before training the same models. I had discussed it previously in [Adding Risk Factors]( but here's the final FE code from the winning version:\n\n```python\ndf['MonthlyIncome/Age'] = df['MonthlyIncome'] / df['Age']\n\ndf[\"Age_risk\"] = (df[\"Age\"] < 34).astype(int)\ndf[\"HourlyRate_risk\"] = (df[\"HourlyRate\"] < 60).astype(int)\ndf[\"Distance_risk\"] = (df[\"DistanceFromHome\"] >= 20).astype(int)\ndf[\"YearsAtCo_risk\"] = (df[\"YearsAtCompany\"] < 4).astype(int)\n\ndf['NumCompaniesWorked'] = df['NumCompaniesWorked'].replace(0, 1)\ndf['AverageTenure'] = df[\"TotalWorkingYears\"] / df['NumCompaniesWorked']\n# df['YearsAboveAvgTenure'] = df['YearsAtCompany'] - df['AverageTenure']\n\ndf['JobHopper'] = ((df[\"NumCompaniesWorked\"] > 2) & (df[\"AverageTenure\"] < 2.0)).astype(int)\n\ndf[\"AttritionRisk\"] = df[\"Age_risk\"] + df[\"HourlyRate_risk\"] + df[\"Distance_risk\"] + df[\"YearsAtCo_risk\"] + df['JobHopper']\n```", "title": "Starting Strong - XGBoost + LightGBM + CatBoost", "competition_name": "Not explicitly mentioned", "task_category": "Classification", "field": "Feature Engineering, Modeling", "ranking": "Not explicitly mentioned", "score": "Not explicitly mentioned"}, {"content": "High-ranking Kaggle notebooks or competition strategies: (1) The overall design of the code is to train multiple models using different machine learning techniques and combine their predictions to make the final prediction. The code starts by importing necessary libraries and loading the data. It then preprocesses the data by encoding categorical features, scaling numerical features, and creating additional features. After preprocessing, the code trains multiple models including CatBoost, XGBoost, LightGBM, Lasso Regression, Ridge Regression, and a Keras Neural Network. Finally, the code combines the predictions from these models to make the final prediction.\n\n(2) The overall model architecture includes multiple machine learning models such as CatBoost, XGBoost, LightGBM, Lasso Regression, Ridge Regression, and a Keras Neural Network. Each model is trained using the preprocessed data and the predictions from these models are combined to make the final prediction.\n\n(3) The important hyperparameters in this code are set using Optuna library for hyperparameter optimization. The hyperparameters for each model are optimized separately using cross-validation. The hyperparameters include learning rate, depth, number of estimators, subsample, l2_leaf_reg, min_data_in_leaf, random_strength, colsample_bylevel, num_leaves, colsample_bytree, subsample, min_child_samples, reg_lambda, and others.\n\n(4) The optimization objective is to maximize the area under the ROC curve (AUC) or minimize the root mean squared error (RMSE) depending on the model.\n\n(5) The advanced machine learning techniques used in this code include CatBoost, XGBoost, LightGBM, Lasso Regression, Ridge Regression, and a Keras Neural Network. These techniques are known for their high performance in various machine learning tasks.\n\n(6) Some important tricks that play a role in high performance include feature engineering, such as creating additional features based on domain knowledge, using advanced encoding techniques like WOEEncoder, and scaling numerical features. Additionally, hyperparameter optimization using Optuna helps in finding the best set of hyperparameters for each model. Finally, ensembling the predictions from multiple models helps in improving the overall performance.", "title": null, "competition_name": null, "task_category": "Classification or Regression", "field": "Modeling", "ranking": null, "score": null}, {"content": "High-ranking Kaggle notebooks or competition strategies: (1) The overall design of this code is to train and evaluate multiple machine learning models (XGBoost, LightGBM, CatBoost) on a dataset for a Kaggle competition. The code performs feature engineering, splits the data into training and validation sets (if specified), trains the models using k-fold cross-validation, and evaluates the models using mean squared error as the optimization objective. Finally, the code generates predictions on the test dataset and saves them in a submission file.\n\n(2) The overall model architecture consists of three machine learning models: XGBoost, LightGBM, and CatBoost. Each model is trained separately using k-fold cross-validation. The training process involves fitting the model to the training data, evaluating the model on the validation data, and selecting the best model based on the evaluation metric (root mean squared error). The selected models are then used to make predictions on the test dataset.\n\n(3) The important hyperparameters in this code are set as follows:\n\n- XGBoost:\n  - `max_depth`: Maximum depth of a tree. Default value is 9.\n  - `eta`: Learning rate. Default value is 0.01.\n  - `colsample_bytree`: Subsample ratio of columns when constructing each tree. Default value is 0.66.\n  - `subsample`: Subsample ratio of the training instances. Default value is 0.76.\n  - `min_child_weight`: Minimum sum of instance weight needed in a child. Default value is 22.\n  - `lambda`: L2 regularization term on weights. Default value is 16.\n  - `gamma`: Minimum loss reduction required to make a further partition on a leaf node of the tree. Default value is 1.\n  - `tree_method`: Tree construction algorithm. Default value is 'hist'.\n  - `booster`: Booster type. Default value is 'gbtree'.\n  - `predictor`: The type of predictor algorithm to use. Default value is 'cpu_predictor'.\n  - `seed`: Random seed. Default value is 42.\n  - `objective`: Objective function. Default value is 'reg:squarederror'.\n  - `eval_metric`: Evaluation metric. Default value is 'rmse'.\n\n- LightGBM:\n  - `n_estimators`: Number of boosting iterations. Default value is 1000.\n  - `reg_lambda`: L2 regularization term on weights. Default value is 0.8435272531761764.\n  - `reg_alpha`: L1 regularization term on weights. Default value is 0.0047770992003183695.\n  - `colsample_bytree`: Subsample ratio of columns when constructing each tree. Default value is 0.5.\n  - `learning_rate`: Learning rate. Default value is 0.01.\n  - `subsample`: Subsample ratio of the training instances. Default value is 0.8.\n  - `max_depth`: Maximum depth of a tree. Default value is 100.\n  - `min_child_samples`: Minimum number of data points required in a leaf. Default value is 194.\n  - `num_leaves`: Maximum number of leaves in a tree. Default value is 894.\n\n- CatBoost:\n  - `random_seed`: Random seed. Default value is 1234.\n  - `iterations`: Number of boosting iterations. Default value is 15000.\n  - `early_stopping_rounds`: Number of iterations to wait for the metric to improve before stopping. Default value is 1000.\n  - `use_best_model`: Whether to use the best model found during training. Default value is True.\n  - `eval_metric`: Evaluation metric. Default value is 'RMSE'.\n  - `verbose`: Verbosity level. Default value is 1000.\n\n(4) The optimization objective of this code is to minimize the mean squared error (MSE) between the predicted and actual target values. The MSE is calculated using the `mean_squared_error` function from the `sklearn.metrics` module.\n\n(5) This code uses ensemble learning techniques, specifically the ensemble of XGBoost, LightGBM, and CatBoost models. Ensemble learning combines the predictions of multiple models to make a final prediction. In this case, the predictions of the XGBoost, LightGBM, and CatBoost models are averaged to obtain the final prediction.\n\n(6) Some important tricks that play a role in achieving high performance in this code include:\n\n- Feature engineering: The code includes several feature engineering functions that create new features based on the existing data. These features capture different aspects of the data and can improve the predictive performance of the models.\n\n- Cross-validation: The code uses k-fold cross-validation to train and evaluate the models. This helps to assess the generalization performance of the models and reduce overfitting.\n\n- Early stopping: The code uses early stopping during the training process of the XGBoost and CatBoost models. Early stopping allows the training to stop if the performance on the validation set does not improve for a certain number of iterations, preventing overfitting and reducing training time.\n\n- Hyperparameter optimization: The code sets hyperparameters for each model based on predefined values. These hyperparameters can be further optimized using techniques such as grid search or Bayesian optimization to find the best combination of hyperparameters for each model.\n\n- Model ensembling: The code combines the predictions of multiple models (XGBoost, LightGBM, CatBoost) to make a final prediction. Ensembling can improve the predictive performance by reducing the bias and variance of individual models.\n\n- Data preprocessing: The code preprocesses the data by scaling or transforming the features before training the models. This can help to improve the convergence and performance of the models.\n\n- Model selection: The code selects the best models based on their performance on the validation set. This helps to choose the models that are most likely to perform well on unseen data.\n\n- Regularization: The code includes regularization terms in the XGBoost and LightGBM models (L1 and L2 regularization) to prevent overfitting and improve generalization performance.\n\n- Model evaluation: The code evaluates the models using the root mean squared error (RMSE) metric. RMSE is a commonly used metric for regression tasks and provides a measure of the average prediction error.", "title": null, "competition_name": "Kaggle competition", "task_category": "Regression", "field": "Modeling", "ranking": null, "score": null}, {"content": "This episode frustrated me a lot since I couldn't improve my public leaderboard score from day 2, but it ended up giving me a good result in the private leaderboard. I just cleaned up the data and gave only one new feature 'MonthlyIncome/Age' as I posted on the [discussion]( \n\nMy model was very simple. I used the competition and original data for training.\n\n```python\nmodel = CatBoostClassifier(verbose=0,n_estimators=500)\npredictions_cat = make_predictions(full,5,model)\ncat =[np.mean(a) for a in zip(*predictions_cat)]\n```\nI have a note on how I developed my notebook at the end. If you are interested, please have a look at [my notebook]( The best score was from version 8 of this notebook.\n\nHope this helps someone here, and see you soon in the next episode.👍", "title": "not provided", "competition_name": "not provided", "task_category": "Classification", "field": "Modeling", "ranking": "not provided", "score": "not provided"}, {"content": "High-ranking Kaggle notebooks or competition strategies: (1) The overall design of this code is to train a high-performing model for a Kaggle competition. It involves loading the necessary data, preprocessing the data, building and training multiple models, and generating predictions for the test data.\n\n(2) The overall model architecture consists of three separate models: model2, model, and model4. Each model has a similar structure with multiple dense layers, batch normalization, activation functions, and dropout layers. The output of each model is a single neuron with a sigmoid activation function. The predictions from these three models are then averaged to obtain the final prediction.\n\n(3) The important hyperparameters in this code are:\n- For model2: The number of units in the dense layers (256, 128, 64), the dropout rate (0.8), the activation functions ('relu', 'elu', 'tanh', 'gelu'), the optimizer (Adam), the loss function (BinaryCrossentropy), and the metrics (AUC).\n- For model: The number of units in the dense layers (256, 128, 64), the dropout rate (0.8), the activation function ('relu'), the optimizer (Adam), the loss function (BinaryCrossentropy), and the metrics (AUC).\n- For model4: The number of units in the dense layers (500, 400, 300, 200, 100), the dropout rate (0.8), the activation functions ('relu', 'selu', 'tanh', 'elu', 'gelu'), the optimizer (Adam), the loss function (BinaryCrossentropy), and the metrics (AUC).\n- Other hyperparameters: The batch size (32), the number of epochs (100, 120), the learning rate (default value), and the early stopping rounds (200).\n\n(4) The optimization objective is to minimize the loss function, which is the BinaryCrossentropy loss. The models are trained using the Adam optimizer.\n\n(5) The advanced machine learning technique used in this code is the use of multiple models and averaging their predictions to improve the overall performance. This ensemble technique helps to reduce overfitting and increase the generalization ability of the model.\n\n(6) Other important tricks that play a role in high performance include:\n- Data preprocessing: The categorical columns are converted to category type, and the numerical columns are standardized using StandardScaler.\n- Feature encoding: The CatBoostEncoder is used to encode the categorical features.\n- Regularization: Dropout layers are used to prevent overfitting.\n- Batch normalization: Batch normalization layers are used to improve the stability and speed up the training process.\n- Activation functions: Different activation functions (relu, elu, tanh, gelu, selu) are used to introduce non-linearity and improve the model's ability to capture complex patterns in the data.\n- Model architecture: Multiple dense layers with different configurations are used to capture different levels of abstraction in the data.\n- Model training: The models are trained using a combination of train-test split and cross-validation to evaluate the model's performance and prevent overfitting.\n- Model evaluation: The AUC metric is used to evaluate the model's performance on the validation set.", "title": null, "competition_name": null, "task_category": "Classification", "field": "Modeling", "ranking": null, "score": null}, {"content": "Hello all, it was another very fun competition! I have a decent amount to go through in my solution so I'll just get right to it. Link to full notebook: [here](\n\n### Encoding\n\nWe had a decent amount of categorical features so there were many different valid approaches that I observed. Here is what I used:\n```python3\nLabelEncoder() on [\"Gender\", \"OverTime\", \"MaritalStatus\", \"PerformanceRating\"]\nOneHotEncoder() on [\"Department\", \"BusinessTravel\"]\nLeaveOneOutEncoder(sigma = 0.05) on [\"EducationField\", \"JobRole\"]\n```\n\n### Outliers\n\nThere were a couple values in the train set that could be potentially disruptive for building models. Here was my strategy for dealing with them:\n\n```python3\ntrain.at[527, \"Education\"] = 5\ntrain.at[1535, \"JobLevel\"] = 5\ntrain.at[1398, \"DailyRate\"] = train[\"DailyRate\"].median()\n```\n\n### Feature Engineering\n\n@snnclsr had a great idea in the first episode of season 3 to [add a feature to denote if the data is generated or not](\n```python3\ntrain[\"is_generated\"] = 1\ntest[\"is_generated\"] = 1\noriginal[\"is_generated\"] = 0\n```\nI ended up using this feature because we were once again working with synthetic data and it gave a small boost in CV score.\n\n@craigmthomas also had a great idea in the second episode of season 3 to use [Number of Risk Factors as a Feature]( It took a good amount of time but I went through all of features and looked closely at the ratio of `Attrition`. I experimented with a bunch of different subsets but this setup ended up improving CV the most:\n```python3\ndef feature_risk_factors(df):\ndf[\"risk_factors\"] = df[[\n\"RelationshipSatisfaction\", \"MonthlyIncome\", \n\"BusinessTravel\", \"Department\", \"EducationField\", \n\"Education\", \"JobInvolvement\", \"JobSatisfaction\", \n\"RelationshipSatisfaction\", \"StockOptionLevel\", \n\"TrainingTimesLastYear\", \"WorkLifeBalance\", \"OverTime\"\n]].apply(\nlambda x: \\\n0 + (1 if x.MonthlyIncome < 3000 else 0) + \\\n(1 if x.BusinessTravel == \"Travel_Frequently\" else 0) + \\\n(1 if x.Department == \"Human Resources\" else 0) + \\\n(1 if x.EducationField in [\"Human Resources\", \"Marketing\"] else 0) + \\\n(1 if x.Education == 1 else 0) + \\\n(1 if x.JobInvolvement == 1 else 0) + \\\n(1 if x.JobSatisfaction == 1 else 0) + \\\n(1 if x.StockOptionLevel == 0 else 0) + \\\n(1 if x.TrainingTimesLastYear == 0 else 0) + \\\n(1 if x.WorkLifeBalance == 1 else 0) + \\\n(1 if x.OverTime == 1 else 0),\naxis = 1\n)\nreturn df\n```\n\nThis feature actually ended up having the most feature importance by far for CatBoost & XGBoost. Strangely, LGBM only had this feature as 13th most important.\n\nAlright alright, I didn't just use other people's feature engineering ideas. Here are the features I personally engineered:\n```python3\ndef feature_engineering(df):\ndf[\"Dedication\"] = df[\"YearsAtCompany\"] + df[\"YearsInCurrentRole\"] + df[\"TotalWorkingYears\"]\ndf[\"JobSkill\"] = df[\"JobInvolvement\"] * df[\"JobLevel\"]\ndf[\"Satisfaction\"] = df[\"EnvironmentSatisfaction\"] * df[\"RelationshipSatisfaction\"]\ndf[\"MonthlyRateIncome\"] = df[\"MonthlyIncome\"] * df[\"MonthlyRate\"]\ndf[\"HourlyDailyRate\"] = df[\"HourlyRate\"] * df[\"DailyRate\"]\nreturn df\n```\nPretty basic interaction features, not much to comment on here other than using intuition and trial & error.\n\n### Models & Validation\n\n@kirkdco (who placed 1st in episode 2) had an excellent idea to not include the original data that the competition data was generated from in cross validation splits. I used this technique with 10 fold StratifiedKFold. I also used a basic GridSearch to find optimal hyper parameters for all 3 models. Random note: `max_depth = 1` for CatBoost surprisingly worked the best.\n\nfinal blended submission was: `cat_preds * 0.55 + xgb_preds * 0.25 + lgbm_preds * 0.2` \n\nHowever `cat_preds * 0.34 + xgb_preds * 0.33 + lgbm_preds * 0.33` ended up being **just slightly** better (0.00004+).\n\n### Bonus\n\n@tilii7 posted this topic in episode 1: [A colorful reminder to always ensemble your predictions]( He explained that in some cases it helps to plot a cumulative distribution function of multiple models and visualize the differences directly. So that's exactly what I did!\n\n![](\n\nThanks again to everyone who participated and shared their ideas! See you in episode 4!", "title": "not available", "competition_name": "not available", "task_category": "Classification", "field": "Feature Engineering, Modeling", "ranking": "not available", "score": "not available"}, {"content": "High-ranking Kaggle notebooks or competition strategies: (1) The overall design of this code is to perform an exploratory data analysis (EDA) on a dataset and then build a set of simple models for prediction. The code imports necessary libraries, defines constants, and provides functions for data description and visualization. It then imports the data, performs EDA and data modification, prepares the data for modeling, and finally makes predictions and generates a submission file.\n\n(2) The overall model architecture is based on the XGBoost algorithm. The code uses the XGBRegressor class from the xgboost library to build regression models. The models are trained separately on different subsets of the data based on the \"made\" feature. The code sets the hyperparameters of the XGBRegressor, such as max_depth, learning_rate, and n_estimators, and fits the models to the training data. The trained models are then used to make predictions on the test data.\n\n(3) The important hyperparameters in this code are:\n- LR (learning_rate): The learning rate of the XGBoost algorithm. It controls the step size at each boosting iteration. It is set to 0.24.\n- NE (n_estimators): The number of boosting iterations. It determines the number of trees to be built. It is set to 2000.\n- max_depth: The maximum depth of each tree. It controls the complexity of the model. It is set to 3.\n\n(4) The optimization objective of this code is to minimize the mean squared error (MSE) between the predicted prices and the actual prices. The XGBRegressor uses the reg:linear objective function, which is suitable for regression problems.\n\n(5) The advanced machine learning technique used in this code is the XGBoost algorithm. XGBoost is an optimized gradient boosting algorithm that combines the strengths of gradient boosting and regularization techniques. It is known for its high performance and ability to handle large datasets.\n\n(6) Some important tricks that play a role in high performance in this code include:\n- Feature engineering: The code performs feature engineering by creating new features based on the original dataset, such as filling missing values, transforming categorical variables, and creating interaction terms.\n- Data preprocessing: The code preprocesses the data by scaling numerical features using different scalers (StandardScaler, MinMaxScaler, MaxAbsScaler, RobustScaler, Normalizer) to ensure that they are on a similar scale.\n- Model tuning: The code sets the hyperparameters of the XGBoost algorithm (learning_rate, n_estimators, max_depth) to optimize the performance of the models.\n- Ensemble modeling: The code builds separate models on different subsets of the data based on the \"made\" feature and combines the predictions to improve the overall performance.\n- Visualization: The code uses various visualization techniques, such as histograms, scatter plots, and correlation heatmaps, to gain insights into the data and identify patterns or outliers that may affect the modeling process.", "title": null, "competition_name": null, "task_category": "Regression", "field": "Modeling", "ranking": null, "score": null}, {"content": "High-ranking Kaggle notebooks or competition strategies: I wanted to share a technique I've been working on.  It's something that can be used for this episode, and every episode really, especially if the *CV <-> LB score is unreliable*   Note that 20% leaderboards such as we're getting in the playgrounds can suffer from this.\n\nThe idea is to use predicted labels to reverse score back onto train as a way to measure the fitness of your model.\n\nI tried with novoenzymes here and have encountered some success (warning, long thread) - \n\nI also tried with the last playground, and found some success.  I got perfect spearman / rank correlation between the scores on train versus the scores on the private LB for a number of subs I pulled from the public notebooks.   \n\nBut critically, when I scored the winning sub I got roc auc of \"0.9023200244502575\" on train, which was more than all the other subs I tried.   As folks may already know, that sub only scored \"0.87945\" on the public LB.\n\nHere's the code if you'd like to try it yourself - \n\n```python\ntest = pd.read_csv(\"/kaggle/input/playground-series-s3e2/test.csv\")\ntrain = pd.read_csv(\"/kaggle/input/playground-series-s3e2/train.csv\")\nsub =pd.read_csv(\"/kaggle/input/winpg1/submisson_16.csv\") #<- Winning sub\ntraind = pd.get_dummies(train)\ntest['stroke'] = sub['stroke']\nimport xgboost\ntestd = pd.get_dummies(test)\nmodel = xgboost.XGBRegressor()\nX = testd.drop([\"id\", 'stroke'], axis=1)\nmodel.fit(X, testd['stroke'])\nimport sklearn.metrics\nsklearn.metrics.roc_auc_score(traind['stroke'], model.predict(traind.drop([\"id\", \"stroke\"], axis=1)))\n0.9023200244502575\n```\nI've attached a copy of the winning sub to this post.\n\nThis is something I suspect that could be used broadly across all kaggle contests when selecting final submission candidates, and in fact could be used as a way to measure overfitting / fitness itself in perhaps any situation (well, with some tuning of course :)\n\nIn code competitions, the idea there might be to use oof labels predicting against in fold labels and cross validating your score that way.\n\nAs I have time, I'm going to go back over some competitions that suffered shakeup and see if this could have been used.  My guess is that it may be somewhat reliant on relatively good scores in accuracy.  Ie, without accuracy the results might be more noisy and less useful.\n\nIt'd be interesting to see if something like this could also be used for training, eg selecting epochs / forward feature selection / hill climbing based on not just validation loss but also some kind of semi supervised learning coherence.\n\nTo be clear, I'm not suggesting here to use pseudo labels for training.  That works for certain things, but also frequently leads to overfitting.  You still need an underlying set of models that are compelling.", "title": "not provided", "competition_name": "Playground Series - Season 3, Episode 2", "task_category": "Classification", "field": "Model Evaluation", "ranking": "not provided", "score": {"train_roc_auc": "0.9023200244502575", "public_lb_roc_auc": "0.87945"}}, {"content": "High-ranking Kaggle notebooks or competition strategies: (1) The overall design of the code is to train and evaluate different machine learning models for a Kaggle competition. It starts by importing the necessary libraries and setting some parameters. Then, it loads the training and testing data from CSV files. Next, it performs some data preprocessing and feature engineering steps. After that, it defines helper functions for model training and evaluation. Finally, it uses cross-validation to train the models, evaluate their performance, and generate predictions for the test data.\n\n(2) The overall model architecture depends on the selected model. The code supports several models, including Linear Regression, Ridge Regression, Support Vector Regression (SVR), Extra Trees Regressor (ET), Random Forest Regressor (RF), XGBoost, LightGBM, and CatBoost. Each model has its own specific architecture and hyperparameters. The code uses the scikit-learn and XGBoost/LightGBM/CatBoost libraries to implement these models.\n\n(3) The important hyperparameters are set within the code. For example, in the XGBoost model, the hyperparameters include the learning rate, maximum depth, number of estimators (epochs), early stopping rounds, and regularization parameters (lambda and alpha). These hyperparameters are set manually or optimized using Optuna, a hyperparameter optimization library. Other models have their own specific hyperparameters, which are also set within the code.\n\n(4) The optimization objective is to minimize the root mean squared error (RMSE) between the predicted and actual target values. This is achieved by training the models on the training data and evaluating their performance on the validation data. The RMSE is calculated using the mean_squared_error function from the scikit-learn library.\n\n(5) The code uses several advanced machine learning techniques, including cross-validation, hyperparameter optimization with Optuna, feature engineering, feature scaling, outlier detection and removal, PCA, partial dependence plots, and SHAP (SHapley Additive exPlanations) values. These techniques help improve the performance and interpretability of the models.\n\n(6) Other important tricks that play a role in high performance include feature selection, handling missing values, handling categorical variables (e.g., label encoding), and ensembling/stacking multiple models. These tricks are implemented within the code to improve the accuracy and robustness of the models.", "title": "Not provided", "competition_name": "Not provided", "task_category": "Regression", "field": "Modeling", "ranking": "Not provided", "score": "Not provided"}, {"content": "High-ranking Kaggle notebooks or competition strategies: Hi all,\n\nIt seems there was quite a good shake up given that dataset was highly imbalanced and AUC can vary a lot depending the number of samples. I realized there was a good difference between by OOF AUC and the leaderboard so I decided to trust only my CV (10 StratifiedKfold).\n\n### Tricks that worked\n\n1. Fill `unknown` category form `smoking status` as `never smoked`. The ituition was given on my **[EDA]( where you can see that `unknown` class has the lowest probability of stroke.\n2. Fill `other` class from `gender` as `male`. I spotted a boost on CV when filling that record in synthetic dataset. I didn't probe the leaderboard to validate this on test.\n3. Ensemble using gradient descent and ranking the predictions.\n4. Concat original stroke dataset and use StratifiedKfold where validation only has synthetic data.\n5. Feature selection using RecursiveFeatureElimanation. Additional features I tried:\n```Python\ndef generate_features(df):\ndf['age/bmi'] = df.age / df.bmi\ndf['age*bmi'] = df.age * df.bmi\ndf['bmi/prime'] = df.bmi / 25\ndf['obesity'] = df.avg_glucose_level * df.bmi / 1000\ndf['blood_heart']= df.hypertension*df.heart_disease\nreturn df\n```\n\n### Things that didn't work\n1. Use forward selection taken from this [notebook]( This was my second submission and scored 0.89941 on private leaderboard. I think It didn't worked because the final ensemble was only composed of XGBoost models while my best submission has a wide variety of models.\n2. MeanEncoder, WoEEncoder and CountFrequency encoder. Neither of those provided better solutions that OneHotEncoder.\n\n### Final Ensemble:\nMy final ensemble is composed of several models:\n* LogisticRegression with RFE, l2, and liblinear solver.\n* LogisticRegression with RFE, no regularization, lbfgs solver.\n* LightGBM no RFE, no Feature Engineering.\n* Another LightGBM with early stopping and monitoring logloss (yes, logloss no AUC).\n* A Catboost model inspired in [this notebook]( by @dmitryuarov. I made some modifications to make sure the OOF AUC was similar to the mean AUC by fold.\n* A tuned XGBoost with feature engineering. (best single model) See the code and results replica **[Here](\n\nAnd that's all.\nMany congratulations to the winners, looking forward to the next playground competitions.", "title": "High-ranking Kaggle notebooks or competition strategies", "competition_name": "Stroke Prediction", "task_category": "Classification", "field": "Modeling", "ranking": "Not explicitly mentioned", "score": "0.89941 on private leaderboard"}, {"content": "High-ranking Kaggle notebooks or competition strategies: (1) The overall design of the code is to train and evaluate two models: a LightGBM model and a neural network model. The code first loads the necessary data from CSV files and preprocesses it using the DataPrep class. Then, it splits the data into training and validation sets using cross-validation. The LightGBM model is trained on the training set and used to make predictions on the validation set. The neural network model is also trained on the training set and used to make predictions on the validation set. Finally, the predictions from both models are combined to generate the final submission.\n\n(2) The overall model architecture consists of two models: a LightGBM model and a neural network model.\n\nThe LightGBM model is implemented using the LGBClassModel1 class. It uses the LightGBM library to train a gradient boosting model with multiclass classification objective. The model has 87 classes (corresponding to the target values) and uses the specified hyperparameters for training. The features used for training are specified in the \"features\" list.\n\nThe neural network model is implemented using the NNRegModel1 class. It uses a custom neural network architecture implemented in the Net class. The neural network consists of a series of fully connected layers with leaky ReLU activation functions. The number of hidden layers and the number of hidden units per layer are specified in the configuration. The model is trained using the specified hyperparameters and bagging is used to generate multiple predictions for each sample. The bagged predictions are aggregated using the specified aggregation function (mean, median, or max) to generate the final prediction.\n\n(3) The important hyperparameters in this code are:\n\n- LightGBM model hyperparameters:\n  - boosting_type: The type of boosting algorithm to use (gbdt).\n  - objective: The objective function to optimize (multiclass).\n  - num_class: The number of classes in the target variable (87).\n  - n_estimators: The number of boosting iterations (300).\n  - learning_rate: The learning rate for gradient boosting (0.019673004699536346).\n  - num_leaves: The maximum number of leaves in each tree (208).\n  - max_depth: The maximum depth of each tree (14).\n  - min_data_in_leaf: The minimum number of samples required to form a leaf (850).\n  - feature_fraction: The fraction of features to consider for each tree (0.5190632906197453).\n  - lambda_l1: The L1 regularization term (7.405660751699475e-08).\n  - lambda_l2: The L2 regularization term (0.14583961675675494).\n  - max_bin: The maximum number of bins to use for feature discretization (240).\n  - verbose: Verbosity level (-1).\n  - force_col_wise: Whether to use column-wise training (True).\n  - n_jobs: The number of parallel threads to use (-1).\n\n- Neural network model hyperparameters:\n  - tr_collate_fn: The collate function to use for training data (None).\n  - val_collate_fn: The collate function to use for validation data (None).\n  - target_column: The name of the target column in the dataset (\"target_norm\").\n  - output_dir: The directory to save the model outputs (\"results/nn_temp\").\n  - seed: The random seed for reproducibility (-1).\n  - eval_epochs: The number of epochs between each evaluation (1).\n  - mixed_precision: Whether to use mixed precision training (False).\n  - device: The device to use for training (\"cpu\").\n  - n_classes: The number of classes in the target variable (1).\n  - batch_size: The batch size for training (128).\n  - batch_size_val: The batch size for validation (256).\n  - n_hidden: The number of hidden units in each layer of the neural network (64).\n  - n_layers: The number of hidden layers in the neural network (2).\n  - num_workers: The number of worker processes for data loading (0).\n  - drop_last: Whether to drop the last incomplete batch (False).\n  - gradient_clip: The maximum gradient norm for gradient clipping (1.0).\n  - bag_size: The number of models to train in the bagging ensemble (1).\n  - bag_agg_function: The aggregation function to use for bagged predictions (mean).\n  - lr: The learning rate for neural network training (2e-3).\n  - warmup: The number of warmup steps for learning rate scheduling (0).\n  - epochs: The number of training epochs (10).\n  - features: The list of features to use for training.\n\n(4) The optimization objective is to minimize the symmetric mean absolute percentage error (SMAPE) between the predicted and actual target values. The SMAPE is calculated using the smape1p function, which takes the predicted and actual values as inputs and returns the SMAPE score.\n\n(5) The advanced machine learning technique used in this code is gradient boosting with LightGBM. Gradient boosting is an ensemble learning method that combines multiple weak models (decision trees) to create a strong predictive model. LightGBM is a gradient boosting framework that uses a tree-based learning algorithm and is optimized for efficiency and speed.\n\n(6) Some important tricks that play a role in achieving high performance in this code include:\n\n- Feature engineering: The DataPrep class is used to create additional features from the raw data. These features capture information about the patient's previous visits, the target horizon, and other relevant variables. These engineered features provide additional information to the models and help improve their predictive performance.\n\n- Cross-validation: The code uses cross-validation to evaluate the performance of the models. This helps to assess the generalization performance of the models and avoid overfitting.\n\n- Bagging: The neural network model is trained multiple times with different random seeds to create an ensemble of models. This helps to reduce the variance of the predictions and improve the overall performance.\n\n- Learning rate scheduling: The learning rate for the neural network model is scheduled using a cosine annealing schedule with warmup. This helps to improve the convergence of the model during training and prevent it from getting stuck in local minima.\n\n- Gradient clipping: The gradients of the neural network model are clipped to a maximum norm of 1.0. This helps to prevent exploding gradients and stabilize the training process.\n\n- Mixed precision training: The code supports mixed precision training, which uses lower precision (e.g., float16) for some computations to speed up training and reduce memory usage. This can help to train larger models or use larger batch sizes without running out of memory.\n\n- Parallel processing: The code uses parallel processing to speed up data loading and model training. This can help to reduce the overall training time and improve efficiency.\n\n- Model selection: The code trains and evaluates multiple models (LightGBM and neural network) and combines their predictions to generate the final submission. This ensemble approach helps to leverage the strengths of different models and improve the overall predictive performance.", "title": "Not provided", "competition_name": "Not provided", "task_category": "Classification", "field": "Modeling", "ranking": "Not provided", "score": "Not provided"}, {"content": "Sorry for late sharing. First of all, thanks to competition organizers for hosting this interesting competition and my great teammates(@hyd,@rib). And congrats my friend rib for becoming GM.\n\nOur solution is simple, we found information related to \"visit_month\" very useful and information related to proteins are useless. So we focus on the samples, structures and models.\n\n### Samples\nWe used samples with visit_month in \"[0, 6, 12, 18, 24 , 36, 48, 60, 72, 84]\" for training. And found that our cv is much better correlated to LB.\n\n### Features\n- All about “visit_month”\n1) use visit_month as meta feature\n2) gap between visit_month and last visit_month\n3) times of visit for each patient\n- Little about “protein”\nuse NPX’s ratio of each patient, instead of the original values\n![](\n### Structure\n1. 16 labels\nPredict each “updrs” for predicted_month_diff=0,6,12,24\n![](\n2. 4 labels\nUse predicted_month_diff as a feature, and predict each one’s 4 updrs\n![](\n### Models\nSimple MLP with different structures and parameters.Finally we blends with:\n1. Models training in different numbers of labels\n2. Models training in different structure of network\n3. Models training in different parameters of network\n\ncode:[", "title": null, "competition_name": null, "task_category": "Regression", "field": "Modeling", "ranking": null, "score": null}, {"content": "High-ranking Kaggle notebooks or competition strategies: (1) The overall design of the code is to train a high-performing model for a Kaggle competition. It includes the necessary imports, data loading and preprocessing, model training, and inference on test data.\n\n(2) The overall model architecture is not explicitly mentioned in the code. However, based on the code snippets, it can be inferred that the model architecture is defined in the `model.py` file. The `WalkNetwork` class in `model.py` is used to define the model architecture. The model architecture is likely a neural network model that takes input features and outputs predictions for freezing gait events. The specific architecture details are not provided in the code.\n\n(3) The important hyperparameters in this code are defined in the JSON files located in the `params` directory. Each JSON file corresponds to a specific set of hyperparameters for the model. The code loads the hyperparameters from the JSON file based on the model being trained. The hyperparameters include parameters related to the model architecture, training process, and data preprocessing.\n\n(4) The optimization objective is not explicitly mentioned in the code. However, based on the context of the Kaggle competition, the optimization objective is likely to minimize the prediction error for freezing gait events. The model is trained to make accurate predictions for freezing gait events based on the input features.\n\n(5) The code does not explicitly mention the use of any advanced machine learning techniques. However, based on the imports and the use of PyTorch, it can be inferred that the code uses deep learning techniques for training the model. The model architecture is likely a deep neural network that is trained using gradient-based optimization algorithms.\n\n(6) Some important tricks that may play a role in achieving high performance include:\n- Data preprocessing: The code preprocesses the input data by loading and processing the raw data files. It applies specific transformations and manipulations to the data to prepare it for training the model.\n- Model architecture: The code defines the model architecture in the `model.py` file. The specific architecture details are not provided in the code, but the model architecture is likely designed to capture the relevant patterns and features in the input data for predicting freezing gait events.\n- Hyperparameter tuning: The code uses different sets of hyperparameters for training the model. The hyperparameters are defined in the JSON files located in the `params` directory. The code loads the hyperparameters based on the model being trained, allowing for experimentation and optimization of the model's performance.\n- Parallel inference: The code uses parallel inference to speed up the prediction process. It splits the test data into batches and performs inference on each batch in parallel using multiple models. This can help improve the efficiency and speed of the prediction process.\n- Ensemble prediction: The code combines the predictions from multiple models by averaging them. This ensemble prediction approach can help improve the overall prediction accuracy and robustness of the model.\n- Performance evaluation: The code evaluates the performance of the model by comparing the predicted values with the ground truth values. It calculates metrics such as mean squared error or accuracy to assess the model's performance. This allows for monitoring and optimization of the model's performance during training.", "title": null, "competition_name": "Freezing Gait Prediction", "task_category": "Classification", "field": "Modeling", "ranking": null, "score": null}, {"content": "High-ranking Kaggle notebooks or competition strategies: #AMP®-Parkinson's Disease Progression Prediction\nWow, this competition had a close finish at the top. I suspected this would be the case because I believe there was only 1 source of reliable signal (i.e. `patient visit dates`) and all the tops teams were working hard to extract an extra SMAPE 0.1 from it. The metric SMAPE is a percentage so `0.1` is actually `0.001`. That's how close the finish was!\n\nThe final leaderboard is separated into two groups. The top 18 teams have `SMAPE <= 62.5` and the next teams have `SMAPE >= 68.4`. I believe the top 18 teams used signal from `patient visit dates` and the next teams `did not`.\n\n# Signal from Protein/Peptide data\nIn this competition, Kaggle provided 227 Protein NXP features and 968 Peptide PeptideAbundance features. That is 1195 features for each of 17 possible visit dates. We only have 248 train patients. And the `curse of dimensionality` begins when `number of features > train samples / 10`. In other words we only have enough train data to reasonably train 25 features not 1195 features!\n\nI did an experiment where i made 1000 columns of random numbers. Using forward feature selection, I found that columns of `random numbers` would boost GroupKFold CV score **the same amount that protein/peptide features did**. This means that there may be signal hiding in the protein peptide data but it is too weak to detect patterns with only 248 patients (because no protein nor peptide boost CV more than random numbers can).\n\n# Signal from Patient Visit Dates\nNext I searched patient visit dates for signal. Many Kagglers overlooked that we can engineer features from patient visit dates. Here are some example features\n* when was patient's first blood work measured?\n* did patient get blood work at their first doctor visit, yes or no?\n* how many times did a patient visit the doctor?\n* how long ago was the patient's last visit?\n\nEtc etc. We can create 100s of features about when a patient visited the doctor and when a patient had blood work done. I quickly noticed the following trend. **Patients who visit the doctor more often have larger UPDR scores**. This is shown in the following 3 plots. The first are patients who visited the doctor a normal number of times. The second are patients who visited 1 standard deviation less than normal. And the last are patients who visited 1 standard deviation more. In each plot, we display the average target value per visit month for these 3 groups of patients:\n![](\n![](\n![](\n\n# Feature Engineering\nThe above plots show that there is signal in the `patient visit dates`. What is the best way to extract this signal? I generated 100s of features and used `for-loops` with **RAPIDS cuML SVR** to find which features extract the most signal.\n\nIn the end, simple \"booleans\" worked best (and the model \"created its own features internally\"). For each visit month, i created a boolean variable. For example for visit month = 24, i created the following \"boolean\":\n* `v24 = 0` if we know that patient did **not** visit on visit month = 24\n* `v24 = 1` if we know that patient did visit on visit month = 24\n* `v24 = -1` if we **do not** know if patient visited on month = 24\n\nThe reason for the third category is because at each time step of Kaggle's API we are asked to predict `0, 6, 12, 24` months into the future. So if the current visit month = 12 and we are predicting visit month 36, we do **not** know if the patient visited during visit month = 24.\n\n# Single Model RAPIDS cuML - 8th Place Gold\nA single **RAPIDS cuML SVR** model trained with 11 features which are `visit_month` and `v0`, `v6`, `v12`, `v18`, `v24`, `v36`, `v48`, `v60`, `v72`, `v84` where the `v` features are described above achieves `CV = 55.5` and `Public LB = 55.4` and `Private LB = 60.5`. This is 8th place Gold. Using **RAPIDS cuML** was great because it allowed me to experiment dozens of models in minutes!\n\n# Single Model TensorFlow MLP - 4th Place Gold\nAfter I found the above features, i tried different model types. I tried XGBoost with `PseudoHuber loss`. It's CV was not as good as **RAPIDS cuML SVR**. Next I tried TensorFlow MLP with `MeanAbsoluteError`. We built an MLP with 10 hidden layers where each hidden layer has 24 units and activation Relu. We used no Dropout and no BatchNormalization. We trained it for 15 epochs with Adam optimizer `LR = 1e-3` and then 15 epochs `LR = 1e-4`. This achieves `CV = 55.0` and `Public LB 54.9` and `Private LB 60.1`. This is 4th place Gold.\n\n# Creating Train Data\nOur model trained with `train_clinical_data.csv` only. Creating proper train data for the above features was not trivial. We needed to convert each row from the original train data into **4 new rows**. If the original row was `patient_id = 55` and `visit_month = 24`. Then we needed to replace this row with 4 new rows:\n* patient_id=55, visit_month=24, And v0=X1, v6=-1, v12=-1, v24=-1, v>24=-1\n* patient_id=55, visit_month=24, And v0=X1, v6=X6, v12=-1, v24=-1, v>24=-1\n* patient_id=55, visit_month=24, And v0=X1, v6=X6, v12=X12, v24=-1, v>24=-1\n* patient_id=55, visit_month=24, And v0=X1, v6=X6, v12=X12, v24=X24, v>24=-1\n\nwhere `X1`, `X6`, `X12`, `X24` are the values `0` or `1` based on whether `patient_id=55` visited on months 0, 6, 12, 24 in the train data. The 4 new rows are current visit month minus 0, 6, 12, 24. If any of these subtractions are not valid visit months then we don't make that row.\n\n# 4th Place Solution Code\nI published my 4th place submission code using TensorFlow MLP [here][1]. Enjoy!\n\n[1]: ", "title": "AMP®-Parkinson's Disease Progression Prediction", "competition_name": "AMP®-Parkinson's Disease Progression Prediction", "task_category": "Regression", "field": "Feature Engineering", "ranking": "4th Place", "score": {"CV": "55.0", "Public LB": "54.9", "Private LB": "60.1"}}, {"content": "I am very surprised that I can get 7th place &amp; 1st place in students in this M5 forecasting competition. It is my first year that I participate in Kaggle competitions, and the first time that I get ranked here. It is more than happy that I can share my solution here (although it may be a bit too late).\n\n## Model Summary\nIn this competition, I first focused on the Accuracy competition (i.e. producing the mean forecast), and then leveraged on the model built on Accuracy competition to produce any uncertainty estimate (i.e. quantile prediction).\n\nI built two seq2seq LSTM model to produce the mean forecast on the next 28D. One is trying to forecast on the store-item level, another attempts to forecast on the dept-store level. The final accuracy forecast consists of simple averaging of both model. The uncertainty estimate is built using the estimated residuals of both models, while assuming the forecast residuals are i.i.d. normal.\n\n## Takeaway\nI think the key takeaway in this competition is the importance of a reliable local validation scheme, together with the model ensembling technique, which makes my model to deliver stable performance both locally and in public / private LB. At the early stage of the competition where people are optimizing for the public LB, my model performance on public LB is actually not comparable to those top solutions. However, the key benefit of my solution is that it delivers stable performance both locally and in public / private LB.\n\nThe WRMSSE / WSPL metric can be volatile given only 28D of validation window (i.e. public LB), because it is equally weighted on all aggregate levels (meaning that the top aggregate levels forecast, even with a few observations, already give a huge proportion of the loss). It would be potentially overfitting if we focus too much on optimizing for the public LB, without a reliable local validation scheme.\n\n## Model Architecture\nThe seq2seq LSTM model takes an input window of 28D, and output window of 28D. Basically it is similar to an encoder-decoder model for machine translation except that I add some exogenous features to the model, and avoid using any forecast information in the decoder input (i.e. trained &amp; forecasted unconditionally). The rationale behind training unconditionally is to ensure that the model performs similarly at inference time as at training time. In the following graph, y denotes the time series (i.e. sales), z denotes the exogenous features (e.g. weekday, holiday event, is snap, item id), h denotes the hidden state (as well as cell state).\n\n![](\n\n## Features\nI do not use any special features. Basically the features are calendar features (e.g. holiday event, holiday type, weekday), id features (item-id, dept-id, store-id) and price features. By SHAP value analysis, the id features and weekday are significant to the model performance. The categorical features with high cardinality are post-processed using embedding layers.\n\nSome important feature processing steps are:\n1. Re-scale each time-series into [0, 1] using its max.\n2. Train the model to forecast the increment of sales value since the first day of input window (i.e. remove trend).\n\n## Training Method\nThe LSTM models are trained using Adam algorithm. The dept-store model is trained with weighted MSE loss. The store-item model is trained with unweighted zero-inflated poisson loss (to deal with cases with many 0s).\n\n### Improving Model Stability\nDuring training, an issue of model instability is observed, similar to the observations [here]( The following graph shows how the WRMSSE metric (used for accuracy measure) changes during training epochs.\n\n![](\n\nTo resolve the instability issue, each seq2seq LSTM model actually consists of models trained at 20 different checkpoints (i.e. training epochs) and is a simple average of the 20 checkpoint models. The submission model is trained blindly without any early stopping, and is observed to have stable performance.\n\n## Hierarchical Forecast\nThe dept-store level forecast is first converted into store-item level forecast using the 28D historical average of ratio. Then both models' forecasts are simple averaged and converted to forecast on all aggregate level by bottom-up approach.\n\n## CV Scheme\nMy local validation scheme consists of 4 folds of data, each is of 28D. Particularly:\nFold 1: (training) [train st, d1829] --&gt; (validation) [d1830, d1857]\nFold 2: (training) [train st, d1857] --&gt; (validation) [d1858, d1885]\nFold 3: (training) [train st, d1885] --&gt; (validation) [d1886, d1913]\nFold 4: (training) [train st, d1913] --&gt; (validation) [d1914, d1941]\nwhere train st is 2.5 yrs before the end of training data when training store-item model, and is 0 when training dept-store model (i.e. training on full dataset). The model is trained once only on fold 1 so as to speed up the local validation process. It is observed that the score in each fold has large variance, indicating that it may be unreliable / overfitting to optimize on any 28D data (i.e. the public LB). Therefore, I focus on the local CV score which also gives close alignment with both public LB and private LB score.\n\nThanks a lot for the host who gave us a chance to join such a rewarding competition. I learnt a lot from this competition. Also special thanks to @kyakovlev who built a lot of great discussion thread &amp; great notebook (which are super useful for us as a newbie to Kaggle).", "title": "Not explicitly provided", "competition_name": "M5 forecasting competition", "task_category": "Forecasting", "field": "Modeling", "ranking": "7th place & 1st place in students", "score": "Not explicitly provided"}, {"content": "High-ranking Kaggle notebooks or competition strategies: (1) The overall design of the code is to make predictions on a test dataset using multiple trained models. The code first loads the trained models for the Tdcsfog and Defog tasks. Then, it preprocesses the test dataset by scaling the numerical features and creating input arrays for the models. Finally, it makes predictions using the trained models and saves the results.\n\n(2) The overall model architecture consists of multiple instances of the TdcsfogRnnModel and DefogRnnModel classes. These models are recurrent neural networks (RNNs) with GRU cells. The input to the models is a sequence of numerical features, which are passed through a linear layer and layer normalization before being fed into the GRU cells. The output of the GRU cells is passed through another linear layer and layer normalization to obtain the final predictions.\n\n(3) The important hyperparameters in this code are:\n- dropout: The dropout rate used in the linear layers of the models.\n- input_numerical_size: The number of numerical features in the input.\n- numeraical_linear_size: The size of the linear layer applied to the numerical features.\n- model_size: The size of the hidden state in the GRU cells.\n- linear_out: The size of the linear layer applied to the output of the GRU cells.\n- out_size: The number of output classes.\n\n(4) The optimization objective is not explicitly mentioned in the code. However, based on the architecture of the models and the use of sigmoid activation functions in the final linear layer, it can be inferred that the models are trained using binary cross-entropy loss.\n\n(5) The advanced machine learning technique used in this code is the use of recurrent neural networks (RNNs) with GRU cells. RNNs are able to capture temporal dependencies in sequential data, making them suitable for time series analysis tasks like the ones in this code.\n\n(6) Some important tricks that play a role in achieving high performance in this code include:\n- Layer normalization: This technique helps stabilize the training process by normalizing the inputs to each layer.\n- Dropout: This technique helps prevent overfitting by randomly setting a fraction of the input units to 0 during training.\n- Scaling of numerical features: This technique helps ensure that the numerical features have similar scales, which can improve the performance of the models.\n- Ensembling of models: This technique involves training multiple models and combining their predictions to obtain a final prediction. Ensembling can help improve the robustness and generalization of the models.", "title": null, "competition_name": "Tdcsfog and Defog tasks", "task_category": "Classification", "field": "Modeling", "ranking": null, "score": null}, {"content": "High-ranking Kaggle notebooks or competition strategies: When I selected my two final submissions a few hours ago, I decided for - one model which uses only the month data for the predictions (no peptides and proteins) and has a public lb score of 54.7. - another model, which additionally uses the peptides and proteins, has a better cv but a bad public lb score (55.3). It turned out that the public leaderboard was the better indicator than the cv, and the peptide/protein feature engineering was useless. # Recognizing the control group If we plot the median updrs scores for every month, we see that the months which are multiples of 12 (the cyan markers on the gridlines) are usually lower than the non-multiples of 12 (the magenta markers between the gridlines). This cannot be a coincidence. ![b1]( A scatterplot of the 248 patients versus the months of their updrs assessments reveals that there are three groups of patients: The patients of the green group had their first visits in months 0, 3, 6, 9, 12. The patients of the orange group had their first visits in months 0, 6, 12, 18, 24 and the last visit in month 60. The patients of the red group had their first visits in months 0, 12, 24. ![b2]( If we plot the updrs scores over time of every patient, we see differences among the groups. The red group in particular has the lowest updrs scores, which means that these are the healthiest people, and updrs_4 has rarely been measured for them. We can hypothesize that the red group is the control group (a group of people without Parkinson's disease), and the experimenters decided to test the control group only once a year and to skip the updrs_4 test for this group. The real patients (green and orange groups) were tested more often and with all four updrs tests. ![b3]( Conclusion: We can distinguish the control group from the real patients according to their first non-zero visit_month: If the first non-zero visit_month is <12, we have a real patient; if the first non-zero visit_month equals 12, the person belongs to the healthy control group. This distinction has high predictive value for the updrs scores. # The model The model has only two features: - the group to which a patient belongs - the month of the prediction Depending on the group, it predicts a linear or isotonic regression: ![b4]( # Lessons learned - A thorough EDA is important, and the EDA must be adapted to the dataset. Automated EDA tools don't find the hidden information. - Unusual metrics (smape plus one) require unusual methods. - If the training dataset is small, simple models turn out best. - Medical data is scarce and expensive. If we haven't been able to prove a connection between proteins and Parkinson symptoms, this doesn't mean there is none. It only means that another thousand patients must be convinced to participate in a five-year study, and we might see a follow-up competition in 2028... - In biology and medicine, we usually search for very weak effects: Protein measurements are imprecise and updrs scores depend on the mood of the patient and the doctor. If anybody was expecting SMAPE scores far below 50, this expectation was unrealistic. Source code is [here]( ", "title": "Recognizing the control group", "competition_name": "Parkinson's Disease Progression Prediction", "task_category": "Regression", "field": "Modeling", "ranking": "Not explicitly mentioned", "score": {"public_lb_score": "54.7", "cv_score": "Not explicitly mentioned", "alternative_model_public_lb_score": "55.3"}}, {"content": "Thanks my teammates @hookman @zui0711 @max2020 @librauee , I have learnt a lot from them. A crucial trick found by them is there are two groups in the data: **The true patients and the control group**. We can find this by **the minimum visit_month diff** of each id:\n```\nfor df in [clinical, sup_clinical]:\ndf['visit_month_diff'] = df.groupby(['patient_id'])['visit_month'].diff()\ndf['visit_month_diff_min'] = df.groupby('patient_id')['visit_month_diff'].transform('min')\n```\nThere are 3, 5, 6, 12, 36 visit_month diff in clinical and sup_clinical, we choose only 3, 6, 12, 36 parts as training data, and transform 3, 36 to 6. We find 3, 6 and 36 has obviously higher updrs values and 12 has lower updrs values(5 part dropped as abnormal).\n![updrs in different visit_month diff and months](\nWe can draw a conclusion **visit_month diff==6** are true patients and **visit_month diff==12** are control group.\nWe use piecewise function to optimize two groups smape separately:\n```\ndef calculate_predictions(pred_month, trend):\nif target == 'updrs_4': \npred_month = pred_month.clip(60, None) \npred_month2 = (pred_month-60).clip(0, None)\nreturn np.round(trend[0] + pred_month * trend[1] + pred_month2 * trend[2])\n```\n![0=control group, 1=true patients](\nIn the first loop inference, we cannot get visit_month diff, so we train additional coefficients based on true patients + control group. In every loop, we record history data so that we could get the **the minimum visit_month diff**.\nFinding these two groups can help you reach 54.2~54.8 on public board and 60.1~60.7 on private board.", "title": null, "competition_name": null, "task_category": "Classification", "field": "Feature Engineering", "ranking": null, "score": "54.2~54.8 on public board and 60.1~60.7 on private board"}, {"content": "High-ranking Kaggle notebooks or competition strategies: (1) The overall design of this code is to train a model for a Kaggle competition on sales forecasting. It imports necessary libraries and data, preprocesses the data, splits it into training and testing sets, trains a LightGBM model, makes predictions on the test set, and generates a submission file.\n\n(2) The overall model architecture is a LightGBM model for regression. LightGBM is a gradient boosting framework that uses tree-based learning algorithms. The model is trained using the training data and evaluated using the testing data. The model parameters are set to optimize the root mean squared error (RMSE) metric. The model is trained with early stopping to prevent overfitting.\n\n(3) The important hyperparameters in this code are:\n- `boosting_type`: The type of boosting algorithm used, set to 'gbdt'.\n- `metric`: The evaluation metric used, set to 'rmse' (root mean squared error).\n- `objective`: The optimization objective, set to 'regression'.\n- `n_jobs`: The number of parallel threads used for training, set to -1 to use all available threads.\n- `seed`: The random seed used for reproducibility, set to 236.\n- `learning_rate`: The learning rate of the boosting process, set to 0.01.\n- `bagging_fraction`: The fraction of data to be used for each iteration, set to 0.75.\n- `bagging_freq`: Frequency for bagging, set to 10.\n- `colsample_bytree`: The fraction of features to be used for each iteration, set to 0.75.\n- `num_boost_round`: The number of boosting iterations, set to 2500.\n- `early_stopping_rounds`: The number of rounds without improvement before early stopping, set to 50.\n\n(4) The optimization objective is to minimize the root mean squared error (RMSE) between the predicted quantities and the actual quantities.\n\n(5) The advanced machine learning technique used in this code is gradient boosting with LightGBM. Gradient boosting is an ensemble learning method that combines multiple weak models (decision trees) to create a strong predictive model. LightGBM is a fast and efficient implementation of gradient boosting that uses a histogram-based algorithm for splitting features.\n\n(6) Some important tricks that play a role in high performance include:\n- Feature engineering: The code creates additional features based on the calendar data, such as whether a day is a holiday or a weekend. These features can provide valuable information for predicting sales.\n- Data preprocessing: The code preprocesses the data by merging multiple dataframes, dropping unnecessary columns, and converting categorical variables into dummy variables. This ensures that the data is in the correct format for training the model.\n- Hyperparameter tuning: The code sets the hyperparameters of the LightGBM model to optimize the RMSE metric. This helps to find the best combination of hyperparameters for the given data and problem.\n- Early stopping: The code uses early stopping during training to prevent overfitting. This stops the training process if the performance on the validation set does not improve for a certain number of rounds.\n- Cross-validation: Although not explicitly shown in the code, it is common practice to use cross-validation to evaluate the model's performance on multiple subsets of the training data. This helps to assess the model's generalization ability and reduce the risk of overfitting.", "title": "", "competition_name": "sales forecasting", "task_category": "Regression", "field": "Modeling", "ranking": "", "score": ""}, {"content": "High-ranking Kaggle notebooks or competition strategies: (1) The overall design of this code is to train a model for a Kaggle competition on sales forecasting. It preprocesses the sales and calendar data, creates features, splits the data into training, validation, and test sets, builds a neural network model, trains the model, and makes predictions. (2) The overall model architecture is a neural network with multiple inputs and outputs. The inputs include categorical variables such as \"snap_CA\", \"snap_TX\", \"snap_WI\", \"wday\", \"month\", \"year\", \"event\", \"nday\", \"item\", \"dept\", \"cat\", \"store\", \"state\", and numerical variables such as \"num\". The categorical variables are embedded using embedding layers, and the embeddings are concatenated with the numerical variables. The concatenated features are then passed through multiple dense layers with dropout regularization. The output layer has 9 units, corresponding to the 9 quantiles to be predicted. The model is trained using the quantile loss function. (3) The important hyperparameters in this code are: - CATEGORIZE: A boolean variable indicating whether to categorize the categorical variables or not. - START: An integer indicating the starting day for the training data. - UPPER: An integer indicating the upper limit of the days to be included in the dataset. - LAGS: A list of integers indicating the lag values to be used as features. - FEATS: A list of strings indicating the names of the lag features. - batch_size: An integer indicating the batch size for training the model. - epochs: An integer indicating the number of epochs for training the model. (4) The optimization objective is to minimize the quantile loss function, which is a pinball loss for multiple quantiles. The quantiles used are [0.005, 0.025, 0.165, 0.250, 0.500, 0.750, 0.835, 0.975, 0.995]. (5) The advanced machine learning technique used in this code is the use of a neural network with multiple inputs and outputs. The model architecture includes embedding layers for categorical variables, concatenation of embeddings with numerical variables, and multiple dense layers with dropout regularization. (6) Some important tricks that play a role in high performance are: - Categorizing the categorical variables to reduce memory usage and improve model performance. - Preprocessing the sales and calendar data to generate lag features. - Using embedding layers for categorical variables to capture their non-linear relationships with the target variable. - Using dropout regularization to prevent overfitting. - Using the quantile loss function to train the model for multiple quantiles simultaneously. - Using early stopping and learning rate reduction callbacks to prevent overfitting and improve convergence.", "title": "", "competition_name": "sales forecasting", "task_category": "Regression", "field": "Modeling", "ranking": "", "score": ""}, {"content": "First of all, thanks to the host for an interesting competition and congratulations to all the winners!\n\n## Summary\n- We designed separate models for tDCS FOG and DeFog.\n- Both tDCS FOG and DeFog were trained using GRUs.\n- Each Id was split into sequences of a specified length. During training, we used a shorter length (e.g., 1000 for tdcsfog, 5000 for defog), but for inference, a longer length (e.g., 5000 for tdcsfog, 30000 for defog) was applied. This emerged as the most crucial factor in this competition.\n- For the DeFog model, we utilized the ‘notype’ data for training with pseudo-labels, significantly improving the scores; by leveraging the Event column, robust pseudo-labels could be created.\n- Although CV and the public score were generally correlated, they became uncorrelated as the public score increased. Additionally, the CV was quite variable and occasionally surprisingly high. Therefore, we employed the public score for model selection, while CV guided the sequence length.\n\n## tDCS FOG\n- Features\n- Three provided accelerations\n- Feature engineering performed on each acceleration involved:\n- Difference between prior and subsequent accelerations\n- Cumulative sum of acceleration\n\n- Standardization\n- Used RobustScaler\n- Each Id was standardized individually\n\n- Sequence Creation Method:\n- Training\n- Sequence length: 1000\n- Sequences were created by shifting 500 steps from the starting position.\n\n- Inference\n- Sequence length: 3000 or 5000 (3000 if data size was less than 5000, 5000 otherwise)\n- Sequences were created by shifting 1500 or 2500 steps from the starting position.\n- During prediction, the sequence section from 750/1250 to 2250/3750 was utilized.\n- The initial segment spanned from 0 to 2250/3750, while the final segment used from 750/1250 to the end of the sequence. \n\n- Models\n- For each target, we ensembled four models.\n- The following settings were common to each model\n- Model : GRU\n- Cross validation method : StratifiedGroupKFold\n- group : Subject\n- Loss : BCEWithLogitsLoss\n- Optimizer : AdamW\n- Scheduler : get_linear_schedule_with_warmup\n- (Although not verified in detail) get_linear_schedule_with_warmup seemd to work better in CV than get_cosine_schedule_with_warmup.\n- Sequence length\n- Train : 1000\n- Inference : 3000 / 5000\n- Training the model with a longer sequence did not improve CV or public score. However, training with a short sequence and performing inference with a long sequence significantly improved both CV and public score. \n- Model1\n- This model trained with equal loss for each target.\n- CV\n- Sequence length 3000 / 5000 : 0.493 </br>\n(Sequence length 1000 : 0.438)\n- Ensemble weight : 0.2\n\n- Model2\n- The loss weight of one target was set to 0.6, and the remaining targets were set at 0.4.\n- The following three patterns\n- StartHesitation : 0.6 , Turn & Walking : 0.4\n- Turn : 0.6 , StartHesitation & Walking : 0.4\n- Walking : 0.6 , StartHesitation & Turn : 0.4\n- The model was saved at the epoch where the target with the weight set to 0.6 had the best score.\n- Only the predictions with the loss weight set to 0.6 were used in the test predictions.\n- CV\n- Sequence length 3000 / 5000 : 0.520\n- Ensemble weight : 0.4\n\n- Model3 & 4\n- The loss weight for two targets was set to 0.8, and the remaining target was set at 0.2.\n- The following three patterns\n- StartHesitation & Turn : 0.8 , Walking : 0.2\n- StartHesitation & Walking : 0.8 , Turn : 0.2\n- Turn & Walking : 0.8 , StartHesitation : 0.2\n- The model was saved at the epoch where the two targets with the weight set to 0.8 had the best score.\n- Only the predictions with a loss weight set to 0.8 were used in the test predictions.\n- CV \n- Sequence length 3000 / 5000 : 0.536\n- Ensemble weight : 0.4\n\n- ensemble\n- CV\n- Sequence length 3000 / 5000 : 0.537\n\n## DeFog\n- Features\n- Three provided accelerations\n- Feature engineering performed for each acceleration included\n- Difference between prior and subsequent accelerations\n\n- Standardization\n- Used StandardScaler\n- Each Id was standardized individually\n\n- Sequence Creation Method:\n- Training\n- Sequence length: 5000\n- Sequences were created by shifting 2500 steps from the starting position.\n\n- Inference\n- Sequence length: 15000 or 30000 (15000 if data size was less than 200000, 30000 otherwise)\n- Sequences were created by shifting 7500 or 15000 steps from the starting position.\n- During prediction, the sequence section from 3750/7500 to 11250/22500 was utilized.\n- The initial segment spanned from 0 to 11250/22500, while the final segment used from 3750/7500 to the end of the sequence.\n\n- Models\n- We ensembled five models \n- The following settings are common to each model\n- Model : GRU\n- Cross validation method : StratifiedGroupKFold\n- group : Subject\n- Optimizer : AdamW\n- Loss : BCEWithLogitsLoss\n- Scheduler : get_linear_schedule_with_warmup\n- Sequence length\n- Train : 5000\n- Inference : 15000 / 30000\n- The loss weights for each target were uniform\n- Only instances where both 'Valid' and 'Task' were true were considered for loss calculation.\n\nmodel1 CV Sequence length 15000 / 30000 : 0.279 Ensemble weight : 0.35 model2 Utilized the first round of pseudo-labeling Applied hard labels, with the label set to 1 only if the data value of the 'Event' was 1, otherwise it was set to 0 The label was determined based on the highest predictive value among the three target predictions Inference results from sequences of length 15000 from model1 were used The application of pseudo-labeling significantly improved both public and private scores CV Sequence length 15000 / 30000 : 0.306 Ensemble weight : 0.25 model3 Utilized the second round of pseudo-labeling CV Sequence length 15000 &amp; 30000 : 0.313 Ensemble weight : 0.25 model4 Increased the hidden size of the GRU Utilized the first round of pseudo-labeling CV Sequence length 15000 &amp; 30000 : 0.3393 Ensemble weight : 0.10 model5 Trained with all data Utilized pseudo-labeling Ensemble weight : 0.05 ensemble(excluding model5) Sequence length 15000 &amp; 30000 : 0.33706 ## tDCS FOG &amp; DeFog CV : 0.548 Public Score : 0.530 Private Score : 0.450 ## Inference notebook ## Code", "title": "2nd place solution", "competition_name": "unknown", "task_category": "Classification", "field": "Modeling", "ranking": "2nd place", "score": {"CV": "tDCS FOG: up to ~0.537, DeFog: up to ~0.3393", "Public Score": "tDCS FOG & DeFog: ~0.530", "Private Score": "tDCS FOG & DeFog: ~0.450"}}, {"content": "High-ranking Kaggle notebooks or competition strategies: (1) The overall design of the code is to train and evaluate multiple models for a kaggle competition on Parkinson's freezing gait prediction. The code includes functions for data preprocessing, model architecture, training, and inference.\n\n(2) The overall model architecture includes multiple variations of bidirectional LSTM and 1D CNN models. The code provides functions to load and compile these models. The bidirectional LSTM models have multiple layers of bidirectional LSTM cells, followed by dense layers with activation functions. The 1D CNN models have multiple convolutional layers with different filter sizes, followed by bidirectional LSTM layers and a dense layer with a softmax activation function. The models are trained using the Adam optimizer and categorical cross-entropy loss.\n\n(3) The important hyperparameters in this code are:\n- `target_size`: The target size for resizing the input sequences.\n- `lr`: The learning rate for the optimizer.\n- `early_stop_patience`: The number of epochs to wait before early stopping if the validation loss does not improve.\n- `epoch`: The maximum number of epochs for training.\n- `batch_size`: The batch size for training.\n- `model_no`: The model number to load and train.\n- `use_percentile_feat`: Whether to use percentile features in the input data.\n- `train`: Whether to train the models or perform inference.\n\n(4) The optimization objective is to minimize the categorical cross-entropy loss between the predicted and true labels for the presence of events in the input sequences.\n\n(5) The advanced machine learning technique used in this code is the use of bidirectional LSTM and 1D CNN models for sequence classification. These models are capable of capturing temporal dependencies in the input sequences and have been shown to perform well on various sequence classification tasks.\n\n(6) Some important tricks that play a role in high performance include:\n- Resizing the input sequences to a target size to ensure consistent input dimensions for the models.\n- Using percentile features in the input data to capture additional information about the distribution of the sensor data.\n- Applying early stopping during training to prevent overfitting and find the best model weights based on the validation loss.\n- Using a learning rate scheduler to dynamically adjust the learning rate during training.\n- Using batch normalization and dropout layers to regularize the models and prevent overfitting.\n- Ensembling multiple models to improve the overall prediction performance.", "title": "", "competition_name": "Parkinson's freezing gait prediction", "task_category": "Classification", "field": "Modeling", "ranking": "", "score": ""}, {"content": "High-ranking Kaggle notebooks or competition strategies: First of all, I would like to appreciate the participants and organizers of the competition very much. I have learned a lot from this competition. My solution may not seem to be of much value, but I have gained a lot of insight from the community so I felt obligated to share the solution with you. (I especially learned a lot from @kyakovlev kernel. Thank you.) [Solution] - Model - LightGBM (single) - objective = tweedie - Validation - 5 holdout (d1578-d1605, d1830-d1857, d1858-d1885, d1886-d1913, d1914-d1941) - no early stopping - Model split - for each store - for each week - model w1 predicts F01, F02, ..., F07 - model w2 predicts F08, F09, ..., F14 - model w3 predicts F15, F16, ..., F21 - model w4 predicts F22, F23, ..., F28 - Features - General time-series features - General price features - General calendar features - No recursive features When the competition began, I first understood the data and evaluation metrics and created a baseline model. Then I realized that the validation scores varied significantly over the period of time. (I can't build a proper validation.) I was strongly convinced that this competition would be very difficult and that it would be impossible to build a model with high accuracy. So I decided to give up on trying to get a high ranking in the competition. Instead of it, I decided to try to build a \"practical\" solution. My strategy is as follows: - Not to use post processing, multiplier, and leaks - In practice, it is not possible to utilize such information, so I have decided that it should not be used. - Trust CV but Not care about official evaluation metrics (WRMSSE) - WRMSSE is evaluation metrics by the competition organizer, but in practice, I think WRMSSE is not always reasonable. Therefore I didn't make a custom loss function to avoid overfit this competition task itself. - Not to use complex and recursive features - Just use general features that can be applied to any practical tasks. - Recursive features lead to error accumulation - Not to use computation resources too much - Single model (LightGBM only, no stacking/blending) - Memory efficiency (model for each store and week) As I mentioned earlier, I was not aiming for the high ranking, so I was very surprised by this result (4th place). As you can see from the solution above, I'm not doing anything special. What was valuable to me was learning a lot about building a simple solution that can be widely used in practice. The ranking itself means absolutely nothing to me. (However, I feel very sorry for those of you who put in a great deal of effort to get to the top...) Either way, I have learned a lot from this competition and community. Thank you to all the kaggle community members.", "title": "High-ranking Kaggle notebooks or competition strategies", "competition_name": "Not explicitly mentioned", "task_category": "Time Series Forecasting", "field": "Modeling", "ranking": "4th place", "score": "Not explicitly mentioned"}, {"content": "High-ranking Kaggle notebooks or competition strategies: (1) The overall design of the code is to create a high-performing solution for a Kaggle competition related to gait prediction. It uses a combination of deep learning models, data preprocessing techniques, and optimization strategies to achieve accurate predictions. (2) The overall model architecture consists of two main components: the Wave_Block module and the Classifier module. The Wave_Block module is responsible for extracting features from the input data using dilated convolutions. It consists of multiple convolutional layers with different dilation rates, which allows the model to capture both local and global dependencies in the data. The output of the Wave_Block module is then passed through the Classifier module, which consists of a bidirectional LSTM layer followed by fully connected layers. The LSTM layer helps to capture temporal dependencies in the data, while the fully connected layers perform the final classification. (3) The important hyperparameters in this code are: - `WAV_SIZE`: The size of each chunk of the input waveform. - `STEP_SIZE`: The step size for sliding the window over the input waveform. - `TIMES_REAL`: The number of times to repeat the real data during training. - `TIMES_TRAIN`: The number of times to repeat the entire training dataset during training. - `is_mixed_precision`: Whether to use mixed precision training. - `TARGET_COLS`: The target columns for prediction. (4) The optimization objective is to minimize the loss function, which is not explicitly mentioned in the code. However, based on the usage of the `torch.nn.BCEWithLogitsLoss()` loss function in the training process, it can be inferred that the optimization objective is to minimize the binary cross-entropy loss between the predicted probabilities and the true labels. (5) The advanced machine learning technique used in this code is the Wave_Block module, which utilizes dilated convolutions to capture both local and global dependencies in the input data. This allows the model to effectively extract features from the waveform data and improve the prediction performance. (6) Some important tricks that play a role in achieving high performance in this code include: - Data resampling: The code uses the `librosa.resample()` function to resample the input waveform data from 128Hz to 100Hz. This helps to standardize the input data and make it compatible with the model architecture. - Data normalization: The code divides the resampled waveform data by 40 to normalize it. This helps to scale the data within a reasonable range and improve the training process. - Chunking of data: The code splits the input waveform data into chunks of size `WAV_SIZE` with a step size of `STEP_SIZE`. This allows the model to process the data in smaller segments and capture temporal dependencies effectively. - Parallel processing: The code uses the `joblib.Parallel()` function to parallelize the data loading process, which can speed up the training process by utilizing multiple CPU cores. - Mixed precision training: The code uses the `torch.cuda.amp` module to enable mixed precision training, which combines the advantages of both single precision and half precision training. This can improve the training speed and memory efficiency. - Learning rate scheduling: The code uses the `torch.optim.lr_scheduler.OneCycleLR()` scheduler to dynamically adjust the learning rate during training. This helps to find an optimal learning rate and improve the convergence speed of the model. - Model ensembling: The code performs model ensembling by averaging the predictions from multiple models trained with different checkpoints. This helps to reduce the variance in the predictions and improve the overall performance.", "title": null, "competition_name": "gait prediction", "task_category": "Classification", "field": "Modeling", "ranking": null, "score": null}, {"content": "First of all, I would like to thank Kaggle and AMP PD for organizing this great competition. I would also like to thank all the kagglers who participated in this competition. I am very happy to have won my first gold medal and also to have won a prize.\n\nMy solution is simple and consists of three main functions.\n\n## 1. Grouping\n\nAs many have pointed out, I have divided the groups into two, each optimized for a different visit interval (6 or 12 months).\nOne key point is that we need to focus not only on the 6th month, but also on the 18th month. There are patients who are missing the 6th month but have the 18th month present, and this patient is not healthy.\nBy using the cumulative minimum function, I considered patients with either the 6th month or the 18th month present as unhealthy.\n\n#### [Group A : Healthy]\n- Patients with a minimum visit interval of 12 months or more\n#### [Group B : Unhealthy]\n- Patients with a minimum visit interval of 6 months or less\n\n## 2. Labeling (mainly Group B)\n\nAs I looked at the data for Group B, the unhealthy group, I found several patterns. The frequency of protein collection and protein information are linked to the severity of symptoms. I then generated several labels based on protein collection frequency and protein information and used them as features.\n\nThe following 9 labels were finally adopted.\n\n#### [more severe symptoms]\n- Protein was collected at 6 months\n- Protein was collected at 6 months and again at 12 months\n- Low number of unique \"UniPort\" (approximately the bottom 20%)\n- Low number of unique \"UniPort\" (approximately the bottom 10%)\n\n#### [milder symptoms]\n- Protein not collected at 6 months\n- Protein was collected at 6 months but not at 12 months\n- Protein not collected at 6 months, but collected at 18 months\n- High number of unique \"UniPort\" and high change of \"Peptide\" from the previous measurement (approximately the top 20%)\n- High number of unique \"UniPort\" and high change of \"Peptide\" from the previous measurement (approximately the top 10%)\n\n## 3. Modeling\n\nInitially, I also tried LightGBM using these features, but LB worsened and I did not use them in my final model. In my final model, I used these features to obtain the coefficients (severity) by grid search.\nDue to the small sample size of the train data (248 patients), some labels improved for the train data (248 patients) but worsened for the LB (50 patients). In my various experiments, I decided to adopt only those that improved both train and LB (248 + 50 patients).\nI thought this would be a more robust model. As a result, the final scores were also stable.", "title": null, "competition_name": "AMP PD", "task_category": "Classification", "field": "Feature Engineering, Modeling", "ranking": "Gold medal", "score": null}, {"content": "High-ranking Kaggle notebooks or competition strategies: (1) The overall design of the code is to train a sequence classifier model on a dataset of Parkinson's disease patients' accelerometer data. The dataset is preprocessed and transformed into sequences of fixed length. The model architecture consists of a series of convolutional layers with squeeze-and-excitation blocks, followed by a bottleneck layer and a series of transposed convolutional layers. The model is trained using a dataset class and a dataloader, and the trained model is used to make predictions on test data. (2) The overall model architecture consists of an encoder-decoder structure with skip connections. The input to the model is a sequence of accelerometer data, which is passed through a series of convolutional layers with squeeze-and-excitation blocks. The output of the encoder is then passed through a bottleneck layer, and the bottleneck output is then passed through a series of transposed convolutional layers to reconstruct the input sequence. The skip connections between the encoder and decoder layers help to preserve spatial information and improve the model's ability to reconstruct the input sequence. (3) The important hyperparameters in this code are: - BASE_FEATURE_COUNT: The number of base features in the input data (default value: 5). - WINDOW_LENGTH: The length of the input sequence (default value: 10240). - STRIDE_DENOMINATOR: The denominator used to calculate the stride length for creating overlapping sequences (default value: 8). - frequency_bands: The frequency bands used to calculate band powers in the input data (default value: None). - max_sequence_length: The maximum length of the input sequences (default value: 10240). - stride_denominator: The denominator used to calculate the stride length for creating overlapping sequences (default value: 1). - in_channels: The number of input channels to the model (default value: 3). - out_channels: The number of output channels from the model (default value: 4). - model_width_coef: The width coefficient used to determine the number of features in the model (default value: 32). - reduction: The reduction factor used in the squeeze-and-excitation blocks (default value: 16). - use_second_se: Whether to use a second squeeze-and-excitation block in the model (default value: False). - preprocessor_dropout: The dropout rate applied to the preprocessor layers (default value: 0). - se_dropout: The dropout rate applied to the squeeze-and-excitation blocks (default value: 0). - initial_dropout: The dropout rate applied to the initial layers of the model (default value: 0). - center_dropout: The dropout rate applied to the bottleneck layer (default value: 0). - BATCH_SIZE: The batch size used in the dataloader (default value: 64). (4) The optimization objective of this code is not explicitly mentioned in the provided code. However, based on the model architecture and the use of softmax activation in the output layer, it can be inferred that the code is likely performing multi-class classification. The model is trained to minimize the cross-entropy loss between the predicted class probabilities and the true class labels. (5) The advanced machine learning technique used in this code is the squeeze-and-excitation (SE) block. The SE block is a mechanism that allows the model to adaptively recalibrate channel-wise feature responses by explicitly modeling the interdependencies between channels. This helps the model to focus on more informative features and suppress less useful ones, leading to improved performance. (6) Some important tricks that play a role in achieving high performance in this code include: - Preprocessing the accelerometer data: The code normalizes the time and applies wavelet transform to calculate band powers, which helps to extract relevant features from the raw accelerometer data. - Using skip connections: The skip connections between the encoder and decoder layers help to preserve spatial information and improve the model's ability to reconstruct the input sequence. - Applying dropout: Dropout regularization is applied to the model layers to prevent overfitting and improve generalization. - Using multiple models: The code uses an ensemble of multiple models trained on different subsets of the data to improve the overall performance. - Weighted averaging: The code uses weighted averaging of the predicted class probabilities at each timestamp to generate the final predictions, with higher weights given to the start and end timestamps. This helps to account for the varying lengths of the input sequences and improve the accuracy of the predictions.", "title": null, "competition_name": "Parkinson's Disease Accelerometer Data Classification", "task_category": "Classification", "field": "Modeling", "ranking": null, "score": null}, {"content": "High-ranking Kaggle notebooks or competition strategies: (1) The overall design of this code is to generate high-performing forecasts for a Kaggle competition. It combines two different types of forecasts: bottom-level forecasts on item level derived from a lgbm model, and top-level forecasts for levels 1-5 created with N-Beats. The code then aggregates the bottom-level forecasts up to the higher levels and compares them with the N-Beats forecasts to select the most suitable probability distribution for the forecast period. The code also includes calculations of comparison metrics and visualizations for analysis.\n\n(2) The overall model architecture consists of two main components: the lgbm model for bottom-level forecasts and the N-Beats model for top-level forecasts.\n\n- Bottom-level forecasts: The lgbm model is trained to predict the probability of an item being bought based on datetime features, price features, and other non-time-dependent features. The model uses a custom loss function with a multiplier to adjust for trend or other effects. The predictions from this model are aggregated and used as inputs for the higher-level forecasts.\n\n- Top-level forecasts: The N-Beats model is used to generate forecasts for levels 1-5. The model is trained and predicted using two different settings, resulting in two sets of forecasts. These forecasts are then compared with the aggregated bottom-level forecasts to select the most suitable probability distribution for the forecast period.\n\n(3) The important hyperparameters in this code are not explicitly mentioned in the provided code. However, based on the code, we can infer the following hyperparameters:\n\n- For the lgbm model: The hyperparameters for the lgbm model, such as the number of trees, learning rate, maximum depth, and feature importance threshold, are not mentioned in the code. These hyperparameters would have been set during the training process.\n\n- For the N-Beats model: The hyperparameters for the N-Beats model, such as the number of stacks, the number of blocks per stack, the hidden layer size, and the learning rate, are not mentioned in the code. These hyperparameters would have been set during the training process.\n\n(4) The optimization objective of this code is to generate accurate forecasts for the Kaggle competition. The code aims to minimize the error between the predicted forecasts and the ground truth values. The comparison metrics, such as RMSSE (Root Mean Squared Scaled Error), RMSE (Root Mean Squared Error), mean error, and mean absolute error, are calculated to evaluate the performance of the forecasts.\n\n(5) The advanced machine learning technique used in this code is the combination of different models for forecasting. It combines the lgbm model for bottom-level forecasts and the N-Beats model for top-level forecasts. By aggregating and comparing the forecasts from these models, the code aims to select the most suitable probability distribution for the forecast period.\n\n(6) Some important tricks that play a role in achieving high performance in this code include:\n\n- Ensemble averaging: The code builds an ensemble by averaging the predictions from multiple bottom-level lgbm models. This helps to reduce the variance and improve the overall accuracy of the forecasts.\n\n- Aggregation and comparison: The code aggregates the bottom-level forecasts up to the higher levels and compares them with the N-Beats forecasts. This allows for the selection of the most suitable probability distribution for the forecast period, taking into account both the bottom-level and top-level forecasts.\n\n- Custom loss function: The lgbm model uses a custom loss function with a multiplier to adjust for trend or other effects. This helps to improve the fit of the model and capture important patterns in the data.\n\n- Visualization and analysis: The code includes visualizations and calculations of comparison metrics to analyze the performance of the forecasts. This helps to identify any issues or areas for improvement in the models and guide the selection of the final forecasts for submission.\n\nNote: The specific hyperparameters and details of the models used in this code are not provided, so it may not be possible to exactly reproduce the code without additional information.", "title": "not provided", "competition_name": "not provided", "task_category": "Forecasting", "field": "Modeling", "ranking": "not provided", "score": "not provided"}, {"content": "High-ranking Kaggle notebooks or competition strategies: (1) The overall design of this code is to forecast the demand for a set of products in a retail store. It uses historical sales data, calendar data, and selling prices data to train a LightGBM model. The model is then used to make predictions for a future time period. The code is divided into several sections: loading the data, preparing the calendar data, defining helper functions, preparing the model data sets, fitting the LightGBM model, calculating predictions, and saving the predictions to a CSV file.\n\n(2) The overall model architecture is a LightGBM model with a Poisson loss function. LightGBM is a gradient boosting framework that uses tree-based learning algorithms. The Poisson loss function is used because the target variable (demand) is a count variable and follows a Poisson distribution. The model is trained to minimize the root mean squared error (RMSE) metric.\n\nThe model is trained using the following steps:\n- The data is prepared by dropping old dates, reshaping it to a long format, and adding demand features such as lagged values and rolling means.\n- The data is split into training and validation sets using a 90/10 split.\n- The LightGBM model is defined with hyperparameters such as the learning rate, lambda (L2 regularization term), number of leaves, and colsample_bytree (subsample ratio of columns when constructing each tree).\n- The model is trained using the training set and validated using the validation set. Early stopping is used to prevent overfitting.\n- The feature importance is plotted to visualize the importance of each feature.\n- The model is used to make predictions for the test set.\n\n(3) The important hyperparameters in this code are:\n- learning_rate: The learning rate controls the step size at each boosting iteration. It is set to 0.08.\n- lambda: The lambda parameter controls the L2 regularization term. It is set to 0.1.\n- num_leaves: The num_leaves parameter controls the maximum number of leaves in each tree. It is set to 63.\n- sub_row: The sub_row parameter controls the subsample ratio of rows when constructing each tree. It is set to 0.7.\n- bagging_freq: The bagging_freq parameter controls the frequency of bagging. It is set to 1.\n- colsample_bytree: The colsample_bytree parameter controls the subsample ratio of columns when constructing each tree. It is set to 0.7.\n\n(4) The optimization objective is to minimize the root mean squared error (RMSE) metric. The Poisson loss function is used as the objective function for training the LightGBM model. The RMSE metric is a common evaluation metric for regression problems and measures the average difference between the predicted and actual values.\n\n(5) The advanced machine learning technique used in this code is gradient boosting with LightGBM. Gradient boosting is an ensemble learning method that combines multiple weak models (decision trees) to create a strong predictive model. LightGBM is a gradient boosting framework that uses tree-based learning algorithms and is known for its efficiency and scalability.\n\n(6) Some important tricks that play a role in achieving high performance in this code include:\n- Lagged features: The code creates lagged features by shifting the demand values for each product by a certain number of days. This allows the model to capture the temporal dependencies in the data.\n- Rolling mean features: The code calculates rolling mean features by taking the average of the lagged demand values over a certain window size. This helps to smooth out the noise in the data and capture the overall trend.\n- Ordinal encoding: The code uses ordinal encoding to convert categorical variables into numerical values. This allows the model to process the categorical variables as numerical features.\n- Train-validation split: The code splits the data into training and validation sets to evaluate the performance of the model. This helps to prevent overfitting and allows for hyperparameter tuning.\n- Early stopping: The code uses early stopping to stop the training process if the performance on the validation set does not improve after a certain number of iterations. This helps to prevent overfitting and saves computational resources.\n- Feature importance: The code plots the feature importance to visualize the importance of each feature in the model. This helps to identify the most influential features and can guide feature selection and engineering efforts.", "title": null, "competition_name": null, "task_category": "Regression", "field": "Modeling", "ranking": null, "score": null}, {"content": "Hi everyone, We would like to share our solution with you. Firstly, we would like to thank hosts, Kaggle for opening this great competition. Also, thanks to all participants for useful discussions. Personally, this is the first competition I've joined, and I am happy to achieve a meaningful result. Our goal was to achieve a high rank in this competition using deep learning (neural network) approach. I and my colleague are more familiar with deep learning methods and we believed that NN can get competitive result with other ML approaches (especially gradient boosting). ----- ### Summary We trained modified DeepAR with Tweedie loss and make a final prediction from the ensemble of multiple models chosen using the past 14 periods of WRMSSEs. ### Network Our base network is DeepAR( which consisted of multiple LSTMs. We modified the baseline network to predict 28days with rolling predictions in the training phase (original DeepAR only predict 1-day in the training phase). Our modified DeepAR generates losses from rolled 28days and this gives more stable predictions on rolled prediction. ### Loss Tweedie Loss - Thanks to @timetraveller for a good discussion ( ### Features We used the following features. All features are concatenated and fed to the network. * Sale values * Lag 1 value * Moving average of 7, 28 days * Calendar: all values are normalized to [-0.5,0.5] * wday * month * year * week number * day * Event * Event type : use embedding * Event name : use embedding * SNAP : [0, 1] * Price * raw value * Normalized across time * Normalized within the same dept_id * Category * state_id, store_id, cat_id, dept_id, item_id : use embedding * Zero sales * Continuous zero-sale days until today ### Training Scheme We randomly sampled 28-days slice from each sequence and made 64 slices for each batch. Each batch is fed to the network and network predicts the next 28-days. Training iterated 300 epoch (one-epoch = 30490/64 iterations). We used Adam optimizer and used cosine annealing for the learning rate schedule. We used all periods including validation(~1942) for training. ### CV It was hard to select CV period as WRMSSE is severely fluctuated according to the period. Besides, we found that 1914~1942 period is more unreliable as the characteristics of this period are more different from other periods. (There were many items start to selling from zero-sales) As the level 12 value is intermediate and sporadic, we conclude that the network also struggles to learn about training values. And we conclude that we don't need to much care about over-fitting. Instead, we concentrate to select good model from the trained model, which has low WRMSSE values for a specific period. We evaluated WRMSSE for the past 14 periods ((1914, 1886, 1858,... 1550) and selected a model that has a low mean of WRMSSEs. For each model, we evaluated every 10-epoch (from 200~300 epoch) and selected the top-3 epoch. From the trained 8 models, we make an ensemble model from 8*3 selected model for the final prediction. - More precisely, we make a final prediction using 24 + 19 models (24 models have applied dropout, 19 models are not applied dropout). This was just a heuristic strategy. ### What we tried, but failed * Models * We used other network architectures including CNN, Transformers, ..., etc. We could not find any model superior to others, and we choose the most basic model, DeepAR. * Loss * Classification loss (CE loss) * WRMSSE as a loss * Forecast Reconciliation * Used different level but worse than using lv12 ----- We are happy to achieve the goal with our method. More importantly, we've learned many things from this competition. Thanks to all again!", "title": "not provided", "competition_name": "not provided", "task_category": "Regression", "field": "Modeling", "ranking": "not provided", "score": "not provided"}, {"content": "## **Overall Pipeline**\n![](\n## **Training Methodology**\n***DataSet***\n- For Pretraining divide each unlabeled series into segment with length 100000\n- For Training\n- - Divide each time series with window size of 2000 observation with overlapping of 500\n- - For defog randomly select 4 window from the above set. \n- - For tdcsfog select 1 window from the above set. tdcsfog data is resampled 10 100 Hz using librosa (v 0.9.2). when I ported my training on Kaggle code then i found that training is not converging fast enough when I did resampled using librosa( v 0.10.0). Maybe difference is due to default resampling technique.\n- - Set length of dataloader as 8 times number of time series each fold\n***Folds***\n- Create 5 Folds using GroupKFold with Subject as groups\n- - This could be improved by creating by carefully selecting subjects so that there is similar representation of each target type in each fold\n\n***Network Architecture***\nAll models has following architecture\n`class Wave_Block(nn.Module):\n\ndef __init__(self, in_channels, out_channels, dilation_rates, kernel_size):\nsuper(Wave_Block, self).__init__()\nself.num_rates = dilation_rates\nself.convs = nn.ModuleList()\nself.filter_convs = nn.ModuleList()\nself.gate_convs = nn.ModuleList()\n\nself.convs.append(nn.Conv1d(in_channels, out_channels, kernel_size=1))\ndilation_rates = [2 ** i for i in range(dilation_rates)]\nfor dilation_rate in dilation_rates:\nself.filter_convs.append(\nnn.Conv1d(out_channels, out_channels, kernel_size=kernel_size, padding=int((dilation_rate*(kernel_size-1))/2), dilation=dilation_rate))\nself.gate_convs.append(\nnn.Conv1d(out_channels, out_channels, kernel_size=kernel_size, padding=int((dilation_rate*(kernel_size-1))/2), dilation=dilation_rate))\nself.convs.append(nn.Conv1d(out_channels, out_channels, kernel_size=1))\n\ndef forward(self, x):\nx = self.convs[0](x)\nres = x\nfor i in range(self.num_rates):\nx = torch.tanh(self.filter_convs[i](x)) * torch.sigmoid(self.gate_convs[i](x))\nx = self.convs[i + 1](x)\nres = res + x\nreturn res\n`\n`class Classifier(nn.Module):\ndef __init__(self, inch=3, kernel_size=3):\nsuper().__init__()\nself.LSTM = nn.GRU(input_size=128, hidden_size=128, num_layers=4, \nbatch_first=True, bidirectional=True)\n\n#self.wave_block1 = Wave_Block(inch, 16, 12, kernel_size)\nself.wave_block2 = Wave_Block(inch, 32, 8, kernel_size)\nself.wave_block3 = Wave_Block(32, 64, 4, kernel_size)\nself.wave_block4 = Wave_Block(64, 128, 1, kernel_size)\nself.fc1 = nn.Linear(256, 3)\n\ndef forward(self, x):\nx = x.permute(0, 2, 1)\n#x = self.wave_block1(x)\nx = self.wave_block2(x)\nx = self.wave_block3(x)\n\nx = self.wave_block4(x)\nx = x.permute(0, 2, 1)\nx, h = self.LSTM(x)\nx = self.fc1(x)\n\n\nreturn x`\n### Different Models \n#### WaveNet-GRU-v1\nTraining Notebook is found at following link\n- \nThe model is using all available data in training and validation irrespective of *Valid* column value is True and False and only best weight are saved. Last 2 best weights for each fold are used for inference.\n\n#### WaveNet-GRU-v2\nTraining Notebook is found at following link\n- \nThe model is using all available data in training and for validation data *Valid* column value as True is selected.\nAll the weights with average precision score > 0.25 are saved. Best 2 weights, based on average precision score, are selected.\n\n#### WaveNet-GRU-v3\nThis notebook is based on pre-training on unlabeled data. In pretraining target is to predict next value in the time series. For data creation each unlabeled series is divided into segment of length 100000.\n\n**Data Creation Notebook is available at** :  \n*Note*: This notebook will fail in Kaggle kernel as it requires more disk space as default available for kaggle notebooks. Please run on different PC/ Server/ VM\n**PreTraining Notebook is available at** : \nThe training will be executed for single fold and best weight will be used as initial weights (without LSTM layer) \nfor WaveNet-GRU-v3\n*Note*: Singe epoch takes around 1-1:30 hours on RTX 3090 so the kernel will timeout. Please run on different PC/ Server/ VM\n**WaveNet-GRU-v3**: **Training notebook is available at **: \nUse best weight for each fold in final inference. \nCV score for this notebook is low as compared to WaveNet-GRU-v1 and WaveNet-GRU-v2 but it improves the final ensemble ( During competition time it improved CV score but due to some bug in inferencing code the final private leader-board score as come down. I will explain this in inferencing section.\n\n## ** Inference Methodology**\n- Each series is predicted independently\n- For inference, each series are divided into segments of size 16000 or 20000 and the last segment is comprised of last 16000/20000 data points of the series. It is possible that with this size complete tdcsfog series is predicted in single step.\n- tdcsfog data are resampled at 100 Hz and prediction are restored back to 128 Hz.\n- librosa 0.10.0, is used for resampling. After competition, I found that librosa 0.9.2 is improves score a bit. This is miss from my side (as i did training using librosa 0.9.2) but it has not much impact on the final score.\n- Prediction of all the models are ensembled using simple mean.\n\n### **CPU based Inference Methodology**\nAs during last week my GPU quota has been exhausted so i need to use CPU for inference. Simple CPU based pytorch inference was exceeding the time limit of 9 hours. So I need to convert pytorch models into ONNX model. *Please refer following notebook for model conversion*: \n\nThe converted models are used in final inference. One of the final inference notebook is available at:\n\n\nAfter competition I found that, in ensemble, WaveNet-GRU-v3 (model that uses pretrained weight) is overfitting on public leaderboard and in private leaderboard its inclusion had decreased the score. While in local CV ensemble inclusion of this model was increasing  the CV score. \n\nSo i debugged more and I found that with GPU based inference WaveNet-GRU-v3 is indeed increasing the score. in face simple ensemble of WaveNet-GRU-v1 and WaveNet-GRU-v3 has private leaderboard score of 0.437.  More than third position score.\n\nThe best GPU based inference notebook is available at\n\n\nRegards\nAditya", "title": "Overall Pipeline", "competition_name": "Parkinson's Freezing of Gait Prediction", "task_category": "Classification", "field": "Modeling", "ranking": "Not explicitly mentioned", "score": "Private leaderboard score: 0.437"}, {"content": "High-ranking Kaggle notebooks or competition strategies: (1) The overall design of this code is to train a model for a Kaggle competition on sales forecasting. It preprocesses the sales and calendar data, creates features, splits the data into training, validation, and test sets, builds a neural network model, trains the model, and makes predictions on the validation and test sets.\n\n(2) The overall model architecture is a neural network with multiple inputs and outputs. The inputs include categorical variables such as 'snap_CA', 'snap_TX', 'snap_WI', 'wday', 'month', 'year', 'event', 'nday', 'item', 'dept', 'cat', 'store', 'state', and numerical variables such as 'num'. The categorical variables are embedded using embedding layers, and the embeddings are concatenated with the numerical variables. The concatenated features are then passed through multiple dense layers with dropout regularization. The output layer has 9 units corresponding to different quantiles of the target variable. The model is trained using the quantile loss function.\n\n(3) The important hyperparameters in this code are:\n- CATEGORIZE: A boolean variable indicating whether to categorize the categorical variables or not.\n- START: An integer indicating the starting day for the training data.\n- UPPER: An integer indicating the upper limit of the days for the training data.\n- LAGS: A list of integers indicating the lag values for creating lagged features.\n- FEATS: A list of strings indicating the names of the lagged features.\n- batch_size: An integer indicating the batch size for training the model.\n- epochs: An integer indicating the number of epochs for training the model.\n\n(4) The optimization objective is to minimize the quantile loss function, which is a pinball loss for multiple quantiles. The quantiles used in this code are [0.005, 0.025, 0.165, 0.250, 0.500, 0.750, 0.835, 0.975, 0.995].\n\n(5) The advanced machine learning technique used in this code is the use of a neural network with multiple inputs and outputs. The model architecture includes embedding layers for categorical variables, dense layers with dropout regularization, and the quantile loss function for training.\n\n(6) Some important tricks that play a role in high performance include:\n- Categorizing the categorical variables to reduce the dimensionality and improve the model's ability to capture patterns in the data.\n- Creating lagged features to capture temporal dependencies in the data.\n- Using embedding layers for categorical variables to learn meaningful representations.\n- Using dropout regularization to prevent overfitting.\n- Using the quantile loss function to train the model for multiple quantiles simultaneously.", "title": null, "competition_name": "Kaggle competition on sales forecasting", "task_category": "Regression", "field": "Modeling", "ranking": null, "score": null}, {"content": "The first and second place solution have much better fits to the individual defog/tdcs datasets;  this solution fit one model for both.\n\nArchitectures: Deberta/VisionTransformer/VisionTransformerRelPos -> LSTM/GRU\n(typically 2-4 layers, with single-layer RNN)\n\nPatch sizes are 7-13, with sequences of 192-384 patches.\n\nAll sequences have heavy augmentation--stretching, cropping, ablation, accumulated Gaussian noise, etc.\n\n--\n\nSee data.py and model.py for details:\n\nInference Code: \nAdditional Code: ", "title": null, "competition_name": null, "task_category": null, "field": "Modeling", "ranking": null, "score": null}, {"content": "First of all thank you all for organising and participating in this wonderful challenge, I learned a lot about Parkinson and the techniques I used in my solution and especially used by others!\n\nThe biggest thank you goes out to @mayukh18 for an incredible starter notebook.\nPlease give it an upvote if you haven't already!\n\n\n[Mayukh's Baseline Notebook](\n\nI modified this notebook's dataset class to be compatible with with a 1D-ResNet that has three channels, one for each of the sensors ('AccV', 'AccML', 'AccAP'). I also removed the wx-parameter and used 1000ms cuts with a future of 50ms.\n\nAdditionally, I implemented a learning rate scheduler (ReduceLROnPlateau) and started with a learning rate of 0.001.\n\nWhile the original notebook used only one train-validation split, I calculated five models based on the original folds in the notebook using each split.\n\nI calculated the models using my RTX 3060 which took about an hour per model, including validation. CV was around .30 if I remember correctly.\n\nMy submission was the ensemble of the resulting five models and resulted in scores of : Public - .351 / Private - .356.\n\nIf there are any questions I will gladly try to answer them in the upcoming days but as of now this is all I can do (moved to a new city just yesterday!).\n\nBest,\nJan\n\nEDIT: EDIT: EDIT: EDIT: EDIT: EDIT: EDIT: EDIT: EDIT: EDIT: EDIT: \nI took the time to generate a little write-up and publish the clean code, both available [here](\nEDIT: EDIT: EDIT: EDIT: EDIT: EDIT: EDIT: EDIT: EDIT: EDIT: EDIT:", "title": "Not provided", "competition_name": "Parkinson's Disease Detection", "task_category": "Classification", "field": "Modeling", "ranking": "Not provided", "score": "Public - .351 / Private - .356"}, {"content": "High-ranking Kaggle notebooks or competition strategies: Hi kagglers! :)\n\nThis my first solution sharing, i hope it's helpful for you.\n\n## Thanks to\nFirst of all, i'd like to thank the competition organizers and data scientists who participated in the competition. I have learned a lot from you, Really Really thank you.\n(especially, @kyakovlev's kernels and discussions. Really helpful.)\n\n## Solution\nThe method i've used is very simple and not that much great. This is all based on insights from community. \n\n### Pre-processing\n- features based on price\n- features based on calendar\n- features based on target lag (recursvie / non recursive)\n- features based on target lag rolling mean / std (recursive / non recursive)\n\n### CV strategies\n**Time based split** : mimic train/test split\n- cv1 : d_1830 ~ d_1857\n- cv2 : d_1858 ~ d_1885\n- cv3 : d_1886 ~ d_1913\n- public : d_1914 ~ d_1941\n- private : d_1942 ~ d_1969\n- without early stopping\n\n### Modeling strategies\n- recursive / non recursive\n- by store_id\n- by store_id - cat_id\n- by store_id - dept_id\n\n### Model\n- LGBM(single)\n- objective = tweedie\n\n### Post-processing\n- **Without** post-processing. (e.g.) magic multiplier.\n\n### Simple summary as diagram\n<img src=\" width=\"700\">\n\n## Opinion\nA metric called WRMSSE was unfamiliar with me, and data structure was complicated. So I first read the documents provided by the organizer, and I got a lot of insights from the brilliant notebooks and discussions.\n1. different time series by state, store, cat, dept\n2. the effect of disaster and weather on sales(target)\n3. \"out of stock\" problem\n4. the anomaly of sales\n5. the importance of solid CV\n\nand so on...\n\nI decided two things through these insights.\n1. divide into groups with similar time series, and model it.\n(e.g.) by store, by store cat, by store dept, etc.\n2. select final model using mean(cvs, public score) and std(cvs, public score)\n(especially, focusing on std.)\n\nAt first I made baseline using non recursive method, and i saw that there was a lot of variation in cv and public score.(large std)\n\nThen, i made second baseline using recursive method based on @kyakovlev's kernel, but there still was a lot of variation. \n\nThe interesting part here is,\n1. Overall, the recursive method had a better score than non recursive.\n2. non recursive method had best score at cv3.\n3. recursive method had best score at public.\n\nBased on these insights, i expected that ensembling non recur and recur might lead to robustness.\n\nThen, i selected as final model.\n\n---\n\nAs i mentioned earlier, my method is very simple and not that much great. so i didn't expect this at all. I was very lucky to learn a lot and to get unbelievable result. \n\nThank you to all the kagglers!!\n\n(and very sorry for many participants who spent a lot of time and effort on this competition. It's all thanks to you.)", "title": "First Solution Sharing", "competition_name": "Not explicitly mentioned", "task_category": "Time Series Forecasting", "field": "Modeling", "ranking": "Not explicitly mentioned", "score": "Not explicitly mentioned"}, {"content": "I published my solution according to [the guidelines of this competition](\n\nIf you would like to know more about my solution, please see [Model Summary](\n\nHere is my [Presentation Slide](\n\nThis is my model structure.\n\n![Model Structure](\n\nThank you.", "title": null, "competition_name": null, "task_category": null, "field": null, "ranking": null, "score": null}, {"content": "High-ranking Kaggle notebooks or competition strategies: Greetings to the Kaggle Community. In this message I want to tell you about my solution.\n\nThanks to Kaggle for providing free GPU and TPU resources to everyone. On my graphics card (1050 Ti) I would not have achieved those results.\nThanks to Google for the excellent tensorflow library.\nAll of my work was done in Kaggle Notebooks and relies on TensorFlow capabilities.\n\nThe key decisions that, in my opinion, led to a good result:\n1. Use a combination of transformer encoder and two BidirectionalLSTM layers.\n2. Use patches like VisualTransformer.\n3. Reduce the resolution of targets.\n\n*How does it work?*\n\nSuppose we have a tdcsfog sensor data series with AccV, AccML, AccAP columns and len of 5000.\n\nFirst, apply mean-std normalization to AccV, AccML, AccAP columns.\n\n```python\ndef sample_normalize(sample):\n\tmean = tf.math.reduce_mean(sample)\n\tstd = tf.math.reduce_std(sample)\n\tsample = tf.math.divide_no_nan(sample-mean, std)\n\n\treturn sample.numpy()\n```\nThen the series is zero-padded so that the final length is divisible by block_size = 15552  (or 12096 for defog). Now the series shape is (15552,  3). \n\nAnd create patches with the patch_size = 18 (or 14 for defog):\n\n```python\nseries # Example shape (15552, 3)\nseries = tf.reshape(series, shape=(CFG['block_size'] // CFG['patch_size'], CFG['patch_size'], 3)) # Example shape (864, 18, 3)\nseries = tf.reshape(series, shape=(CFG['block_size'] // CFG['patch_size'], CFG['patch_size']*3))  # Example shape (864, 54)\n```\n\nNow the series shape is (864,  54). It's a model input.\n\nWhat to do with the StartHesitation, Turn, Walking data? Same, but apply tf.reduce_max at the end.\n\n```python\nseries_targets # Example shape (15552,  3)\nseries_targets = tf.reshape(series_targets, shape=(CFG['block_size'] // CFG['patch_size'], CFG['patch_size'], 3)) # Example shape (864, 18, 3)\nseries_targets = tf.transpose(series_targets, perm=[0, 2, 1]) # Example shape (864, 3, 18)\nseries_targets = tf.reduce_max(series_targets, axis=-1) # Example shape (864, 3)\n```\n\nNow the series shape is (864, 3). It's a model output.\n\nAt the end, simply return the true resolution with tf.tile\n\n```python\npredictions = model.predict(...) # Example shape (1, 864, 3)\npredictions = tf.expand_dims(predictions, axis=-1) # Example shape (1, 864, 3, 1)\npredictions = tf.transpose(predictions, perm=[0, 1, 3, 2]) # Example shape (1, 864, 1, 3)\npredictions = tf.tile(predictions, multiples=[1, 1, CFG['patch_size'], 1]) # Example shape (1, 864, 18, 3)\npredictions = tf.reshape(predictions, shape=(predictions.shape[0], predictions.shape[1]*predictions.shape[2], 3)) # Example shape (1, 15552, 3)\n```\n# Details\n\nDaily data, events.csv, subjects.csv, tasks.csv have never been used.\n\nTdcsfog data is not used to train defog models. \n\nDefog data is not used to train tdcsfog models.\n\n*Optimizer* \n\n```python\ntf.keras.optimizers.Adam(learning_rate=Schedule(LEARNING_RATE, WARMUP_STEPS), beta_1=0.9, beta_2=0.98, epsilon=1e-9)\n```\n\n*Loss function*\n\n```python\n'''\nloss_function args exp\n\nreal is a tensor with the shape (GPU_BATCH_SIZE, CFG['block_size'] // CFG['patch_size'], 5) where the last axis means:\n0 - StartHesitation\n1 - Turn\n2 - Walking\n3 - Valid\n4 - Mask\n\noutput is a tensor with the shape (GPU_BATCH_SIZE, CFG['block_size'] // CFG['patch_size'], 3) where the last axis means:\n0 - StartHesitation predicted\n1 - Turn predicted\n2 - Walking predicted\n\n'''\n\nce = tf.keras.losses.BinaryCrossentropy(reduction='none')\n\ndef loss_function(real, output, name='loss_function'):\n\tloss = ce(tf.expand_dims(real[:, :, 0:3], axis=-1), tf.expand_dims(output, axis=-1)) # Example shape (32, 864, 3)\n\n\tmask = tf.math.multiply(real[:, :, 3], real[:, :, 4]) # Example shape (32, 864)\n\tmask = tf.cast(mask, dtype=loss.dtype)\n\tmask = tf.expand_dims(mask, axis=-1) # Example shape (32, 864, 1)\n\tmask = tf.tile(mask, multiples=[1, 1, 3]) # Example shape (32, 864, 3)\n\tloss *= mask # Example shape (32, 864, 3)\n\n\treturn tf.reduce_sum(loss) / tf.reduce_sum(mask)\n```\n*Model* \n\n```python\nCFG = {'TPU': 0,\n\t'block_size': 15552,\n\t'block_stride': 15552//16,\n\t'patch_size': 18,\n\t \n\t'fog_model_dim': 320,\n\t'fog_model_num_heads': 6,\n\t'fog_model_num_encoder_layers': 5,\n\t'fog_model_num_lstm_layers': 2,\n\t'fog_model_first_dropout': 0.1,\n\t'fog_model_encoder_dropout': 0.1,\n\t'fog_model_mha_dropout': 0.0,\n\t}\n\n'''\nThe transformer encoder layer\nFor more details, see [Attention Is All You Need]\n'''\n\nclass EncoderLayer(tf.keras.layers.Layer):\ndef __init__(self):\nsuper().__init__()\t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t self.mha = tf.keras.layers.MultiHeadAttention(num_heads=CFG['fog_model_num_heads'], key_dim=CFG['fog_model_dim'], dropout=CFG['fog_model_mha_dropout'])\t self.add = tf.keras.layers.Add()\t self.layernorm = tf.keras.layers.LayerNormalization()\t self.seq = tf.keras.Sequential([tf.keras.layers.Dense(CFG['fog_model_dim'], activation='relu'),\ttf.keras.layers.Dropout(CFG['fog_model_encoder_dropout']),\ttf.keras.layers.Dense(CFG['fog_model_dim']),\ttf.keras.layers.Dropout(CFG['fog_model_encoder_dropout']),\t])\t def call(self, x):\tattn_output = self.mha(query=x, key=x, value=x)\tx = self.add([x,...", "title": "Greetings to the Kaggle Community", "competition_name": "Parkinson's Freezing of Gait Prediction", "task_category": "Classification", "field": "Modeling", "ranking": "Not explicitly stated", "score": {"private_score": "0.514", "public_score": "0.527"}}, {"content": "The overall design of the code is a pipeline for a kaggle competition. It consists of several steps: importing libraries, defining utility functions, setting up the environment, and performing feature engineering. The overall model architecture is not explicitly mentioned in the code. However, based on the functions and classes used, it can be inferred that the model architecture involves preprocessing of peptides and proteins, generating features from the data, and using these features to train a machine learning model for prediction. The important hyperparameters in this code are not explicitly mentioned. It is possible that the hyperparameters are set within the functions and classes used for feature engineering and model training. Without further information, it is difficult to determine the specific hyperparameters used. The optimization objective of the code is not explicitly mentioned. However, based on the context of the code being used for a kaggle competition, the optimization objective is likely to minimize the error between the predicted values and the ground truth values. The code does not explicitly mention the use of any advanced machine learning techniques. However, based on the functions and classes used, it is likely that the code utilizes techniques such as feature engineering, preprocessing, and model training to achieve high performance. Some important tricks that may play a role in achieving high performance include: - Proper preprocessing of peptides and proteins to remove modifications and calculate relevant features. - Generation of additional features such as peptide length, count of modifications, amino acid composition, molecular weight, and sequence motifs. - Proper handling of missing data and data cleaning. - Use of appropriate machine learning algorithms and techniques for model training and prediction. - Iterative testing and prediction to evaluate the performance of the model. - Use of symmetric mean absolute percentage error (SMAPE) as the evaluation metric. - Potential use of ensemble methods or model stacking to improve performance.", "title": "", "competition_name": "", "task_category": "Regression", "field": "Feature Engineering, Modeling", "ranking": "", "score": ""}, {"content": "High-ranking Kaggle notebooks or competition strategies: (1) The overall design of this code is to create a high-performing solution for a Kaggle competition. It aims to push the public leaderboard score under 0.50. The code is adapted from a previous kernel and makes updates to be valid for the second and last step of the competition. It uses the LightGBM library for training and prediction. (2) The overall model architecture is a LightGBM model. LightGBM is a gradient boosting framework that uses tree-based learning algorithms. It uses a gradient-based one-side sampling (GOSS) technique to select the most informative samples for training. The model architecture consists of multiple decision trees, where each tree is built iteratively to minimize the objective function. (3) The important hyperparameters in this code are: - \"objective\": The optimization objective, which is set to \"poisson\" in this code. - \"metric\": The evaluation metric, which is set to \"rmse\" (root mean squared error) in this code. - \"learning_rate\": The learning rate for the gradient boosting algorithm, set to 0.075. - \"sub_row\": The subsampling rate for rows, set to 0.75. - \"bagging_freq\": The frequency for bagging, set to 1. - \"lambda_l2\": The L2 regularization term, set to 0.1. - \"num_iterations\": The number of boosting iterations, set to 1200. - \"num_leaves\": The maximum number of leaves in each tree, set to 128. - \"min_data_in_leaf\": The minimum number of data points required in a leaf, set to 100. (4) The optimization objective is to minimize the root mean squared error (RMSE) between the predicted sales and the actual sales. (5) The advanced machine learning technique used in this code is gradient boosting with LightGBM. Gradient boosting is an ensemble learning method that combines multiple weak models (decision trees) to create a strong predictive model. LightGBM is a fast and efficient implementation of gradient boosting that uses a histogram-based algorithm for splitting and a GOSS technique for sampling. (6) Some important tricks that play a role in high performance include: - Lag features: The code creates lag features by shifting the sales values for different time periods. This helps capture the temporal dependencies in the data. - Rolling mean features: The code calculates rolling mean features by taking the average of lagged sales values over different time windows. This helps capture the trend and seasonality in the data. - Categorical encoding: The code converts categorical variables into numerical codes using the \"cat.codes\" method. This allows the categorical variables to be used in the model. - Random subsampling: The code randomly subsamples the training data to create a validation set for model evaluation. This helps prevent overfitting and provides an estimate of the model's performance on unseen data. - Hyperparameter tuning: The code sets the hyperparameters of the LightGBM model based on domain knowledge and experimentation. Tuning the hyperparameters can improve the model's performance.", "title": null, "competition_name": null, "task_category": "Regression", "field": "Modeling", "ranking": null, "score": "under 0.50 on public leaderboard"}, {"content": "Finally our joint paper (with my colleague [Costas Voglis]( is published by [IJF]( Preprint can be downloaded [here](\n\n## **Thanks**\nI would like to thank the organizers for putting out such an exceptional competition on this scale. I also need to mention that my involvement in the M5 competition was both tasked and sponsored by my employer (Nodalpoint Systems, Athens, Greece). Due to other engagements, including a [3rd prize in the SpaceNet 6 challenge]( hosted at Topcoder (team SatShipAI), I was able to get involved in both M5 tracks (Accuracy &amp; Uncertainly) no sooner that the beginning of May, i.e. more than 2 months after the competitions had started.\n\n## **Background**\nTogether with my colleague [Costas Voglis]( we formed a team (Nodalpoints) for the Accuracy track of M5, ending up in the [21st position]( For several reasons, we preferred to participate in the Uncertainty track separately, having first [confirmed]( that this was indeed not a violation of the competition terms. Costas himself ended up 26th in the Uncertainty track.\n\n## **Solution** \nMy solution is an extension of my own contribution to the team Nodalpoints submission to the M5 Accuracy track; in other words, the **starting point** of my solution is **my own part** of the predictions submitted to the M5 accuracy track by the team Nodalpoints. \n\nHaving many failures at the beginning trying to tackle this competition with a classic RNN approach, probably due to the hierarchical nature of the outcome, I realized that I wouldn’t get good results if I continued treating it as a time series problem, and I should treat / transform it to a regression problem instead (as already suggested in several forum threads). \n\nAll necessary code is now available at [GitHub repo](\n\n## **Accuracy Modeling:**\n• **1 lightgbm model per store** (10 stores) training for different number of rounds for every store (700-1600) using a total of 70 features and all available data. \n• **3 keras models** (with categorical embeddings) of almost similar architecture training on the last 17*28=476 days data using only 19 features.\n• Ensembling, weighted geometric mean:\n((Lgbm ** 3) * KerasSimpleAverageOf3Models) ** (1/4)\n**Keypoint:** Keras models fails on last day’s prediction (outlier – see note below) probably due to NBA finals on that day (and because I only used 1 year’s data for training – mainly to speed up). For that day, I have just let Lightgbm predictions alone (no ensemble).\n\n(Note: from sales_train_evaluation.csv file, mean sales per day over the last 2 years (28*26 days) is 1.25 with a standard deviation of 0.22. Keras last day mean prediction is 3.9, which is over 6 sigma away from the mean, thus an outlier.)\n\n![](\n\nThis M5 accuracy solution is the outcome of a regression problem. But there is another dimension which is not mined: for every item we get the predictions for 28 days; these regression predictions can benefit from the fact that this is actually a time-series problem, utilizing a simple **exponential weighted mean** (row-wise):\n\nAcc_subm.iloc[:,1:]=Acc_subm.iloc[:,1:].ewm(com=0.04, axis=1).mean().values\n\nThis is a post-process that should be done in the Accuracy track, but because it was a last minute finding (2 hours before competitions closing), I only inserted it in the Uncertainty track (it cost us 3 places in the Accuracy one).\n\n## **Uncertainty Predictions:**\nFurthermore, for the Uncertainty track, we had to calculate the median and four prediction intervals, not just for every item but for all 12 levels. Having the median from the Accuracy track as a starting point for level 12, **with simple aggregations we obtain the median for the other 11 levels**. Going from the median to complete 9 quantiles estimations was done mostly by **tuning coefficient multipliers**. Tuning was done using only 1 fold (trying to overfit the public LB), but for more accurate results more folds should be used.\n\nThe higher the aggregation level, the more confident we are in the point prediction and thus we use lower (closer to 1) coefficient multipliers. For multipliers estimation for each level the **normal distribution was used in levels 1 – 9 and a skew-normal distribution for levels 10-12**. Also, **due to right-skewness** in our sales data on every aggregation level, the last of 9 quantiles (=99.5%) was furthermore multiplied with a factor (1.02 or 1.03).\n\nIn the Accuracy track, I worked on 3 different folds, and the final model ensembling weights were selected from the mean score of those folds. Looking at every fold alone, I noticed that there was a multiplier that could be used to maximize accuracy. These multipliers were 1.04, 0.97 and 1.0 for each fold. The meaning of this is that the **final submission in the Accuracy track will be very sensitive to multipliers**, and this will affect the Uncertainty track, too. Needing to minimize this volatility for the Uncertainty track, I decided to amplify the above tuned coefficient multipliers by a really small amount. **All tuned multipliers (except for the median) was moved away from 1 by 0.5%.**\n\n**Level 12** (the only non-aggregated one) was the most difficult for accurate estimations, and the above calculations were not enough here. Statistical calculations played a major role for this level. **Sales quantiles** were calculated over the last 364 days and over the last 28 days for every item and later weighted averaged (weights = [1, 1.75], accordingly). Also, **weekly sales quantiles** were calculated over the last 13*28 days and 3*28 days, and these results were simply averaged. Finally, Level 12 was calculated as:\nall quantiles excluding median\n**0.2*coefficient tuning + 0.7 * sales quantiles + 0.1 * weekly sales quantiles**\nmedian (not sure if should have done this)\n0.8*coefficient tuning + 0.2 * sales quantiles\n\nAs for Level 12, so for **level 11 of item_id – state_id aggregation**, sales quantiles were calculated too and final predictions were calculated as:\nall quantiles excluding median (which was left as-is)\n**0.91*coefficient tuning + 0.09 * sales quantiles**\n\n## **Flowchart**\n![](\n\n## **Late submissions**\nFrom late submissions both to M5 Accuracy and Uncertainty competitions, as expected, there is a strong correlation between scores.\n\n![](\n\n## **Summary**\n\n- I used accuracy predictions as a starting point for uncertainty estimations.\n- Better accuracy results give better uncertainty estimations.\n- Weaker Keras models strongly increase overall accuracy performance.\n- Ensembling of statistical calculated sales quantiles with tuned coefficient multipliers for level 12 was the key in the uncertainty competition.\n- Talking about multipliers: if I had used the magic number 0.97, I would have ended up on the top of the leaderboard in the uncertainty track and in place 6 in the accuracy.\n- I played around with recurrent implementations, but they never reached an appropriate maturity level in order to include them in the final blend.", "title": "M5 Competition Solution", "competition_name": "M5 Forecasting", "task_category": "Regression", "field": "Modeling", "ranking": "21st in Accuracy track; 26th in Uncertainty track", "score": "Not explicitly mentioned"}, {"content": "High-ranking Kaggle notebooks or competition strategies: (1) The overall design of the code is to train a machine learning model using the sales data from a Kaggle competition. The code performs various data preprocessing steps, such as merging different datasets, encoding categorical variables, introducing lag features, and creating rolling and expanding window features. It then uses the LightGBM regressor model to train the data and make predictions. Finally, it generates a submission file for the competition.\n\n(2) The overall model architecture is based on the LightGBM regressor model. The code uses the LightGBMRegressor class from the lightgbm library. The model is trained using the training data and evaluated using the validation data. The model is then used to make predictions on the test data. The model architecture includes various hyperparameters such as the number of estimators, learning rate, maximum depth, number of leaves, subsample ratio, column subsampling ratio, and minimum child weight.\n\n(3) The important hyperparameters in this code are set using the hyperopt library for hyperparameter tuning. The hyperparameters are defined in the valgrid dictionary, which includes the following hyperparameters: n_estimators, learning_rate, max_depth, num_leaves, subsample, colsample_bytree, and min_child_weight. The hyperopt library is used to search for the best combination of hyperparameters by maximizing the cross-validation score.\n\n(4) The optimization objective of this code is to minimize the root mean squared error (RMSE) between the predicted sales values and the actual sales values. The model is trained using the RMSE as the evaluation metric.\n\n(5) The advanced machine learning technique used in this code is the LightGBM regressor model. LightGBM is a gradient boosting framework that uses tree-based learning algorithms. It is designed to be efficient and scalable, making it suitable for large-scale datasets. The code uses the LGBMRegressor class from the lightgbm library to train the model.\n\n(6) Some important tricks that play a role in achieving high performance in this code include:\n- Data preprocessing: The code performs various data preprocessing steps such as merging datasets, encoding categorical variables, and introducing lag features. These preprocessing steps help to extract meaningful information from the raw data and improve the performance of the model.\n- Feature engineering: The code creates rolling and expanding window features, which capture the trend and seasonality in the data. These features provide additional information to the model and help improve its predictive accuracy.\n- Hyperparameter tuning: The code uses the hyperopt library to search for the best combination of hyperparameters for the LightGBM regressor model. Hyperparameter tuning helps to optimize the performance of the model and improve its predictive accuracy.\n- Memory optimization: The code includes a function called \"reduce_mem_usage\" that reduces the memory usage of the datasets by converting the data types of the columns to more memory-efficient types. This helps to avoid memory allocation alerts and improves the efficiency of the code.\n- Model evaluation: The code uses cross-validation to evaluate the performance of the model. Cross-validation helps to estimate the generalization performance of the model and avoid overfitting.", "title": null, "competition_name": "sales data from a Kaggle competition", "task_category": "Regression", "field": "Modeling", "ranking": null, "score": null}, {"content": "High-ranking Kaggle notebooks or competition strategies: (1) The overall design of this code is to train a machine learning model using the LightGBM algorithm on a dataset from a Kaggle competition. The code reads in multiple CSV files containing data related to sales, prices, and calendar information. It then preprocesses the data by creating new features, merging the datasets, and performing one-hot encoding. The dataset is split into training and testing sets, and the LightGBM model is trained on the training set. The trained model is then used to make predictions on a separate test set, and the predictions are saved to a CSV file.\n\n(2) The overall model architecture is based on the LightGBM algorithm, which is a gradient boosting framework that uses tree-based learning algorithms. The code uses the `lgb.train` function from the LightGBM library to train the model. The model is trained using a regression objective and the root mean squared error (RMSE) metric. The model architecture includes the following hyperparameters:\n\n- `n_jobs`: The number of parallel threads to use for training. It is set to -1, which means to use all available threads.\n- `boosting_type`: The type of boosting algorithm to use. It is set to 'gbdt', which stands for gradient boosting decision tree.\n- `objective`: The objective function to optimize during training. It is set to 'regression', indicating a regression problem.\n- `metric`: The evaluation metric to use during training. It is set to 'rmse', which is the root mean squared error.\n- `num_leaves`: The maximum number of leaves in each tree. It is set to 64.\n- `learning_rate`: The learning rate or shrinkage factor for each iteration. It is set to 0.005.\n- `bagging_fraction`: The fraction of data to be used for each bagging iteration. It is set to 0.7.\n- `feature_fraction`: The fraction of features to be used for each iteration. It is set to 0.5.\n- `bagging_frequency`: The frequency of bagging. It is set to 6, which means bagging is performed every 6 iterations.\n- `bagging_seed`: The random seed for bagging. It is set to 42.\n- `verbosity`: The level of verbosity. It is set to 1, which means to print messages during training.\n- `seed`: The random seed for reproducibility. It is set to 42.\n\n(3) The important hyperparameters in this code are set as follows:\n\n- `n_jobs`: -1\n- `boosting_type`: 'gbdt'\n- `objective`: 'regression'\n- `metric`: 'rmse'\n- `num_leaves`: 64\n- `learning_rate`: 0.005\n- `bagging_fraction`: 0.7\n- `feature_fraction`: 0.5\n- `bagging_frequency`: 6\n- `bagging_seed`: 42\n- `verbosity`: 1\n- `seed`: 42\n\nThese hyperparameters control various aspects of the model training process, such as the type of boosting algorithm, the number of leaves in each tree, the learning rate, and the fraction of data and features used for each iteration.\n\n(4) The optimization objective of this code is to minimize the root mean squared error (RMSE) between the predicted quantities and the actual quantities. The model is trained using the `lgb.train` function with the 'regression' objective and the 'rmse' metric. The goal is to find the set of model parameters that minimize the RMSE on the training data.\n\n(5) The advanced machine learning technique used in this code is gradient boosting with the LightGBM algorithm. Gradient boosting is an ensemble learning method that combines multiple weak models (decision trees) to create a strong predictive model. LightGBM is a fast and efficient implementation of gradient boosting that uses a tree-based learning algorithm. It is designed to handle large-scale datasets and provides high performance and accuracy.\n\n(6) Some important tricks that play a role in achieving high performance in this code include:\n\n- Feature engineering: The code creates new features based on the calendar information, such as whether a day is a holiday or a weekend. These features can capture important patterns and relationships in the data that can improve the model's performance.\n- Data preprocessing: The code merges multiple datasets and performs one-hot encoding to convert categorical variables into numerical representations that can be used by the model. This preprocessing step ensures that the data is in a suitable format for training the model.\n- Hyperparameter tuning: The code sets various hyperparameters of the LightGBM model to appropriate values. These hyperparameters control the behavior of the model during training and can have a significant impact on its performance. By tuning these hyperparameters, the code aims to find the best set of values that optimize the model's performance.\n- Model evaluation: The code splits the dataset into training and testing sets and uses the testing set to evaluate the model's performance. It uses the root mean squared error (RMSE) as the evaluation metric, which provides a measure of the model's accuracy. By evaluating the model on a separate test set, the code can assess its generalization performance and identify any potential issues or areas for improvement.", "title": "LightGBM Model Training for Sales Prediction", "competition_name": "Sales Prediction Competition", "task_category": "Regression", "field": "Modeling", "ranking": "Not specified", "score": "Not specified"}, {"content": "High-ranking Kaggle notebooks or competition strategies: First of all we would like to thank Kaggle and AMP PD for hosting this competition and providing a great dataset to dig into and rich enough to get lost in it for several months. It is always an extra motivation to work on problems that can bring value to the medical field or contribute to scientific research. Additional words of gratitude of course go to @kyakovlev for the amazing work he has done, I think we formed a great team for this competition and the results reflect that.\n\nWe publish the full code of the winning notebook [here](\n\n## Quick summary\n\nOur final solution is a simple average of two models: LGB and NN. Both models were trained on the same features (+ scaling/binarization for NN):\n- Visit month\n- Forecast horizon\n- Target prediction month\n- Indicator whether blood was taken during the visit\n- Supplementary dataset indicator\n- Indicators whether a patient visit occurred on 6th, 18th and 48th month\n- Count of number of previous “non-annual” visits (6th or 18th)\n- Index of the target (we pivot the dataset to have a single target column)\n\nThe winning solution fully ignores the results of the blood tests. We’ve tried hard to find any signal in this crucial piece of the data, but unfortunately we came to the conclusion that none of our approaches or models can benefit from blood test features significant enough to distinguish it from random variations. The final models were trained only on the union of clinical and supplementary datasets.\n\n## LGB\n\nFor the entire duration of the competition LGB was our model to beat and only a NN trained with the competition metric as the loss function was able to achieve competitive performance on CV. At first, we tried running a regression LGB model with different hyperparameters and custom objective functions, but nothing was better than l1 regression, which does not optimize the desired metric SMAPE+1. We also noticed that on CV the performance of every model is always better when the regression outputs are rounded to integers. Then we switched to an alternative approach.\n\nOur LGB model is a classification model with 87 target classes (0 to maximum target value) and logloss objective. To produce the forecast we applied the following post-processing: given the predicted distribution of target classes, pick a value that minimizes SMAPE+1. Taking into account the observation that the optimal predictions are always integers, the task boils down to a trivial search among 87 possible values. Such an approach would have worked well for the original SMAPE metric also, because the approach treats cases with multiple local minimums naturally.\n\nWe ran an optimization routine to tune LGB hyperparameters to minimize SMAPE+1 on CV using the described post-processing.\n\n## NN\n\nThe neural network has a simple multi-layer feed-forward architecture with a regression target, using the competition metric SMAPE+1 as the loss function. We fixed the number of epochs and scheduler, and then tuned the learning rate and hidden layer size. The only trick there was to add a leaky relu activation as the last layer to prevent NN from getting stuck at negative predictions. Of course there are alternative ways to solve this issue.\n\n## Cross-Validation\n\nWe’ve tried multiple cross-validation schemes due to the small training sample size, all of them were stratified by patient id. Once a sufficient number of folds is used, they all are quite well correlated to each other. Better than to the public leaderboard :) The final scheme we relied on was leave-one-(patient)-out or, in other words, a group k-fold cross validation with a fold for each patient. We used it because it doesn’t depend on random numbers. The cross-validation correlated well enough with the private leaderboard, and the submit we chose turned out to be our best private LB submission.\n\n## What worked\n\nThe most impactful feature was the indication of whether a patient visit happened on the 6th month or not. It correlates strongly with the UPDRS targets (especially 2 and 3) and with frequency of medications being taken. As we can observe only the data correlation, it is impossible to judge what is the core reason for that. During the competition our hypothesis was that the patients that had more severe symptoms during the first examination (UPDRS scores parts 2 and 3) were more likely to get invited for a visit after 6 months and more likely to get medications prescribed. But for model training it was important that the patients that made a visit on the 6th month, have higher UPDRS scores on average. The same is true for an 18th month visit as well, but these 2 features are correlated. I personally wonder if presence / absence of these variables in the models are the reason for the private LB cliff effect around 20th place.\n\nAnother curious effect related to it is observed for the forecasts made at visit_month = 0. If you look at the model forecasts for 0, 12 and 24 months ahead, they are consistently lower than the forecasts 6 months ahead. It is very logical from the math point of view - if a patient will show up on the 6th month, they will have higher UPDRS scores on average, and if not - the forecast will be ignored. But such model behaviour is unreasonable from a clinical point of view of course.\n\nIt was also important to pay attention to the differences between training and test datasets as e.g. nicely summarized [here]( That, for instance, explains well why adding a feature indicating the visit on the 30th month could improve the CV, but ruin LB.\n\n## What didn’t work\n\nBlood test data. We’ve tried many approaches to add proteins and/or peptides data to our models, but none of them improved CV. We narrowed it down to a bag of logistic regressions that forecasted the visit on the 6th month based on the blood test result on the 0th month. We applied soft up/down scaling of model-based predictions for patients that were more/less likely to visit on the 6th month based on the logistic regression probabilities. It worked on public LB after tuning a couple of “magic” coefficients directly on public LB itself. That gave us a boost all the way up to the second place on public LB, but it was clearly an overfit. We chose a “mild” version of that approach as our second final submission. It scored worse on private LB than the other submission, but, interestingly enough, not by as much as one could have expected (60.0 vs 60.3).\n\nThanks to everyone who participated in the competition, those who kept many interesting discussions going on the forum and those who suggested improvements! And congrats to all the winners!", "title": "Winning Solution Summary", "competition_name": "AMP PD Competition", "task_category": "Regression", "field": "Modeling", "ranking": "1st place", "score": "60.0"}, {"content": "High-ranking Kaggle notebooks or competition strategies: Hi Kagglers!\n\nfirst of all I would like to thank Prof. Makridakis, Evangelos Spiliotis, the organizing team, the generous sponsors and everyone else involved for hosting this interesting competition.\n\nAlso I want to thank all the great public kernel contributors that built the basis for my solution and final rank. Without your great work this would not have been possible! (Please see credits at the end of the summary)\n\n### 1. Before we start...\nThe overall approach consists of two separate modelling streams on top and bottom of the grouping hierarchy that are aligned to get a result.\nIt should be reproducible for any given time-frame as well as automatable and therefore valuable for any complex grouped/hierarchical time series problems.\n\n### 2. The starting point\nAs a quick reminder what our baseline was [a quick look at this notebook]( is helpful.\nPretty clear that if we cannot beat 0.75 significantly we are on the wrong track.\n\n### 3. The bottom level lgb model - \"Probability\" of single item being bought:\n\nThe bottom level is based on the lgb models that many participants used. ( @kyakovlev  - thank you for your great inputs in this challenge )\nOne really important aspect is that I did not use any historic sales data as features (no rollings, no lags, no last buy etc.).\nMy hypothesis is that the drivers for a peppermint candy bar being bought in the WI_1 shop are not whether or not this candy bar was bought once yesterday and twice on Monday but only price, date-time, SNAP, etc.\n\nThe lgb model learns a \"probability\" for each item(-quantity) being bought in a given shop on a given day based on the external drivers.\n( By the way - [sorry to all the statisticians reading my crazy ideas here]( )\n\nIt will be a major next step to dig into the understanding of this bottom level models. \nFor example: Why do errors cancel out so nicely when aggregating? (I have a theory too embarrassing to write about yet - will follow up after some testing)  \n\nMaybe my hypotheses turn out completely wrong but empirically they did hold for this given data set.\nAs a sidenote: lr 0.2, 3600 iterations ... pretty basic settings on this one. Trained by store.\n\n### 4.) The problem with the correct level\n\nWhen following this bottom level approach we run into one problem. *The resulting models do not incorporate any trend or seasonalities.* (See comments for discussion - this point is not correct)\nWe cannot (or at least I cannot) \"de-trend\" the underlying signals due to their intermittent nature.\n\nMaybe incorporating some kind of rolling/lag data might work - but I didn't see how to do this in a stable way that I understand or at least believe to understand (sometimes not the same :-) ) and am able to control.\n\nA lot of people in this competition chose to tackle this issue with \"magic multipliers\".\n\nWhat I used to shift the level up or down was [one of the custom loss functions discussed in the forums]( \n\ndef custom_asymmetric_train(ypred, ytrue):\ny_true = y_true.get_label()\nresidual = (y_true - y_pred).astype(\"float\")\ngrad = np.where(residual &lt; 0, -2 * residual, -2 * residual * multiplier)\nhess = np.where(residual &lt; 0, 2, 2 * multiplier)\nreturn grad, hess\n\nWith a multiplier &gt;1 we can train the model to \"overshoot\" the ground-truth with a multiplier &lt;1 we train the model to \"undershoot\" the ground truth.\nI think the loss approach will work better than shifting the result with a multiplier but did not compare the two approaches.\n\nTop level aggregations for a good fit and an overshot fit look like this:\n\n![](\n\n![](\n\n### So how do we find the right level if we do not want to guess? (i.e. \"play the lottery\")\n\n### 5.) Aligning with an independent top-level prediction\n\nWhat we need to find the right level is a top level prediction for which we are confident that trends and seasonalities are learned very well. \nThe approach I used was to use N-Beats for the top 5 levels. \n\nThe resulting predictions are very good and a great alignment basis as you can see for example in this top level (lvl1) validation result:\n\n![](\n\nNow I trained 15 different bottom level lgb solutions with different loss multipliers. \nThose bottom level predictions were aggregated and aligned with the N-Beats predictions for levels 1-5.\nSelection of the best fit was basically done when the mean error between N-Beats and aggregated bottom level predictions \"flipped\" from positive to negative or vice versa. \n\n![](\n\nAfter selecting the best fitting bottom level solution I built an ensemble consisting of this solution and the 2 solutions above as well as the 2 solutions below. \n( In my earlier experiments I saw that this had a quite beneficial effect for hitting the optimal level - my intuition was that we get a better \"loss surface\" with the ensemble - but again ... a lot of \"intuition\" here given that there was no time to analyze all ideas I had and given that I am not the best programmer. )\n\nThe final alignment for Level1 of my submission looked like this:\n\n![](\n\n### 6. ) What did not work\n\nIn the beginning I played around with DeepAR and some other ideas.\nLater on I tried to reconcile the different prediction levels with the R/hts implementation. \nAfter renting out a 128Gig instance on AWS and a sleepless night I came to the conclusion that this will not work for me :-) - I am pretty sure I messed up the residual calculation for MinT but my feeling is that it will not work anyway given that we have &gt;30k bottom level signals and just over 100 top level signals .... OLS/WLS did not work for me either.\n\n### 7. ) What I would love to see\n\nSolutions that did not use lgb at all. Just saw the 3rd place writeup a minute ago - looking forward to reading more on this one.\n\n### 8. ) Credits\n\nThe kernel I used for all my features is: [\nFrom the same author the starting point of my lgbm exploration was (many of you may have seen it already): [\nAnother input to my lgbm exploration was: [\n\nThe kernel that put me in touch with GluonTS (great framework!!) was this one: [\nEven though I did not end up having success with DeepAR getting to know GluonTS was key to my final path.\n\nThe kernel that allowed me to rapidely test hypothesis and give me visual insight to the results was this one (really love this one!!): [ \n\nMy aggregation code was copied from this kernel: [\n\nYou see that a lot of community input was used - thank you everyone also for the great discussions on the kernels.\n\nThank you all for this amazing competition.", "title": "High-ranking Kaggle notebooks or competition strategies", "competition_name": "M5 Forecasting", "task_category": "Time Series Forecasting", "field": "Modeling", "ranking": "Not explicitly mentioned", "score": "Not explicitly mentioned"}, {"content": "High-ranking Kaggle notebooks or competition strategies: (1) The overall design of the code is to create a high-performing solution for a Kaggle competition related to gait prediction. It uses a deep learning model called WaveNet to predict three target variables: StartHesitation, Turn, and Walking. The code includes data preprocessing, model architecture, training process, and testing process.\n\n(2) The overall model architecture consists of a Wave_Block module and a Classifier module. The Wave_Block module is responsible for capturing temporal dependencies in the input data using dilated convolutions. It takes the input data and applies a series of dilated convolutions with different dilation rates. The output of each convolutional layer is passed through a tanh activation function and a sigmoid activation function, and then multiplied element-wise. The resulting tensor is added to the input tensor, creating a residual connection. This process is repeated for each dilation rate. The Classifier module consists of a bidirectional LSTM layer followed by four Wave_Block modules. The output of the last Wave_Block module is passed through a linear layer to obtain the final predictions.\n\n(3) The important hyperparameters in this code are:\n- WAV_SIZE: The size of each chunk of the input waveform.\n- STEP_SIZE: The step size for creating chunks from the input waveform.\n- TIMES_REAL: The number of times to repeat each real sample in the training dataset.\n- TIMES_TRAIN: The number of times to repeat each augmented sample in the training dataset.\n- is_mixed_precision: Whether to use mixed precision training.\n- TARGET_COLS: The names of the target variables.\n\n(4) The optimization objective is to minimize the loss function. The specific loss function used in the code is not provided, but it is likely a binary cross-entropy loss or a similar loss function suitable for multi-label classification tasks.\n\n(5) The advanced machine learning technique used in this code is the WaveNet architecture. WaveNet is a deep learning model that uses dilated convolutions to capture long-range dependencies in sequential data. It has been successfully applied to tasks such as speech synthesis and music generation.\n\n(6) Some important tricks that may play a role in achieving high performance include:\n- Data augmentation: The code applies resampling and scaling to the input waveform data to increase the diversity of the training samples.\n- Wave_Block module: The Wave_Block module with dilated convolutions helps capture temporal dependencies in the input data.\n- Bidirectional LSTM: The bidirectional LSTM layer in the Classifier module allows the model to capture both past and future context information.\n- Mixed precision training: The code uses mixed precision training, which combines single precision and half precision floating-point numbers to speed up training and reduce memory usage.\n- Learning rate scheduling: The code uses the OneCycleLR scheduler to adjust the learning rate during training, which can help improve convergence and prevent overfitting.\n- Ensemble of models: The code loads multiple pre-trained models and averages their predictions to obtain the final predictions, which can help improve the overall performance.", "title": null, "competition_name": "gait prediction", "task_category": "Classification", "field": "Modeling", "ranking": null, "score": null}, {"content": "High-ranking Kaggle notebooks or competition strategies: (1) The overall design of the code is to train a model for a Kaggle competition on sales forecasting. It preprocesses the sales and calendar data, creates a dataset, defines the model architecture, trains the model, and makes predictions.\n\n(2) The overall model architecture consists of an embedding layer for categorical features, followed by three GRU layers with dropout regularization. The model takes in multiple inputs including categorical features (such as snap_CA, snap_TX, etc.) and numerical features (such as lagged sales values). The categorical features are embedded into lower-dimensional representations, and all the features are concatenated and fed into the GRU layers. The output of the model is a dense layer with 9 units, representing the predicted quantiles of the sales.\n\n(3) The important hyperparameters in this code are:\n- CATEGORIZE: A boolean variable indicating whether to categorize the categorical features or not.\n- START: An integer indicating the starting day of the sales data to consider.\n- UPPER: An integer indicating the upper limit of the days to consider in the sales data.\n- LAGS: A list of integers representing the lag values for the lagged sales features.\n- seq_len: An integer representing the sequence length of the input data.\n- batch_size: An integer representing the batch size for training the model.\n- patience: An integer representing the number of epochs with no improvement after which training will be stopped.\n- min_lr: A float representing the lower bound of the learning rate during training.\n\n(4) The optimization objective is to minimize the weighted quantile loss (wqloss) function. This loss function calculates the pinball loss for multiple quantiles and weights the losses based on the actual sales values.\n\n(5) The advanced machine learning technique used in this code is the use of a recurrent neural network (RNN) architecture, specifically the GRU (Gated Recurrent Unit) layers. The GRU layers allow the model to capture temporal dependencies in the sales data and make predictions based on the historical sales values.\n\n(6) Some important tricks that play a role in high performance include:\n- Categorizing the categorical features to reduce the dimensionality and improve the model's ability to learn from the data.\n- Using lagged sales values as additional features to capture temporal patterns in the data.\n- Using dropout regularization to prevent overfitting and improve generalization.\n- Using the Adam optimizer for efficient gradient-based optimization.\n- Using early stopping and learning rate reduction techniques to prevent overfitting and improve convergence.", "title": null, "competition_name": "Kaggle competition on sales forecasting", "task_category": "Regression", "field": "Modeling", "ranking": null, "score": null}, {"content": "High-ranking Kaggle notebooks or competition strategies: First of all, I would like to express my gratitude to everyone who organized this competition, thank you! Given the small amount of data, the competition was quite uncertain, but I'm glad that I was able to achieve good results. Now, I will describe my solution below.\n\n# Solution Overview\nThe important points of my solution are as follows.\n\n## Rule-based Patient splitting (most important)\nI was looking at train data and noticed that healthy patients with very low updrs values are tested only every other year (0, 12, 24, 36, 48, 60 month...) and semi-annual data (6, 18, 30, 42, 54 month ..) were not present. This was also the case in the test data. Patients without data at either the 6th or 18th month would see a significant improvement in LB by lowering the UPDRs value.\n\n## Modeling using only visit_month\nModeling basically uses only visit_month feature. However, the \"healthy patients with very low updrs values\" mentioned in (1) always have low updrs even after a month has passed, so these patients are removed from the train for modeling. Supplemental data is also used, but data for patients with month = 5 and patients with only month = 0 data are removed.\n\nThe modeling used below.\n- simple linear regression (referred [AmbrosM notebook]( \n- catboost regression with loss as huber loss\n- catboost regression with loss as mae loss\nThree types of regression were created and weighted averaged to obtain a higher CV. For validation, group k fold was performed by aligning the distribution of target as much as possible in each fold.\n\n## Submit Selection\nFor the last submit, the following two sub were selected.\n\nA. LB and CV Best sub: applying approaches 1) to 2), both LB and CV is high and align (CV:54.41 LB:54.4).\nB. only CV Best sub: For patients for whom protein/peptido is available in the test data, using the results of the model with protein / peptido features without using the results of visit_month. In this case, CV improves by about 0.4, but LB decreases by the same amount.(CV:54.02 LB:54.9)\n\nAs a result, sub A was better score(Private:60.5). sub B score is 61.2.\n\nIn summary, it was a very uncertain competition, but by looking carefully at the data, and carefully adopting an approach that improves both CV and LB, I can achieve good results.\n\nBasically I did all the work in kaggle notebook, so I am publishing the code. However, it has not been refactored, so readability is poor. [Code]( ", "title": "Solution Overview", "competition_name": "Not explicitly mentioned", "task_category": "Regression", "field": "Modeling", "ranking": "Not explicitly mentioned", "score": {"CV": {"sub_A": 54.41, "sub_B": 54.02}, "LB": {"sub_A": 54.4, "sub_B": 54.9}, "Private": {"sub_A": 60.5, "sub_B": 61.2}}}, {"content": "High-ranking Kaggle notebooks or competition strategies: (1) The overall design of this code is to train a high-performing model for a Kaggle competition. It involves preprocessing the sales and calendar data, creating a dataset, defining the model architecture, training the model, and generating predictions for validation and evaluation.\n\n(2) The overall model architecture consists of multiple input features, including numerical features (e.g., \"num\"), categorical features (e.g., \"snap_CA\", \"snap_TX\", \"snap_WI\", \"wday\", \"month\", \"year\", \"event\", \"nday\", \"item\", \"dept\", \"cat\", \"store\", \"state\"), and lagged features (e.g., \"x_28\", \"x_35\", \"x_42\", \"x_49\", \"x_56\", \"x_63\"). These features are passed through embedding layers for categorical features and concatenated with the numerical features. The concatenated features are then passed through multiple dense layers with dropout regularization. The final output layer predicts 9 quantiles of the target variable. The model is compiled with a custom quantile loss function and optimized using the Adam optimizer.\n\n(3) The important hyperparameters in this code are:\n- CATEGORIZE: A boolean variable indicating whether to categorize the categorical features.\n- START: An integer indicating the starting day for the sales data.\n- UPPER: An integer indicating the upper limit day for the sales data.\n- LAGS: A list of integers indicating the lagged features to be used.\n- FEATS: A list of strings indicating the lagged feature names.\n- batch_size: An integer indicating the batch size for training the model.\n- epochs: An integer indicating the number of epochs for training the model.\n\n(4) The optimization objective is to minimize the quantile loss function, which is a custom loss function defined as the pinball loss for multiple quantiles. The quantiles used in this code are [0.005, 0.025, 0.165, 0.250, 0.500, 0.750, 0.835, 0.975, 0.995].\n\n(5) The advanced machine learning technique used in this code is the use of embedding layers for categorical features. Embedding layers are a way to represent categorical variables as continuous vectors, allowing the model to learn meaningful representations of the categorical variables.\n\n(6) Other important tricks that play a role in high performance include:\n- Lagged features: The use of lagged features helps capture temporal dependencies in the data and improve the model's ability to make accurate predictions.\n- Dropout regularization: The use of dropout regularization helps prevent overfitting by randomly dropping out a fraction of the neurons during training, forcing the model to learn more robust representations.\n- ReduceLROnPlateau callback: This callback reduces the learning rate when the validation loss plateaus, allowing the model to fine-tune its parameters and potentially improve performance.\n- EarlyStopping callback: This callback stops training early if the validation loss does not improve for a certain number of epochs, preventing overfitting and saving computational resources.\n- ModelCheckpoint callback: This callback saves the weights of the best-performing model during training, allowing the model to be loaded and used for predictions later.", "title": null, "competition_name": null, "task_category": "Regression", "field": "Modeling", "ranking": null, "score": null}, {"content": "High-ranking Kaggle notebooks or competition strategies: Hi guys, I would like to share my solution with you, but first I would like to thank Kaggle, the hosts, and all participants, especially @kneroma and @kailex for their kernel contributions. In addition, thanks to the whole discussion about the magic multiplier led by the @kyakovlev kernels. **1) The features:** A) From the calendar: I created features from the remaining days for the event. Each event would be a column, and the values in this column refer to the \"strength\" of the proximity of the event limited to 30. Still in this matter, a new variable that would be the sum of all these \"forces\" was created, if this column had a high value, it would indicate that they would have one or more events nearby. Also used some variables to indicate seasonality. For example, indicating how near the day is to the end of the month. Week of the year, day of the week... B) Prices: I decided to remove the current price of the items in the model. Instead, I calculated the percentage difference between the price of the week and the price of previous weeks, thus creating some columns related to that price difference. I figured that a fall or rise in price that week was going to make more sense for a more generalized prediction. C) Historical series Here, thanks to the @kkiller and @kxx kernels with the variables ['lag_7', 'lag_28', 'rmean_7_7', 'rmean_28_7', 'rmean_7_28', 'rmean_28_28']. Also inserted some other variables like the item id and the store id as cat variables. **2) The model** I used an LGBM model with early stopping, and with Poisson objective, for each department, resulting in a total of 7 models. It made it easier for me not to burst the memory and be able to use more days from the past. I also used the predicted value to predict the next (eg lag_7) **3) Post-processing magic multipliers.** A magic multiplier of ~1.03 really improved the result, but I was not confident on that. So I went to analyze how the true values differed from the predicted values, for each store and department. And we have graphs like these: ![]( ![]( Some stores/departments showed the prediction \"constantly below\" (of course with a lot of noise) of the true value. And other stores/departments showed the prediction \"constantly above\" the true value. I then decided to create an average correction factor for each store/department, based on the last week (validation). And we have a matrix like this: ![]( ... That is, ~ 0.92 represents a specific factor for FOODS_1/CA_1, because the true value was, on average, 92% of the predicted value to the validation set. In this way, I imagined that the historical correction factors for the validation would behave similarly from the historical to the evaluation. In summary for this item, instead of using a magic multiplier, I used a magic multiplier for each store/department. Here, I was not afraid of overfitting the result. It could be much worse, I could overfit a lot more by creating a factor for each item, but it would be too much. So, it was a compromise between creating just one magic multiplier for the entire result and one magic multiplier for each item. **4) A simple diagram:** ![]( The solution in the public was far from winning, but the private score remained close to the public one. Finally, I hope to be able to contribute more to the discussions of the next challenges. I am very grateful to everyone for the great learning I was able to absorb in this competition, regardless of the result. Thank you again", "title": "", "competition_name": "", "task_category": "Regression", "field": "Feature Engineering, Modeling", "ranking": "", "score": ""}, {"content": "High-ranking Kaggle notebooks or competition strategies: I learned a lot from the community in this competition, so I wanted share my solution and some learnings I had from the competition as well. \n\nBefore I go deeper, I wanted to first thank the hosts, Kaggle, and the community as a whole. I learned a lot from this experience and am glad to have done it. Credit also to these two notebooks where a lot of my inspiration came from:\n* @kyakovlev :  \n* @kneroma : \n\n# Solution\n\nMy solution itself is not too innovative, but how I got there might be interesting. One of the big things I learned from this competition is the importance of having a reliable and fast cross-validation method. Common with themes in other posts, I ended up finding that simpler was better. With the cross-validation, I pruned a lot of features that I found did not provide a large benefit to keep the model simpler.\n\n## Algorithm\nGradient boosting trees (LightGBM), one model per store\n\n## Features\n* Item id, department id, category id\n* Price features: current price, price relative to past prices, statistics on the price (max, min, standard deviation, mean… etc.)\n* Sales features: recursive 7-day, 14-day lagged rolling means + 28-day lagged rolling means. No lagged rolling standard deviations\n* Date features: date attributes (e.g. month, year, is weekend, day of week, … etc.), nearest upcoming/past event name, event name 1, event name 2, SNAP, no event type\n\n## Cross-validation / hyperparameter optimization\n* It took me a while to come up with a cross-validation approach I was happy with, trying to balance accuracy and speed. I took the data for stores CA1, TX2, and WI3 to increase training speed, and used time periods d1550-d1577, d1858-d1885, d1886-d1913 as my cross-validation periods. For each period, I trained a model with all data before the period, and then used the models to predict the sales within the period.\n* I tested the sensitivity of the method by running it on the same model with different seeds to see how widely the scores varied by random chance.\n* Even with those optimizations, cross validation took a while: ~24 hours for 40 parameter sets\n* I tuned LightGBM parameters with [hyperopt](\n* A shoutout also to [this thread]( for helping to improve LightGBM training speed by ~2x.\n\n## Things that I tried but did not include\nI think the following, if done better, may have helped. However, I found the benefit of these improvements to be marginal so opted not to use them for simplicity.\n* Predicting overall sales for each day and scaling predictions accordingly. I did notice that if I could perfectly predict overall sales for each day, the scores would improve tremendously. \n* Weighting data points \n* Predicting number of dollars spent per item instead.\n* Removing \"out-of-stock\" periods from the training dataset.\n\nFor those that are interested, I also wrote a quick [blog post]( on some high-level learnings.\n\nHope you might find some of these thoughts helpful and happy to answer any questions!", "title": "Solution", "competition_name": "Not explicitly mentioned", "task_category": "Regression", "field": "Modeling", "ranking": "Not mentioned", "score": "Not mentioned"}, {"content": "High-ranking Kaggle notebooks or competition strategies: (1) The overall design of the code is to train a high-performing model for a Kaggle competition. It involves loading and preprocessing the data, applying feature engineering techniques, training a LightGBM regressor model, and generating a submission file.\n\n(2) The overall model architecture is as follows:\n- The code starts by loading the necessary data files using pandas.\n- It then performs some exploratory data analysis and visualization to understand the data.\n- The data is then preprocessed and optimized for memory usage using a function called `reduce_mem_usage`.\n- Categorical variables are encoded to numerical values using dictionaries to store the categories and their codes.\n- Lag features are introduced into the dataset to capture temporal patterns.\n- Various combinations of features are created to capture different levels of aggregation and trends.\n- Rolling window and expanding window concepts are applied to calculate moving averages and expanding means.\n- The data is split into training, validation, and test sets.\n- Hyperparameter tuning is performed using the hyperopt library to find the best set of hyperparameters for the LightGBM regressor model.\n- The model is trained using the best hyperparameters and predictions are made on the validation and test sets.\n- The model is saved using the joblib library.\n- Finally, the validation and evaluation results are formatted and saved in a submission file.\n\n(3) The important hyperparameters in this code are tuned using the hyperopt library. The hyperparameters that are tuned include:\n- `n_estimators`: The number of boosting iterations.\n- `learning_rate`: The learning rate of the boosting process.\n- `max_depth`: The maximum depth of the tree.\n- `num_leaves`: The maximum number of leaves in a tree.\n- `subsample`: The subsample ratio of the training instances.\n- `colsample_bytree`: The subsample ratio of columns when constructing each tree.\n- `min_child_weight`: The minimum sum of instance weight needed in a child.\n\nThe hyperparameters are tuned using the `fmin` function from the hyperopt library, which performs a Bayesian optimization search.\n\n(4) The optimization objective is to minimize the root mean squared error (RMSE) between the predicted sales and the actual sales. This is achieved by training the LightGBM regressor model and optimizing the hyperparameters.\n\n(5) The advanced machine learning technique used in this code is the LightGBM regressor model. LightGBM is a gradient boosting framework that uses tree-based learning algorithms. It is known for its efficiency, accuracy, and ability to handle large-scale datasets.\n\n(6) Some important tricks that play a role in achieving high performance in this code include:\n- Memory optimization: The code uses the `reduce_mem_usage` function to reduce the memory usage of the dataframes, which helps in handling large datasets efficiently.\n- Feature engineering: The code creates lag features, combinations of features, and rolling/expanding window features to capture temporal patterns and trends in the data.\n- Hyperparameter tuning: The code uses the hyperopt library to perform hyperparameter tuning and find the best set of hyperparameters for the LightGBM model.\n- Cross-validation: The code uses cross-validation to evaluate the performance of the model and select the best set of hyperparameters.\n- Early stopping: The code uses early stopping in the training process to prevent overfitting and improve generalization performance.\n- Model serialization: The code saves the trained model using the joblib library, which allows for easy reuse and deployment of the model.", "title": "", "competition_name": "", "task_category": "Regression", "field": "Modeling", "ranking": "", "score": ""}, {"content": "High-ranking Kaggle notebooks or competition strategies: (1) The overall design of the code is to generate a high-performing solution for a Kaggle competition. It involves reading in multiple CSV files, manipulating the data, and generating predictions for the competition.\n\n(2) The overall model architecture is not explicitly mentioned in the code. However, based on the code, it appears that the model is using a combination of ensemble methods, such as gradient boosting (LightGBM) and deep learning (Keras), to make predictions. The code reads in multiple CSV files containing predictions from different models and combines them using weighted exponential moving average. The final predictions are then adjusted using quantile coefficients based on different aggregation levels (e.g., item_id, dept_id, cat_id, store_id, state_id, etc.). The adjusted predictions are then used to generate the final submission file.\n\n(3) The important hyper-parameters in this code are the coefficients used for calculating the quantile ratios. These coefficients are set manually in the code and control the range of the quantiles. The code provides different functions (`get_ratios`, `get_ratios2`, `get_ratios3`) to calculate the quantile ratios based on different distributions (e.g., normal, skew-normal, power-log-normal). The coefficients for each aggregation level are stored in the `level_coef_dict` dictionary.\n\n(4) The optimization objective of this code is to generate accurate point predictions and quantile predictions for the Kaggle competition. The code aims to minimize the difference between the predicted values and the actual values in the training data.\n\n(5) The advanced machine learning technique used in this code is ensemble learning. The code combines predictions from multiple models (LightGBM, Keras) using weighted exponential moving average. This ensemble approach helps to improve the overall performance and robustness of the predictions.\n\n(6) Some important tricks that play a role in achieving high performance include:\n- Using ensemble methods to combine predictions from multiple models.\n- Adjusting the predictions using quantile coefficients based on different aggregation levels.\n- Applying exponential moving average to smooth the predictions.\n- Handling different quantile ranges for different aggregation levels.\n- Adjusting the predictions for specific quantiles (e.g., median) to improve accuracy.\n- Manipulating the data to handle different time periods and aggregation levels.\n- Using a combination of different distributions (e.g., normal, skew-normal, power-log-normal) to calculate the quantile ratios.", "title": null, "competition_name": null, "task_category": "Regression", "field": "Modeling", "ranking": null, "score": null}, {"content": "High-ranking Kaggle notebooks or competition strategies: (1) The overall design of this code is to optimize the weights of different base models in order to create an ensemble model that performs well in a Kaggle competition. The code reads in the predictions from multiple base models, merges them together, and then applies a weighted average to generate the final submission.\n\n(2) The overall model architecture is an ensemble model that combines the predictions from multiple base models. The code reads in the predictions from five base models: LSTM, XGBoost, LGBM, Prophet, and SARIMAX. It then merges these predictions together using a weighted average approach. The weights for the average are optimized using a custom minimization function. The optimized weights are then used to calculate the final submission.\n\n(3) The important hyper-parameters in this code are the initial weights for the base models (x0), the step size for the optimization process (stepsize), and the maximum number of iterations for the optimization process (maxiter). These hyper-parameters are set in the `minimize` function call.\n\n(4) The optimization objective is to minimize the WRMSSE (Weighted Root Mean Squared Scaled Error) score. The `WRMSSEEvaluator` class is used to calculate the WRMSSE score for a given set of predictions. The `function` function is defined to calculate the WRMSSE score for a given set of weights and predictions. The `minimize` function is then used to find the set of weights that minimizes the WRMSSE score.\n\n(5) The advanced machine learning technique used in this code is ensemble learning. The code combines the predictions from multiple base models using a weighted average approach. This allows the ensemble model to benefit from the strengths of each individual base model and improve overall performance.\n\n(6) One important trick that plays a role in high performance is the use of the `WRMSSEEvaluator` class to calculate the WRMSSE score. This allows the code to evaluate the performance of the ensemble model and optimize the weights of the base models accordingly. Additionally, the use of the custom minimization function helps to find the optimal set of weights that minimizes the WRMSSE score.", "title": null, "competition_name": null, "task_category": "Regression", "field": "Modeling", "ranking": null, "score": null}, {"content": "High-ranking Kaggle notebooks or competition strategies: (1) The overall design of this code is to train a model for a Kaggle competition on sales forecasting. It uses the LightGBM library to build a model and make predictions. The code first loads the necessary libraries and defines some constants and data types. Then, it defines functions to create the training and testing datasets, as well as to create additional features. After that, it preprocesses the data, splits it into training and validation sets, and trains the LightGBM model. Finally, it makes predictions on the test set and generates the submission file.\n\n(2) The overall model architecture is a LightGBM model. LightGBM is a gradient boosting framework that uses tree-based learning algorithms. It is designed to be efficient and scalable, and it can handle large datasets with high-dimensional features. The model is trained using the training data and validated using a subset of the training data. The model is then used to make predictions on the test data.\n\n(3) The important hyperparameters in this code are:\n- \"objective\": The optimization objective, which is set to \"poisson\" in this code.\n- \"metric\": The evaluation metric, which is set to \"rmse\" in this code.\n- \"learning_rate\": The learning rate for the gradient boosting algorithm, set to 0.075.\n- \"sub_row\": The subsample ratio of the training data, set to 0.75.\n- \"bagging_freq\": The frequency of bagging, set to 1.\n- \"lambda_l2\": The L2 regularization term, set to 0.1.\n- \"num_iterations\": The number of boosting iterations, set to 1500.\n- \"num_leaves\": The maximum number of leaves in each tree, set to 128.\n- \"min_data_in_leaf\": The minimum number of data points in each leaf, set to 100.\n\n(4) The optimization objective is to minimize the root mean squared error (RMSE) between the predicted sales and the actual sales.\n\n(5) The advanced machine learning technique used in this code is gradient boosting with LightGBM. Gradient boosting is an ensemble learning method that combines multiple weak models (decision trees in this case) to create a strong predictive model. LightGBM is a fast and efficient implementation of gradient boosting that uses a histogram-based algorithm to speed up training and prediction.\n\n(6) Some important tricks that play a role in high performance include:\n- Creating lag features: The code creates lag features by shifting the sales values for different time periods. This allows the model to capture the temporal dependencies in the data.\n- Rolling mean features: The code calculates rolling mean features by taking the average of lag features over different time windows. This helps to smooth out the noise in the data and capture the underlying trends.\n- Categorical encoding: The code converts categorical variables into numerical codes using the \"cat.codes\" method. This allows the model to handle categorical variables as numerical features.\n- Random subsampling: The code randomly subsamples the training data to create a validation set for model evaluation. This helps to prevent overfitting and provides an unbiased estimate of the model's performance.\n- Regularization: The code applies L2 regularization to the model using the \"lambda_l2\" parameter. This helps to prevent overfitting and improve generalization.\n- Feature engineering: The code creates additional date-related features such as weekday, week of year, month, quarter, and year. These features provide additional information about the time patterns in the data and can improve the model's performance.", "title": "not provided", "competition_name": "not provided", "task_category": "Regression", "field": "Modeling", "ranking": "not provided", "score": "not provided"}, {"content": "High-ranking Kaggle notebooks or competition strategies: (1) The overall design of this code is to make predictions for a kaggle competition. It uses a combination of linear trends, CatBoost models, and other techniques to predict the rating for each prediction_id.\n\n(2) The overall model architecture consists of the following steps:\n- Load trend data: This code loads various trend data files that are used for prediction.\n- Load CatBoost protein models: This code loads pre-trained CatBoost models for each UPDRS score (1, 2, 3) and each fold (0-9).\n- Prediction loop: For each test sample, the code performs the following steps:\n  - Get protein model prediction: The code pivots the test_proteins and test_peptides dataframes and joins them to create a test_pr_pe_base dataframe. Then, it uses the CatBoost models to make predictions for each UPDRS score (1, 2, 3) and stores the predictions in the oof_df dataframe.\n  - Pred loop: For each prediction_id, the code calculates the prediction based on the visit_month, UPDRS score, and time difference. It uses linear trends, CatBoost models, and other ratios to calculate the final prediction.\n  - Store predictions: The code stores the prediction_id and corresponding rating in the result dataframe.\n- Predict: The code uses the env object to predict the ratings for the test samples and outputs the result.\n\n(3) The important hyper-parameters in this code are:\n- cb_model_path: The path to the directory containing the pre-trained CatBoost models.\n- folds: The number of folds used in the CatBoost models.\n- use_model_ratio: The ratio of using the CatBoost models for prediction.\n- first_cb_huber_use_ratio: The ratio of using the CatBoost huber predictions for the first visit month.\n- first_cb_mae_use_ratio: The ratio of using the CatBoost mae predictions for the first visit month.\n- cb_huber_use_ratio: The ratio of using the CatBoost huber predictions for non-healthy patients.\n- cb_mae_use_ratio: The ratio of using the CatBoost mae predictions for non-healthy patients.\n\n(4) The optimization objective of this code is to minimize the difference between the predicted ratings and the actual ratings for the test samples. The code uses various techniques such as linear trends, CatBoost models, and ratios to optimize the predictions.\n\n(5) The advanced machine learning technique used in this code is the CatBoostRegressor. CatBoost is a gradient boosting framework that uses decision trees as base models. It is known for its ability to handle categorical features and its fast training speed.\n\n(6) Some important tricks that play a role in high performance are:\n- Using linear trends: The code uses linear trends to make predictions for the first visit month and for non-healthy patients.\n- Using CatBoost models: The code uses pre-trained CatBoost models to make predictions for each UPDRS score. It combines the predictions from the models with other techniques to improve the accuracy.\n- Using ratios: The code uses different ratios to combine the predictions from linear trends, CatBoost models, and other techniques. These ratios are tuned to optimize the predictions.\n- Handling missing values: The code handles missing values in the test_pr_pe_base dataframe by replacing them with NaN values.\n- Grouping and folding: The code uses GroupKFold and StratifiedKFold to split the data into folds for training the CatBoost models. This helps to prevent overfitting and improve generalization.", "title": "Not provided", "competition_name": "Not provided", "task_category": "Regression", "field": "Modeling", "ranking": "Not provided", "score": "Not provided"}, {"content": "High-ranking Kaggle notebooks or competition strategies: (1) The overall design of the code is to train a model for a Kaggle competition on sales forecasting. It preprocesses the sales and calendar data, creates features, splits the data into training, validation, and test sets, builds a neural network model, trains the model, makes predictions, and generates a submission file. (2) The overall model architecture is a neural network with multiple inputs and outputs. The inputs include categorical variables such as snap_CA, snap_TX, snap_WI, wday, month, year, event, nday, item, dept, cat, store, state, and numerical variables represented by the features. The categorical variables are embedded using embedding layers, and the embeddings are concatenated with the numerical features. The concatenated features are then passed through multiple dense layers with dropout regularization. The output layer has 9 units corresponding to different quantiles of the target variable. (3) The important hyperparameters in this code are: - CATEGORIZE: A boolean variable indicating whether to categorize the categorical variables or not. - START: An integer indicating the starting day of the sales data to consider. - UPPER: An integer indicating the upper limit of the sales data to consider. - LAGS: A list of integers indicating the lag values to use for creating lagged features. - FEATS: A list of strings indicating the names of the lagged features. - batch_size: An integer indicating the batch size for training the neural network. - epochs: An integer indicating the number of epochs for training the neural network. (4) The optimization objective is to minimize the quantile loss function, which is a pinball loss for multiple quantiles. The quantiles used are [0.005, 0.025, 0.165, 0.250, 0.500, 0.750, 0.835, 0.975, 0.995]. (5) The advanced machine learning technique used in this code is a neural network with multiple inputs and outputs. It uses embedding layers to represent categorical variables and combines them with numerical features to make predictions. (6) Some important tricks that play a role in high performance are: - Categorizing the categorical variables to reduce memory usage and improve model performance. - Creating lagged features to capture temporal patterns in the data. - Using embedding layers to represent categorical variables in the neural network. - Adding dropout regularization to prevent overfitting. - Using a quantile loss function to optimize the model for different quantiles of the target variable.", "title": null, "competition_name": "sales forecasting", "task_category": "Regression", "field": "Modeling", "ranking": null, "score": null}, {"content": "Thanks to Kaggle and the competition hosts for this competition, and congratulations to the other teams! This was for me the first Kaggle competition in which I invested myself, and it was an awesome experience, I truly learnt a lot. \n\nThe model that performed the best for me is a variant of a multi-layer GRU model in which some residual connections and fully connected layers have been added between the GRU layers:\n\n![](\n\nHere are the PyTorch classes corresponding to this model: \n\n```\nclass ResidualBiGRU(nn.Module):\ndef __init__(self, hidden_size, n_layers=1, bidir=True):\nsuper(ResidualBiGRU, self).__init__()\n\nself.hidden_size = hidden_size\nself.n_layers = n_layers\n\nself.gru = nn.GRU(\nhidden_size,\nhidden_size,\nn_layers,\nbatch_first=True,\nbidirectional=bidir,\n)\ndir_factor = 2 if bidir else 1\nself.fc1 = nn.Linear(\nhidden_size * dir_factor, hidden_size * dir_factor * 2\n)\nself.ln1 = nn.LayerNorm(hidden_size * dir_factor * 2)\nself.fc2 = nn.Linear(hidden_size * dir_factor * 2, hidden_size)\nself.ln2 = nn.LayerNorm(hidden_size)\n\ndef forward(self, x, h=None):\nres, new_h = self.gru(x, h)\n# res.shape = (batch_size, sequence_size, 2*hidden_size)\n\nres = self.fc1(res)\nres = self.ln1(res)\nres = nn.functional.relu(res)\n\nres = self.fc2(res)\nres = self.ln2(res)\nres = nn.functional.relu(res)\n\n# skip connection\nres = res + x\n\nreturn res, new_h\n\nclass MultiResidualBiGRU(nn.Module):\ndef __init__(self, input_size, hidden_size, out_size, n_layers, bidir=True):\nsuper(MultiResidualBiGRU, self).__init__()\n\nself.input_size = input_size\nself.hidden_size = hidden_size\nself.out_size = out_size\nself.n_layers = n_layers\n\nself.fc_in = nn.Linear(input_size, hidden_size)\nself.ln = nn.LayerNorm(hidden_size)\nself.res_bigrus = nn.ModuleList(\n[\nResidualBiGRU(hidden_size, n_layers=1, bidir=bidir)\nfor _ in range(n_layers)\n]\n)\nself.fc_out = nn.Linear(hidden_size, out_size)\n\ndef forward(self, x, h=None):\n# if we are at the beginning of a sequence (no hidden state)\nif h is None:\n# (re)initialize the hidden state\nh = [None for _ in range(self.n_layers)]\n\nx = self.fc_in(x)\nx = self.ln(x)\nx = nn.functional.relu(x)\n\nnew_h = []\nfor i, res_bigru in enumerate(self.res_bigrus):\nx, new_hi = res_bigru(x, h[i])\nnew_h.append(new_hi)\n\nx = self.fc_out(x)\n\nreturn x, new_h  # log probabilities + hidden states\n```\n\nNote that the code can be simplified: for my best model which performed a private lb score of 0.417, the \"h\" was actually always initialized with None. \n\n## Preprocessing\nIn terms of data, the choice I made for my model is very simplistic: consider only the accelerometer data (AccV, AccML, AccAP), merge the data from tdcsfog and defog together and train a single model on it. The main steps of my preprocessing pipeline are the following ones: \n- downsample each sequence from their initial frequency (resp. 128 and 100 Hz) to 50Hz;\n- for defog: \n- convert from g units to m/s^2 units;\n- build a mask using \"Valid\" and \"Task\" to know which time steps are labeled during the training. The unlabeled time steps are fed to the model to get the full sequence context, but they are masked during the loss computation.\n- add a 4th \"no-activity\" class: the model is trained to recognize this class in the same way as the other classes. Outside of the loss, during the validation, i only use the 3 other classes to compute my metrics;\n- per-sequence standard normalization (StandardScaler). \n\nOutside of the unlabeled time steps coming from defog, I did not use any other unlabeled data. \n\nFor the prototype of another model i did not have the time to finish, I also began to consider some of the characteristics associated to the person who was producing the sequence, in particular I used \"Visit\", \"Age\", \"Sex\", \"YearsSinceDx\", \"UPDRSIII_On\" and \"NFOGQ\". This prototype was roughly following the same architecture as my best model ; the main idea was to initialize the GRU's hidden states with these characteristics, after using some fully connected layers to project them in the dimension of the hidden states. This prototype was also using 1D convolutions to extract features from the accelerometer data before passing them to the GRU layers, and I also considered adding dropout. I think that with more time for me to tune it, it would have beaten my current best model. The first version achieved a private lb score of 0.398. \n\n## Training details\nMy best model - the one which performed 0.417 on the private leaderboard - has been trained without any form of cross-validation, only with a train/validation split of 80% / 20%. To be honest, this model appeared as a prototype in my early experimentation process, and I considered stratified cross-validation only after. \n\nIn this solution, I fed **each whole downsampled (50Hz)** sequence to my model, one after the other ie with **a batch size of 1**. Note that I would have been unable to feed some of the sequences to my model without downsampling them. I tried multiple different approaches with this architecture, but was unable to produce a better score when increasing the batch size. I tried multiple window sizes for my sequences ; however as I am pretty new in time series and as I also arrived pretty late in the competition, I did not implement any form of overlap and only thought about it too late. This could have probably been a key. Also when increasing the batch size, it seemed apparent that batch normalization was better than layer normalization. \n\nFor the loss, I used a simple cross entropy. As the classes are pretty imbalanced (in particular with my 4th artificial one), I also considered using a weighted cross-entropy, using the inverse frequency of each class as a weight. I also considered trying a focal loss ; but these initial tests seemed unable to perform better than the cross entropy in my case. Despite these negative experiments, I still think that dealing with the imbalance nature of the problem in a better way than I did is important. \n\nIn terms of optimizer, I used Ranger. I also tried Adam and AdamW and honestly i don't think this choice mattered too much. With Ranger I used a learning rate of 1e-3 with 20 epochs, with a cosine annealing schedule starting at 15. \n\nNote that I also used mixed precision training and gradient clipping. \n\nThe best parameters I found for the architecture of my model are:\n- hidden_size: 128;\n- n_layers: 3;\n- bidir: True.\n\nLater on, I also tried a stratified k-fold cross-validation in which I stacked the predictions of my k models via a simple average. The architecture and the training details for each fold were the same as for my 0.417 lb model, and this stacking process led to my 2nd best model, performing a score of 0.415 on the private leaderboard (with k=5). I also tried retraining my model on the whole dataset, but this approach did not improve my lb score. \n\nIn no particular order, here are a few other architectures that I also tried but did not improve my score: \n- replacing GRU by LSTM in my model: with my architecture, GRUs outperformed LSTMs in all the tests I've realized;\n- multiple variants of  ;\n- a classic multi-layers bidirectional GRU followed by one or more fully connected layers, also with layer normalization and ReLUs. \n\nEdit: \nSubmission Notebook: \n\nPretrained models \"dataset\": \n\nFull open-source code: ", "title": "Not provided", "competition_name": "Not provided", "task_category": "Classification", "field": "Modeling", "ranking": "Not provided", "score": "0.417"}, {"content": "High-ranking Kaggle notebooks or competition strategies: (1) The overall design of the code is to preprocess the data, read the data, perform feature engineering, make predictions using a combination of constant values and slope coefficients, and then output the predictions.\n\n(2) The overall model architecture is as follows:\n- Preprocessing: The code includes functions for missing value completion and data interpolation.\n- Reading Data: The code reads the training data from multiple CSV files and concatenates them into a single dataframe.\n- Feature Engineering: The code creates new features based on the protein and peptide data, including rank normalization, variance, mean, cumulative mean, and cumulative count.\n- Prediction (Const): The code sets initial constant values for each target variable and updates them based on specific conditions.\n- Prediction (Slope): The code calculates slope coefficients for each target variable based on specific conditions and adds them to the constant values.\n- CV Score: The code calculates the SMAPE score for cross-validation.\n- Time Series API: The code uses the Time Series API to iterate over the test data, preprocess it, perform feature engineering, make predictions, and output the results.\n\n(3) The important hyperparameters in this code are the initial constant values (const_init1, const_init2, const_init3, const_init4) and the lists of increment values (list_const_increment1, list_const_increment2, list_const_increment3, list_const_increment4) used to update the constant values. These hyperparameters can be modified to improve the performance of the model.\n\n(4) The optimization objective of this code is to minimize the Symmetric Mean Absolute Percentage Error (SMAPE) between the predicted values and the true values of the target variables.\n\n(5) The advanced machine learning technique used in this code is the combination of constant values and slope coefficients to make predictions. The constant values provide a baseline estimate, while the slope coefficients capture the rate of change over time.\n\n(6) Some important tricks that play a role in high performance include:\n- Rank normalization of the protein and peptide data to handle outliers and improve comparability.\n- Creating new features based on the protein and peptide data, such as variance, mean, cumulative mean, and cumulative count, to capture different aspects of the data.\n- Using specific conditions and rules to update the constant values and calculate the slope coefficients, taking into account the visit month, visit month cumulative minimum, and other features.\n- Using the Symmetric Mean Absolute Percentage Error (SMAPE) as the evaluation metric to optimize the model's performance.", "title": "Not available", "competition_name": "Not available", "task_category": "Regression", "field": "Modeling", "ranking": "Not available", "score": "Not available"}, {"content": "High-ranking Kaggle notebooks or competition strategies: (1) The overall design of this code is to predict the ratings for different target variables (updrs_1, updrs_2, updrs_3, updrs_4) based on protein data. It uses a combination of month trend predictions and protein-specific shifts to make the predictions. (2) The overall model architecture can be described as follows: - The code starts by generating the train dataset by merging the clinical data and protein data. - It then calculates the month trend predictions for each target variable using the provided trend values and the predicted month. - Next, it divides the NPX values of a specific protein into several groups based on quantiles and finds the best shift after the month trend predictions for each group. - Finally, it sums the predictions from the month trend and the corresponding NPX group shift to get the final ratings. (3) The important hyper-parameters in this code are: - `quantiles`: A list of quantiles used to divide the NPX values into groups. - `target_to_trend`: A dictionary mapping each target variable to its corresponding trend values and the minimum month with a non-zero median for updrs_4. - `target_to_clip_max`: A dictionary mapping each target variable to its maximum clipping value for the shifts. - `npx_groups`: A list of dictionaries, where each dictionary represents an NPX group and contains the quantile range, clipping range, and feature name. (4) The optimization objective of this code is to minimize the SMAPE+1 metric between the true ratings and the predicted ratings. The `function_to_minimize` function calculates the SMAPE+1 metric based on the true ratings, predicted ratings, and protein shifts. (5) The advanced machine learning technique used in this code is the combination of month trend predictions and protein-specific shifts. The month trend predictions capture the overall trend in the ratings over time, while the protein-specific shifts capture the protein-specific effects on the ratings. (6) Some important tricks that play a role in high performance are: - Filling missing values in the protein data using forward fill (`fillna(method='ffill')`). - Clipping the shifts to avoid extreme values that may lead to unrealistic predictions (`clip()` function). - Dividing the NPX values into groups based on quantiles to capture protein-specific effects on the ratings. - Using the Powell optimization method (`method='Powell'`) to find the best shift values that minimize the SMAPE+1 metric.", "title": null, "competition_name": null, "task_category": "Regression", "field": "Modeling", "ranking": null, "score": null}, {"content": "all provided content", "title": "not available", "competition_name": "not available", "task_category": "Classification", "field": "Modeling", "ranking": "not available", "score": "0.369/0.462"}, {"content": "High-ranking Kaggle notebooks or competition strategies: We are really glad to reach top 10 in our first Kaggle Competition. (We did invest countless hours in this project)\n\nOne thing to know about our team is that we are all Supply Chain professionals first, data scientists second. We used a lot of domain knowledge to crack the problem, and many of the techniques we've used were recycled from things we do on a daily basis at Lokad (where we all work or used to work). \n\n**Summary**\n\nOur solution is a multi-stage state-space model, states being active or inactive. \n(A good reference here: \n\nOur predictions were generated through Monte Carlo simulation at level 12, we considered demand at different stores to be independent so we aggregated demand trajectories from level 12 up to level 10. Levels 1 to 9 time-series were handled individually with simple innovation state space models.  We modeled emission with a Negative Binomial distribution to represent the fact that demand is discrete. \n\nSeasonality factors were carefully hand-crafted and events were modeled with simple linear coefficients. (Calculated at store department level)\n\n**Good properties**\n\n1. Our solution is fully explainable, (white-box approach) - so we can easily describe each forecast in case we are challenged. \n\n2. It is linearly scalable, you can give us the whole WalMart dataset and it will still run without a problem (of course we would need some extra cpu =). (And we could still get a factor 10x by moving some core parts of the code to a compiled language).\n\n3. It clearly differentiates demand from sales, (how much it would sell if we were never stock-out)\n\n4. It can output full demand distributions for horizons, example: how much will it sell next week ? Note that this is different from how much will sell day by day.\n\n5. It can be used for training agent-based models (used for our MEIO solutions)   \n\n**Not so good properties**\n\n1. Time consuming. Adding new categories would require additional human analysis.\n\n2. Does not account for pricing effects (could not properly model it with the given dataset)\n\n3. Does not forecast new SKU. (We would require a separate solution for this case)\n\n**Conclusion**\n\nWe do believe that tailored statical models were a good fit to the problem at hand. We had a fairly stable score accross the years and periods and above all full control of the solution.", "title": "Not available", "competition_name": "Not available", "task_category": "Forecasting", "field": "Modeling", "ranking": "Top 10", "score": "Not available"}, {"content": "High-ranking Kaggle notebooks or competition strategies: (1) The overall design of the code is to predict the rating of patients with Parkinson's disease based on their visit data. The code takes in test data consisting of peptides and proteins, and uses a set of pre-trained MLP models to make predictions. The predictions are then combined to generate the final rating. (2) The overall model architecture is a multi-layer perceptron (MLP) model. The MLP model consists of several fully connected layers (fc1, fc2, fc3, fc4) with ReLU activation functions. The input to the model is a feature vector (X) which is passed through the fully connected layers to generate the predictions (preds). The model also includes batch normalization (bn) and layer normalization (ln) layers to normalize the input data. Dropout layers (dropout1, dropout2, dropout3, dropout4, dropout5) are used for regularization to prevent overfitting. (3) The important hyperparameters in this code are the hidden layer sizes (hid1, hid2, hid3, hid4), the dropout rates (0.1, 0.2, 0.3, 0.4, 0.5), and the learning rate for optimization. (4) The optimization objective is to minimize the mean squared error (MSE) loss between the predicted ratings and the true ratings. (5) The advanced machine learning technique used in this code is ensemble learning. Multiple MLP models are trained separately on different subsets of features and combined to make predictions. The predictions from different models are averaged to generate the final rating. (6) Other important tricks that play a role in high performance include batch normalization and layer normalization for input normalization, dropout for regularization, and using pre-trained models for transfer learning. Additionally, the code uses feature engineering techniques such as creating binary features based on the visit month and patient history to capture temporal patterns in the data.", "title": null, "competition_name": "Parkinson's Disease Rating Prediction", "task_category": "Regression", "field": "Modeling", "ranking": null, "score": null}, {"content": "High-ranking Kaggle notebooks or competition strategies: (1) The overall design of the code is to create a high-performing solution for a Kaggle competition related to gait prediction in Parkinson's disease. The code includes data preprocessing, model architecture, training process, and evaluation.\n\n(2) The overall model architecture consists of a Wave_Block module and a Classifier module. The Wave_Block module is a series of dilated convolutional layers with different dilation rates, which helps capture long-range dependencies in the input data. The Classifier module includes a bidirectional LSTM layer followed by several Wave_Block modules. The output of the model is a linear layer that predicts the probabilities of three target classes: StartHesitation, Turn, and Walking.\n\n(3) The important hyperparameters in this code are:\n- WAV_SIZE: The size of each chunk of the input waveform.\n- STEP_SIZE: The step size for sliding the window over the input waveform.\n- TIMES_REAL: The number of times to repeat the real data during training.\n- TIMES_TRAIN: The number of times to repeat the entire training dataset during training.\n- is_mixed_precision: Whether to use mixed precision training.\n- TARGET_COLS: The names of the target columns.\n\n(4) The optimization objective is to minimize the loss function during training. The specific loss function used in the code is not provided, but it is likely a binary cross-entropy loss or a multi-class cross-entropy loss, depending on the number of target classes.\n\n(5) The advanced machine learning technique used in this code is the Wave_Block module, which employs dilated convolutions to capture long-range dependencies in the input data. This helps the model learn complex patterns and improve performance.\n\n(6) Some important tricks that may play a role in high performance include:\n- Resampling the input waveform to a lower sample rate to reduce computational complexity.\n- Normalizing the input waveform by dividing it by 40.\n- Splitting the input waveform into chunks of fixed size for efficient processing.\n- Using a bidirectional LSTM layer to capture temporal dependencies in the input data.\n- Using the Wave_Block module with different dilation rates to capture long-range dependencies.\n- Using mixed precision training to speed up training and reduce memory usage.\n- Ensembling multiple models trained with different checkpoints to improve performance.\n\nNote: Some parts of the code are missing or incomplete, so the exact details of the model architecture and training process may vary.", "title": null, "competition_name": "Gait Prediction in Parkinson's Disease", "task_category": "Classification", "field": "Modeling", "ranking": null, "score": null}, {"content": "High-ranking Kaggle notebooks or competition strategies: (1) The overall design of the code is to create a high-performing solution for a Kaggle competition related to gait prediction. It uses a deep learning model called WaveNet to predict three target variables: StartHesitation, Turn, and Walking. The code includes data preprocessing, model architecture, training process, and testing process.\n\n(2) The overall model architecture consists of a Wave_Block module and a Classifier module. The Wave_Block module is responsible for capturing temporal dependencies in the input data using dilated convolutions. It takes the input data and applies a series of dilated convolutions with different dilation rates. The output of each convolutional layer is passed through a tanh activation function and a sigmoid activation function, and then multiplied element-wise. The result is added to the input data, creating a residual connection. This process is repeated for each dilation rate. The Classifier module consists of a bidirectional LSTM layer followed by four Wave_Block modules. The output of the last Wave_Block module is passed through a linear layer to obtain the final predictions.\n\n(3) The important hyperparameters in this code are:\n- WAV_SIZE: The size of each chunk of the input waveform.\n- STEP_SIZE: The step size for creating chunks from the input waveform.\n- TIMES_REAL: The number of times to repeat each real sample in the training dataset.\n- TIMES_TRAIN: The number of times to repeat each sample in the training dataset.\n- is_mixed_precision: Whether to use mixed precision training.\n- TARGET_COLS: The names of the target variables.\n\n(4) The optimization objective is not explicitly mentioned in the code. However, based on the model architecture and the use of sigmoid activation function in the final layer, it can be inferred that the optimization objective is binary cross-entropy loss. The model aims to minimize the binary cross-entropy loss between the predicted probabilities and the true labels for each target variable.\n\n(5) The advanced machine learning technique used in this code is the WaveNet architecture. WaveNet is a deep learning model that is specifically designed for generating audio waveforms. It uses dilated convolutions to capture long-range dependencies in the input data, making it suitable for time series data with temporal dependencies.\n\n(6) Some important tricks that play a role in high performance are:\n- Resampling the input waveform: The code resamples the input waveform from 128 Hz to 100 Hz using librosa library. This helps to reduce the dimensionality of the input data and make it more manageable for the model.\n- Normalizing the input waveform: The code divides the resampled waveform by 40 to normalize it. This helps to bring the input data to a similar scale and improve the convergence of the model.\n- Creating chunks from the input waveform: The code creates chunks of fixed size from the input waveform. This helps to handle variable-length input data and enables batch processing.\n- Using residual connections: The code uses residual connections in the Wave_Block module. This helps to alleviate the vanishing gradient problem and improve the flow of gradients during training.\n- Using mixed precision training: The code uses mixed precision training, which combines both single precision and half precision floating-point numbers. This helps to speed up the training process and reduce memory usage without sacrificing model performance.", "title": null, "competition_name": "Gait Prediction", "task_category": "Classification", "field": "Modeling", "ranking": null, "score": null}, {"content": "The overall design of this code is to predict the progression of Parkinson's disease based on clinical data, peptides, and proteins. It assumes that there are three groups of patients: the control group, the green group, and the orange group. The control group is examined only once a year, while the other two groups are examined more frequently. The model aims to predict the updrs scores for each group based on the visit month and other features.\n\nThe overall model architecture consists of the following steps:\n- Reading the data: The code reads the clinical data, peptides, and proteins from CSV files.\n- Preprocessing the training data: The code preprocesses the training data by creating a dataframe with one row per (patient_id, visit_month, pred_month) triple. It also distinguishes the three groups of patients based on their visit months.\n- Defining the model: The code defines a custom model called \"IsotonicGroups\" which predicts the updrs scores based on the group and pred_month features. It uses linear regression for the ill group and isotonic regression for the healthy group.\n- Cross-validation: The code performs cross-validation to evaluate the performance of the model using the SMAPE metric.\n- Training: The code trains the model on the full training set.\n- Submission: The code generates predictions for the test set and creates a submission file.\n\nThe important hyperparameters in this code are not explicitly set in the code. However, there are some hyperparameters that can be adjusted in the optimization functions, such as the bounds for the linear regression coefficients and the optimization method used. These hyperparameters can be modified in the `optimize_smapep1_linear` and `optimize_smapep1_isotonic` functions.\n\nThe optimization objective in this code is to minimize the SMAPE (Symmetric Mean Absolute Percentage Error) metric. The code defines a custom scorer object called `smapep1_scorer` which calculates the SMAPE score. The model is trained to minimize this score during cross-validation and optimization.\n\nThe advanced machine learning technique used in this code is isotonic regression. Isotonic regression is used to model the relationship between the visit month and the updrs scores for the healthy group. It ensures that the predicted updrs scores are monotonically increasing with the visit month.\n\nSome important tricks that play a role in high performance include:\n- Distinguishing the control group from the real patients based on their first non-zero visit month.\n- Using isotonic regression for the healthy group to capture the monotonic relationship between visit month and updrs scores.\n- Optimizing the linear regression coefficients for the ill group to minimize the SMAPE score.\n- Performing cross-validation to evaluate the model's performance and tune hyperparameters.\n- Using the SMAPE metric as the optimization objective to account for the nonlinearity of the problem.", "title": null, "competition_name": "Parkinson's Disease Progression Prediction", "task_category": "Regression", "field": "Modeling", "ranking": null, "score": null}, {"content": "After missing the gold medal zone by picking the wrong submission in the 2019 Data Science Bowl, here I missed it again by just one place, what a pity. Anyway, if this will be my 2nd first student prize after the DSB, I'm more than happy.\n\n**Here a short wrap up of my solution:**\n\nI focussed on the Accuracy part of the competition (where my final private LB rank isn't that good though (274/5558)) and decided to go for day-to-day LGBM models. The notebook to create my uncertainty forecasts for horizon h=8 can be found here:\n\nThe notebooks for other forecast horizons look similar.\n\n**The following steps are carried out for each horizon:**\n\n**1. Preprocessing:**\n- Process calendar dataframe to get some more features\n- Process selling prices dataframe: first, I built selling prices for aggregate time series by just taking the mean of the aggregated time series (e.g. for the Total aggregation, I put as sell_price the mean of all sell prices); second, I built some more features as sell_prices_std and so on\n- Process sales dataframe: first, I built the aggregate time series for all levels. For the state_id columns etc. I used the following strategy: If all aggregated time series had the same value, I used it, otherwise I put nan (e.g. for the CA_1 aggregate, all aggregated time series have state_id CA, so I left it; for the FOODS aggregate on the other hand, the aggregated time series have different state_ids, so I put state_id nan). Next, I removed some outliers (Christmas, Thanksgiving and something else), normalized each of the time series (details see below), and computed further features as rolling means, target encodings of calendar features etc.    \n\n**2. Modelling:**\nFor each quantile q, I trained a LGBM model with objective 'quantile' and 'alpha'=q on all time series. The last 28 days were left out as validation set for early stopping. The WSPL weights were used during training passing them to the LGBM dataset as\ntrain = lgb.Dataset(train[features],train[['demand']],weight=train['weight'])\n\n**Normalization of sales time series**\nBased on some CV tests in my work on the accuracy part, I came up with the following normalization for all sales time series (aggregated ones and normal ones):\nFirst, I divided each time series by their nonzero mean.\nSecond, to remove the trend, I considered some form of differences and set \na_trendRemoved[t]=a[t]+maxRollMean(28)-laggedRollMean(28,h)\nfor each mean normalized time series a[t]. Here maxRollMean(28) is the maximum rolling mean over a 28 days period that the time series had anywhere during the 1941 provided days. The laggedRollMean(28,h) is the mean of a[t-28-h+1],...,a[t-h].\nSo how did I come to this? Actually I wanted to use something like\na_trendRemoved[t]=a[t]-rollMean(28)\nmeaning how the sales at time t differ from the mean of the last 28 days. However, undoing this preprocessing after the predictions requires to use the predictions for the days F1,...,F(h-1) to build the rollMean(28) and I wanted the forecasts for each time horizon to be independent from all other forecasts to prevent error propagation. Therefore, I decided to replace the rollMean(28) by the laggedRollMean(28,h). Adding further the maxRollMean(28) term ensures that all values stay positive. I thought that this shouldn't matter, but in my CV experiments, it gave better results, so I used it.  \n\n**Sidenotes:**\n- As I used only kaggle kernels and no other ressources, it was quite a struggle to fit everything into RAM and into the 9 hours wallclock limit. Therefore, I used only days after dstart=1100 for training and only considered the forecast weekday and one similar weekday for training (e.g. F8 is a Monday, so for the horizon h=8 models, I used only Mondays and Fridays for training and discarded all other days). \n- Tuning LGBM parameters didn't work out for me at all, I simply used the parameters that I found in some public kernel in the Accuracy part (except from objective=quantile and alpha=q of course).\n- I tried feature selection for the accuracy part. Leaving always one feature out, retraining my model and checking whether my CV score improved. As I didn't observe any stable improvements, I simply used all features here.\n- I refer to some CV tests above which worked like this: I considered only the accuracy part and picked 2 horizons, namely 8 and 22 days for which I used the last 3 28 days periods for cross validation. All parameter, feature and normalization decisions that I made where based on the results obtained there. However, I'm not sure, if this was such a good idea, as the CV obtained in those experiments indicated way higher scores than I obtained in the end on the accuracy private LB. Therefore, I think that I might have overfitted to the 2 specific horizons. Setting up a CV using all 28 horizons with day-to-day models (-&gt; always training 28 models * 3 validation sets) doesn't seem feasible either though, so I don't know how I could have done better.\n- I said I use the WSPL weights for my LGBM model. Actually, I do not use the original weights, but normalize them s.t. they all weights have mean 1. Then I clip them s.t. all weights lie between 0.2 and 30. The first step ensures that everything still works fine with normal learning rates. The clipping was done to make it a bit more stable ensuring that there aren't time series with weights in the order of 100 and others with weights in the order of 0.001.\n\nHappy Kaggling\nTobias\n\nEdit: Unfortunately, @david1352413524 in front of me appended now as well _stu to his team name s.t. I guess this here is only the 2nd student place :( congrats to him though. Would you mind sharing your solution as well @david1352413524 ?", "title": "Not explicitly stated", "competition_name": "2019 Data Science Bowl", "task_category": "Forecasting", "field": "Modeling", "ranking": "274/5558", "score": "Not explicitly stated"}, {"content": "High-ranking Kaggle notebooks or competition strategies: (1) The overall design of the code is to preprocess the data, read the data, perform feature engineering, make predictions using a combination of constant values and slope coefficients, and then output the predictions.\n\n(2) The overall model architecture is as follows:\n- Preprocessing: The code includes functions for missing value completion and rank normalization of features.\n- Reading Data: The code reads the training data from multiple CSV files and concatenates them into a single dataframe.\n- Feature Engineering: The code creates additional features based on the original data, such as differences between visit months, cumulative minimum visit months, and rank-based features for proteins and peptides.\n- Prediction (Const): The code defines constant values for each target variable (updrs_1, updrs_2, updrs_3, updrs_4) based on specific conditions and increments.\n- Prediction (Slope): The code calculates slope coefficients for each target variable based on specific conditions and coefficients.\n- CV Score: The code calculates the SMAPE score for cross-validation using the predicted values and the actual values.\n- Time Series API: The code uses the Time Series API to iterate over the test data, preprocess it, perform feature engineering, and make predictions using the trained model.\n\n(3) The important hyperparameters in this code are the initial constant values (const_init1, const_init2, const_init3, const_init4) and the lists of increments for each target variable (list_const_increment1, list_const_increment2, list_const_increment3, list_const_increment4). These hyperparameters determine the values of the constant and slope coefficients used for prediction.\n\n(4) The optimization objective of this code is to minimize the Symmetric Mean Absolute Percentage Error (SMAPE) between the predicted values and the actual values of the target variables.\n\n(5) The advanced machine learning technique used in this code is time series analysis. The code takes into account the temporal nature of the data by considering the differences between visit months, cumulative minimum visit months, and rank-based features for proteins and peptides.\n\n(6) Some important tricks that play a role in high performance include:\n- Missing value completion: The code replaces missing values with appropriate values based on the context.\n- Rank normalization: The code performs rank normalization of features to ensure that they have similar scales and distributions.\n- Feature engineering: The code creates additional features based on the original data to capture important patterns and relationships.\n- Constant and slope coefficients: The code uses a combination of constant values and slope coefficients to make predictions, taking into account specific conditions and increments.\n- Cross-validation: The code calculates the SMAPE score for cross-validation to evaluate the performance of the model.", "title": null, "competition_name": null, "task_category": "Regression", "field": "Modeling", "ranking": null, "score": null}, {"content": "High-ranking Kaggle notebooks or competition strategies: (1) The overall design of this code is to combine the predictions from multiple models and create an ensemble model. The code reads the predictions from six different CSV files, averages the predictions for each day, and saves the final ensemble predictions in a new CSV file called 'submission.csv'.\n\n(2) The overall model architecture is not explicitly mentioned in the code. However, based on the information provided in the comments, it can be inferred that the code uses a combination of different models to make predictions. The code imports predictions from six different CSV files, which suggests that each file corresponds to a different model. The predictions from these models are then averaged to create the final ensemble predictions.\n\n(3) The code does not explicitly mention the hyperparameters used in the models. However, based on the information provided in the comments, it can be inferred that the hyperparameters were set by the contributors of the project. The code does not include any hyperparameter tuning or optimization process.\n\n(4) The optimization objective of this code is to improve the forecasting accuracy for daily sales. The code combines predictions from multiple models to create an ensemble model, which is expected to provide more accurate and robust predictions compared to individual models.\n\n(5) The advanced machine learning technique used in this code is ensemble learning. The code combines predictions from multiple models to create an ensemble model. Ensemble learning is a technique where multiple models are trained independently and their predictions are combined to make a final prediction. This technique often leads to improved performance and robustness compared to individual models.\n\n(6) One important trick that plays a role in high performance is model averaging. The code averages the predictions from multiple models to create the final ensemble predictions. Model averaging helps to reduce the impact of individual model biases and errors, leading to more accurate and robust predictions. Additionally, the code mentions that the contributors used existing kernels to improve their models, suggesting that they leveraged existing knowledge and techniques to enhance their performance.", "title": null, "competition_name": null, "task_category": "Regression", "field": "Modeling", "ranking": null, "score": null}, {"content": "High-ranking Kaggle notebooks or competition strategies: (1) The overall design of this code is to build a model for a Kaggle competition on sales forecasting. It preprocesses the sales and calendar data, creates features, and trains a model using a combination of numerical and categorical inputs.\n\n(2) The overall model architecture consists of an embedding layer for categorical features, followed by a concatenation of the embeddings with the numerical features. This concatenated input is then passed through three GRU layers with dropout, and finally a dense layer with 9 outputs corresponding to the quantiles of the sales forecast.\n\n(3) The important hyperparameters in this code are:\n- CATEGORIZE: a boolean flag indicating whether to categorize the categorical features or not.\n- START: the starting day of the sales data to consider.\n- UPPER: the upper limit of the days to consider in the sales data.\n- LAGS: a list of lag values to use for creating lagged features.\n- seq_len: the length of the input sequence for the GRU layers.\n- batch_size: the batch size for training the model.\n- epochs: the number of epochs for training the model.\n- learning_rate: the learning rate for the optimizer.\n\n(4) The optimization objective is to minimize the weighted quantile loss, which is a pinball loss for multiple quantiles. The quantiles used are [0.005, 0.025, 0.165, 0.250, 0.500, 0.750, 0.835, 0.975, 0.995].\n\n(5) The advanced machine learning technique used in this code is the GRU (Gated Recurrent Unit) layer, which is a type of recurrent neural network (RNN) layer. The GRU layer is used to capture the temporal dependencies in the sales data.\n\n(6) Some important tricks that play a role in achieving high performance include:\n- Lagged features: The code creates lagged features of the sales data using the specified lag values. These lagged features capture the historical patterns in the sales data.\n- Embedding layers: The categorical features are converted into embeddings using embedding layers. This allows the model to learn meaningful representations of the categorical variables.\n- Dropout: Dropout is applied to the GRU layers to prevent overfitting and improve generalization.\n- Weighted quantile loss: The quantile loss is weighted by the inverse of the sales volume for each item, which gives more importance to items with higher sales volume.\n- Early stopping: The training process is stopped early if the validation loss does not improve for a certain number of epochs, which helps prevent overfitting.", "title": null, "competition_name": "sales forecasting", "task_category": "Regression", "field": "Modeling", "ranking": null, "score": null}, {"content": "High-ranking Kaggle notebooks or competition strategies: (1) The overall design of the code is to preprocess and engineer features for time series data in order to improve the performance of a machine learning model for a Kaggle competition. (2) The overall model architecture is not explicitly mentioned in the code. However, based on the code, it seems that the model architecture is a LightGBM regressor, which is a gradient boosting framework that uses tree-based learning algorithms. (3) The important hyper-parameters in this code are not explicitly mentioned. However, based on the code, some possible hyper-parameters that could be set are the number of trees, learning rate, maximum depth of trees, and feature fraction. (4) The optimization objective is not explicitly mentioned in the code. However, based on the code, the optimization objective could be to minimize the mean squared error between the predicted and actual sales values. (5) The advanced machine learning technique used in this code is LightGBM, which is a gradient boosting framework that uses tree-based learning algorithms. (6) Some important tricks that play a role in high performance in this code are downcasting the data to reduce memory usage, converting the data from wide to long format, introducing lags and rolling/expanding window statistics as features, and mean encoding categorical variables. These tricks help to improve the efficiency and effectiveness of the machine learning model.", "title": null, "competition_name": "Kaggle competition", "task_category": "Regression", "field": "Feature Engineering, Modeling", "ranking": null, "score": null}, {"content": "High-ranking Kaggle notebooks or competition strategies: (1) The overall design of the code is to make predictions on test sequences using a trained model and generate a submission file for a Kaggle competition. It loads the trained model, preprocesses the test sequences, makes predictions using the model, and updates the submission dataframe with the predicted labels. Finally, it saves the submission dataframe as a CSV file.\n\n(2) The overall model architecture is a MultiResidualBiGRU. It consists of a series of ResidualBiGRU layers followed by fully connected layers. The ResidualBiGRU layers are bidirectional GRU layers with skip connections. The input sequence is passed through the ResidualBiGRU layers, and the output is then passed through fully connected layers to obtain the final predictions. The model takes into account the hidden size, number of layers, input size, and output size as hyperparameters.\n\n(3) The important hyperparameters in this code are loaded from a JSON file named \"params.json\". The hyperparameters include:\n- \"ISIZE\": Input size of the model.\n- \"HSIZE\": Hidden size of the model.\n- \"NC\": Number of output classes.\n- \"NL\": Number of layers in the model.\n- \"DOWNHZ\": Downsampled frequency of the input sequences.\n\n(4) The optimization objective is not explicitly mentioned in the code. However, based on the model architecture and the use of softmax activation function on the final predictions, it can be inferred that the optimization objective is to minimize the cross-entropy loss between the predicted labels and the true labels.\n\n(5) The advanced machine learning technique used in this code is the use of a MultiResidualBiGRU model. This model combines the power of bidirectional GRU layers with skip connections to capture temporal dependencies in the input sequences and improve the performance of the model.\n\n(6) Some important tricks that play a role in high performance are:\n- Resampling the input sequences to a lower frequency using the `resample_seq_df` function. This reduces the computational complexity and allows the model to process the sequences more efficiently.\n- Normalizing the input sequences using the `normalize` function. This ensures that the input features have zero mean and unit variance, which can improve the convergence of the model during training.\n- Using the `autocast` context manager from `torch.cuda.amp` to enable mixed precision training. This can speed up the training process by utilizing the lower precision of certain operations without sacrificing accuracy.\n- Using the `torch.optim.lr_scheduler` module to adjust the learning rate during training. This can help the model converge faster and potentially improve the final performance.\n- Using the `torch.utils.data.DataLoader` class to load the training data in batches. This allows for efficient processing of the data and can improve the training speed.\n- Using the `torch.cuda.get_device_name` function to check if a GPU is available and using it for training if `USE_GPU` is set to `True`. This can significantly speed up the training process by utilizing the parallel processing power of the GPU.", "title": null, "competition_name": "Kaggle competition", "task_category": "Classification", "field": "Modeling", "ranking": null, "score": null}, {"content": "Congrats to the winners! Thanks to the competition organizers for putting together an interesting challenge! Here's my solution.\n\n# Model architecture\n\nI used a 1D convolutional U-Net with squeeze-and-excitation and 5 encoder/decoder pairs.\n\nSqueeze-and-excitation seemed to be very beneficial, presumably because it allows the model to take global context into consideration while classifying each sample. I processed the data in extremely long context windows (10240 samples).\n\n# Features\n\n- **Raw acleration values:** AccV, AccML, AccAP\n- I did not normalize these in any way. \n- **Time features:** \n`\ndf['NormalizedTime'] = df['Time'] / df['Time'].max()\n`\n`\ndf['SinNormalizedTime'] = np.sin(df['NormalizedTime'] * np.pi)\n`\n\nI also experimented with adding a variety of frequency domain features that were calculated using wavelet transforms but that didn't help.\n\n# Training data augmentation\n\n- **Random low pass filtering:**\n- Frequency cutoff was 5% - 37.5% the sample rate\n- Applied to half the training sequences\n- **Random time warp:**\n- Used linear interpolation to change the sequence length by +/- 10% (or any value in between; the scale was sampled from a uniform distribution)\n- Applied to half the training sequences\n- **Random flip:**\n- Multiplied AccML by -1 to reverse right & left\n- Applied to half the training sequences\n- **Random magnitude warping:**\n- The difference between each acceleration feature's value and its mean value was multiplied by a coefficient randomly sampled from a gaussian distribution with a mean of 0 and a standard deviation of 0.1\n- Applied to half the training sequences\n- **Noisy time features:**\n- Normalized times within each context window shifted by value sampled from gaussian distribution with mean of 0 and standard deviation of 0.05\n- Applied before calculating SinNormalizedTime (so the same noise impacts both features).\n- Applied to ALL the training sequences\n\n# Inference time data augmentation\n\nEach sample was classified 16 times by each model.\n- With and without multiplying AccML by -1 to reverse right & left\n- Sequences were classified in overlapping context windows with a stride equal to 1/8 the window length. Similar to random crop data augmentation.\n\nThe values saved to the submission file were the simple mean of all predictions from all models.\n\n# Handling defog vs tdcsfog\n\nI used the same models for both datasets. I did not do anything to normalize the sample rates or feature values. I did not even convert the features to have the same units. Normalization seemed to be harmful.\n\n# Ensembling / random seed hacking\n\nI used 2 near-identical models that were trained with identical hyperparameters from the same cross-validation fold, but with different random seeds for weight initialization & shuffling the training data. They were filtered to have mAP scores in the top 20% of my local cross validation and top 50% of my LB scores. This probably improved my score by around 0.01 - 0.02 vs. just using 2 random models.\n\n**Inference notebook:** ", "title": "Solution for Competition", "competition_name": "unknown", "task_category": "Classification", "field": "Modeling", "ranking": "unknown", "score": "unknown"}, {"content": "High-ranking Kaggle notebooks or competition strategies: (1) The overall design of this code is to predict the progression of Parkinson's disease in patients based on clinical data. It uses a machine learning model to make predictions for different time periods (0, 6, 12, and 24 months) and different target variables (updrs_1, updrs_2, updrs_3, and updrs_4). The code preprocesses the data, trains the models, and generates predictions for the test data. (2) The overall model architecture is based on LightGBM, a gradient boosting framework that uses tree-based learning algorithms. The code trains separate models for each target variable and time period combination. The features used for training include the predicted month, patient group, visit flags (indicating whether a visit occurred at specific time points), and trend values calculated based on the predicted month. The models are trained using the LGBMRegressor class from the LightGBM library, with the objective set to mean absolute error (MAE). (3) The important hyperparameters in this code are set as follows: - verbose: -1 (no output during training) - objective: 'mae' (mean absolute error) - plus_month: [0, 6, 12, 24] (time periods for predictions) - nan_to_trend: a dictionary containing trend values for replacing missing values in predictions (4) The optimization objective is to minimize the mean absolute error (MAE) between the predicted and actual values of the target variables. The models are trained using the LGBMRegressor class with the objective set to 'mae'. (5) The advanced machine learning technique used in this code is gradient boosting with LightGBM. Gradient boosting is an ensemble method that combines multiple weak models (decision trees) to create a strong predictive model. LightGBM is a fast and efficient implementation of gradient boosting that uses a histogram-based algorithm for splitting data and reducing memory usage. (6) Some important tricks that play a role in high performance include: - Preprocessing the data: The code preprocesses the data by creating additional features, such as visit flags and trend values, which capture important patterns in the data. - Handling missing values: The code replaces missing values in predictions using trend values calculated based on the predicted month. This helps to improve the accuracy of the predictions. - Training separate models: The code trains separate models for each target variable and time period combination. This allows the models to capture the specific patterns and trends associated with each target variable and time period. - Using LightGBM: LightGBM is a high-performance gradient boosting framework that uses a histogram-based algorithm for splitting data and reducing memory usage. This allows the code to train models quickly and efficiently, leading to high performance.", "title": "", "competition_name": "", "task_category": "Regression", "field": "Modeling", "ranking": "", "score": ""}, {"content": "High-ranking Kaggle notebooks or competition strategies: (1) The overall design of the code is to train a neural network model to predict the target variable based on the given features. The code includes data loading, data preprocessing, model training, and evaluation.\n\n(2) The overall model architecture is a neural network with multiple hidden layers. The input layer has the same dimensionality as the number of features. The hidden layers have a specified number of units, and the output layer has a single unit. The activation function used in the hidden layers is LeakyReLU. The model is trained using the Adam optimizer and the mean squared error loss function.\n\n(3) The important hyperparameters in this code are:\n- input_dim: the dimensionality of the input data\n- additional_layers: the number of additional hidden layers between the input/output and encoding layers\n- hidden_dim: the dimensionality of the hidden layer\n- learning_rate: the learning rate for the optimizer\n- num_epochs: the number of training epochs\n- batch_size: the batch size for training\n\n(4) The optimization objective is to minimize the mean squared error loss between the predicted values and the target values.\n\n(5) The advanced machine learning technique used in this code is the use of a neural network model for regression.\n\n(6) Some important tricks that play a role in high performance include:\n- Data preprocessing: The code includes a proteinPrep class that preprocesses the protein data, including imputing missing values and scaling the data using MinMaxScaler.\n- Model architecture: The neural network model used in the code has multiple hidden layers, which allows for more complex representations of the data.\n- Training process: The code uses the Adam optimizer and the mean squared error loss function, which are commonly used for training neural networks. The code also includes a learning rate scheduler to adjust the learning rate during training.", "title": null, "competition_name": null, "task_category": "Regression", "field": "Modeling", "ranking": null, "score": null}, {"content": "High-ranking Kaggle notebooks or competition strategies: (1) The overall design of the code is to train a model for a Kaggle competition on sales forecasting. It preprocesses the sales and calendar data, creates a dataset, defines the model architecture, trains the model, and makes predictions.\n\n(2) The overall model architecture consists of an embedding layer for categorical features, followed by three GRU layers with dropout regularization. The model takes in multiple inputs including categorical features (such as snap_CA, snap_TX, etc.) and numerical features (such as lagged sales values). The categorical features are embedded into lower-dimensional representations, and all the features are concatenated and fed into the GRU layers. The output of the model is a dense layer with 9 units, representing the predicted quantiles of the sales.\n\n(3) The important hyperparameters in this code are:\n- CATEGORIZE: A boolean variable indicating whether to categorize the categorical features or not.\n- START: An integer indicating the starting day of the sales data to consider.\n- UPPER: An integer indicating the upper limit of the days to consider in the sales data.\n- LAGS: A list of integers indicating the lag values to use for creating lagged features.\n- seq_len: An integer indicating the sequence length of the input data.\n- batch_size: An integer indicating the batch size for training the model.\n- patience: An integer indicating the number of epochs with no improvement after which training will be stopped.\n- min_lr: A float indicating the lower bound of the learning rate during training.\n\n(4) The optimization objective is to minimize the weighted quantile loss (wqloss) function. This loss function calculates the pinball loss for multiple quantiles and weights the losses based on the actual sales values.\n\n(5) The advanced machine learning technique used in this code is the use of a recurrent neural network (RNN) architecture, specifically the GRU (Gated Recurrent Unit) layers. The GRU layers allow the model to capture temporal dependencies in the sales data and make predictions based on the historical sales values.\n\n(6) Some important tricks that play a role in high performance include:\n- Categorizing the categorical features: This reduces the dimensionality of the categorical features and allows the model to learn more efficiently.\n- Lagged features: Creating lagged features helps the model capture the temporal patterns in the sales data.\n- Dropout regularization: Adding dropout regularization to the GRU layers helps prevent overfitting and improves generalization.\n- Embedding layers: Using embedding layers for categorical features helps the model learn meaningful representations of the categorical variables.\n- Weighted quantile loss: Using a weighted quantile loss function allows the model to focus more on accurately predicting the sales values at specific quantiles, which is important for sales forecasting.", "title": null, "competition_name": "Kaggle competition on sales forecasting", "task_category": "Regression", "field": "Modeling", "ranking": null, "score": null}, {"content": "High-ranking Kaggle notebooks or competition strategies: (1) The overall design of the code is to train a high-performing model for a Kaggle competition on Parkinson's freezing gait prediction. It uses various machine learning techniques and signal processing methods to preprocess the data and build a convolutional neural network (CNN) model for prediction.\n\n(2) The overall model architecture is a CNN model with three parallel convolutional branches. Each branch takes a different kernel size (4, 8, and 16) and applies convolutional layers with batch normalization and ReLU activation. The outputs of the three branches are concatenated and flattened, followed by a dropout layer and a dense layer with sigmoid activation. The input to the model is a 3D tensor of shape (window_size, n_features), where window_size is the size of the input window and n_features is the number of input features.\n\n(3) The important hyperparameters in this code are:\n- `cfg.train_sub_dirs`: A list of directories containing the training data.\n- `cfg.metadata_paths`: A list of paths to metadata files.\n- `cfg.splits`: The number of splits for cross-validation.\n- `cfg.batch_size`: The batch size for training.\n- `cfg.defog_window_size`: The size of the input window for the \"defog\" module.\n- `cfg.defog_window_future`: The number of future steps to predict for the \"defog\" module.\n- `cfg.defog_window_past`: The number of past steps to consider for the \"defog\" module.\n- `cfg.tdcsfog_window_size`: The size of the input window for the \"tdcsfog\" module.\n- `cfg.tdcsfog_window_future`: The number of future steps to predict for the \"tdcsfog\" module.\n- `cfg.tdcsfog_window_past`: The number of past steps to consider for the \"tdcsfog\" module.\n- `cfg.wx`: The downsampling factor for the input data.\n- `cfg.model_dropout`: The dropout rate for the model.\n- `cfg.model_hidden`: The number of hidden units in the convolutional layers.\n- `cfg.model_nblocks`: The number of convolutional blocks in the model.\n- `cfg.lr`: The learning rate for the optimizer.\n- `cfg.num_epochs`: The number of training epochs.\n- `cfg.feature_list`: A list of feature names used for training.\n- `cfg.label_list`: A list of label names used for training.\n- `cfg.n_features`: The number of input features.\n- `cfg.n_labels`: The number of output labels.\n\n(4) The optimization objective is to minimize the binary cross-entropy loss between the predicted labels and the true labels.\n\n(5) The advanced machine learning technique used in this code is the convolutional neural network (CNN) model. CNNs are well-suited for analyzing sequential data such as time series, and they can capture local patterns and dependencies in the data.\n\n(6) Some important tricks that play a role in high performance include:\n- Wavelet denoising: The code applies wavelet denoising techniques to preprocess the input signals and remove noise.\n- Standardization: The code standardizes the input signals by subtracting the mean and dividing by the standard deviation.\n- Downsampling: The code downsamples the input signals by a factor of `cfg.wx` to reduce the computational complexity.\n- Regularization: The code applies L2 regularization to the convolutional layers to prevent overfitting.\n- Batch normalization: The code applies batch normalization after each convolutional layer to improve the stability and convergence of the model.\n- Dropout: The code applies dropout regularization to the fully connected layer to prevent overfitting.\n- Sigmoid activation: The code uses sigmoid activation in the output layer to obtain probabilities for each class.\n- Adam optimizer: The code uses the Adam optimizer with a learning rate of `cfg.lr` for training the model.\n- Cross-validation: The code performs cross-validation with `cfg.splits` splits to evaluate the model's performance on different subsets of the data.", "title": null, "competition_name": "Parkinson's freezing gait prediction", "task_category": "Classification", "field": "Modeling", "ranking": null, "score": null}, {"content": "Thanks to the organizer and the Kaggle team for hosting this competition. And thanks to many participants who shared their ideas with notebook or discussion. It's difficult to improve the score until we find the \"magic\". Fortunately, our team make the breakthrough and get 3rd place at the end of the competition. Great thanks to my teammates and their hard work! @xiamaozi11 @renxingkai @decalogue \n\n## Summary\n\nOur team tried to find the additional information about anchor and target in the [public dataset]( shared by the organizer. However, this method has a little benefit because only part of them are matched or those texts are useless.\n\nThe essential part of our solution is adding targets with the same anchor to each data sample. This data processing trick boosts our score from 0.84x to 0.85x on LB by a single model.\n\nWe stack 12 different models in the final submission. DeBERTa V3 large with MSE loss gives the best single model score on both CV and LB.\n\n\n## Validation strategy\n\nBoth `StratifiedGroupKFold` and  `GroupKFold` can prevent data with the same anchor from leaking to validation set. `GroupKFold` can keep the same training data size of each fold, while `StratifiedGroupKFold` can keep the distribution of the label. Both of them are used (by different team member) and get relatively strong correlation between CV and LB.\n\n\n## Data processing\n\nInput data from baseline\n```\nanchor [SEP] target [SEP] context text\n```\n\nOur input data\n```\nanchor [SEP] target; target_x1; target_x2; ... traget_xn; [SEP] context text\n```\nwhere target_xi are targets with the same anchor and context code.\n\nIt's easy to get comaprable improvement by hard encoding them while shuffling the sequence can reach higher score.\n\n\n## Model\n\nPretrained model\n- Electra large\n- Bert For Patent\n- DeBERTa V3 large\n- DeBERTa V1\n- DeBERTa V1 xlarge\n\nLoss\n- binary cross entropy loss\n- mean squared error loss\n- pearson correlation loss\n\nThere is no big difference among those loss functions. However, using different loss in training phrases will lead to high diversity when ensembling because the distribution of the prediction looks different from oof.\n\nTricks\n- different learning rate for different layer\n- fgm\n- ema\n\nYou may get around 1k~2k improvement by adding all of those tricks.\n\n## Result\n\nSingle Model\n\n| Model             | CV     | Public Score | Private Score |\n| ----------------- | ------ | ------------ | ------------- |\n| Bert For Patent   | 0.8362 | /            | /             |\n| DeBERTa V3 large  | 0.8516 | 0.8559       | 0.8675        |\n| DeBERTa V1        | 0.8385 | /            | /             |\n| DeBERTa V1 xlarge | 0.8423 | /            | /             |\n| Electra large     | 0.8483 | /            | /             |\n\nEnsemble\n\n12 models with different cross validation strategy, different concatenating methods, different pretrained models and different loss function.\n\n| Model              | CV     | Public Score | Private Score |\n| ------------------ | ------ | ------------ | ------------- |\n| Mean of 12 models  | 0.8674 | 0.8627       | 0.8765        |\n| Stacking 12 models | 0.8683 | 0.8640       | 0.8772        |\n\n## Other ideas\n\nThere are some ideas we think useful but have no time to try\n\n- Pretrained with the cpc text\n- Prompt learning\n- Predict the score of those concatenated targets together", "title": "not available", "competition_name": "not available", "task_category": "Regression", "field": "Modeling", "ranking": "3rd place", "score": {"single_model_best_cv": "0.8516", "single_model_best_public_score": "0.8559", "single_model_best_private_score": "0.8675", "ensemble_mean_cv": "0.8674", "ensemble_mean_public_score": "0.8627", "ensemble_mean_private_score": "0.8765", "ensemble_stacking_cv": "0.8683", "ensemble_stacking_public_score": "0.8640", "ensemble_stacking_private_score": "0.8772"}}, {"content": "High-ranking Kaggle notebooks or competition strategies: (1) The overall design of this code is to train a high-performing model for a Kaggle competition. It uses an ensemble approach to combine the predictions of multiple models trained on different subsets of the data. The code also includes preprocessing, postprocessing, and evaluation steps.\n\n(2) The overall model architecture is not explicitly mentioned in the code. However, based on the code snippets and comments, it can be inferred that the model architecture used is deberta-v3-large. This architecture is used in an ensemble fashion, where multiple instances of the model are trained on different subsets of the data. The predictions of these models are then combined using weighted averaging.\n\n(3) The important hyperparameters in this code are the batch size (`bs`), the weights assigned to each model in the ensemble (`WEIGHTS`), and the model directories (`model_dir`) for each model in the ensemble. The batch size is set to 128. The weights assigned to each model in the ensemble are specified in the `WEIGHTS` list. The model directories are obtained from the `MODEL` and `INDEXES_LIST` variables.\n\n(4) The optimization objective is not explicitly mentioned in the code. However, based on the comments and code snippets, it can be inferred that the objective is to minimize the difference between the predicted and actual values of the target variable. This is achieved through training the models on the training data and adjusting the model parameters to minimize the loss function.\n\n(5) The advanced machine learning technique used in this code is ensemble learning. Multiple instances of the deberta-v3-large model are trained on different subsets of the data, and their predictions are combined using weighted averaging. This ensemble approach helps to improve the overall performance of the model by reducing overfitting and capturing different aspects of the data.\n\n(6) Some important tricks that play a role in achieving high performance in this code include:\n- Preprocessing: The code includes preprocessing steps to prepare the data for training. This may include tokenization, normalization, and other data transformations.\n- Postprocessing: The code includes postprocessing steps to normalize the predictions and prepare them for evaluation and submission.\n- Weighted Averaging: The code uses weighted averaging to combine the predictions of multiple models in the ensemble. This allows the models with higher performance to have a greater influence on the final predictions.\n- Model Selection: The code includes a mechanism to select the models to include in the ensemble. This allows for experimentation and optimization of the ensemble composition.\n- Evaluation: The code includes evaluation steps to assess the performance of the model on the validation data. This helps in monitoring the model's progress and making adjustments if necessary.", "title": null, "competition_name": "Kaggle competition", "task_category": "Classification", "field": "Modeling", "ranking": null, "score": null}, {"content": "High-ranking Kaggle notebooks or competition strategies: (1) Please give a summary of the overall design. The overall design of the code is to perform inference on a test dataset using multiple pre-trained models. The code first loads the test dataset and the pre-trained models. Then, it performs inference using each model and saves the predictions. Finally, it performs stacking using the predictions from the different models to generate the final predictions. (2) What is the overall model architecture? Please use a long article to answer this question as accurately and in detail as possible. The overall model architecture consists of multiple pre-trained models, including DebertaV2, DebertaV3, and CatBoost. Each model is used to perform token classification for the task of discourse effectiveness prediction. The models take as input the tokenized text and output the predicted probabilities for each class (Ineffective, Adequate, Effective). The models use various techniques such as residual LSTM, sliding window approach, and multi-task learning to improve performance. The models are trained using cross-entropy loss and are evaluated using log loss. (3) How are the important hyper-parameters setting in this code? The important hyper-parameters in this code are set based on the pre-trained models used. For example, the model architecture (DebertaV2, DebertaV3, CatBoost) is specified by the \"model\" parameter. The number of labels (3) is specified by the \"num_labels\" parameter. Other hyper-parameters such as the window size, inner length, and edge length are also specified based on the specific model architecture. (4) What is the optimization objective? The optimization objective is to minimize the log loss between the predicted probabilities and the true labels. This is achieved by training the models using cross-entropy loss and evaluating the models using log loss. (5) What advanced machine learning technique does this copy of code use? This copy of code uses several advanced machine learning techniques, including pre-trained models (DebertaV2, DebertaV3, CatBoost), residual LSTM, sliding window approach, multi-task learning, and stacking. These techniques are used to improve the performance of the models and generate more accurate predictions. (6) What other important tricks do you think play an important role for high performance? Some other important tricks that play an important role for high performance include feature engineering, such as calculating features based on the token probabilities and using neighbor features. Additionally, stacking is used to combine the predictions from multiple models and improve the overall performance.", "title": "not provided", "competition_name": "not provided", "task_category": "Classification", "field": "Modeling", "ranking": "not provided", "score": "not provided"}, {"content": "# Abstract \nIn this competition, my main model structure is mainly based on prompt learning，Because prompt learning can make more full use of the existing knowledge of the model for reasoning and has obvious advantages in few shot learning, and I used prompt learning to get the first place in the SEMEVAL 2022 PCL Detection.I first reformulate the task as a specific form of cloze prompt, and then apply prompt-based learning on it to predict the confidence of label words.\n\n# Method\n\n### prompt learning\n![](\nIn order to enable the model to directly output the similarity between anchor and target, I improved the model of the pet paper. I manually set YES as the label words of 1, and then took out the logits of the model in this word as input, and used bce loss to calculate ,make logits of YES  equal to the similarity.\n\nIn the experiment, we found that the effect of the prompt model was 0.005 better than that of the regular model\n\n| method | cv | lb |\n| :------| ------: | :------: |\n| attention_pool | 0.8485| 0.8535 |\n| prompt |  0.8535| 0.8570|\n\n### Trick \n\nThrough eda, I found that there are very similar transformations between all the target parts under the same anchor. At the same time, I found that the same anchor was grouped and the target-related features were sorted in the use of lgb to construct features, which improved a lot. , so I decided to construct the input for teammate_info\n\nteamte_info = \";\".join(set(train.group(['anchor'])['target'].tolist())\n\ncontext = anchor+[SEP]+target+[SEP]+teamate_info\n\n### Summarize\nIn the last few days of the competition I was busy with something more important than the competition and lost a lot of time for the final sprint, but thank god I still finished the gold medal in solo and became a kaggle GM, thank you all.", "title": null, "competition_name": "SEMEVAL 2022 PCL Detection", "task_category": "Classification", "field": "Modeling", "ranking": "first place", "score": {"cv": {"attention_pool": 0.8485, "prompt": 0.8535}, "lb": {"attention_pool": 0.8535, "prompt": 0.857}}}, {"content": "High-ranking Kaggle notebooks or competition strategies: (1) The overall design of the code is to blend the predictions from multiple models for a Kaggle competition. It loads the necessary libraries and dependencies, sets the hyperparameters and configurations, reads the training data, and then proceeds to load the trained models and make predictions. Finally, it blends the predictions from different models and generates the submission file.\n\n(2) The overall model architecture is not explicitly mentioned in the code. However, based on the code snippets, it can be inferred that the models used are based on various architectures such as DeBERTa, BART, and BigBird. These models are loaded using their respective configurations and pretrained weights. The models are then used to make predictions on the test data.\n\n(3) The important hyperparameters in this code are:\n- FOLD: The fold number used for cross-validation.\n- cache_allowed: A boolean variable indicating whether to use cached predictions or run inference.\n- THRESHOLD: A boolean variable indicating whether to apply a threshold to the predictions.\n- nposn: The maximum number of positions in the predictions.\n- NMODELS: The number of models used for blending.\n- map_clip: A dictionary specifying the maximum length for each discourse type.\n- load_configs: A list of configuration names for the models to be loaded.\n- model_weights: A list of weights for each model used in blending.\n- start_threshold: The threshold value for the start predictions.\n- position_proba_threshold: The threshold value for the position predictions.\n\n(4) The optimization objective is not explicitly mentioned in the code. However, based on the code snippets, it can be inferred that the objective is to optimize the predictions for discourse type classification and position prediction.\n\n(5) The code uses a blending technique to combine the predictions from multiple models. It calculates weighted averages of the predictions from each model based on the specified model weights. The blending is performed separately for the discourse type predictions and the position predictions.\n\n(6) Some important tricks that play a role in high performance include:\n- Caching: The code allows for caching of predictions to avoid re-running inference if the cached predictions already exist.\n- Thresholding: The code applies thresholding to the predictions to filter out low-confidence predictions.\n- Position Embeddings: The code regenerates position embeddings for certain models to handle extended labels.\n- Linking Classes: The code performs post-processing to link certain classes together based on specific criteria, such as minimum gap, minimum span distance, and minimum length.\n\nOverall, the code demonstrates a comprehensive approach to blending predictions from multiple models and includes various techniques and tricks to improve performance.", "title": null, "competition_name": null, "task_category": "Classification", "field": "Modeling", "ranking": null, "score": null}, {"content": "The overall design of the code is to train a text classification model using the Longformer architecture and evaluate its performance on a test dataset. The code includes functions for data preprocessing, model training, and evaluation.\n\nThe overall model architecture is a Longformer model followed by a linear layer for classification. The Longformer model is a transformer-based model that can handle long-range dependencies in text data. It uses self-attention mechanisms to capture the relationships between words in a text sequence. The linear layer takes the output of the Longformer model and maps it to the number of classes in the classification task.\n\nThe important hyperparameters in this code include the learning rate, batch size, number of training steps, and the maximum length of input sequences. These hyperparameters can be set in the command line arguments when running the code.\n\nThe optimization objective is to minimize the cross-entropy loss between the predicted labels and the ground truth labels. The loss is computed using the softmax function applied to the output of the linear layer.\n\nThe code uses the Longformer architecture, which is an advanced machine learning technique for handling long-range dependencies in text data. The Longformer model uses self-attention mechanisms to capture the relationships between words in a text sequence, allowing it to handle long sequences more efficiently than traditional transformer models.\n\nSome important tricks that play a role in high performance include data augmentation, such as adding noise to the input data, and using advanced optimization techniques, such as the Cosine Annealing Warmup Restarts scheduler and the Early Stopping technique. These tricks help improve the model's generalization ability and prevent overfitting.", "title": "", "competition_name": "", "task_category": "Classification", "field": "Modeling", "ranking": "", "score": ""}, {"content": "High-ranking Kaggle notebooks or competition strategies: (1) The overall design of the code is to make predictions on a given test dataset using multiple pre-trained models. The code loads the test dataset, tokenizes the text using different tokenizers, and then feeds the tokenized input to each model to obtain predictions. The predictions from each model are then combined using an ensemble approach to generate the final predictions.\n\n(2) The overall model architecture used in this code is based on transformer models. The code utilizes different pre-trained transformer models such as Longformer, Funnel Transformers, and DeBERTa. These models are loaded using the AutoModel class from the transformers library. The input text is tokenized using the corresponding tokenizer for each model. The tokenized input is then passed through the transformer model, and the output is fed into a linear layer to obtain the final predictions. The models are trained using a multi-label classification objective.\n\n(3) The important hyperparameters in this code are set using the `args` classes. Each `args` class represents a different model configuration and contains hyperparameters such as the input path, model path, batch size, maximum sequence length, and the folds to use for training. The hyperparameters are set based on the specific requirements of the competition and the performance of the models.\n\n(4) The optimization objective of this code is to minimize the multi-label classification loss. The models are trained using a cross-entropy loss function, which measures the dissimilarity between the predicted probabilities and the true labels. The objective is to maximize the probability of the correct labels and minimize the probability of incorrect labels.\n\n(5) The advanced machine learning technique used in this code is ensemble learning. The code combines the predictions from multiple models using a weighted average approach. Each model is assigned a weight based on its performance, and the final predictions are obtained by averaging the predictions from each model. This technique helps to improve the overall performance and robustness of the predictions.\n\n(6) Some important tricks that play a role in achieving high performance in this code include:\n- Data preprocessing: The code preprocesses the input text by removing inappropriate words and punctuation, and tokenizes the text using different tokenizers. This helps to improve the quality of the input data and ensure compatibility with the transformer models.\n- Model selection: The code utilizes multiple pre-trained transformer models with different architectures and sizes. This allows for a diverse set of models to capture different aspects of the data and improve the overall performance.\n- Ensemble learning: The code combines the predictions from multiple models using a weighted average approach. This helps to reduce the impact of individual model biases and improve the overall accuracy and robustness of the predictions.\n- Hyperparameter tuning: The code sets the hyperparameters based on the specific requirements of the competition and the performance of the models. The hyperparameters are tuned to optimize the performance of the models and achieve high accuracy on the test dataset.", "title": null, "competition_name": null, "task_category": "Classification", "field": "Modeling", "ranking": null, "score": null}, {"content": "Thanks a lot to the host and Kaggle for this interesting competition and congrats to the winners. Our solution is a great collaborative effort. Thank you @crodoc @thedrcat @ivanaerlic @tascj0 for teaming up. # Summary Our solution is an ensemble of several transformer based models, which take a full essay (including special tokens) or a concatenation of all discourse_text in the essay as input. Key points of our solution are a powerful MLM pre-training and soft pseudo labeling on previous competition data. Our MLM pipeline always forced special tokens to be masked and predicted which was important to detect span boundaries. # Cross-Validation For cross-validation we used MultilabelStratifiedKFold on discourse effectiveness and topic clusters to make efficient split on essays. These folds were really stable and CV to LB correlation was great. Most of our blending submissions have the same private and public lb score. # Modeling Overall, we followed the token classification approach. Our main modeling approach has input has follow: [CLS] [cls_lead]  Hi, i'm Isaac, i'm going to be writing about how this face on Mars is a natural landform or if there is life on Mars that made it. The story is about how NASA took a picture of Mars and a face was seen on the planet. NASA doesn't know if the landform was created by life on Mars, or if it is just a natural landform. [end_lead]   [cls_position]  On my perspective, I think that the face is a natural landform because I dont think that there is any life on Mars. In these next few paragraphs, I'll be talking about how I think that is is a natural landform [end_position].....[SEP] We feed this sample to the backbone and take cls embeddings or mean pooling between cls and end tokens for each discourse text. cls embeddings works better than mean pooling for us. **Model Backbones** - DeBERTa-Large - DeBERTa-XLarge - DeBERTa-V3-Large # What works - Pre-Training MLM - Soft pseudo labeling - Adversarial Weight Perturbation ( AWP) - Stochastic Weight Averaging (SWA) - Removing Dropout - Random mask augmentation (token dropout) # Efficiency solution Our best single model scored 0.562 with 8 min inference time. This single model finished 2nd place in the efficiency track and would make a gold medal score in the accuracy track. Unfortunately this model was not included in any blend of the final submission for accuracy. Please refer to [this]( post to read about our efficiency solution.", "title": "Not provided", "competition_name": "Not provided", "task_category": "Classification", "field": "Modeling", "ranking": "2nd place in the efficiency track", "score": "0.562"}, {"content": "High-ranking Kaggle notebooks or competition strategies: (1) The overall design of the code is to train a high-performing model for a Kaggle competition. It includes importing necessary libraries, setting up the environment, defining classes and functions, loading the test data, creating a dataset and dataloader, defining the model architecture, loading the trained model weights, making predictions, and generating the submission file.\n\n(2) The overall model architecture is a SlidingWindowTransformerModel. It consists of a backbone model (e.g., DeBERTa) for encoding the input text, followed by a ResidualLSTM layer for further processing the hidden states. The backbone model is loaded from a pre-trained model checkpoint, and the ResidualLSTM layer is used to capture the contextual information and generate the final hidden states. The model also includes a classification head for predicting the effectiveness of feedback.\n\n(3) The important hyperparameters in this code are:\n- `BATCH_SIZE`: The batch size used during training and inference.\n- `NUM_WORKERS`: The number of worker processes for data loading.\n- `MAX_LEN`: The maximum length of input sequences.\n- `WINDOW_SIZE`: The size of the sliding window used for processing long input sequences.\n- `RNN`: The type of recurrent neural network used in the ResidualLSTM layer (either \"GRU\" or \"LSTM\").\n\n(4) The optimization objective is to minimize the loss function during training. The specific loss function used is not mentioned in the code.\n\n(5) The advanced machine learning technique used in this code is the Sliding Window Transformer. It allows the model to process long input sequences by dividing them into smaller windows and applying the transformer model to each window separately. This technique helps to overcome the limitation of transformer models in handling long sequences.\n\n(6) Some important tricks that play a role in high performance include:\n- Using a pre-trained transformer model as the backbone for encoding the input text.\n- Applying a ResidualLSTM layer to capture contextual information and generate final hidden states.\n- Using a sliding window approach to process long input sequences.\n- Incorporating discourse information into the model by adding discourse embeddings.\n- Using XGBoost models to generate additional features and make predictions.\n- Ensembling multiple models with different hyperparameters and averaging their predictions.\n\nNote: Some parts of the code are commented out or not included in the final version, so their impact on performance is not clear.", "title": "", "competition_name": "", "task_category": "Classification", "field": "Modeling", "ranking": "", "score": ""}, {"content": "High-ranking Kaggle notebooks or competition strategies: (1) The overall design of the code is to make predictions on a test dataset using multiple pre-trained models. The code loads the test dataset, creates a tokenizer, and defines the model architecture. It then loads the trained models, makes predictions on the test dataset using each model, and calculates the average prediction across all models. Finally, it saves the predictions to a CSV file.\n\n(2) The overall model architecture is a combination of pre-trained transformer models and a linear regression layer. The code uses different pre-trained models such as Electra, Deberta, and BERT to extract features from the input text. These models are fine-tuned on a specific task, which is to predict the similarity score between two phrases. The output of the pre-trained models is passed through a linear regression layer to obtain the final prediction.\n\n(3) The important hyperparameters in this code are:\n- exp_id: The experiment ID used to identify the trained models and the output predictions.\n- input_path: The path to the input data files.\n- cpc_path: The path to the pre-processed CPC texts.\n- model_path: The path to the pre-trained transformer models.\n- trained_models: The path to the trained models.\n- drop_folds: A list of fold numbers to skip during training.\n- seed: The random seed for reproducibility.\n- max_len: The maximum length of the input text.\n- num_classes: The number of output classes.\n- num_fold: The number of folds used for cross-validation.\n- batch_size: The batch size for training and inference.\n- device: The device to use for training and inference (CPU or GPU).\n\n(4) The optimization objective is to minimize the mean squared error between the predicted similarity scores and the true similarity scores.\n\n(5) The advanced machine learning technique used in this code is transfer learning. The code utilizes pre-trained transformer models that have been trained on large-scale language modeling tasks. These models are fine-tuned on the specific task of predicting similarity scores between phrases.\n\n(6) Some important tricks that play a role in high performance include:\n- Using multiple pre-trained models and averaging their predictions to reduce overfitting and improve generalization.\n- Using attention mechanisms to capture important information from the input text.\n- Using dropout layers to prevent overfitting and improve model robustness.\n- Using softmax activation and label scaling to convert model outputs into similarity scores.\n- Using a learning rate schedule to adjust the learning rate during training.\n- Using k-fold cross-validation to evaluate the model performance and select the best models.", "title": null, "competition_name": null, "task_category": "Regression", "field": "Modeling", "ranking": null, "score": null}, {"content": "## Some Feelings\n\nI would like to thank the organizers for bringing us the wonderful competition, and thank you for the atmosphere of sharing and discussion. This competition is a practical project required by the natural language processing course. My teammates and I learned in this competition than in the school class. Of course, thanks to the lucky shake, luck is also an important factor.\n\n## What we did in the comp\nOur final submission only used a 4fold microsoft/deberta v3 large. Because each team member's academic pressure and time reasons, we did not plan to study various tricks or training skills from the beginning, but started with the quality and diversity of data.\n\nWHY data? Because we found that the training data provided, only contains four topics, but from our own experience to think, training a student writing ability requires a lot of different topics, so the real test scenario, the model for the understanding of different topics is the most important (subsequent other players through prob test set also proved this), and we found that the LLM game, many people use LLM data increase and obtained the exciting fect, so we focus on improving the diversity of topic.(We continue to focus on other competitions and competitors' experience and progress in using LLM, but we do not see anyone openly revealing whether using LLM is \"USEFUL\", even if they have tried to use the generated data.)\n\n**We sincerely hope that our ideas can provide some feasible ideas for the use of LLM in the FUTURE competitions, and can bring reference value to other participants**\n\n### The key points of our solution:\n\n1. Meta pseudo label (3 rounds), the most critical and time-consuming part, is the key to associating unannotated data with annotated data, from a paper by Google.(\n\n2. Carefully designed prompt to guide LLM to spit out the topic and topic text in his stomach (we can actually use the commonlit website, but we didn't realize that at the moment.)\n\n3. Another prompt used to generate ten summary of different quality for each additional topic.\n\n4. Change the data preprocessing in the open source training code to introduce prompt text into the model, but most other good teams have this key point, which commonly mentioned in discussion.\n\n5. Two stage traning: stage1 - Use pseudo labeled data only for 2epoch and valid on train. stage2 - Use train data only for 2-3 epochs. In this way, we need not to pay too much attention to the data distribution of pseudo-labels, which mentioned by  @philippsinger in his insightful [solution]( of Feedback-ELL.\n\n6. Sort index according to the length of the input text, and reduce the infer time. The whole model of inference is estimated to be 7 hours, but if you do not do so, the inference time will exceed the limit of 9 hours.\n\n7. Traning and inference pipeline[code]( shared by @tsunotsuno ,the perfect process steps save us a lot of time to build pipeline.\n\n## Other words\nWe only used the open source code and did not make any improvement on the model.\nIn these days, we have read the plans of other teams, which impressed us, especially the \"Head Mask\" mentioned by  @ivanaerlic  and his deep understanding and insight into the game itself and the nature of the model structure, which made us admire and hope that one day we can make such excellent model optimization like you.\n\nI believe combine the head mask and llm meta pseudo procedure, the private score might improved to .43+ ONLY BY ONE MODEL.\n\nThanks again to all the participants for your selfless sharing. I hope our working can contribute to the community!!  :)\n\n## Prompt used for LLM generate prompts:\n![](\n## Prompt used for LLM generate summaries:\n![](\n\n## Related source:\n\ninference code: \n\nllm generated data: ", "title": "Some Feelings", "competition_name": "Feedback-ELL", "task_category": "Classification", "field": "Modeling", "ranking": null, "score": null}, {"content": "Congrats all and thank you Georgia State University, Kaggle and all the organizers for hosting such an amazing competition. We were unfortunate to finish just short of a prize in both tracks of the competition, but will take the learnings with us!\n### TL;DR\nOur solution is based on deberta-v3, mlm, pseudo labeling and stacking with LGB. We found the combination of a number of NLP improvements added up to a solid score. \n\n### Pre/Data processing\nThe core of our solution was to combine, in order, all discourse ids, and then start and finish them with discourse typeids and special tokens. \nA cls_position was used as start or end of the discourse. In python, see below, \n```\ninput_ids = []\nessay_df = = trndf.loc[essay_id]\nfor i in range(len(essay_df))\ntext = f'{discourse_types[i]}: {discourse_texts[i]} {self.tokenizer.sep_token} :{discourse_types[i]}'\ni_ids = self.tokenizer.encode(text, add_special_tokens=False)\ninput_ids += i_ids\ncls_pos += [0] * (len(i_ids) - 1) + [1]\n```\n\nAn example of the output can be seen below. \n```\nLead: Computers can do many things for us. The idea that a computer can read your emotions is amazing  [SEP] :Lead Position: I do not belive it is true. I will believe it when I see it.  [SEP] :Position Evidence: In paragraph 8 it says \" But in a false smile, the mouth is stretched sideways ising the zygomatic major and different muscle, the risorius.\" however this may be true for most people; there has to be someone out there in our world of 7 billion that smiles there smiles with their zygomatic muscle or their risorius muscle  [SEP] :Evidence Claim: Everyone has diffrent emotions and everyone shows them diffrently  [SEP] :Claim Counterclaim: The muscles in our face does say a lot about the emotions we are feeling.  [SEP] :Counterclaim Concluding Statement: This is why I believe computures can not read your emotions  [SEP] :Concluding Statement\n```\n\nAuxiliary labels such as ranking (Ineffective -> Adequate -> Effective) and essay topic cluster were also used. \nWe also added the essay text, which was not in annotated discourses to the end, and sometimes positioned in order between discourses. \nReplacing line breaks with special tokens and cleaning text in some models was found to increase diversity significantly in the overall blend. \n\n### Level1 Models\nWe used three different model pipelines, with some smaller changes in data preprocessing, along with different auxiliary labels and model heads. We only used `deberta-v3` as the backbone. Other backbones did not help our blend in CV. \n\n###### Model1, \n- Non discourse essay text moved to the back of input, and text cleaned with line breaks added.  \n- Used auxiliary targets of rank (rmse loss) and essay topic. Lowered auxiliary weight, from 0.4 to 0.01, as model trained. \n- Linear head extracting the first token of each discourse in the input, with categorical crossentropy loss.  \n###### Model2, \n- Non discourse essay text between discourses. No cleaning or line breaks\n- Used auxiliary targets of rank (rmse loss). Weight of auxiliary loss ~0.2. \n- Linear head extracting the last token of each discourse in the input, with categorical crossentropy loss.  \n###### Model3, \n- Non discourse essay text between discourses. No cleaning or line breaks\n- Used auxiliary targets of rank (rmse loss).  Weight of auxiliary loss ~0.2. \n- This was actually two models - one with an rnn head applied to the mean pooling of the tokens belonging to each discourse; and one with an attention head on the same input.\n\nIt is important to remove deberta hidden layer dropout on all models. We also found it helpful to pretrain the weights on the earlier feedback competition essays for around 20 epochs (low lr, large batchsize). \nAll models were trained with 2-3 epochs, with backbone set to lr ~2e-5 and the model head was set to ~1e-4. \n### Level2 Models\nWe created meta pseudo labels on the essays from the first feedback competition (excl. current comp essays). In-fold predictions from all models were used to create an averaged in-fold prediction, which can be used as a leak-free pseudo label.\n\nEach model was then retrained on the hard labels from current competition and the soft pseudo labels. Hard labels from current competition were upweighted in the loss function. \n### Stacking\nAll level2 model predictions were averaged and used in a lightgbm stacking model. This was trained at discourse level, along with meta features from the respective essay, such as word count, sentence count, position in essay-topic and lead & lag features.\n\nNo special postprocessing was applied after that. \n### What did not help\n- Other backbones such as deberta-v1, deberta-v2, t5, facebook-opt, distilled-bloom\n- 2nd or third round pseudo labelling. \n- Training models for a more epochs (this overfit, should have tried AWP)\n- The character decoding/encoding used in the public scripts.\n- Model soup\n- Test time augmentation\n- Token dropout\n- etc. etc.", "title": "Not provided", "competition_name": "Not provided", "task_category": "Classification", "field": "Modeling", "ranking": "Just short of a prize", "score": "Not provided"}, {"content": "My solution is rather simple, because I used almost no complex tricks - instead I just built a reliable pipeline and found good hyperparameters. I had some brilliant ideas (at least I think so :)) - to use augmentation and generate synthetic data using some big model based on other texts from commonlit.org. But at that time, when I was still actively contributing, there was uncertainty with the license for the texts, and I did not complete the use of augmentations - I was too busy with my work (trying to get RLHF to work), so I left the competition - my last commit was a month ago. But apparently the decision was good, at least I didn’t overfit :)\n\nSo let's break my solution down into parts.\n\n**1. Data:**\nI used a fairly standard template: prompt + question + text. At the end of my participation, I tried to dig into the data and do a good pre-processing - after all, there were quite a lot of very similar essays with exact or different scores. So, I tried to find these samples by similarity (like Levenstein) and then merge them. In addition, I decided to make augumentations based on this insight - if there are many similar essays (differing only in typos, for example) - I could use something like reverse autocorrect - randomly replace some words with its close analogues. With this technique I got 0.453 in private ONLY on fold3 (which is better than my chosen blend and probably could lead to a second place) - but I was too tired at this point so I didn't look further into augmentations. But I think augmentations could probably lead me to victory.\n\n**2. Models**\nDeberta is the king, so there's not much to say here. I tried using decoder models like Llama, but Deberta was still better. There were some techniques that gave me a boost - using EMA (honestly, without EMA it was very unstable, so it's probably just necessary) and using differential learning rates.I tried several pooling options, but the best option for me was to use concatenation of CLS token and student's text meanpooling. I also used token_type_ids to separate the prompt, question and essay.\n\n**3 Inference & train**\nI used following scheme - I tried to find a good hyperparameters on some fold (for example, fold0), and then train with exact hyperparameters on other folds. I then sumbittend the entire blend and 4 individual models (5 submission total - one day) and repeated the procedure the next day. I realized that I could use maxlen 1500 for inference (didn't research this number much, tried something like 1024 and 2048, but 1500 was better in terms of efficiency), so in my final mix I took the 10 best checkpoints across folds (some folds got 2 checkpoints, some folds got 3). First I averaged by folds, then averaged the rest. That's all.\n\nBriefly what worked (ranked from most important to least important, IMO):\n1. Using Deberta\n2. EMA\n3. Augumentation\n4. Defferentiated learning rates\n5. Custom pooling\n6. token_type_ids\n7. Data cleaninig\n\nWhat did not work (random order):\n1. Decoder models\n2. AWP\n3. FGM\n4. WD\n5. Constant LR\n6. Handcrafted features\n7. GBT for stacking\n\nIn the end, it was a good competition for me. Last year I competed in another NLP competition and got a silver medal, but I grinded all day at that competition (I wasn't working that time, so I had a lot of free time). This time I also expected silver, which I consider a solid result, but I got 3rd place. In any case, this competition was a cakewalk for me, since I spend very little effort on it (compared to the previous competition, at least). I'm hoping this means I'll grow a lot this year - and I think that's the main goal of participating in Kaggle.\n\nGood luck to all of you.", "title": null, "competition_name": "CommonLit Readability Prize", "task_category": "Regression", "field": "Modeling", "ranking": "3rd place", "score": "0.453"}, {"content": "High-ranking Kaggle notebooks or competition strategies: First of all, much thanks to the competition hosts and Kaggle administrators for holding such an interesting competition! Here is the our 10th solution: **Token classification (NER)** We created 6 deberta-large models and 1 deberta-xlarge model then took weighted average of probability of each token (the weight is according to LB). Points are following: - Various versions of deberta-large models with these modifications: - Tagging of tokens (begin, inside, outside / begin, inside, end, outside / begin, inside, end, begin-of-outside, inside-of-outside, end-of-outside). - Pretrain with MLM (Masked Language Model) method. - Replace tokens with masked tokens randomly when training. - Add LSTM before classification head. - Higher and lower learning rate. - Multi-task learning of ordinary NER and NER focused on specific discourses. Additional loss with higher weight on begin tokens. - Train deberta-xlarge - Deberta-xlarge often failed to converge. To make it converged, we used warm-up scheduler and tried several patterns of learning rate. - Ensemble - We tried various backbones like Bigbird etc., but found ensemble of deberta-large models achieves the highest score. - Especially ensemble of models with different tokenizers lowered score when decomposing tokens to char-level to take weighted average of probability. - Maybe ensemble of models with shared tokenizer is desirable. - Credit - Architectures of models are based on @Abhishek's code. - Experiment results of deberta etc. from @hengck23 were very helpful. - Thanks to @Abhiskek and @hengck23, we could focus on try-and-error instead of spending time on building architectures of models. **Postprocessing with LGBM** Points are following: - First, generate predictionstrings from results of token classification (it's same with public notebooks' \"create_submission\" function). - Second, create a LGBM model that predicts whether generated predictionstrings are TP or not, then outputs the probability of TP. - Features are mainly come from aggregation of probability of token classification results. 75 aggregation features are generated from each material of ensemble (5 types of aggregation (min, max, mean, 20 percentile, 80 percentile) * 15 types of tokens (Beginning, Inside * 7 discourses + Outside)) - Other feats are about 15, length of prediction strings, length of essays etc. - Finally, filter predictionstrings with probability of TP. - Without this postprocessing: Public: 0.716 Private 0.724, With this postprocessing Public: 0.719 Private 0.727 **Other postprocessing** Followed by the filtering written in previous section , these postprocessing methods are applied. - Define the starts of predictionstrings as these patterns: begin token or a token that differs from the previous class (exp. I-Claim, B-Claim <-). - Calculate mean probability (begin + inside) of predictionstrings then filter predictionstrings by it and length of predictionstrings. - If multiple Lead, Position and Concluding Statement are found, keep only one with the highest mean probability. - Apply [link evidence]( on Evidence, Counterclaim and Rebuttal (much thanks to @kaggleqrdl!).", "title": "10th solution", "competition_name": "Not explicitly mentioned", "task_category": "Token Classification (NER)", "field": "Modeling and Postprocessing", "ranking": "10th", "score": {"public": 0.719, "private": 0.727}}, {"content": "High-ranking Kaggle notebooks or competition strategies: (1) The overall design of the code is to load pre-trained models (DEBERTA-V3-LARGE and ELECTRA-LARGE) and use them to make predictions on the test dataset. The code also includes data loading, tokenization, model architecture, and inference functions. (2) The overall model architecture consists of a pre-trained DEBERTA-V3-LARGE model or ELECTRA-LARGE model, followed by a linear regression layer. The input to the model is a concatenation of the anchor phrase, target phrase, anchor-target pairs, and context text. The model uses attention mechanisms to capture the relevant information from the input and predicts a score for each input. (3) The important hyperparameters in this code are: - `batch_size`: The batch size used during training and inference. - `max_len`: The maximum length of the input sequences. - `dropout`: The dropout rate used in the model. - `num_workers`: The number of workers used for data loading. - `seed`: The random seed used for reproducibility. (4) The optimization objective is to minimize the mean squared error (MSE) between the predicted scores and the true scores. (5) The advanced machine learning technique used in this code is transfer learning. The code loads pre-trained DEBERTA-V3-LARGE and ELECTRA-LARGE models and fine-tunes them on the specific task of phrase-to-phrase matching. (6) Some important tricks that play a role in high performance include: - Data shuffling: The anchor-target pairs are randomly shuffled to introduce more diversity in the training data. - Attention mechanisms: The model uses attention mechanisms to focus on relevant parts of the input sequences. - Dropout regularization: The model uses dropout to prevent overfitting and improve generalization. - Ensembling: The code combines predictions from multiple models trained on different folds of the training data to improve performance.", "title": null, "competition_name": null, "task_category": "Regression", "field": "Modeling", "ranking": null, "score": null}, {"content": "Hi kagglers! Congrats to the winners and everyone who enjoyed this competition! I saw many people were tired, and me as well... But I've got my very first solo gold medal 🎖️ and I'm now really happy to become a Kaggle master! To be honest, I participated this competition about 3 weeks ago. Thanks to the community, I can accelerate my experiments and improve the score quickly. If I had more time, maybe I could get more chances... 🤔🤔 I think some tricks and techniques are important in this competition. [The lightgbm postprocessing]( is really cool and I've never thought about that idea. I focused on some technical processing and I managed to get a high score. ## Resolve Encoding Error As you can see, there are some abnormal characters in the documents. Let's see `0D1493FDAAD3`: ``` ... Another reason to talk to multiple people when making a purchase is to learn from their successes. ÃÅf you saw a group of people successfully do what you are trying now, learn what they did to overcome the obstacle. ... ``` There are nonrecognizable characters `ÃÅ` and you may see this frequently in other documents. After some tries, I found this is a problem about `cp1252` and `utf8` encodings, and the below code can clean the documents. ![]( The result is as follows: ``` ... Another reason to talk to multiple people when making a purchase is to learn from their successes. If you saw a group of people successfully do what you are trying now, learn what they did to overcome the obstacle. ... ``` Actually, It doesn't seem to improve the final scores significantly, but I just applied this to make sure. And because it reduces the characters in the documents, we have to adjust the `discourse_start` and `discourse_end` offsets. To correct the offsets, I use `difflib.SequenceMatcher` to compare the differences of the characters. The details are in my code. ## `word_ids` vs `offset_mapping`? Because many NER examples use `word_ids` with `is_split_into_words=True` parameter, I also tried to use this for labeling BIO-named subword tags. However, I got 0.595 public LB with a single-fold bigbird base model. So I tried another way from the community, `offset_mapping` with `return_offsets_mapping=True` parameter to make subword NER tags, and I could get 0.630 public LB score. | model name | public lb score | private lb score | |:--:|:--:|:--:| | bigbird-roberta-base (single fold, `word_ids`) | 0.595 | 0.609 | | bigbird-roberta-base (single fold) | 0.630 | 0.644 | | bigbird-roberta-base (5 folds) | 0.659| 0.677 | Why is this happened? What is the difference between `word_ids` and `offset_mapping` approach? After trying some experiences, I found that `word_ids` needs to split the text into words using `.split()`, and it prunes the line-break information `\n`. Since this task is for recognizing the structure of the document, **it would be necessary to use the line-break characters.** Remember this because I will mention this fact in the later section. ## Beam-Search Decoding BIO-naming rule is quite complex, so the greedy decoding (i.e. argmax from the token predictions) cannot perform well. I observed many cases like: | sorted candidate tags | sorted corresponding probs | |:--:|:--:| | `B-Claim` ... | 1.0 ... | | `I-Claim` ... | 0.99  ... | | `I-Claim` ... | 0.99 ... | | `I-Claim` `B-Evidence` ... | 0.49 0.43 ... | | `I-Evidence` `I-Claim` ... | 0.99 0.01 ... | | `I-Evidence` `I-Claim` ... | 0.99 0.01 ... | According to the greedy decoding, the prediction result would be `B-Claim I-Claim I-Claim I-Claim I-Evidence I-Evidence`. The entities should be started with B-tags, so the Evidence entity will be dropped even it has high confidence. Therefore I implement beam search decoding algorithm for NER tagging: ![]( I wrote this code on PyTorch and GPU-capable for parallelization. I use `beam_size=4` for all both evaluation and prediction. ## Entity-Level Post-Ensemble The above multi-fold predictions are from averaged token probabilities. However, if the architectures are different and the subword tokenizers are different as well, it is impossible to combine the subword token predictions (probabilities). Some people tried to ensemble with character-level probabilities, but it did not work for me. Hence I created entity-level post ensemble algorithm. The main idea is from the metric of this competition. This compeition treats more than 50% matched entities as the same group. So I group at least 50% overlapped entities which have same class. After that, I average the ranges in each group. I tested the longest, shortest, union and intersection ways, but they were all worse than the average method. ![]( It indeed showed significant improvements by ensembling several models! It can be even applied to the folds (I mean, it is useful for the same tokenizer and same subwords as well) and I can get about +0.002 lb score. | model name | cv | public lb score | private lb score | |:--:|:--:|:--:|:--:| | deberta-large (5folds) | 0.6938 | 0.705 | 0.713 | | deberta-large (5folds, entity-level ensemble) | 0.6938 | 0.707 | 0.714 | | deberta-large + deberta-xlarge | 0.718 | 0.712 | 0.722 | | deberta-v3-large-v2 + deberta-v2-xlarge-v2 | 0.7251 | 0.719 | 0.731 | ## `DebertaV2TokenizerFast`? Unfortunately, deberta-v2 does not have fast-version of its tokenizer. The slow-version does not support `offset_mapping`, so we need the fast one. Fortunately, [the code]( is already written and I could train deberta-v2 and deberta-v3 without tokenization errors. But the problem was the performance of models. CV scores were around ~0.68, even worse than longformers. After some experiments, I observed that **the deberta-v2 tokenizer removes line-break `\n` characters.** As I mentioned above, including `\n` characters is necessary, so I changed the code as below: ![]( Finally I can get the correct scores from deberta-v2 and deberta-v3 models. | model name | cv | public lb score | private lb score| |:--:|:--:|:--:|:--:| | deberta-v2-xlarge | 0.7019 | 0.705 | 0.714 | | deberta-v3-large | 0.7038 | 0.707 | 0.719 | I also tried larger models (e.g. deberta-v2-xxlarge) but they are all worse than the above models. Thus I only used up to deberta-xlarge scale. ## Hyperparameters I know many people used small batch size like 2 or 4, but I use 8 to activate tensor-cores on A100 😁 I had to train the model faster because I had no time. All models are trained for 5k/7k steps with 500/700 warmup steps. The learning rate is basically 3e-5, but depends on the scale. The detailed configurations are in my code as well. The learning rate is decayed linearly. I applied gradient clipping with `1.0` and gradient checkpointing to reduce the memory usage. AdamW optimizer is used, and I evaluate 20 times per epoch to save the best-scored model. Note that I use exactly same evaluation metric (overlap-based f1 score) to avoid the score mismatch from validation to lb score. ## Conclusion I tried many combinations of the models to submit because there is a time limit. The belows are my last three submissions🥲 ![]( And these are my final selections: ![]( | model name | public lb score | private lb score | |:--:|:--:|:--:| deberta-v3-large (10 folds) + deberta-xlarge (3/5) + deberta-v2-xlarge (4/5) | 0.721 | 0.735 deberta-large + deberta-v3-large + deberta-v3-large + deberta-xlarge (3/5) + deberta-v2-xlarge (3/5) | 0.724 | 0.735 Since deberta-xlarge and deberta-v2-xlarge are too heavy to run all, I only use some of them.", "title": "Not available", "competition_name": "Not available", "task_category": "Classification", "field": "Modeling", "ranking": "Gold medal", "score": {"public_lb_score": "0.724", "private_lb_score": "0.735"}}, {"content": "High-ranking Kaggle notebooks or competition strategies: (1) The overall design of the code is to train multiple models using different pre-trained transformer models and then use the trained models to make predictions on the test data. The predictions from each model are then combined using weighted averaging to generate the final submission.\n\n(2) The overall model architecture involves using pre-trained transformer models for text classification. The code uses different pre-trained transformer models such as \"microsoft/deberta-v2-xlarge\", \"microsoft/deberta-xlarge\", \"microsoft/deberta-large\", and \"microsoft/deberta-v3-large\". Each model is trained separately and used to make predictions on the test data. The predictions from each model are then combined using weighted averaging to generate the final submission.\n\n(3) The important hyperparameters in this code are:\n- `use_mixup`: A boolean parameter indicating whether to use mixup augmentation during training.\n- `forward_type`: A string parameter indicating the type of forward pass to use during training.\n- `use_token_types`: A boolean parameter indicating whether to use token types during training.\n- `use_layer_norm`: A boolean parameter indicating whether to use layer normalization during training.\n- `batch_size`: The batch size used during training.\n- `maxlen`: The maximum length of the input sequences.\n- `num_workers`: The number of workers used for data loading during training.\n- `weight`: The weight assigned to each model during the weighted averaging of predictions.\n- `config_path`: The path to the configuration file for the pre-trained transformer model.\n- `tokenizer_path`: The path to the tokenizer used for tokenizing the input sequences.\n- `is_pickle`: A boolean parameter indicating whether to use pickle for saving/loading data.\n- `device`: The device (CPU or GPU) used for training.\n- `model_paths`: The paths to the saved model checkpoints for each fold.\n- `oof_name`: The name of the out-of-fold (oof) predictions file.\n- `dataset_module`: The module containing the dataset-related functions.\n- `inference_module`: The module containing the inference-related functions.\n\n(4) The optimization objective is to minimize the loss function during training. The specific loss function used is not mentioned in the code.\n\n(5) The advanced machine learning technique used in this code is the use of pre-trained transformer models for text classification. These models have been trained on large amounts of text data and can be fine-tuned on specific tasks such as the Kaggle competition in this case.\n\n(6) Some important tricks that play a role in high performance include:\n- Using mixup augmentation during training to improve generalization.\n- Using different pre-trained transformer models and combining their predictions using weighted averaging to leverage the strengths of each model.\n- Using layer normalization to improve the stability and convergence of the training process.\n- Using a large batch size and maximum sequence length to capture more information from the input sequences.\n- Using multiple workers for data loading to speed up the training process.\n- Using pickle for saving/loading data to improve efficiency.\n- Using GPU acceleration if available to speed up the training process.\n- Using out-of-fold (oof) predictions to evaluate the performance of the models during training.", "title": "", "competition_name": "", "task_category": "Classification", "field": "Modeling", "ranking": "", "score": ""}, {"content": "High-ranking Kaggle notebooks or competition strategies: (1) The overall design of the code is to make predictions on a test dataset using multiple pre-trained models. The code imports the necessary libraries, sets the directory paths, defines the configuration parameters, and loads the test dataset. It then defines the necessary functions and classes for data loading, model architecture, and inference. Finally, it loads the pre-trained models, makes predictions using each model, and combines the predictions to generate the final submission file. (2) The overall model architecture consists of multiple pre-trained models, including Deberta v3 large, BERT for Patents, Deberta large, and XLM-RoBERTa large. Each model is loaded with its respective tokenizer and configuration. The models are then used to extract features from the input text using attention mechanisms. The extracted features are passed through fully connected layers to obtain the final predictions. The models are trained using a combination of cross-entropy and mean squared error loss functions. (3) The important hyperparameters in this code are: - `num_workers`: Number of workers for data loading. - `batch_size`: Batch size for training and inference. - `fc_dropout`: Dropout rate for the fully connected layers. - `seed`: Random seed for reproducibility. - `n_fold`: Number of folds for cross-validation. - `trn_fold`: List of fold indices to use for training. (4) The optimization objective is to minimize the mean squared error (MSE) loss between the predicted scores and the ground truth scores. (5) The advanced machine learning technique used in this code is transfer learning. The code utilizes pre-trained models that have been trained on large-scale datasets to extract features from the input text. These features are then used to make predictions on the test dataset. (6) Some important tricks that play a role in high performance include: - Using multiple pre-trained models and combining their predictions to improve the overall performance. - Using attention mechanisms to extract relevant features from the input text. - Using a combination of cross-entropy and mean squared error loss functions to train the models. - Applying post-processing techniques to adjust the predicted scores and improve the final results.", "title": "Not available", "competition_name": "Not available", "task_category": "Regression", "field": "Modeling", "ranking": "Not available", "score": "Not available"}, {"content": "The overall design of this code is to train multiple models and ensemble their predictions to generate a final submission for a Kaggle competition. The code first installs a required package and copies several Python files and pre-trained models from the input directory. Then, it trains multiple models using different Python scripts and pre-trained models. Finally, it combines the predictions from these models and generates a submission file.\n\nThe overall model architecture is not explicitly mentioned in the code. However, based on the Python scripts that are being executed, it can be inferred that the models used in this code are based on deep learning architectures. The specific architectures used in each script are as follows:\n\n- `expkuro431fs_maxlen1500wopp.py`: This script uses a deep learning model with a custom architecture designed by the author. The architecture includes a combination of convolutional layers, recurrent layers, and fully connected layers. It also incorporates feature selection and word preprocessing techniques.\n\n- `exp147wopp.py`: This script uses a deep learning model based on the Transformer architecture. It utilizes the Hugging Face library to load a pre-trained Transformer model and fine-tunes it on the task at hand.\n\n- `exp224fs_maxlen1500wopp.py`: This script uses a deep learning model with a custom architecture similar to the one used in `expkuro431fs_maxlen1500wopp.py`. It also includes feature selection and word preprocessing techniques.\n\n- `exp276wopp.py`: This script uses a deep learning model with a custom architecture similar to the one used in `expkuro431fs_maxlen1500wopp.py`. It also includes feature selection and word preprocessing techniques.\n\n- `exp176wopp.py`: This script uses a deep learning model with a custom architecture similar to the one used in `expkuro431fs_maxlen1500wopp.py`. It also includes feature selection and word preprocessing techniques.\n\n- `expkuro259wopp.py`: This script uses a deep learning model with a custom architecture similar to the one used in `expkuro431fs_maxlen1500wopp.py`. It also includes feature selection and word preprocessing techniques.\n\n- `exp147fs_new331wopp.py`: This script uses a deep learning model based on the Transformer architecture. It utilizes the Hugging Face library to load a pre-trained Transformer model and fine-tunes it on the task at hand. It also includes feature selection and word preprocessing techniques.\n\nThe important hyperparameters in this code are set within each individual Python script. Unfortunately, the specific values of these hyperparameters are not mentioned in the code provided. To reproduce this code, one would need to refer to the original Python scripts (`expkuro431fs_maxlen1500wopp.py`, `exp147wopp.py`, etc.) and examine the hyperparameter settings within those scripts.\n\nThe optimization objective of this code is to minimize the loss function during the training process. The specific loss function used in each model is defined within the corresponding Python script. Again, the exact loss functions used in this code are not mentioned in the provided code snippet.\n\nThe advanced machine learning technique used in this code is ensemble learning. The code trains multiple models with different architectures and combines their predictions to generate a final submission. This ensemble approach helps to improve the overall performance and robustness of the model.\n\nSome important tricks that may play a role in achieving high performance in this code include:\n- Feature selection: The code includes feature selection techniques to select the most relevant features for the task at hand. This helps to reduce noise and improve the model's ability to generalize.\n- Word preprocessing: The code includes word preprocessing techniques to clean and normalize the text data. This can help to improve the model's ability to understand and extract meaningful information from the text.\n- Pre-trained models: The code utilizes pre-trained models in some of the scripts. These pre-trained models have been trained on large-scale datasets and can capture rich representations of the input data. Fine-tuning these models on the specific task at hand can help to leverage the knowledge learned from the pre-training phase and improve performance.\n- Ensemble learning: The code combines the predictions from multiple models using ensemble techniques. This helps to reduce the impact of individual model biases and errors, leading to more accurate and robust predictions.\n- Debugging: The code includes an option to enable debugging mode (`--debug True`). This can be useful for identifying and fixing any issues or errors during the training process.", "title": null, "competition_name": null, "task_category": "Classification", "field": "Modeling", "ranking": null, "score": null}, {"content": "First of all, I would like to thank competition organizers for hosting this interesting competition. And thanks to my great teammate [@Tifo]( , we discuss and work hard for the whole last month to explore new methods. And also thank to the community of great notebooks and discussions.\n\n## **Where is magic**\n\nThe key is that there exits strong correlations between different targets under the same anchor.  (you can see from the gap between groupkfold and kfold) For example, some targets are similar to the origin target and some are similar to the anchor. In short, adding them to the context can more effectively capture the correlation between the anchor and the target.\n\nWe used various methods to take advantage of this magic:\n\n#### stage1\n\n1. Group the targets from the same `anchor`, such as 'target1, target2, target3, ...'. Then add them to the context.\n2. Group the targets from the same `anchor` and `context`. This brings more relevant targets.\n3. Group the targets from the same `anchor`.  Group the anchors from the same `context`. Add them to the context in turn.\n\n#### stage2\n\n1. Group the targets from the same `anchor` and add oof score to describe more specific quantitative information, like 'target1 23, target2 47, ...'. The scores are multplied by 100 so can be recognized as a token.\n\n2. Group the targets from the same `anchor` and `context`, with score.\n\n#### details\n\n- During training, the group is performed inside the train-set, and the score is derived from the oof score from the first-stage models.\n- During inference, the group is performed after concatenating train-set and test-set, and the score is derived from both the oof and the prediction of test-set from first-stage models. (Why concat? Because overlap anchors in train and test.)\n\n## **Things that worked**\n\n- FGM\n\n-  [Adversarial-training in NLP]( \n-  eps: 0.1\n-  single model cv 0.002-0.005\n\n- EMA （Exponential Moving Average）\n\n- decay: 0.999\n- single model cv 0.001-0.003\n\n- Knowledge distillation\n- In other words, soft label from ensemble oof. In this way, single model can achieve performance close to ensemble models (just save time but no more diversity)\n- Make sure to use only the corresponding label for each fold to avoid leakage\n- The actual performance of second or more rounds is almost the same as first round, and the cv will be distorted in a strange way. We only use few models distiled from the first round.\n\n## **Not worked**\n\n- BCE Loss\n- MLM\n- Post processing\n\n## **Models**\n\n- Deberta-v3-large\n- Bert-for-patents\n- Deberta-large\n\n## **CV split**\n\nWe use the 5fold StratifiedGroupKFold (the same seed 42, group by anchor).  So we are able to use OOF to get ensemble scores and model weights effectively. Linear regression is much faster than optuna search.\n\nWhen there are enough models, our CV and LB are perfectly correlated. \n\n## **Notebook**\n\nsubmit: \n\nYou can find more details in the code.", "title": "Where is magic", "competition_name": "Not explicitly mentioned", "task_category": "Not explicitly mentioned", "field": "Modeling", "ranking": "Not available", "score": "Not available"}, {"content": "High-ranking Kaggle notebooks or competition strategies: (1) The overall design of the code is to train multiple models on different folds of the data and then use the trained models to make predictions on the test data. The predictions from each model are then combined to generate the final submission.\n\n(2) The overall model architecture consists of a transformer-based model (e.g., DeBERTa) as the backbone, followed by a custom head for each model. The transformer model is responsible for encoding the input text, and the custom head is responsible for making predictions based on the encoded representation. The code supports different types of custom heads, such as Extra_Head_1, Weighted_Linear, Cat_LSTM, and Pool_LSTM. Each custom head has its own specific architecture and functionality.\n\n(3) The important hyperparameters in this code are:\n- `n_classes`: The number of output classes.\n- `n_workers`: The number of workers for data loading.\n- `device`: The device to use for training (e.g., 'cuda' for GPU).\n- `batch_size`: The batch size for training and inference.\n- `max_len`: The maximum length of input sequences.\n- `tokenizer`: The path to the tokenizer used for encoding the input text.\n- `config`: The path to the model configuration file.\n- `folds`: The list of paths to the trained model weights for each fold.\n- `weight`: The weight assigned to each model's predictions during the final aggregation.\n- `aux`: Whether to use an auxiliary head for making additional predictions.\n- `head`: The type of custom head to use for each model.\n- `extra_head_instances`: The list of extra head instances to use for each model.\n\n(4) The optimization objective is not explicitly mentioned in the code. However, based on the usage of the models, it can be inferred that the objective is to minimize the loss between the predicted outputs and the ground truth labels. The specific loss function used is not provided in the code.\n\n(5) The advanced machine learning technique used in this code is transfer learning. The code utilizes pre-trained transformer-based models (e.g., DeBERTa) as the backbone for encoding the input text. These pre-trained models have been trained on large-scale datasets and have learned rich representations of text. By fine-tuning these pre-trained models on the specific task at hand, the code leverages the knowledge learned from the pre-training to improve performance on the target task.\n\n(6) Some important tricks that play a role in achieving high performance include:\n- Using different types of custom heads: The code supports multiple types of custom heads, each with its own architecture and functionality. This allows for flexibility in modeling different aspects of the data and capturing different patterns.\n- Using auxiliary heads: The code supports the use of auxiliary heads, which can make additional predictions based on the encoded representation. This can help capture different aspects of the data and improve overall performance.\n- Using weighted linear combination: The code combines the predictions from multiple models by taking a weighted linear combination of the predictions. This allows for the models with higher weights to have a larger influence on the final predictions, potentially improving performance.\n- Using pre-trained models: The code utilizes pre-trained transformer-based models as the backbone. These pre-trained models have learned rich representations of text from large-scale datasets, which can help improve performance on the target task.\n- Using data parallelism: The code uses data parallelism to train and make predictions with multiple models simultaneously. This can help speed up the training and inference process and improve overall performance.", "title": null, "competition_name": null, "task_category": "Classification", "field": "Modeling", "ranking": null, "score": null}, {"content": "The data was input to the model as follows : \n\n'Think through this step by step : ' + prompt_question + [SEP] + 'Pay attention to the content and wording : ' + text + [SEP] + prompt_text\n\n**Pooling Method [High Impact]**\n\n**Input :** [TOKEN] [TOKEN] [SEP] [TOKEN] [TOKEN] [SEP] [TOKEN] [TOKEN]\n**Head Mask :** [0] [0] [1] [1] [1] [0] [0] [0]\n\nInstead of using the normal attention mask created by the model tokenizer. I used a head mask that only had ones for the students' answer (text) portion of the input and zeros for all other tokens. I used the normal attention mask for the attention mask that the model consumed but I used the head mask for the mean pooling.\n\nThis had the biggest impact out of all the tricks I used. It increased the CV by a huge margin in all folds, but especially for the difficult prompts : 3b9047 and 814d6b. In my opinion this was the “magic” for this competition.\n\n**Prompt Question Augmentation [Moderate Impact]**\n\nI created 10 extra prompt questions per a prompt. I used an LLM. I asked the LLM to give me 10 variations of the prompt question. I then used this as augmentation during training. In inference, I used the default prompt question. In total I had 44 different prompt questions across all folds.\n\n**Auxiliary Classes [Moderate Impact]**\n\nI used auxiliary classes during the competition. These auxiliary classes were the target classes from Feedback 3.0 - \n['cohesion','syntax','vocabulary','phraseology','grammar','conventions'].\n\nTo create these labels I used models that were trained on the Feedback 3.0 data and ran the data from this competition through those models. I used only the ‘text’ column from this competition. In doing this I produced pseudo labels to use for this competition.\n\nI used the auxiliary classes in the following way : (loss * .5) + (aux_loss * .5)\n\nThe auxiliary classes were used every second step.\n\nThe Feedback 3.0 competition was hosted by The Learning Agency Lab and to the best of my knowledge this is a legal technique.\n\n**Max Length**\n\nModels were trained on a maximum length ranging from 896-1280 during initial training. During the pseudo labelling rounds they were trained with a maximum length ranging from 1280-2048. Pseudo labels allowed the models to learn at a higher maximum length.\n\nDuring inference the models used 1792 for large and 2048 for base.\n\n**Pseudo Labels [Moderate Impact]**\n\nOnce a CV of .4581 was reached across the grouped kfold I started creating pseudo labels. \n\nThe pseudo labels allowed me to train deberta-v3-base effectively. Before PL, I was not able to train the base model. They also allowed me to increase the maximum length during training.\n\nPL increased the CV from .4581 to .4476\n\nThe models were trained using a concatenation of the original labels and pseudo labels.\n\n**Final Ensemble (PL)**\n\n</br>\n\n|  Model Name | Training Max Length | Inference Max Length | Head | Model CV |\n| --- | --- |\n| microsoft/deberta-v3-large | 2048 | 1792 | Mean Pooling + LSTM Layer Pooling | .460 |\n| microsoft/deberta-v3-base | 2048 | 2048 | Mean Pooling + LSTM Sequence Pooling | .468 |\n| OpenAssistant/reward-model-deberta-v3-large-v2 | 2048 | 1792 | Mean Pooling + LSTM Layer Pooling | .464 |\n| microsoft/deberta-large | 2048 | 1792 | Mean Pooling + Linear | .466 |\n| microsoft/deberta-v3-large | 1280 | 1792 | Mean Pooling + LSTM Sequence Pooling | .461 |\n\n</br>\n</br>\n\n**Did work:**\n\n- Layer wise learning rate decay\n- Freezing layers (bottom 8)\n- LSTM layer pooling\n- LSTM Sequence pooling\n- Turn off dropout in transformer backbone\n- Multisample dropout in head\n\n**Did not work:**\n\n- AWP\n- SWA\n\n**Inference script :** \n\n**Note :** The inference script and input datasets will contain extra tricks that I haven't mentioned here, such as the inclusion of additional head for the model. Only the main points are outlined in this write-up.\n\nAlso, you can find the training script for each model inside of the dataset that contains the weights.", "title": "Not provided", "competition_name": "Not explicitly provided, but references Feedback 3.0", "task_category": "Classification", "field": "Modeling", "ranking": "Not provided", "score": {"CV_initial": ".4581", "CV_after_PL": ".4476", "model_CV_scores": {"microsoft/deberta-v3-large": ".460", "microsoft/deberta-v3-base": ".468", "OpenAssistant/reward-model-deberta-v3-large-v2": ".464", "microsoft/deberta-large": ".466", "microsoft/deberta-v3-large_1280": ".461"}}}, {"content": "High-ranking Kaggle notebooks or competition strategies: (1) The overall design of the code is to train multiple models using different architectures and techniques, and then combine their predictions using weighted averaging to obtain the final prediction.\n\n(2) The overall model architecture consists of multiple models, including FeedbackModel and ModelYauhen. FeedbackModel uses the DeBERTa-Large backbone and applies different pooling techniques (such as All [CLS] token pooling and GeM pooling) to extract features from the input text. These features are then passed through a linear layer to obtain the final logits. ModelYauhen also uses the DeBERTa-Large backbone and applies word-level pooling to extract features from the input text. These features are then passed through a linear layer to obtain the final logits.\n\n(3) The important hyper-parameters in this code are set in the configuration files (cfg.yaml) for each model. These hyper-parameters include the backbone architecture, whether to use lowercase text, the text column in the dataset, the cache directory for the backbone model, the path to the model checkpoint, and whether to add wide dropout or types to the model.\n\n(4) The optimization objective is to minimize the cross-entropy loss between the predicted probabilities and the true labels. This is achieved by training the models using gradient descent and backpropagation.\n\n(5) The advanced machine learning technique used in this code is the use of pre-trained transformer models (DeBERTa-Large) for text classification tasks. These models have been trained on large amounts of text data and can capture complex patterns and relationships in the text.\n\n(6) Some important tricks that play a role in high performance include:\n- Using different pooling techniques (such as All [CLS] token pooling and GeM pooling) to extract features from the input text.\n- Applying word-level pooling to extract features from the input text.\n- Using weighted averaging to combine the predictions of multiple models.\n- Scaling the predicted probabilities to ensure that they sum to 1 and align with the label means.\n- Using pre-trained transformer models (DeBERTa-Large) for text classification tasks, which have been shown to perform well on various natural language processing tasks.\n- Using different data augmentation techniques, such as adding types or wide dropout, to improve the generalization ability of the models.\n- Using ensemble methods to combine the predictions of multiple models and reduce the variance of the final prediction.", "title": "Not provided", "competition_name": "Not provided", "task_category": "Classification", "field": "Modeling", "ranking": "Not provided", "score": "Not provided"}, {"content": "High-ranking Kaggle notebooks or competition strategies: (1) The overall design of the code is to train and evaluate a model for a Kaggle competition on CommonLit. It includes data preprocessing, feature engineering, model training, and model inference.\n\n(2) The overall model architecture is based on the DeBERTa model, which is a transformer-based model for sequence classification. The model consists of an encoder layer, a pooling layer, and a fully connected layer. The encoder layer uses the DeBERTa model to encode the input text into hidden representations. The pooling layer aggregates the hidden representations into a fixed-length representation. The fully connected layer maps the fixed-length representation to the target variables.\n\n(3) The important hyperparameters in this code are:\n- `learning_rate`: the learning rate for the optimizer\n- `weight_decay`: the weight decay for the optimizer\n- `hidden_dropout_prob`: the dropout probability for the hidden layers\n- `attention_probs_dropout_prob`: the dropout probability for the attention layers\n- `num_train_epochs`: the number of training epochs\n- `n_splits`: the number of folds for cross-validation\n- `batch_size`: the batch size for training\n- `random_seed`: the random seed for reproducibility\n- `save_steps`: the number of steps to save the model during training\n- `max_length`: the maximum length of the input text\n\n(4) The optimization objective is to minimize the mean squared error (MSE) between the predicted target variables and the true target variables.\n\n(5) The advanced machine learning technique used in this code is the DeBERTa model, which is a state-of-the-art transformer-based model for sequence classification. It uses self-attention mechanisms to capture the relationships between words in the input text.\n\n(6) Some important tricks that play a role in high performance include:\n- Preprocessing and feature engineering: The code includes various preprocessing steps such as cleaning the text, encoding categorical variables, and extracting statistical features. These steps help to extract meaningful information from the raw data.\n- Ensembling: The code uses an ensemble of multiple models trained on different folds of the data. This helps to reduce overfitting and improve generalization performance.\n- Fine-tuning: The code fine-tunes the DeBERTa model on the specific task of predicting target variables. This allows the model to learn task-specific representations and improve performance.\n- Data augmentation: The code includes data augmentation techniques such as adding spelling errors and generating synthetic samples. This helps to increase the diversity of the training data and improve the model's ability to generalize to unseen examples.", "title": null, "competition_name": "CommonLit", "task_category": "Regression", "field": "Modeling", "ranking": null, "score": null}, {"content": "My solution is an simple ensemble of bert models. I have tried to use recall of different models to do l2 rerank using lgb, but failed to make it work, sad story:(. So no stacking here, just simple ensemble of level 1 bert models with optimized post process(search by optuna). - Best single model is **deberta-v3-large**! deberta-v3-large is the king for both feedback-prize and nbme maybe😉 deberta-v3-large + maxlen 1536 single model(train on all 15k) could get **LB 705, PB 718** the submission run is about 34min , I late submit test 5 folds of this model, score is **LB 708, PB 723** Longformer maxlen 1536 with the same model structure could only get **LB 690, PB 705** - Longformers(maxlen >= 1024) could improve but shortformers(maxlen == 512) can help a lot! We could get **Lb 705, PB 717** using just two seperately train 512 length models. deberta-v1-xlarge first 512 + deberta-v1-xlarge last 512 We could get **LB 712, PB 723** with 10 shortformers only ensemble. list(zip(range(len(model_dirs)), model_dirs, mns, weights)): [(0, '../input/feedback-model0', 'base.deberta-v3.start', 1), (1, '../input/feedback-model1', 'base.deberta-v3.end', 1), (2, '../input/feedback-model2', 'base.deberta-v3.se', 1), (3, '../input/feedback-model3', 'large.deberta-v2-xlarge.start', 1), (4, '../input/feedback-model4', 'large.deberta-v2-xlarge.se2', 1), (5, '../input/feedback-model5', 'base.deberta.start', 1), (6, '../input/feedback-model6', 'base.deberta.mid', 1), (7, '../input/feedback-model7', 'base.electra.start', 1), (8, '../input/feedback-model8', 'large.deberta-v3.start.mui-end-mid', 2), (9, '../input/feedback-model9', 'large.electra.start.mui-end-mid', 2)] len(model_dirs): 10 - What improved single model performance? Be sure **not to remove '\n'**, super important feature, I change '\n' to new word '[BR]' , to make sure all models(like tokenizer of roberta) can handle it correctly. **Word level LSTM on top of bert** help a lot! (using torch scatter_add, LB +2K, PB +3K) I used multi obj model, **token classfication**(8 class) + **seperator classification**(binary) Lovasz loss help a bit (LB 4K, but no gain on PB) - Post process How to split is important, I found below rules help a lot ! But it could not beat LGB:) ![image.png]( - Ensemble Use per word prob mean of different models, model weight is choosen from 1-10 with optuna. Backbones: deberta-v3-large, deberta-xlarge, deberta-large, longformer-large, bart-large, roberta-larege. (funnel-transformer-large help a bit on PB , but no gain on LB I did not choose it) Best model is online **LB 716, PB 729**, **local CV 724**(about **721** without fancy parameter search) 16 models running 5hour 20min, model names without len. means 512 length models, start means from position 0, end means from the end(last position), se means like first 256 + end 256, mid means from middle position, seq_encoder-0 means not using word level LSTM. [(10, 'deberta-v3.start.nwemb-0.mark_end-0'), (10, 'deberta-v3.start.len1024.stride-256.seq_encoder-0'), (10, 'deberta-v3.se2'), (10, 'deberta-v3.se'), (10, 'deberta-v3.end.len1024.seq_encoder-0'), (9, 'roberta.start.nwemb-0'), (9, 'deberta-xlarge.start'), (9, 'deberta-xlarge.end'), (9, 'bart.start.run2'), (8, 'deberta.start'), (8, 'deberta-v3.start.len1024.rnn_bi'), (8, 'deberta-v3.mid.len1024'), (7, 'deberta-v3.start.stride-256.seq_encoder-0'), (7, 'deberta-v3.start.len1536'), (6, 'longformer.start.len1536'), (6, 'deberta-v3.start.len1024.stride-256')] ![image.png]( ![image.png]( ![image.png]( ![image.png]( ![image.png]( ![image.png]( - Thanks @nbroad . I used two of your notebooks. corrected train.csv help improve LB and PB around 0.001. fast tokenizer of deberta-v3 is a key for best single model. My code has open sourced here: infering: training:", "title": "Not provided", "competition_name": "Feedback Prize", "task_category": "Classification", "field": "Modeling", "ranking": "Not provided", "score": {"LB": {"best_single_model": "705", "best_ensemble_model": "716"}, "PB": {"best_single_model": "718", "best_ensemble_model": "729"}, "local_CV": {"ensemble_model": "724"}}}, {"content": "High-ranking Kaggle notebooks or competition strategies: (1) The overall design of the code is to generate predictions for a Kaggle competition. It uses multiple models and techniques to make accurate predictions on the given dataset.\n\n(2) The overall model architecture consists of multiple components. It starts by loading pre-trained models and executing them using the `run_cmd` function. Then, it loads the predictions from these models and performs various data processing steps. It uses an LSTM model to generate additional features and combines them with the original features. Finally, it uses a LightGBM model to make predictions based on these features.\n\n(3) The important hyperparameters in this code are the `proba_thresh` and `inter_thresh` dictionaries, which define the probability thresholds for classifying predictions and the intersection thresholds for merging overlapping predictions, respectively. These thresholds are set based on the specific requirements of the Kaggle competition.\n\n(4) The optimization objective of this code is to maximize the accuracy of the predictions on the given dataset. It achieves this by using multiple models and techniques to generate accurate predictions.\n\n(5) The advanced machine learning technique used in this code is the combination of multiple models and the use of ensemble learning. It uses pre-trained models, LSTM models, and LightGBM models to generate predictions and combines them to improve the overall accuracy.\n\n(6) Some important tricks that play a role in high performance include:\n- Using pre-trained models to leverage pre-existing knowledge and improve prediction accuracy.\n- Using ensemble learning to combine the predictions from multiple models and improve overall accuracy.\n- Performing data processing steps such as feature engineering and data cleaning to improve the quality of the input data.\n- Setting appropriate hyperparameters such as probability thresholds and intersection thresholds to optimize the performance of the models.\n- Using advanced techniques such as PCA and SVD for dimensionality reduction and feature extraction.\n- Implementing post-processing steps such as merging overlapping predictions to improve the quality of the final predictions.", "title": null, "competition_name": null, "task_category": "Classification", "field": "Modeling", "ranking": null, "score": null}, {"content": "High-ranking Kaggle notebooks or competition strategies: First of all, I would like to thank the competition organizers for this great competition. At the same time, I am very grateful to many brothers for providing very good notebooks and discussions. I learned a lot from them and applied them to our final solution. \n\nIn this competition, because each token needs to be combined into a sentence as the final result, in order to reduce post-processing, we divide our solution into two stages\n\n# stage 1: bert token prediction\nFirst thanks to the excellent notebooks and discussions @cdeotte @abhishek @hengck23 and others\n\netc...\n\nwe tried various pretrain models, since the max length of some models is 512, for these models, we choose the method of segmented prediction and splicing, Finally we choice longformer-large, roberta-large, deberta-xxlarge, distilbart_mnli_12_9, bart_large_finetuned_squadv1 for ensemble. This stage takes 7 hours online, and **cv score 0.712**, **lb score 0.706** with post-processing.\n\nhere is each pretrain model cv score:\n[![1647309894393-e37bd0b0-7aac-45e6-a7d0-d749e3a10fb2.png](\nWe put the bert training code [here]( Because the kaggle online resources are insufficient, you need to copy it to your own machine for training\n\n# stage 2: lgb sentence prediction\nThanks @chasembowers for the excellent notebook \n\nwe first recall as many candidate samples as possible by lowering the threshold. On the training set, we recall three million samples to achieve a mean of 95% of recalls, the recalls for each class are \n| class | recall  |\n| --- | --- |\n| Claim | 0.938 |\n| Concluding Statement | 0.972 |\n| Counterclaim | 0.906 |\n| Evidence | 0.974 |\n| Lead | 0.970 |\n| Position | 0.928 |\n| Rebuttal | 0.895 |\n\nin addition, after getting the recall samples, we select sample with high boundary threshold and choice 65% length with the highest probability of the current class as a new sample, this method can help improve score about 0.008. Finally, We made about 170 features for lgb training, and select some samples as the final submission. This stage takes 1.5 hours online, and **cv score 0.748**, **lb score 0.742**.\n\nWe tested our lgb on the 5 fold longformer model, and the score increased from [0.697]( to [0.727]( Because lgb is not trained on this prediction, the improvement will be lower than the actual. At the same time, we uploaded our model ensemble results [here]( If you are interested, you can replace the prediction results with your own to see how much the cv score can improve.\n\n# Summarize\n**useful attempt:**\n1、adversarial learning (awp/fgm): cv increase 0.01，lb 5fold ensemble increase 0.003.\n2、model ensemble: single model lb 0.691, model ensemble 0.706, longformer and deberta ensemble increase most.\n3、lgb sentence prediction: cv increase 0.036, lb increase 0.036, among this, select sample with high boundary threshold and choice 65% length with the highest probability of the current class as a new sample can increase 0.008\n\n**useless attempt:**\n1、add paragraph information to input\n2、back translation\n3、adjust the weight according to the position of the sentence in which the word is located\n4、lgb model use overlap percentage as label to train\n5、stage 2 use bert to predict and ensemble with lgb\n\n**code:**\nlongformer train: \nlgb train: \n5fold longfomer with post-processing(lb 0.697): \n5fold longfomer with lgb(lb 0.727): \ncv ensemble with lgb(cv 0.747): \n\nOur code and data is published on GitHub [here]( ", "title": "High-ranking Kaggle notebooks or competition strategies", "competition_name": "Not explicitly mentioned", "task_category": "Classification", "field": "Modeling", "ranking": "Not explicitly mentioned", "score": {"cv_score_stage_1": "0.712", "lb_score_stage_1": "0.706", "cv_score_stage_2": "0.748", "lb_score_stage_2": "0.742"}}, {"content": "High-ranking Kaggle notebooks or competition strategies: First of all, thanks to competition organizers for hosting this competition and great teammates ( @shinomoriaoshi, @horsek, @runningz, @nickycan ). Thanks also to the community for sharing many ideas in Notebook and Discussion. Note: This post is a brief summary, and more detailed information will be updated or posted as a new topic by my teammates. - [tri's pipeline]( - [housuke's pipeline]( # Summary We ensembled 6 token classification models and 1 seq classification model. ![]( # Models We trained following models and used them for final submission. - tri( @shinomoriaoshi )'s pipeline - token classification Deberta-v3-large - housuke( @horsek )'s pipeline - token classification Deberta-v3-large - token classification Deberta-large - nakama( @yasufuminakama )'s pipeline - token classification Deberta-v3-large - seq classification Deberta-v3-large - RunningZ ( @runningz )'s pipeline - token classification Deberta-v3-large - token classification Deberta-v2-xlarge - 鲲 ( @nickycan )'s pipeline - mostly engaged on efficiency track # Main methods that worked - MLM pretraining - - Resolve encoding error - This method was used in previous 2021 Feedback Prize competition. - - Mask augmentation - This method was used in previous 2021 Feedback Prize competition. - - Adversarial training (AWP, FGM) - This method was used in previous 2021 Feedback Prize competition. - - Multi-sample dropout - This method was used in Google QUEST Q&A Labeling competition. - - Add GRU layer - Label smoothing - Add discourse_type for each discourse_text - Add [head] [tail] tokens for each discourse_text - Back translation (worked only for RunningZ's pipeline) - Pseudo labeling # 2nd stage Stacking using LSTM housuke( @horsek ) tried this early in the competition, and it worked very well. # 3rd stage Stacking using XGBoost After the 2nd stage Stacking, we applied 3rd stage Stacking using XGBoost, it improved result a bit. # Final Result CV: 0.5609 Public LB: 0.555 Private LB: 0.560", "title": "not available", "competition_name": "not available", "task_category": "Classification", "field": "Modeling", "ranking": "not available", "score": {"CV": 0.5609, "Public LB": 0.555, "Private LB": 0.56}}, {"content": "Thank you Georgia State University, The Learning Agency Lab, and Kaggle for a very well run competition. The data was high quality and interesting. It was great learning. Thanks also to Huggingface 🤗. Where would NLP be without you. Unfortunately, we missed out on the best of the postprocessing shown in some of the top approaches - WBF, GBM stackers, and Yolo-style span detector… really great work. Next time! Our [solution]( was blending a number of models (Big bird, Longformer, Deberta, Deberta-v2, Deberta-v3, Bart) all large models. We used a weighted average which was tuned with Optuna. Thresholds were also tuned with Optuna. As opposed to BIO tagging we used 9 model outputs - 7 classes & No span, as well one output to predict the initial token of each span. We found token dropout worked well to reduce overfitting. Training on very long sequences did not help too much. Using max 1250 tokens seemed to do well. For the shorter model it worked well to adjust the model to extend position token lengths, and just repeat the position embeddings 2X or 3X times.", "title": null, "competition_name": null, "task_category": "Classification", "field": "Modeling", "ranking": null, "score": null}, {"content": "Thanks contest organizer for holding such an interesting game. Thanks everyone joining and sharing during this contest. I learned a lot from discussions.\n\n- **CV strategy**\n\tGroupby anchor and stratify by score, also there are some words occur in both anchor and target, make sure to put them in the same fold.\n\n- **NN model detail**\n\t\ta. Pearson loss worked best for me\n\t\tb. 5 epochs training, start AWP training from the 2nd epoch. \n\t\tAWP helps a lot in all my nlp contests recently.\n\t\tc. Groupby['anchor',  'context'] ['target'] -> targets, add to input(anchor[SEP]target[SEP]CPC_TEXT[SEP]targets)  produce best model\n\t\tGroupby['anchor',  'context[0]'] ['target'] -> targets,  add to input help ensemble a lot, let me define context[0] as sector, it is like F21 -> F\n\t\tRemember to exclude current target from targets.\n\t\td. Random shuffle targets during each training step. (did not test enough, I remembered improved a lot on LB)\n\t\te. Freeze bert embedding layer (not much difference maybe but I used it for final models)\nFreeze embedding layer not hurt, means we do not need to finetue so much as our targets is simple short words similarity.\n\t\tf. Using different learning rates for bert (2e-5, 3e-5) and other parts(1e-3), especially useful when adding LSTM which need large lr.\n\t\tg. Add BI-LSTM header help a lot.\n\t\tDeberta-v3-large CV 858-> 861  “prompt is all you need\" gave me a hint we do not need to finetune/change bert model a lot, so I tried to add LSTM on top of bert and freeze bert embedding layer.\n\t\th.  Using linear attention pooling on top of BI-LSTM before fc.\n\t\ti.  Lr matters a lot for best single model deberta-v3-large,  2e-5 much better then 3e-5 \n\t\tDeberta-v3-large CV 861 -> 8627\n\t\tj. Change rnn output dim * 2 from (bert out dim like 1024 to 2048) help a lot for some weak models like bert-for-patents and simcse-bert-for-patent.\nSo for weak models we might need models to be widder.\nk. One possible method might be using token classfication to predict all targets score in 1 instance. \nSeems a bit complex to implement and I do not know if it will help improve score, not tried that yet.\n\n| model |  CV | backbone lr | base lr | scheduler | rnn dim * 2 | weight | 1 Fold LB | 1 Fold PB | Full train LB | Full train PB | 5 Folds LB | 5 Folds PB | \n| --- | --- |\n| microsoft/deberta-v3-large | 8627  | 2e-5 | 1e-3 | linear | No | 1 | 8599 | 8710 | 8604 | 8745 | 8604 (may shake to 8615) | 8761 |\n| anferico/bert-for-patents | 8451  | 3e-5 | 1e-3 | cosine | Yes | 0.4 |  |  |  |  |  |  |\n| ahotrod/electra_large_discriminator_squad2_512 | 8514  | 2e-5 | 1e-3 | cosine | No | 0.3 |  |  |  |  |  |\n| Yanhao/simcse-bert-for-patent | 8393  | 3e-5 | 1e-3 | cosine | Yes | 0.2 |  |  |  |  |\n| funnel-transformer/large | 848  | 3e-5 | 1e-3 | cosine | No | Exp after game end |  |  |  |\n\nInteresting to see deberta-v3-large and electra-large work best, they are both pretrained using electra style RTD not MLM.\nBut for this problem bert-for-patents ensemble most well with deberta-v3-large due to better diversity.\n\n- **Ensemble**\n\t\ta. Using 5 folds + 1 full train for each backbone, with full train model weight * 2\nweight 2 is choosing by e., and tested ineed better then 1:1 for LB and PB.\n\t\tb. Minmax scale for each model's output before adding to ensemble.\n\t\tc. Be sure to use weighted ensemble as for simple mean average hurt LB, maybe due to deberta-v3-large is much better then other models. \n\t\td. 5 folds self ensemble improve LB a lot which is a bit hard to measure by local cv\n\t\te. Use 20% data left out and train 10 folds models on the 80% and could find only lower down weight of weak models you could get gain.But this is costing, in the final days I only choose model weights by manually choosing those make my local first level cv best.\n| Ensemble | CV  | LB | PB \n| --- |\n| --- |\n| --- |\n| --- |\n| --- |\n| --- |\n| --- |\n| --- |\n| --- |\n| --- |\n| --- |\n| --- |\n| --- |\n| --- |\n| --- |\n| --- |\n| --- |\n| --- |\n| --- |\n| --- |\n| --- |\n| --- |\n| --- |\n| --- |\n| --- |\n| --- |\n| --- |\n| --- |\n| --- |\n| --- |\n| --- |\n| --- |\n| --- |\n| --- |\n| --- |\n| --- |\n| --- |\n| --- |\nGlad to see CV and LB PB match :)    \n\n\n- **Summary**    \n-- Add targets groupby anchor,context, key magic/trick to the gold. \n-- Add LSTM help me get good enough single model, which is the key for win on PB. (8745 -> 8779) \n-- Add targets groupby anchor,sector(context[0]) bring diverse models (comparing to change loss function, pooling method) )(8779->8782)    \ninference code:\n\nmost training code in:\n\nall training code opensource here:", "title": "not available", "competition_name": "not available", "task_category": "Classification", "field": "Modeling", "ranking": "not available", "score": "not available"}, {"content": "High-ranking Kaggle notebooks or competition strategies: (1) The overall design of the code is to make predictions on a test dataset using a trained model. It loads the necessary libraries and configurations, defines the dataset and model architecture, loads the trained models, and performs inference on the test dataset.\n\n(2) The overall model architecture consists of a transformer-based model followed by a convolutional LSTM head. The transformer model is used to encode the input text and extract contextualized representations. The output of the transformer model is then passed through a convolutional LSTM layer to capture sequential information. Finally, a linear layer is used for classification.\n\n(3) The important hyperparameters in this code are:\n- `N_XGB_FOLDS`: The number of folds used for cross-validation during training.\n- `config`: A dictionary containing various hyperparameters such as model name, maximum sequence length, batch size, learning rates, etc.\n\n(4) The optimization objective is to minimize the loss function during training. The specific loss function used is not mentioned in the code.\n\n(5) The advanced machine learning technique used in this code is the use of transformer models for text encoding and sequence classification. Transformers have been shown to be highly effective in natural language processing tasks.\n\n(6) Some important tricks that play a role in high performance include:\n- Ensemble of models: The code loads multiple models for each discourse type and takes an ensemble of their predictions to improve performance.\n- Sliding window approach: The code uses a sliding window approach to process long sequences by dividing them into smaller windows and concatenating the predictions.\n- Feature engineering: The code extracts various features from the input text and uses them as input to the model for better performance.\n- Hyperparameter tuning: The code tunes the probability thresholds for sub-sequence predictions to optimize performance.", "title": null, "competition_name": null, "task_category": "Classification", "field": "Modeling", "ranking": null, "score": null}, {"content": "A big thanks to Kaggle & the completion hosts for introducing the `Efficiency Track`, which is an amazing addition and will surely lead to more creative solutions. This is a detailed version of our solution for the `Feedback Prize - Predicting Effective Arguments` competition. \n\n# Links\n* TL;DR: \n* Code: \n* Inference Notebook: \n\n# Model Architecture \nOverall, we followed the span classification approach with model architecture as below\n![](\n\n# Pre-Processing\nWe pre-processed each essay to insert newly added span start and span end tokens for each discourse types. To provide more context to our models, we added a topic segment in this format `[TOPIC] <prompt_text> [TOPIC END] <essay>`. As a minor detail, we inserted `[SOE]` and `[EOE]` tokens to indicate essay start and end. As an illustration here is an example:\n\n\n```\n[TOPIC] Should computers read the emotional expressions of students in a classroom? [TOPIC_END] [SOE] Lead [LEAD] Imagine being told about a new new technology that reads emotions. Now imagine this, imagine being able to tell how someone truly feels about their emotional expressions because they don't really know how they really feel. [LEAD_END]  In this essay I am going to tell you about my opinions on why  Position [POSITION] I believe that the value of using technology to read student's emotional expressions is over the top. [POSITION_END] \n\n...\n\nConcluding Statement [CONCLUDING_STATEMENT] In conclusion I think this is not a very good idea, but not in the way students should be watched. The way teachers are able to read students' facial expressions tells them how they feel. I don't believe it's important to look at students faces when they can fake their emotions. But, if the teacher is watching you then they're gonna get angry. This is how I feel on this topic. [CONCLUDING_STATEMENT_END] [EOE]\n```\n\n# Span MLM\nTo train the newly added tokens (e.g. `[LEAD]`, `[POSITION]`) and adapting to the specific task domain (i.e. student essays from grade 6-12) we continued the pre-training phase of each backbone (e.g. `deberta-v3-large`) with masked language modelling (MLM) objective. While standard MLM works alright, we found big boost with the following modifications:\n* Changing masking probability to 40-50% instead of 15% used typically. For a detained analysis on masking rate, please refer to this : **Should You Mask 15% in Masked Language Modeling?** \n* Masking contiguous tokens of length 3-15 instead of regular random masking approach. Out motivation came from this paper: **SpanBERT: Improving Pre-training by Representing and Predicting Spans** \n* Changing chuck size / max length to 720 to match average essay length in the fine-tuning stage\n\nHere we used the ~15k essays from the 2021 feedback competition. In addition, we added ~25k synthetically generated essays by leveraging T5-large model. More on this in the next section.\n\n# T5 Augmentations\nSince we couldn't find external data sources that worked for us, we explored ways to create our own augmented / synthetic data / essays. To this end, we adopted two approaches\n\n**Label Preserving Training Data Augmentation with T5** Here we used 2022 labelled data to generate synthetic examples, which are directly added to train dataset during fine-tuning step. For this purpose, we first train the T5-large model with a seq2seq (text-to-text) text generation task. To be specific, this was the task input-output format:\n\n- Input Template: `Generate text for <discourse effectiveness> <discourse type> | Prompt: <prompt text> | Left Context: <left context> | Right Context: <right context>`, where left context is essay up to the discourse element we try to generate and right context is anything after the discourse element\n- Output Template: `<discourse text>` \n\nHere is one example:\n\n`Generate text for Ineffective Evidence | Prompt: Should the electoral college be abolished in favor of popular vote? | Left Context:Dear, State Senator\n\nWith the elctoral college vote most of people are not getting what they prefer. For the the electoral college vote, voters vote fro not the president, but for a not slate of electors. <....> majority of the people would rather have the popular vote.| Right Context: the electoral college election consist of the 538 electors. All you have to do is win most of those votes and you win the election. <.....> The electoral college is unfair, outdated, and irrational to all the people`\n-->\n`It does not make any sense to me how the president with the votes does not win the presidential election. The electoral college is unfair for all voters that vote. When you think of a vote and how it works you would think by the most one with the most votes wins cause that pretty much means that most of the people would rather have the most wins over the win that had less votes but more electoral votes.`\n\nThe trained T5 model was pretty amazing, we couldn't distinguish which one was generated text and which one was original. The augmentations copied the student writing styles, identity masks e.g. <LOCATION_NAME> and included effects such as that mentioned by @hengck23 in the previous competition discussion:\n\njust imagine you are asked to write the essay for homework. you are a bad student and want to copy other people work. you want to do so, such that that your teacher will not know that you are copying other people's work.\nyou can:\n1) choose an essay of the train data. replace the claim from another essay. (if the other essay has the same position as the first essay)\n\nReference: **Data Augmentation using Pre-trained Transformer Models** \n\n**T5: Non-Label Preserving Essay Augmentation**\nWe used this to mainly generate essays for MLM. It's quite similar to previous augmentation task with minor changes\n* uses all ~15k essays from feedback 2021 dataset\n* model only sees left context \n* no discourse effectiveness label is given in input prompt\n\n\n# Fine-tuning\nIn the fine-tuning stage, we mixed varying degree of T5 label-preserved augmented data (0-50% of original essays) with actual data. This was pretty much standard with following key highlights\n\n* Inclusion of prompts in essay: This helped models to boost performance on Lead and Position discourse types\n* Adversarial Training with AWP\n* Mask Augmentations (10-25%)\n* Multi-sample dropouts\n* Multi-head attention over span representations\n* LSTM over transformer encoder representations\n* Loss = CE Loss + Focal loss\n* Cosine scheduler\n* Layer wise learning rate decay\n* Mean pooling to extract span representations as opposed to [CLS] token based ones\n\n# Model Backbones\n* DeBERTa-Large\n* DeBERTa-XLarge\n* DeBERTa-V3-Large\n* Longformer\n* LUKE\n\n# Ensembling\nWe built two meta models based on OOF model probabilities + additional features\n\n**LSTM based**\n* Used only stage-1 model probabilities as features\n* Had better correlations with CV and LB\n\n**LGB based**\n* Used stage-1 model probabilities as features + additional features\n- Count of next line per essay text\n- Count of discourse_id per essay_id\n- Pos tags features (NN, VB etc)\n\n# Things that had most impact\n* Span MLM: 0.02 to 0.03\n* AWP: 0.005 to 0.01\n* Prompts: 0.002 to 0.005\n* Direct use of T5 Augmentations: -0.002 to 0.005\n* Mask Augmentation + MSD: 0.002 - 0.005\n* LSTM + LGB ensemble: 0.002-0.004 \n\n# Things that added for diversity\n* LUKE model\n* Multitask objectives e.g. predicting discourse type, ordered encoding of labels e.g. ineffective -> [0, 0], adequate -> [1, 0], effective -> [1, 1]\n* Different sampling ratio of augmented data\n* Impact moderation of focal loss with its gamma parameter\n* Knowledge distillation\n\n# How to make training stable?\nWe could train our models up to 6-7 epoch with best results obtained in penultimate/last epoch. The following helped in prolonging and stabilizing the training\n* Careful selection of key params e.g. batch size, learning rate, weight decay\n* Cosine learning rate scheduler\n* Task adaptation with MLM\n* AWP\n* Mask augmentations + Multi-sample dropouts\n* Layer wise learning rate decay\n* **Full precision training**\n\n# Things that didn't work for us \n* Pseudo labelling / meta pseudo labelling\n- on hindsight, this was a big miss for us\n* Random augmentation \n* UDA - Unsupervised Data Augmentations\n* Contrastive Learning\n* SWA\n* Mixout\n\nThanks for reading this far! Hope this helps you in your future NLP competitions! Looking forward to your comments and feedbacks.\nOur team ( @trushk , @harshit92) dynamics was brilliant throughout the competition. We had a lot of fun and learned so much together. Looking forward to future teaming up! \nThanks 😊", "title": "Detailed Solution for Feedback Prize - Predicting Effective Arguments", "competition_name": "Feedback Prize - Predicting Effective Arguments", "task_category": "Classification", "field": "Modeling", "ranking": "Not explicitly mentioned", "score": "Not explicitly mentioned"}, {"content": "High-ranking Kaggle notebooks or competition strategies: First of all, many thanks to the Kaggle team and Feedback Prize team for hosting this competition, and congrats to all winners ! Thanks to my teammates too, namely @amedprof and @crodoc for their hard work and commitment during all those 3 laborious months.\n\n## At the beginning\nWe struggle a lot during this comp’. We spent almost 2 months far from the bronze zone because our strategy was the exploration one. In fact, a great kernel was published by Abishek at the early beginning of the comp’ and one could just stick to it and keep tuning its hyperparameters to get a decent score (silver zone). But, we didn’t go that way and we kept exploring many ideas.\n\n## Solution approach\nIt seems like the go-to approach here is NER. We didn’t reinvent the wheel, we went that way as well since it seems straightfull and answers the problem quite correctly. In fact, we tested some QA approaches but not only were they too slow (training and much more inference) but they had slightly lower scores than our NER approaches. \n\n**Setup 1:**  *siblings NER & Span Segmentation*\nWe use a multitask approach to output the segmentation scores (multiclass classification on 3 different values: 0 for background, 1 when inside any entity and 2 for beginning) and the entity scores (15 classes). We still use 15 classes for the NER as well but before computing the class, we convert B-eginning tokens into I-nside.\n\n**Backbone:** 5 folds Deberta-v1 Large + 5 folds Deberta-v1 xLarge  (maxlen = 1024, stride during inference, positinon_biased_inputs=False), trained 5 epochs\n**Scheduler:** Cosine Annealing with no warmup\n**Optimizer:** AdamW\n**Loss:**  Cross-Entropy with dynamic cosine-based class weights. In fact we overweight rare classes (Rebuttal and Counterclaim) by starting with high values and converge to 1 on final epochs.\n\n**Setup 2:**  *Pure NER over 15 classes*, alternatively over 10 classes by removing the B target for non-overlapping classes.\n**Backbone:** 5 folds Deberta Large + 5 folds Deberta xLarge  (maxlen = 1024, stride during inference, positinon_biased_inputs=False), trained 5 epochs\n**Scheduler:** Polynomial decay  with 10% warmup\n**Optimizer:** AdamW\n**Loss:**  Cross-Entropy (no weights over classes)\n\n## Validation strategy\nWe used same validation strategy as the one shared by Abishek we also use an enhanced version of the clustesr made by cdeotte to make our MultilabelStratifiedKFold.\nThese folds were really stable and CV to LB correlation was great.\n\n## Post-processing and ensembling models & boxes\nAs cdeotte’s team, we make use of WBF on our final solutions. WBF was very effective and was the main ingredient behind our spectacular jump in the final days of the competition. Take a look on this tab for further details about CV / LB.\n\n![cv/lb before and after wbf](\n\n## What works\n* Filtering on num_tokens and score\n* Smart boxe ensembling (WBF)\n* Random Masking\n* Random start (if not striding during training)\n* Small batch size\n* Small learning rates\n\n## What doesn’t work\n* Training on longer sequences\n* Training long text aware models : LongFormer, Funnel and BigBird wasn’t better than deberta-v1 for us.\n* More epochs, higher batch size\n* Training on cleaned data\n* Using better word splitter than python split\n* QA instead of NER\n* Simply bagging models by averaging word level scores\n\n## Final thoughts\n\n* **Training on 10 labels**\nWe saw in [this kernel]( markov transition matrix that some *discourse_types* never overlap so we decide to use B-I-O only on Claim and Evidence and binary target for others.\n\n* **positinon_biased_inputs = False**\nThe HuggingFace Debrta-v1 version has positinon_biased_inputs parameter set to False by default, so Deberta-v1 is not using global position information by default. We manage to turn global position ON but the perfs are not much better than the vanilla one. Furthermore, turning positinon_biased_inputs OFF allows to use maxlen above 512 without the need to resize the embedding layers.\n\nThanks for reading our solution.\n\n### Edit\n* **Setup 1 source code**: \n* **Setup 2 source code**: ", "title": "Not provided", "competition_name": "Feedback Prize", "task_category": "Classification", "field": "Modeling", "ranking": "Not provided", "score": "Not provided"}, {"content": "Thanks to The U.S. Patent and Trademark Office (USPTO) and Kaggle for organizing such an engaging competition. This was my 3rd NLP competition, and I wouldn’t be able to get the position I got without the teachings and sharing of the Kaggle community, particularly @cdeotte, @abhishek, @theoviel, @yasufuminakama, and @cpmpml. Thank you! I finally got some time off work yesterday to review some of the posts and it seems that all top teams used the same base idea. So, instead of just talking about my solution, today I’m going to also share a bit about my journey through NLP competitions and my thought process. # My journey This was my 3rd NLP competition. I learned a lot in each one. From the first one in which I relied mainly in tuning a public notebook for one epoch while consuming a week of GPU quota, to the second in which I managed to train a deberta-v3-large model end-to-end, and this one in which I managed to train a deberta-v2-xlarge, it’s been quite a ride. Even now, after reading some of the write-ups I learned new stuff about the capabilities of the torch library. Kaggle is truly a unique platform that gives you the opportunity to compete with the best and learn from them. My journey in this competition started in early June after I was done with reviewing the write ups of my previous competition and doing some tests. I wondered if it wasn’t too late to join. I took a look at the data, compiled a list of ideas and decided to give it a try. First, I built a base solution that I could use as a benchmark. To my surprise even after some tweaks, its CV was pretty low when compared to both the LB and the top scoring public notebook. I expected a bump up from simply ensembling the various folds of a model, but my basis was so low that I doubted that would help much. With about two and a half weeks left I seriously considered moving on. Yet, I was curious to see whether some of my ideas would work and I figured that I could spend that time and pressed forward. The next day, June 6th, I made my first submission, mainly to make sure I could do it successfully. In my second competition I waited to submit until I had a model worth submitting and I struggled for several days to get it right with only 5 submissions per day to run tests, while the competition deadline was fast approaching. Since then, I like to get that out of the way as soon as possible. I wasn’t yet ready to submit anything other than single models, so that’s what I did. From then on, every day I’d use my 5 submissions, if for nothing else, to get more data to understand the correlation between my CV and the LB. On the second day, while continuing to train models, I completed the code for submitting an ensemble, and I submitted my first one. It was a simple mean of the models I had at the time. The following day I realized the submission had failed. I corrected a bug and made another submission right away. It didn’t take long for it to fail. I corrected the problem (a left over from the bug fix tests) and submitted again. A few hours later I realized it had also failed. I fixed another bug and repeated the submission. It was almost the end of the Kaggle day, so I submitted 2 more single models and with that completed my 3rd day of submissions. The next morning, I woke up in solid silver medal territory with LB=0.8525. The CV was 0.8589, but given that I hadn’t submitted any ensemble yet, I had no idea how that would translate in the LB. I was a great and encouraging surprise. Little did I know that the PB for that first ensemble, consisting of a simple mean of my first models, was 0.8714; more than enough to win a gold medal. To think that just 3 days before I was ready to move on because essentially those same individual models compared very poorly with the LB. I guess that if a large number of teams make a large number of attempts, it’s likely that some of them will get a good score by chance (aka overfit). Hence, the LB scores may not reflect the quality of a team’s solutions. Only each team can assess what they have. Others can only guess. Persistence pays off, or in my case, curiosity. The next day I got into gold territory and stayed there through the end. The competition was fierce. Two or three of the teams were always farther away at the top, but the others changed positions frequently. Given that my initial ideas were working well, I parked the other ones. I planned on trying 3 of them in the last days. Yet on the last Thursday I got a “nan” validation score during training. That was big wake-up call. I redirected my efforts to try to understand what had happened. For some reason, the prediction of the last items in the last validation batch was nan. Why the hell was that happening? There was nothing unusual in the input data. My focus changed completely. I realized that my gold medal position could be a mirage. What if the same thing was happening with my previous submissions and my PB score was nan? I spent most of my remaining time and submissions making my code as robust as possible. That seriously hampered my progress but felt like the right thing to do. I can now see that none of my submissions had a PB problem, but I didn’t know that, and I didn’t want to take any chances. I’m pretty happy with the outcome and if placed in the same circumstances, I’d do the same thing.# solution The input data was small enough that I could review it in Excel. I noticed that small variations of the same words had an impact on the score. I further noticed that the same anchor and target would sometimes have different scores depending on the context. I compiled a list of ideas for postprocessing and checked how well some of them would work considering the whole data. I knew that applying rules to the whole data was a recipe for disaster, but this was just Excel and I figured that I could use that “knowledge” to build new features and properly test them with an L2 model. But why build hand-made features and use level 2 models when transformers are great at doing that? I decided to use them instead. That lead to my decision to create two types of models: one based on a text prediction and another on a token prediction.", "title": "My journey", "competition_name": "The U.S. Patent Phrase to Phrase Matching", "task_category": "Regression", "field": "Modeling", "ranking": "Gold Medal", "score": "LB=0.8610"}, {"content": "(1) The overall design of the code is to perform inference on a test dataset using a pre-trained model. It uses the Deberta model architecture and applies it to the CommonLit Kaggle competition. The code loads the necessary libraries and modules, preprocesses the data, and then performs inference using different variations of the Deberta model. Finally, it combines the predictions from different models and generates a submission file.\n\n(2) The overall model architecture used in this code is the Deberta model. Deberta is a transformer-based model that incorporates both local and global attention mechanisms. It uses a combination of self-attention and cross-attention layers to capture dependencies between words and sentences in the input text. The model consists of multiple layers of self-attention and feed-forward neural networks. It also includes residual connections and layer normalization to improve training stability. The Deberta model has been pre-trained on a large corpus of text data and fine-tuned on the CommonLit dataset for the Kaggle competition.\n\n(3) The important hyperparameters in this code are set using the `ModelArguments`, `DataArguments`, and `TrainingArguments` data classes. The `model_path` hyperparameter specifies the path to the pre-trained Deberta model. The `df_path` hyperparameter specifies the path to the test dataset. The `model_type` hyperparameter specifies the type of Deberta model to use (e.g., `deberta_large`). The `max_token_len` hyperparameter specifies the maximum length of tokens in the input text. The `fp16` hyperparameter enables mixed-precision training using 16-bit floating-point numbers. The `output_dir` hyperparameter specifies the directory to save the output files.\n\n(4) The optimization objective of this code is to generate predictions for the test dataset that are as accurate as possible. The Deberta model is trained to minimize the mean squared error loss between the predicted and actual target values. The goal is to minimize the difference between the predicted and actual readability scores of the student summaries.\n\n(5) The advanced machine learning technique used in this code is transfer learning. The Deberta model is pre-trained on a large corpus of text data and then fine-tuned on the CommonLit dataset for the Kaggle competition. By leveraging the pre-trained weights, the model can learn to extract meaningful features from the input text and make accurate predictions on the test dataset.\n\n(6) Some important tricks that play a role in achieving high performance include:\n- Using different variations of the Deberta model (e.g., `deberta_large`, `deberta_base`) to capture different levels of complexity in the input text.\n- Adjusting the batch size (`bs`) based on the length of the input text to optimize memory usage and training speed.\n- Sorting the test dataset in descending order of total length to prioritize longer texts during inference.\n- Using mixed-precision training (`fp16`) to speed up training and reduce memory usage.\n- Employing data augmentation techniques (e.g., geometric transformations) to increase the diversity of the training data and improve generalization.\n- Applying a minimum learning rate schedule (`ema-min-lr`) during training to prevent overfitting and improve convergence.\n- Using a maximum token length (`max_token_len`) to limit the input text size and improve computational efficiency.", "title": "not provided", "competition_name": "CommonLit", "task_category": "Regression", "field": "Modeling", "ranking": "not provided", "score": "not provided"}, {"content": "High-ranking Kaggle notebooks or competition strategies: First of all, I would like to thank kaggle and the staff for hosting such an interesting competition. Also, I really appreciate my teammates, @harshit92, @ynishizono, @muhammad4hmed Congratulations to become the competition master and @trushk Congratulations to 2nd gold medal !\n\n# 1. Summary (Our Magic and got single model public LB : 0.8562, private : 0.8717) Our magic was to group the target words per \"anchor + context\" and attach them to the end of each sentence.Maybe it's easier to understand by looking at the code, so I'll share it.\n\n```\ntrain['group'] = train['context'] + \" \" + train['anchor']\n\nallres = {}\n\nfor text in tqdm(train[\"group\"].unique()):\ntmpdf = train[train[\"group\"]==text].reset_index(drop=True)\ntexts = \",\".join(tmpdf[\"target\"])\nallres[text] = texts\n\ntrain[\"target_gp\"] = train[\"group\"].map(allres)\n\ntrain[\"input\"] = train.anchor + \" \" + tokenizer.sep_token + \" \" + train.target + \" \" + tokenizer.sep_token + \" \" + train.title + \" \" + tokenizer.sep_token + \" \" + train.target_gp\n```\nfor example, we get like this sentence as input. And training.\n\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\nabatement [SEP] abatement of pollution [SEP] HUMAN NECESSITIES. FURNITURE; DOMESTIC ARTICLES OR APPLIANCES; COFFEE MILLS; SPICE MILLS; SUCTION CLEANERS IN GENERAL [SEP] abatement of pollution,act of abating,active catalyst,eliminating process,forest region,greenhouse gases,increased rate,measurement level,minimising sounds,mixing core materials,multi pollution abatement device,noise reduction,pollution abatement,pollution abatement incinerator,pollution certificate,rent abatement,sorbent material,source items pollution abatement technology,stone abutments,tax abatement,water bodies\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\nBy doing so, we thought that we could not only train one sentence, but also train considering the correlation of the target words for each \"anchor + context\" with attention. Moreover, in order to avoid leakage, groupkfold of \"anchor + context\" was adopted. As a result, this magic boosted our models (in best case, public lb 0.8418 → 0.8562) two days before closing.\n\nThis idea was decisive for getting into the gold medal zone. (Only this single model we can get the gold)\n\n------------------Details below---------------------------------------\n\n# 2. Preprocess and cross validation\n\npreprocess and cross validation is proposed by @harshit92 Basically, we used the lower case, not using [SEP] but uses [sep], remove \";\" , \",\" , and \".\" like this.\n\n~~~\ntrain['input'] = train['anchor'] + ' [SEP] ' + train['target'] + ' [SEP] '  + train['context_text']\ntrain['input'] = train['input'].apply(lambda x: x.lower())\ntrain['input'] = train['input'].apply(lambda x: x.replace(';','').replace(',','').replace('.',''))\n~~~\n\nAnd he found the boosting by changing 5kfold to 10kfold as NBME 1st solution (public LB : 5kfold 0.8395 → 10kfold 0.8435). These were the strong tools for us.\n\n# 3. Model making\n\n## 3.1 How to catch the problem We did not just solve the 1 target prediction, but to make it more diverse, we solved the problem as follows.\n\n### 3.1.1 BCE with binning The score value was replaced as follows. And sigmoid was calculated in each predictions and averaged.\n\n~~~\n0:[0,0,0,0], 0.25:[1,0,0,0], 0.5:[1,1,0,0], 0.75:[1,1,1,0],1:[1,1,1,1]\noutput = sigmoid in each prediction and averaged\n\nFor example, prediction = [0.1, 0.3, 0.2, 0.4], output = (0.1 + 0.3 + 0.2 + 0.4) /4\n~~~\n\n### 3.1.2 Softmax with binning The score was replaced as follows. And softmax was calculated in each predictions and convoluted.\n\n~~~\n0:[0, 0, 0, 0, 0], 0.25:[0,1,0,0,0], 0.5:[0,0,1,0,0], 0.75:[0,0,0,1,0],1:[0,0,0,0,1]\noutput = softmax in each prediction and convolution operation\n\nFor example, prediction = [0.1, 0.3, 0.2, 0.4, 0], output = 0*0.1 + 0.25*0.3 + 0.5*0.2 + 0.75*0.4 +1.0*0\n~~~\n\n## 3.2 AWP As with Feedback and NBME, we were able to improve our score with AWP.\nI got the code from the following in Feedback [code](\n\nThis boosted my model public LB : 0.8394 to 0.8418\n\n## 3.3 Other tips that worked well\n\n- Mixout by @trushk \n- Knowledge distillation(KD) by @ynishizono \n- text embedding with SVR \n- mix various loss (ex. MSE + Corr) \n- dynamic padding for some arches \n\n## 3.4 Didn't work well\n\n- MLM \n- pseudo labeling (export all combination of anchor and target per context) \n- Random noise of [MASK] \n- change the order of input \n- post process of Gradiant Boost \n- adding per subsection title (some case is better.) \n- concat text embedding and SVR like PetFinder 1st solution\n\n# 4. Ensemble For our ensemble, we used the nelder-mead coefficient by oof files. Candidates were automatically exported by @trushk 's code which uses the mix of the hill climb and nelder-mead algorithm. Finally, the used models were extracted based on over 90 oof files, and adjusted manually.\n\nThere are the list of models for the final submission.\n\n| model id | model                        | Feature   | Task            | Magic | kfold | cv      | public LB  | private LB | weight |\n|----------|------------------------------|-----------|-----------------|-------|-------|---------|------------|------------|--------|\n| 1        | deberta-v3-large             | AWP       | MSE             | TRUE  | 15    | 0.8605  | 0.8562     | 0.8717     | 0.237  |\n| 2        | electra-large-discriminator  |           | MSE             | TRUE  | 15    | 0.8456  | 0.8406     | 0.8534     | 0.166  |\n| 3        | electra-large-discriminator  |           | MSE             |       | 15    | 0.8381  | 0.8339     | 0.8486     | 0.049  |\n| 4        | bert-for-patents             | KD + SVR  |  BCE binning    |       | 5     | 0.8339  |            |            | 0.087  |\n| 5        | deberta-v3-large             | KD + SVR  | MSE             |       | 5     | 0.8470  |            |            | 0.129  |\n| 6        | deberta-v3-large             |           |  BCE binning    | TRUE  | 5     | 0.8471  | 0.8512     | 0.8664     | 0.067  |\n| 7        | deberta-v3-large             | Mixout    | Softmax binning | TRUE  | 5     | 0.8440  | 0.8506     | 0.8644     | 0.057 |\n|8        |\ndeberta-v3-large             |\nmixout    |\nbce binning    |\ntrue |\nkfold |\ncross validation |\nlb |\nprediction |\nsigmoid |\naveraged |\npseudo labeling |\ndynamic padding |\nmse |\ncorr |\nbce binning    |\nelectra-large-discriminator    |\nmix various loss    |\nmse    |\nbce binning    |\nmse    |\nbce binning    |\nmix various loss    |\nmse    |\nbce binning    |\nmse    |\nbce binning    |\nmse    |\nbce binning    |\nmse    |\nbce binning    |\nmse    |\nbce binning    |\nmse    |\nbce binning    |\nmse    |\nbce binning    |\nmse    |\nbce binning    |\nmse    |\nbce binning    |\nmse    |\nbce binning    |\nmse    |\nbce binning    |\nmse    |\nbce binning    |\nmse    |\nbce binning    |\nmse    |\nbce binning    |\nmse    |\nbce binning    |\nmse    |\nbce binning    |\nmse    |\nbce binning    |\nmse    |\nbce binning    |\nmse", "title": "Our Magic and got single model public LB : 0.8562, private : 0.8717", "competition_name": "Not explicitly mentioned", "task_category": "Regression", "field": "Modeling", "ranking": "11th place", "score": {"public_lb": "0.8604", "private_lb": "0.875"}}, {"content": "High-ranking Kaggle notebooks or competition strategies: (1) The overall design of the code is to train multiple models using different configurations and then use an ensemble of these models to make predictions on the test data. The code first preprocesses the data by cleaning and transforming it. It then defines a custom dataset class and a collate function for creating data loaders. Next, it defines the model architecture and a function for testing the model. It then loads the trained models, makes predictions on the test data, and combines the predictions using an ensemble approach. Finally, it generates a submission file with the predicted scores. (2) The overall model architecture is based on pre-trained transformer models (BERT and DeBERTa). The code uses the Hugging Face library `transformers` to load the pre-trained models and tokenizer. The models are fine-tuned for sequence classification by adding a linear layer on top of the transformer output. The input to the model is a sequence of tokens, which includes the anchor phrase, target phrase, and context text. The model outputs a single value representing the similarity score between the anchor and target phrases. (3) The important hyperparameters in this code are defined in the `CFG` dictionaries. These hyperparameters include: - `fold_num`: Number of folds for cross-validation. - `seed`: Random seed for reproducibility. - `model`: Path to the pre-trained model. - `path`: Path to save the trained model. - `max_len`: Maximum length of the input sequence. - `epochs`: Number of training epochs. - `train_bs`: Batch size for training. - `valid_bs`: Batch size for validation. - `lr`: Learning rate for optimization. - `num_workers`: Number of workers for data loading. - `weight_decay`: Weight decay for regularization. - `sigmoid`: Whether to apply sigmoid activation to the model output. (4) The optimization objective is to minimize the mean squared error (MSE) loss between the predicted similarity scores and the true scores. (5) The advanced machine learning technique used in this code is transfer learning. The code utilizes pre-trained transformer models (BERT and DeBERTa) that have been trained on large-scale language modeling tasks. By fine-tuning these models on the specific task of phrase matching, the code leverages the pre-trained knowledge to improve performance on the target task. (6) Some important tricks that play a role in high performance include: - Data preprocessing: The code cleans and transforms the data to create informative input sequences for the model. - Custom dataset class: The code defines a custom dataset class to handle the input data and create batches for training and validation. - Collate function: The code defines a collate function to handle variable-length input sequences and create tensors for model input. - Model architecture: The code uses state-of-the-art transformer models for sequence classification, which have been shown to perform well on various natural language processing tasks. - Ensemble approach: The code combines predictions from multiple models using an ensemble approach, which can improve the overall performance by reducing the impact of individual model biases. - Seed setting: The code sets the random seed to ensure reproducibility of the results. - GPU acceleration: The code checks for the availability of a GPU and uses it for model training and inference, which can significantly speed up the process. - Hyperparameter tuning: The code explores different hyperparameter settings by training multiple models with different configurations, allowing for better performance optimization.", "title": null, "competition_name": null, "task_category": "Regression", "field": "Modeling", "ranking": null, "score": null}, {"content": "High-ranking Kaggle notebooks or competition strategies: (1) The overall design of the code is to train a model for predicting the content and wording scores of student summaries. It uses a combination of transformer models and gradient boosting machines (lightgbm) for the training process. The code also includes post-processing steps to further improve the predictions.\n\n(2) The overall model architecture consists of two main components: the transformer models and the gradient boosting machines (lightgbm).\n\n- Transformer Models: The code uses the Huggingface library to load pre-trained transformer models for sequence classification. It uses the AutoTokenizer and AutoModelForSequenceClassification classes to load the models. The models are fine-tuned on the training data using the Trainer class from the transformers library. The input to the transformer models is a concatenation of the prompt title, prompt question, and student summary. The models output the predicted scores for content and wording.\n\n- Gradient Boosting Machines (lightgbm): The code uses the lightgbm library to train gradient boosting machines on the features extracted from the transformer models. The features include the predicted scores from the transformer models, as well as additional features such as the length of the summary, the ratio of copied words, and cosine similarity scores. The lightgbm models are trained using the lgb.train function and are used to make final predictions for content and wording scores.\n\n(3) The important hyperparameters in this code are:\n- `MODE`: Determines whether the code is running in training or test mode.\n- `POSTPROCESS`: Determines whether post-processing steps should be applied.\n- `model_name`: The name or path of the pre-trained transformer model to be used.\n- `hidden_dropout_prob`: The dropout probability for the transformer model.\n- `attention_probs_dropout_prob`: The dropout probability for the attention mechanism in the transformer model.\n- `max_length`: The maximum length of the input sequences for the transformer model.\n- `ENSEMBLE`: The index of the ensemble model to be used.\n\n(4) The optimization objective is to minimize the root mean squared error (RMSE) between the predicted scores and the true scores for both content and wording.\n\n(5) The advanced machine learning technique used in this code is the combination of transformer models and gradient boosting machines. The transformer models are used to extract features from the input sequences, while the gradient boosting machines are used to make final predictions based on these features.\n\n(6) Some important tricks that play a role in high performance are:\n- Cleaning and standardizing the input sequences: The code includes functions to clean and standardize the prompt text and student summaries, which helps in finding common sequences and improving the quality of the predictions.\n- Feature engineering: The code includes various features such as the length of the summary, the ratio of copied words, and cosine similarity scores, which provide additional information for the models to make predictions.\n- Ensemble learning: The code uses an ensemble of multiple models trained on different subsets of the data to improve the robustness and generalization of the predictions.\n- Post-processing: The code includes post-processing steps such as normalizing features and applying additional models (lightgbm) to further refine the predictions.", "title": "not provided", "competition_name": "not provided", "task_category": "Regression", "field": "Modeling", "ranking": "not provided", "score": "not provided"}, {"content": "Thank you very much for organizing such an interesting competition. I am greatly thankful to the hosts and the Kaggle staff. This competition turned out to be exactly what we had imagined and we are really happy to have won 4th place. And thank you so much @kurokurob for teaming up with me and for the daily discussions and experiments. Congratulations on your 4th GOLD MEDAL. (And I will become competition Grand Master!!!). We are a great team! # 1. Summary Our best private solution is 1 fulltrain x 7 models ensemble. This competition had only 4 prompts in the training data and with the information that 122 prompts were in the test data, one could imagine a big shake. Also, the public lb was very unstable. These things made us think that robustness is important, not only for cv. I used all 4kfold at first. Especially the models with prompt text, because I had to increase the maxlen to increase the score, I had to increase the inference time and could not ensemble other models (only 2-3 models could be included). Just then, I and kuro have team merged. And we mixed the fulltrain idea he had been working on. By replacing 4kfold with 1fulltrain, we arrived at the idea of compressing the information of 4kfold to 1fulltrain and ensemble more models. We imagined that by doing so, we would prevent the variation and reduction of scores on each prompt in the private test data and, in total, get better score. As a result, we believe we were able to prevent a shake down and finish in this position! | sub  | type      | models                 | cv      | public lb | private lb | rank | comment                                     | |------|-----------|------------------------|---------|-----------|------------|------|---------------------------------------------| | sub1 | best lb   | 1 fulltrain × 9 models | 0.4679 | 0.41991     | 0.45785      | 11 | using gbdt and expand of inference-maxlen   | | sub2 | best cv   | 1 fulltrain × 7 models | 0.4639 | 0.42979     | 0.45515      | 4    | just NLP result(expand of inference-maxlen) | | sub3 | insurance | 1 fulltrain × 8 models | 0.4693  | 0.43855     | 0.45597      | 6  | just NLP result                             | The best cv in sub2 is our best private, and that is the main explanation below. # 2. training Each of our models in sub2 is shown below. | modelno | InfNo | model                   | training<br/>maxlen | inference <br/>maxlen | freezing | layerwise | input           | pooling |                                   |                             | 2nd loss | preprocess | cv of 4kfold<br/> earlystop | |---------|-------|-------------------------|---------------------|-----------------------|----------|-----------|-----------------|---------|-----------------------------------|-----------------------------|----------|------------|-----------------------------| |         |       |                         |                     |                       |          |           | original prompt | cls     | attention of <br/>original prompt | mean of <br/>text part only |          |            |                             | | 1       | 91    | deberta-v3-large        | 768                 | 1500                  | ✓        |           |                 | ✓       |                                   |                             |          |            | 0.4818                      | | 2       | 22    | deberta-v3-large        | 1050                | 950                   |          | ✓         | ✓               |         | ✓                                 |                             |          |            | 0.4855                      | | 3       | 63    | deberta-v3-large        | 850                 | 1500                  |          | ✓         |                 |         |                                   | ✓                           |          |            | 0.4984                      | | 4       | 72    | deberta-v3-large        | 868                 | 1024                  |          | ✓         |                 | ✓       |                                   |                             | Arcface  | ✓          | 0.4919                      | | 5       | 2,3   | deberta-v3-large        | 868                 | 868                   |          | ✓         |                 | ✓       |                                   |                             |          |            | 0.4880                       ||6       ||259   ||deberta-v3-large-squad2 ||768                 ||1500                  ||✓        ||           ||                 ||✓       ||                                   ||                             ||          ||            ||0.4952                      ||7       ||331   ||deberta-v3-large-squad2 ||1050                ||950                   ||          ||✓         ||✓               ||         ||✓                                 ||                             ||          ||            ||0.4993                      The details are described below. ##2.1 model no1 : basemodel This model is a typical base for our model. First, two inputs are prepared and put into the tokenizer as a pair (an example of dataset). The same result can be obtained by connecting them with [SEP] even if you do not put them as a pair. ~~~~ self.text = self.df[\"text\"]. self.prompt = self.df[\"prompt_title\"] + [SEP] + self.df[\"prompt_question\"] + [SEP] + self.df[\"prompt_text\"] tokens = tokenizer.encode_plus( self.text, self.prompt,. ... ) ~~~~ Now all we have to do is put this in the model, increase the maxlen, and output the cls in the fc layer. ##2.2 model no2 : original prompt In this model, an original prompt was created and used for input. ~~~ self.text = \"Evaluating the summarized text and calculating content and wording score : \" + self.df[\"text\"].values self.prompt = prompt_title + [SEP] + prompt_question + [SEP] + prompt_text tokens = tokenizer.encode_plus( self.text, self.prompt, � ) ~~~ Then, only the part of the original prompt (Evaluating the summarized...) is attentional pooled (an example of a model). ~~~ ##init self.pool = AttentionPooling(self.config.hidden_size) ... ##forward output = self.model(ids, mask, token_type_ids) output = output[0][:,:12,:] output = self.pool(output,mask[:,:12]) output = self.fc(output) ~~~ ##2.3 model no4 : using 2nd loss and preprocess As discussed in the discussion and notebook, the train data can be classified into 38 types. I thought I could make good use of this, so I included arcface as an auxiliary loss. I tried to make good use of embeddings at the end, but it was not available. However, it did contribute to the diversity of the ensemble. Also, as a preprocss, I made sure to include a space after the period and comma; after doing EDA, I noticed that if a sentence comes after a period or comma without a space, it is divided differently in the tokenizer. However, I don't think this affected the score significantly. ##2.4 Extending the inference max length Scores have been greatly improved by increasing the inference length over that of training. An example is shown below. The following was trained with maxlen850, but by setting maxlen to1500 during inference, cv and public lb improved (maybe not so much contribution to private). training<br/>maxlen inference<br/>maxlen39c16e<br/>fold0814d6b<br/>fold1ebad26<br/>fold23b9047<br/>fold3cv8508500.45050.55950.50510.50240.498485010240.45240.55900.48360.50180.49278501500 .45270 .55880 .46140 .50130 .4867 However, some models may degrade.insurance submission(sub3) consisted only of models that did not expand this inference max length.As a result , cv and public were affected , but private had almost no effect.#3.inference(ensemble)For best cv sub , we initially post-processed using GBDT(LGBM+Catboost+XGboost), but in the end , ensemble without GBDT resulted in a better CV , The submission that produced the best private did not use post-processing with GBDT.We also considered nealder-mead and optuna , but we did not use them because of the concern that they would definitely overfit.So we use the simple mean ensemble using a hill climb technique(we also added a full train with different seed to further increase robustness for the extra inference time).final cv(4kfold earlystopping result):0 .46394 , public :0 .42979 , private0 .455154th Futhermore , we took as insurance(sub3) that the inference max lengths were the same as that in training.This result was as follows.final cv0 .4693 , public :0 .43855 , private0 .455976th.In this result , cv and lb were bad , but private was good , which shows how important the robustness of model was in this competition.#4.Not working for us-mlm-awp-svr-other model-regression from classification model-other many many things...#5.AcknowledgementsWe could not have achieved these results on our own.We were greatly influenced by those who we have collaborated with in the past , and we are grateful for their contributions.We would also like to express our sincere gratitude to those who have shared their knowledge and insights through previous competitions . Thank you very much.We would especially like to thank the following people for their help in this competition!Thank you very much.*Fulltrain:Team Hydrogen[ref1]( [ref2]( Raja Biswas@conjuring92[ref3]( *Freezing:Takamichi Toda@takamichitoda[ref4]( *37-38 classification:MOTH@alejopaullier[ref5]( Alexander Chervov@alexandervc[ref6]( *Postprocess:nogawanogawa@tsunotsuno[ref7]( *Model selection(feedback3):CHRIS DEOTTE@cdeotte[ref8]( TOM@tikutiku[ref9]( #6.team member*@chumajin*@kurokurob ![]( #7.code inference code:(This is the cleaned code.Same score as the submission.) training code(chumajin part): training code(kuro_B part):", "title": "Not provided", "competition_name": "Not provided", "task_category": "Classification", "field": "Modeling", "ranking": "4th", "score": {"cv": "0.46394", "public_lb": "0.42979", "private_lb": "0.45515"}}, {"content": "High-ranking Kaggle notebooks or competition strategies: (1) The overall design of the code is to train multiple models using different architectures and combine their predictions to generate the final submission for a Kaggle competition. The code uses pre-trained models such as DebertaV2, DebertaV1Large, DebertaV1XLarge, and Roberta to extract features from the input text. These features are then passed through convolutional layers and a linear layer to obtain the final predictions. The code also includes functions for data preprocessing, dataset creation, and evaluation of the model's performance.\n\n(2) The overall model architecture consists of the following components:\n- Pre-trained models: DebertaV2, DebertaV1Large, DebertaV1XLarge, and Roberta.\n- Feature extraction: The input tokens are passed through the pre-trained models to obtain the transformer output.\n- Convolutional layers: The transformer output is then passed through three 1D convolutional layers with different kernel sizes (1, 3, and 5) to capture different patterns in the data.\n- Concatenation: The outputs of the convolutional layers are concatenated and reshaped.\n- Linear layer: The concatenated output is passed through a linear layer to obtain the final predictions.\n\n(3) The important hyperparameters in this code are:\n- `average_folds_logits`: A boolean variable that determines whether to average the logits of different folds or not.\n- `add_models_logits`: A boolean variable that determines whether to add the logits of different models or not.\n- `token_len_filters`: A list of integers that represents the minimum number of tokens required for each category.\n- `score_filters`: A list of floats that represents the minimum score required for each category.\n- `exts`: A list of integers that represents the number of tokens to extend the predicted spans for each category.\n\n(4) The optimization objective of this code is to minimize the loss function during the training process. The specific loss function used is not mentioned in the provided code.\n\n(5) The advanced machine learning technique used in this code is the use of pre-trained transformer models (DebertaV2, DebertaV1Large, DebertaV1XLarge, and Roberta) for feature extraction. These models have been trained on large amounts of text data and can capture complex patterns and relationships in the input text.\n\n(6) Some important tricks that play a role in achieving high performance in this code are:\n- Using multiple models with different architectures and combining their predictions to improve the overall performance.\n- Using convolutional layers after the transformer output to capture different patterns in the data.\n- Applying various filters and thresholds to filter out entities with low confidence or insufficient token length.\n- Extending the predicted spans by a certain number of tokens to include more context and improve the accuracy of the predictions.", "title": null, "competition_name": "Kaggle competition", "task_category": "Classification", "field": "Modeling", "ranking": null, "score": null}, {"content": "The overall design of the code is to train and evaluate a model for a Kaggle competition on phrase-to-phrase matching in US patents. It uses a combination of pre-trained transformer models (DeBERTa and BERT) and ensembles their predictions to make the final submission.\n\nThe overall model architecture consists of a transformer-based model for sequence classification. The code uses the `AutoModelForSequenceClassification` class from the `transformers` library to load the pre-trained model specified in the configuration. The model takes input sequences (anchor, target, and context) and outputs a single value representing the similarity score between the anchor and target phrases. The model is trained using a binary cross-entropy loss function.\n\nThe important hyperparameters in this code are specified in the configuration dictionaries (`CFG1`, `CFG2`, etc.). These hyperparameters include the number of folds for cross-validation (`fold_num`), the random seed (`seed`), the path to the pre-trained model (`model`), the maximum sequence length (`max_len`), the number of training epochs (`epochs`), the batch size for training and validation (`train_bs` and `valid_bs`), the learning rate (`lr`), the number of workers for data loading (`num_workers`), the weight decay for regularization (`weight_decay`), and whether to use sigmoid activation for the final output (`sigmoid`).\n\nThe optimization objective is to minimize the binary cross-entropy loss between the predicted similarity scores and the true labels (0 or 1) for the phrase-to-phrase matching task.\n\nThe advanced machine learning technique used in this code is transfer learning. The code utilizes pre-trained transformer models (DeBERTa and BERT) that have been trained on large-scale language modeling tasks. By fine-tuning these models on the specific phrase-to-phrase matching task, the code leverages the learned representations and attention mechanisms of the pre-trained models to improve performance on the target task.\n\nSome important tricks that play a role in achieving high performance include:\n- Using ensembling: The code combines predictions from multiple models trained with different hyperparameters and architectures to improve the overall performance.\n- Data preprocessing: The code preprocesses the input data by tokenizing the text using a tokenizer from the `transformers` library and truncating or padding the sequences to a fixed length.\n- Seed fixing: The code sets the random seed for reproducibility by using the `seed_everything` function to fix the random seed for various libraries and frameworks.\n- GPU acceleration: The code checks if a GPU is available and uses it for training and inference to accelerate the computations.\n- Efficient data loading: The code uses the `DataLoader` class from PyTorch to efficiently load and batch the training and validation data, utilizing multiple workers for parallel data loading.\n- Gradient scaling: The code uses the `GradScaler` class from the `torch.cuda.amp` module to scale the gradients during training, which can help prevent underflow or overflow issues when using mixed-precision training.\n- Model checkpointing: The code saves the trained model weights after each fold of cross-validation, allowing for easy evaluation and ensembling of the models.\n- TQDM progress bar: The code uses the `tqdm` library to display a progress bar during training and inference, providing visual feedback on the progress of the code execution.", "title": null, "competition_name": "phrase-to-phrase matching in US patents", "task_category": "Classification", "field": "Modeling", "ranking": null, "score": null}, {"content": "High-ranking Kaggle notebooks or competition strategies: (1) The overall design of the code is to train a SlidingWindowTransformerModel on a Kaggle competition dataset and make predictions on the test set. The code includes the necessary imports, data preprocessing steps, model architecture definition, training loop, and inference process.\n\n(2) The overall model architecture is a SlidingWindowTransformerModel. It consists of a backbone transformer model (e.g., DeBERTa, Longformer) followed by a residual LSTM layer and a classification head. The backbone model is responsible for encoding the input text into contextualized representations. The LSTM layer captures the temporal dependencies within each discourse segment. The classification head maps the final hidden states to the output classes.\n\n(3) The important hyperparameters in this code are set in the `Experiment` class. These hyperparameters include:\n- `DOWNLOADED_MODEL_PATH`: The path to the downloaded pre-trained model.\n- `TRAINED_MODEL_PATH`: The path to the trained model.\n- `XGB_PATH`: The path to the XGBoost models.\n- `FOLDS`: The folds used for training and inference.\n- `hidden_state_dimension`: The dimension of the hidden states in the model.\n- `BATCH_SIZE`: The batch size used during training and inference.\n- `NUM_WORKERS`: The number of workers for data loading.\n- `MAX_LEN`: The maximum length of the input text.\n- `WINDOW_SIZE`: The size of the sliding window used for processing long texts.\n\n(4) The optimization objective is not explicitly mentioned in the code. However, based on the model architecture and the use of softmax activation in the final layer, it can be inferred that the optimization objective is to minimize the cross-entropy loss between the predicted probabilities and the true labels.\n\n(5) The advanced machine learning technique used in this code is the Sliding Window approach. It allows the model to process long texts by dividing them into smaller windows and applying the model to each window separately. This approach helps overcome the limitation of transformer models that have a fixed input length.\n\n(6) Some important tricks that play a role in high performance include:\n- Preprocessing the input text to include special tokens and discourse markers.\n- Using a residual LSTM layer to capture temporal dependencies within each discourse segment.\n- Applying sliding window technique to process long texts.\n- Using XGBoost models to generate additional features for the final predictions.\n- Ensembling multiple models with different hyperparameters and averaging their predictions.", "title": null, "competition_name": null, "task_category": "Classification", "field": "Modeling", "ranking": null, "score": null}, {"content": "# Submission Overview\nI split the data into 4 folds on `prompt_id` and computed a 4-fold CV. Rather than submitting all 4 models for inference, I retrained on 100% of the training data. My final submission is 6x deberta-v3-large: 2 models with different random seeds from each of my top 3 experiments. I took the unweighted mean of the 6 models' predictions.\n\n# Source code\nI mostly work in Python scripts rather than notebooks. Here's a repo containing a package for running my training and inference scripts: \n\n# Inputs and max length\n\nIn addition to using the summary text, I found that using the `prompt_question` improved the score slightly, and using the `prompt_text` helped quite a bit, assuming that the max length was also increased. Increasing the max length only helped up to 1024 tokens for training, although increasing up to 1536 during inference improved both CV (on prompt `ebad26`) and LB scores.\n\nIt was hard to tell if increasing beyond 1536 was worth it as none of the prompts in the training set were long enough, and I didn't get any consistent improvements from the LB when increasing to 2048 either.\n\n# Special tokens\n\nAnother thing that helped was adding a special token for each section of the input rather than using `[SEP]`. I added `<text>`, `<question>`, and `<summary>` tokens to the tokenizer before training, and then fine-tuned them. Inputs took the format:\n```\n\"<question> The prompt question text here. <summary> The student summary text here. <text> The original prompt text here.\"\n```\nI put the prompt text last to account for extremely long texts that would need to be truncated.\n\nI did also try adding the prompt title and a `<title>` token, but this didn't improve CV.\n\n# Inference\n\nEarlier in the competition I was submitting the mean of the 4 models trained in each experiment. However after I started increasing the max length up to and beyond 1024 tokens, I found that inference time increased quite significantly. It took about an hour to run inference with 1 deberta-v3-large at 1024 token max length, and about 1.5 hours at 1280 or 1536 tokens.\n\nThis means a 4-fold mean would take 6 hours or more at 1536 tokens. To be able to submit a more diverse ensemble I decided to start retraining on 100% of training data instead. I found the LB scores of these 100% models to be fairly consistent with the ones trained on 75% of the data. This allowed me to submit an ensemble of my best 3 CV experiments. I retrained on 100% of training data twice with different random seeds for each of the experiments.\n\n# GPU resources\n\nI don't have access to any dedicated GPUs, and each 4 fold experiment took a long time on Kaggle P100s (particularly when training with long sequence lengths), so I subscribed to Paperspace Gradient which gave me intermittent access to an RTX5000 or an A4000, both of which allowed me to run experiments about 4x faster than running on Kaggle GPUs.\n\nSince none of these GPUs have more than 16GB of RAM, I was only able to train with a batch size of 1 at max length 1024. To compensate for this, I used gradient accumulation. I initially accumulated gradients for 8 steps per optimizer update, but found that 16 steps worked even better.\n\n# Dropout\n\n[This thread]( pointed out that turning off dropout can be useful in regression tasks. I gave this a try and found that turning off dropout in fully-connected layers helped a little, but not in attention layers.\n\n# Pooling\n\nI saw some public notebooks which used mean pooling or GeM pooling, but in my experiments neither of these worked better than the default [ContextPooler]( which is built into `transformers.DebertaV2ForSequenceClassification`.\n\n# Things which didn't work\n\nHere's a list of ideas either by me, or which I ~~stole~~ borrowed from public notebooks or discussions, which didn't lead to any noticeable improvement:\n\n* Using `prompt_title`.\n* Freezing embeddings.\n* Freezing encoder layers.\n* Max, mean, or GeMText pooling.\n* Extra attention head.\n* MSE, SmoothL1, or (modified) MarginRankingLoss. (I mostly used MCRMSE loss).\n* Training separate models to predict content and wording scores.\n* Training with max sequence lengths longer than 1024.\n* deberta-v2-xlarge with LoRA (even with large alpha).\n* Autocorrecting spelling.\n* Ensembling with linear models or gradient-boosted regressors with hand-made features. (I didn't spend much time on this, but I tried using some of the features from the high-scoring public notebooks and they didn't seem very useful)\n* Using abstractive summarization to reduce the length of the `prompt_text`. I was able to improve my CV a bit with this, but it significantly hurt my public LB, which was a good warning not to do this. I decided it was too risky, because I wouldn't be able to validate any generated summaries when scoring on the private test data. If the generative model hallucinated even once it could screw up my final LB score.\n\nI would've liked to have tried extractive summarization as this would prevent the hallucination problem, but I didn't come up with a good way to train a model to rank the most important sentences in each `prompt_text`. It would've been a fun direction to go down, but probably ultimately a waste of time in comparison to just increasing the max sequence length.", "title": "Submission Overview", "competition_name": "unknown", "task_category": "Regression", "field": "Modeling", "ranking": "unknown", "score": "unknown"}, {"content": "High-ranking Kaggle notebooks or competition strategies: (1) The overall design of the code is to train and evaluate multiple models for a Kaggle competition. It includes the following steps: - Import necessary libraries and packages. - Define utility functions for evaluation metrics. - Install required packages. - Set file paths for data and configuration. - Run inference on multiple models using the specified model directories and file paths. - Apply post-processing smoothing to the predictions. - Prepare a weighted ensemble of the model predictions. - Optionally, train and predict using LightGBM models. - Save the final predictions to a submission file. (2) The overall model architecture includes the following components: - Utility functions: `MCRMSE` and `MCRMSE_SINGLE` calculate the mean squared error (MSE) and root mean squared error (RMSE) for multi-column and single-column predictions, respectively. `get_score` calculates the MCRMSE score and individual scores for a set of true and predicted values. - Data loading and preprocessing: The code reads the training and test data from CSV files and performs any necessary preprocessing steps. - Model training and evaluation: The code trains multiple models using different configurations and evaluates their performance using cross-validation. The models are trained using LightGBM, a gradient boosting framework. - Model prediction: The code makes predictions using the trained models on the test data. - Post-processing: The code applies post-processing smoothing to the predictions to improve their quality. - Ensemble: The code combines the predictions from multiple models using a weighted ensemble approach. - Output: The final predictions are saved to a submission file. (3) The important hyperparameters in this code are: - `alpha` (in the `apply_smoothing` function): Smoothing parameter for post-processing smoothing. It controls the amount of smoothing applied to the predictions. - LightGBM hyperparameters: The code sets various hyperparameters for the LightGBM models, such as `boosting_type`, `random_state`, `objective`, `metric`, `learning_rate`, `max_depth`, `lambda_l1`, and `lambda_l2`. These hyperparameters control the training and optimization process of the LightGBM models. (4) The optimization objective is to minimize the mean squared error (MSE) or root mean squared error (RMSE) between the true and predicted values. The code uses the `mean_squared_error` function from scikit-learn to calculate the MSE or RMSE. (5) The advanced machine learning technique used in this code is gradient boosting. The code trains and evaluates multiple LightGBM models, which are gradient boosting models. Gradient boosting is an ensemble learning method that combines multiple weak models (decision trees) to create a strong predictive model. (6) Some important tricks that play a role in high performance are: - Post-processing smoothing: The code applies post-processing smoothing to the predictions to improve their quality. This can help reduce the impact of outliers and noise in the predictions. - Weighted ensemble: The code combines the predictions from multiple models using a weighted ensemble approach. This allows the models with higher performance to have a greater influence on the final predictions. - Hyperparameter tuning: The code does not explicitly perform hyperparameter tuning, but the hyperparameters used in the LightGBM models can be optimized to improve performance.", "title": null, "competition_name": null, "task_category": "Regression", "field": "Modeling", "ranking": null, "score": null}, {"content": "High-ranking Kaggle notebooks or competition strategies: (1) The overall design of the code is to train and evaluate a model for a Kaggle competition. It uses a transformer-based model (DeBERTa) for sequence classification. The code preprocesses the data, trains the model using cross-validation, and makes predictions on the test data. Finally, it creates a submission file.\n\n(2) The overall model architecture is a transformer-based model called DeBERTa. It uses the DeBERTa-v3-large pre-trained model from the Hugging Face Transformers library. The model consists of a stack of 24 transformer layers with a hidden size of 1024. It uses gradient checkpointing to reduce memory consumption during training. The model is fine-tuned for sequence classification using a mean pooling layer and a linear layer for prediction. The input to the model is a concatenation of the prompt question, prompt text, and summary text, separated by a special token. The model is trained using a custom training loop with the Adam optimizer and mean squared error loss.\n\n(3) The important hyperparameters in this code are:\n- `model_name`: The name of the pre-trained model to use (DeBERTa-v3-large).\n- `learning_rate`: The learning rate for the optimizer (1e-5).\n- `weight_decay`: The weight decay for regularization (1e-8).\n- `hidden_dropout_prob`: The dropout probability for the hidden layers (0.0).\n- `attention_probs_dropout_prob`: The dropout probability for the attention layers (0.0).\n- `num_train_epochs`: The number of training epochs (2).\n- `n_splits`: The number of cross-validation folds (4).\n- `batch_size`: The batch size for training (4).\n- `random_seed`: The random seed for reproducibility (42).\n- `save_steps`: The number of steps between saving checkpoints (200).\n- `max_length`: The maximum length of input sequences (1700).\n- `folds`: The list of fold indices for cross-validation ([0, 1, 2, 3]).\n- `n_classes`: The number of output classes (2).\n\n(4) The optimization objective is to minimize the mean squared error loss between the predicted scores and the true scores.\n\n(5) The advanced machine learning technique used in this code is transfer learning. The code uses a pre-trained DeBERTa-v3-large model and fine-tunes it on the specific task of sequence classification.\n\n(6) Some important tricks that play a role in high performance are:\n- Gradient checkpointing: This technique reduces memory consumption during training by recomputing intermediate activations on-the-fly.\n- Mean pooling: This technique aggregates the hidden states of the transformer layers into a single representation for prediction.\n- Early stopping: This technique stops training if the validation loss does not improve for a certain number of epochs.\n- Learning rate scheduling: This technique adjusts the learning rate during training to improve convergence.\n- Dropout regularization: This technique randomly sets a fraction of the hidden units to zero during training to prevent overfitting.\n- Cross-validation: This technique evaluates the model's performance on multiple subsets of the data to get a more robust estimate of its generalization performance.", "title": null, "competition_name": null, "task_category": "Classification", "field": "Modeling", "ranking": null, "score": null}, {"content": "Thanks for the Hosts organized this competation and all the teammates who equally shared the contribution to this competation.\n\nI'd like to share our solution, it is an easy and effective solution\n\n1. As like other top teams, the data preprcess is the key for this compettion. In the data,  we added element type before the element text, using the [SEP] token as a separator, then we integrate all the elements in an article into one big long sentence, and then predict the classification label for each sentence. the follwing is the sample of input data\n\n[SEP]Lead. *Discourse_00*[SEP]Position. *Discourse_01*[SEP]Claim. *Discourse_02* .......\n\n2. And then we used the deberta-base as the back-bone to test different model architecture, we used multi-drop out in the final output layer \n\n3. we chose the **DeBERTa series model**, specifically using **\"microsoft/deberta-large \"**, **\"microsoft/deberta-v3-large \"** from the HuggingFace library.\n\n4. AWP was also added in the training stage which was proven effective\n\n5. we also labeled the previous feedback1 training data as external data source which can also improved the cv & pl\n\n6. Final CV-5Fold and simple weighted fusion.\n\n\nfollowing are LB result \n1. deberta-base Baseline 5Fold，Public LB : 0.608；\n2. used the whole easay as the input ，Public LB : 0.589；\n3. used deberta-v3-large，Public LB : 0.577；\n4. introduced Pseudo Label，Public LB : 0.572；\n5. introduced AWP training，Public LB : 0.570；\n6. more fintune lr and awp arguments，Public LB : 0.568；\n7. simple average weight ensemble，(deberta-v3-large, deberta-large, deberta-xlarge)Public LB : 0.560；", "title": "Not provided", "competition_name": "Not provided", "task_category": "Classification", "field": "Modeling", "ranking": "Not provided", "score": "Public LB: 0.560"}, {"content": "The overall design of the code is to train a DebertaV3 model for predicting the content and wording scores of student summaries. The code includes data preprocessing, model training, validation, and prediction steps.\n\nThe overall model architecture is based on the DebertaV3 model, which is a transformer-based model. The code uses the `AutoModelForSequenceClassification` class from the `transformers` library to load the pre-trained DebertaV3 model. The model is fine-tuned for sequence classification with a single output label. The input to the model is a concatenation of the prompt question, summary text, and prompt text. The model tokenizes the input using the `AutoTokenizer` class and generates input tensors for the model. The model architecture consists of multiple transformer layers with self-attention mechanisms, followed by a linear layer for classification.\n\nThe important hyperparameters in this code are set in the `CFG` class. The hyperparameters include the model name, learning rate, weight decay, hidden dropout probability, attention dropout probability, number of training epochs, number of cross-validation splits, batch size, random seed, save steps, and maximum sequence length.\n\nThe optimization objective is to minimize the root mean squared error (RMSE) between the predicted scores and the ground truth scores. The code uses the mean squared error (MSE) as the loss function and calculates the RMSE as the evaluation metric.\n\nThe advanced machine learning technique used in this code is transfer learning. The code loads a pre-trained DebertaV3 model and fine-tunes it on the student summary dataset. Transfer learning allows the model to leverage knowledge learned from a large pre-training dataset to improve performance on a specific task.\n\nSome important tricks that play a role in high performance include:\n- Data preprocessing: The code preprocesses the input data by tokenizing the text, removing stop words, fixing misspellings, and extracting features such as text length, word overlap, n-gram co-occurrence, quotes overlap, and grammar check.\n- Model architecture: The code uses the DebertaV3 model, which is a state-of-the-art transformer-based model known for its strong performance on various natural language processing tasks.\n- Training strategy: The code uses k-fold cross-validation to train and validate the model on multiple subsets of the data. This helps to reduce overfitting and obtain a more robust evaluation of the model's performance.\n- Evaluation metric: The code uses the root mean squared error (RMSE) as the evaluation metric, which is a common metric for regression tasks. This metric penalizes large errors more than mean absolute error (MAE) and provides a more comprehensive measure of the model's performance.\n- Feature engineering: The code incorporates additional features such as word difficulty, readability scores, and cosine similarity between the summary and prompt text. These features capture different aspects of the text and can provide additional information for the model to make predictions.\n- Ensemble learning: The code combines the predictions from multiple folds of the cross-validation to obtain a more robust prediction. This helps to reduce the variance and improve the overall performance of the model.", "title": "not provided", "competition_name": "not provided", "task_category": "Regression", "field": "Modeling", "ranking": "not provided", "score": "not provided"}, {"content": "High-ranking Kaggle notebooks or competition strategies: (1) The overall design of this code is to train a model for a Kaggle competition on feedback effectiveness. It uses a transformer-based model architecture to perform token classification on the input text data. The code tokenizes the input text, adds special tokens for discourse types, and trains the model using the provided hyperparameters. Finally, it generates predictions on the test dataset and saves them in a submission file.\n\n(2) The overall model architecture is based on a transformer model for token classification. It uses the 'deberta-v3-large' pre-trained model as the base model. The input text is tokenized using the AutoTokenizer from the transformers library. Special tokens are added for each discourse type, such as '[CLS_CLAIM]' and '[END_CLAIM]'. The tokenized input is then passed through the transformer model, and the output is fed into a linear layer for token classification. The model is trained using the AdamW optimizer with gradient checkpointing and mixed precision training (FP16). The training process includes multiple epochs and uses a batch size of 8 for training and 1 for evaluation.\n\n(3) The important hyperparameters in this code are set in the 'trainingargs' dictionary. Some of the key hyperparameters are:\n- 'output_dir': The directory where the trained model and other outputs will be saved.\n- 'do_train' and 'do_eval': Boolean values indicating whether to perform training and evaluation, respectively.\n- 'per_device_train_batch_size' and 'per_device_eval_batch_size': The batch size for training and evaluation, respectively.\n- 'learning_rate': The learning rate for the optimizer.\n- 'num_train_epochs': The number of training epochs.\n- 'warmup_ratio': The ratio of warmup steps to total training steps.\n- 'optim': The optimizer used for training (in this case, 'adamw_torch').\n- 'logging_steps': The number of steps between logging training information.\n- 'save_strategy' and 'evaluation_strategy': The strategy for saving and evaluating the model during training.\n- 'metric_for_best_model' and 'greater_is_better': The metric used for selecting the best model during training.\n- 'seed': The random seed for reproducibility.\n- 'fp16': Boolean value indicating whether to use mixed precision training.\n- 'gradient_checkpointing': Boolean value indicating whether to use gradient checkpointing for memory optimization.\n- 'gradient_accumulation_steps': The number of steps to accumulate gradients before performing an optimizer step.\n\n(4) The optimization objective is to minimize the loss function during training. The loss function used for token classification is not explicitly mentioned in the code, but it is likely to be the CrossEntropyLoss function, which measures the difference between the predicted probabilities and the true labels.\n\n(5) The advanced machine learning technique used in this code is the transformer model architecture. Transformers have been shown to be highly effective for natural language processing tasks, including token classification. The code uses the 'deberta-v3-large' pre-trained transformer model, which has been fine-tuned for token classification on the feedback effectiveness task.\n\n(6) Some important tricks that play a role in high performance include:\n- Tokenization: The code uses the AutoTokenizer from the transformers library to tokenize the input text. It adds special tokens for each discourse type, which helps the model learn the structure of the text.\n- Label handling: The code handles the labels for token classification by aligning them with the input tokens. It assigns a label of -100 to tokens that are not CLS tokens, so that they are ignored by the loss function.\n- Gradient checkpointing: The code uses gradient checkpointing, which trades off memory usage for computation time during backpropagation. This can be especially useful when training large models with limited GPU memory.\n- Mixed precision training: The code uses mixed precision training (FP16) to speed up training and reduce memory usage. This technique takes advantage of the fact that some computations can be performed with lower precision without significantly affecting the final results.\n- Grouping and batching: The code groups the input data by essay_id and applies batching to improve training efficiency. It also uses the DataCollatorForTokenClassification from the transformers library to handle padding and batching of the input data.\n- Model ensemble: The code performs k-fold cross-validation and generates predictions for each fold. The final predictions are obtained by averaging the predictions from all folds, which can help improve the model's performance and reduce overfitting.", "title": "not provided", "competition_name": "feedback effectiveness", "task_category": "Classification", "field": "Modeling", "ranking": "not provided", "score": "not provided"}, {"content": "High-ranking Kaggle notebooks or competition strategies: # Overview Before writing our solution, we really thank to Georgia State University and Kaggle for hosting this competition and congrats to all. Also, I really enjoyed doing this competition with my UPSTAGE team (sergei, ducky, and dlrgy22). The training code and inference notebook are here: * [Training code]( * [Inference notebook]( * [model weights]( * [solution documents]( The pipeline is here. Validation strategy -> Text pre-processing -> Model -> Ensemble -> Post-processing on logits ✔️ Things that worked. - Initial learning rate 1e-5 - Max gradient norm to small (about 1.0) - Plateau or Linearly Reduced LR With Warmup - SWA (stabilize valid performance, at least +0.01 boost) - Mean teacher with noise label filtering by exponential moving average ❌ Not worked. - Initial learning rate 3e-5 - Max gradient norm to large (abot 10) - SAM Optimizer - Dice Loss / Focal Loss with gamma 2.0 - Position Bucket Expanding at DeBERTaV3 ## Validation strategy * Cross validation with topic from [CHRIS DEOTTE notebook]( * Use half of all oof data as a test to find post-processing hyper-parameters. ## Text pre-processing * We use mask tokens to reflect newline information. * adjusting start of each entity to nearest alphanumeric character to the right entity before pre-p: ,Some quotation here. entity after pre-p: Some quotation here. * some samples with a word split by the start or end of entity text Ex) discourse_id -> 1621804837671 given text: t would allow students to ... modified text: it would allow students to ... ## Model We used 4 DeBERTa models: DeBERTa version 1 with large and xlarge model, DeBERTa version 2 with xlarge model and DeBERTa version 3 with large model. Here are the training code for each model and how to run it. * [DeBERTa v1 large and DeBERTa v2 xlarge]( * [DeBERTa v1 xlarge]( * [DeBERTa v3 large]( For more details with examples, see the solution documents above. ## Ensemble We used **First Token Ensemble**. For this competition we conducted an ensemble targeting logits of tokens. However, since the vocab defined for each tokenizer used in each model is different, the tokenized result may be different even for the same text. Therefore, it is not possible to simply sum the results of the two models because the results from tokenizer are different, and one idea is applied here: **First Token Ensemble** that will group overlapping tokens and add log probabilities for the first token of each group. For more details with examples, see the solution documents above. ## Post-processing We applied **Start With I-tag**,  **Look a Head**, **First Appearance** and **Extending end span** pp. * Start With I-tag pp Not really a B tag but it starts with an I tag. * Look a Head pp There were cases where tags appeared in succession and only one was empty. * First Appearance pp Handling of classes that appear once per essay. * Extended extracted entities to the right Extending end span to some extent. For more details with examples, see the solution documents above.", "title": "High-ranking Kaggle notebooks or competition strategies: # Overview", "competition_name": "Not explicitly mentioned", "task_category": "Classification", "field": "Modeling", "ranking": "Not explicitly mentioned", "score": "Not explicitly mentioned"}, {"content": "High-ranking Kaggle notebooks or competition strategies: First of all, I would like to thank the host for hosting such a wonderful competition.Also thanks to kagglers for sharing valuable information in notebooks and discussions.\n\nI'll briefly share my approach that led to the 5th place finish. Honestly, I didn't use any special techniques, so I believe the shake-up was largely due to luck. However, I'm extremely pleased with my first solo gold.\n\n### Overview\nThe key points of my approach are mainly threefold.\n* Use all of summary, question, title, and prompt_text.\n* Use a single deberta v3 large model, improved with longer max_len and freeze layer, etc.\n* An ensemble of deberta v3 large and LightGBM.\n\n### Approach\n* deberta v3 large\n* Input all of summary + question + title + prompt_text.\n* No preprocessing.\n* max_len: 1536.\n* Freeze embedding and the first 18 layers. \n* No dropout.\n* Train content and wording simultaneously.\n\n* LightGBM\n* Uses mostly the same features as public notebooks.\n\n* ensemble\n* Weighted average of deberta and LGB.\n* Weights optimized using nelder mead.\n\n### validation\n* strategy\n* groupkfold (group = prompt_id)\n* cv score\n* deberta v3 large :0.4816\n* LGBM :  0.5513\n* ensemble : 0.4748\n\n### What Didn't Work\n\n* Models other than deberta v3 large.\n* When including prompt_text as input, other models (including deberta-v3-base) had much poorer performance.\n\n* Additional training data with LLM\n* Considered data augmentation by creating summaries from prompt_texts using LLM.\n* I used the scraped prompt_text from commonlit.\n* Created ground truth using pseudo labels and added to training, but it did not improve.\n\n* LGB-based stacking\n* Tried stacking using deberta's oof, similar to public notebooks, but it did not improve in my model.\n* Hence, changed to the weighted average of each model as mentioned above.\n\n* Text preprocessing.\n* Inputting other summaries from the same prompt.\n* Inspired by the PPPM competition's magic, considered concatenating other summaries from the same prompt, but it did not improve.\n\n* etc...", "title": "5th Place Solution Overview", "competition_name": "Not explicitly mentioned", "task_category": "Not explicitly mentioned", "field": "Modeling", "ranking": "5th place", "score": {"deberta_v3_large": 0.4816, "LGBM": 0.5513, "ensemble": 0.4748}}, {"content": "all provided content", "title": "Second Place Solution", "competition_name": "Not explicitly mentioned, but inferred to be an NLP competition hosted by Georgia State University, The Learning Agency Lab, and Kaggle", "task_category": "Classification", "field": "Modeling, Post-Processing", "ranking": "2nd Place", "score": "Not explicitly mentioned, but various CV and LB scores are provided for individual models and the ensemble"}, {"content": "Thanks a lot to the hosts and Kaggle for hosting this interesting competition, we had great fun working on both the accuracy and efficiency tracks. Also congratulations to all other competitors for the great solutions and results. Our solution is the result of perfect teamwork.\n\n# Summary\n\nOur solution is based on a two-stage approach ensembling multiple transformer-based models with different techniques and adding second level models on top. We additionally employ multiple rounds of pseudo tagging and add pseudo labels with different techniques to our models.\n\n# Cross validation\n\nThroughout this competition we had near perfect correlation between CV and LB. Whenever we saw some improvement on CV, we saw it reflected in a similar manner on the LB with very small random range. For splitting the folds, we just used an efficiency-stratified split on essays.\n\nAs the data is small to medium size and the metric is log loss, the scores can vary between different runs. This is typical for deep learning models as they are quite dependent on the seed at hand that influences weight initializations, batching, or augmentations. Yet, this means one should not judge model performance on single seeds, and it is better to always evaluate on multiple seeds.\n\nGiven that model training was quite fast, we thus only relied on checking blends of 3 seeds for each model. Also, single model scores did not correlate well here with their ability to blend into larger ensembles. So a better individual model could have quite a worse performance in the blend, diversity really mattered here. Consequently, we also always checked models in the blend, even if they did not seem too promising on an individual basis. Similar to how we checked CV, we then always subbed a blend of 3 seeds of models trained on the full data.\n\nOur correlation looked like follows:\n<img src=\" width=\"500\">\n\n# Modeling\n\nOur final solution is a combination of different modeling approaches. Most of them are based on the idea of training on all discourses from a single essay at the same time. This not only made training and inference much faster, but also improved accuracy significantly. In the following we want to describe our main approaches in more detail. For backbones, we could only get deberta-(v3)-large to work. Other backbones did not improve the ensemble.\n\n#### Essay group model\n\nThe main idea of this approach is to feed a full essay into the model, and pool each discourse separately and then feed it through the final linear layer for prediction. The main approach here is similar to what others shared, but there are some peculiarities and different sub-approaches. \n\nOur main version has an input as follows:\n\n```\nLead Position Claim Evidence Counterclaim Rebuttal Evidence Counterclaim Concluding Statement [SEP]  [START] Hi, i'm Isaac, i'm going to be writing about how this face on Mars is a natural landform or if there is life on Mars that made it. The story is about how NASA took a picture of Mars and a face was seen on the planet. NASA doesn't know if the landform was created by life on Mars, or if it is just a natural landform. [END]   [START] On my perspective, I think that the face is a natural landform because I dont think that there is any life on Mars. In these next few paragraphs, I'll be talking about how I think that is is a natural landform [END] … more text follows here\n```\n\nAs mentioned, one sample includes one essay. We start by adding a list of all types of the discourses in the essay with a SEP token and then we mark the individual discourses with custom START and END tokens. We then run this sample through the backbone, and pool between START and END tokens for each discourse. The input batch size is always 1, and this gets transformed to a batch size that depends on the number of discourses within the essay. These pooled embeddings then run through a final linear layer predicting the class.\n\nYou can see that in this example we do not specifically add the type to each discourse, but we use an additional auxiliary loss to predict the type of each one. This helped with regularizing the model and allowed for a bit longer training.\n\nAn additional sub-approach does not have this auxiliary loss and trains a model based on the following input:\n\n```\nLead Position Claim Evidence Counterclaim Rebuttal Evidence Counterclaim Concluding Statement [SEP]  [START_Lead]  Hi, i'm Isaac, i'm going to be writing about how this face on Mars is a natural landform or if there is life on Mars that made it. The story is about how NASA took a picture of Mars and a face was seen on the planet. NASA doesn't know if the landform was created by life on Mars, or if it is just a natural landform. [END_Lead]   [START_Position]  On my perspective, I think that the face is a natural landform because I dont think that there is any life on Mars. In these next few paragraphs, I'll be talking about how I think that is is a natural landform [END_Position]  … more text follows here\n```\n\nWhile the latter approach was better individually on CV, the former approach blended significantly better in our large ensemble.\n\n#### Token classification\n\nIn this approach the chunks of the essays are treated as separate tokens. Individual chunks either get the efficiency label or “O” label if they are outside of the annotated essay text. And the subsequent process is similar to the idea above: pass the whole essay through the backbone, apply local average poolings for each chunk and add a dense classification layer on top. The input essay didn’t have any extra special tokens apart from discourse type in front of all the chunks.\n\n#### Further models\n\nFor diversity, we added the following models with minor impact to our solution:\n* Simple Deberta classification on Discourse input only\n* Bag-of-words LightGBM model \n\n# Regularization and hyperparameter tuning\n\nWe spent significant efforts on hyperparameter tuning and playing with various regularization techniques. We implemented quite a few augmentation techniques, but as always they were not really helpful for NLP finetuning. Only mask augmentations worked with decent results as it was bringing some diversity for the ensemble. Hyperparameter tuning was very important though, and it was time well spent.\n\n# Adjustment, ensembling & 2nd level models\n\nThe log loss metric is always only optimal if the mean prediction per column matches the mean of the target columns for that label. Our different models (specifically if trained in batch-wise manner on essays) do not always reflect this mean very well, which is why we added an additional optimization after each model to adjust to the train mean. This additionally makes the scores more reliable and comparable. We then also employ these learned scaling factors on LB.\n\nFor ensembling different models we resorted to directly optimizing the blending weights between the models. Interestingly, we also had several models with negative weights, but this worked for us both on CV as well as LB.\n\nWe additionally trained several 2nd level models to further improve our predictions.\n\n#### LightGBMs\n\nFor the 2nd level LightGBM model we took the weighted ensemble prediction, together with individual models predictions, and generated some aggregate features based on the whole essay. We trained 2 LightGBM versions with different features and parameters.\n\n#### Neural networks\n\nWe tuned two types of neural networks here. The first takes the weighted ensemble prediction, as well as an average across the essay and across the type within an essay for each of the three target columns as input and trains a three-layer DNN. The second one takes the same features, but on an individual model basis and then uses a three-layer Conv1d with average pooling afterwards.\n\nAll together, 2nd level models were consistently bringing us about 0.003-0.005 points on CV and the leaderboard throughout the competition.\n\n# Pseudo labels\n\nAnother major part of our solution is pseudo labeling. We applied 3 stages of pseudo labeling on the extra data from the previous Feedback competition. It was done in a leak-free manner for the individual folds and additionally for our models trained on all the data (6 versions of pseudo labels in total). The process consisted of the following steps:\n1. Train an ensemble of models only on the given train data\n2. Run predictions on the previous Feedback competition data using our full 2-stage pipeline\n3. Use soft pseudo labels from this extra dataset and apply it to modeling in two different ways:\n* Concatenate pseudo labels with the actual labels in the given train data, and train simultaneously on all this data\n* Pre-train models on the pseudo labels and finetune it only on the given train data afterwards. Similar to: \n4. Repeat steps 1-3 three times using an ensemble of models trained on pseudo labels now\nApart from using previous Feedback competition data for pseudo labels, it was also used in some models as a pre-training dataset. The model was warmed up on the old data predicting the type of the chunk and further finetuned on the given train data.\n\n# Efficiency solution\n* Please refer to [this]( post to read about our efficiency solution.\n* And [here]( you can find our most efficient kernel that gets 0.557 Private LB scores in 5 minutes and 40 seconds!\n### Extra links\n* [Here]( you can find our final inference kernel\n* [Here]( you can find our code to train the models", "title": "Not provided", "competition_name": "Feedback Prize - Evaluating Student Writing", "task_category": "Classification", "field": "Modeling", "ranking": "Not provided", "score": "Not provided"}, {"content": "High-ranking Kaggle notebooks or competition strategies: First of all, thanks to the organizers for hosting an interesting and very competitive competition and congrats to all the winners. Next, thanks to my amazing teammates @aerdem4 @thedrcat Although we shook down by one place, it was still a good team effort and I'm happy about the results. This was my first NLP comp although it does fall in a familiar category (i.e. seq2seq predictions) for me.\n\nOur inference notebook is public:  and training code is public as well: \n\n# Overview\nOur solution is a combination of token classification models using transformers and a stacking framework that classifies spans for 7 discourse types separately. Credit to @cdeotte and @chasembowers for sharing their amazing notebooks ( and  ).\n\n![overview](\n\n# Deep learning models\n\nOur best ensemble consists of 6 folds of Longformer and 6 folds of sliding windows Deberta-xl models (weighted by discourse type based on cv). Due to the sequential nature of the problem, we add a 2-layer GRU on top of the transformer hidden states before outputting predictions for each token. We find it beneficial to increase max_len during training/inference to 2048, beyond which we actually saw performance degradation. In our case, deberta-l outperforms longformer large by quite a bit, and deberta-xl is even better, although deberta-xl is more difficult to train.\n\nBelow I will discuss some specificities of training these models.\n\n### Longformer\nTraining longformers is relatively simple because longformers can take sequences longer than 512 without any issues. Our pipeline is similar to what's publicly available, mostly from @cdeotte \n\n### Sliding window (SW) Deberta-xl\nTraining deberta is a little trickier than longformers since we can't directly input a sequence longer than 512. Instead, we use a sliding window method when the sequence length is longer than 512. First, the first 512 positions are inputted to the deberta encoder. When we input the next segment into the deberta, we actually only increment the end position by 384, input position [512-64:512-64+512], and only concat the hidden states of the middle segment [64:448] to the hidden states of the first 512 positions, which avoids edge effects. We do this until we reach the end of the sequence and if the last segment is equal to smaller than 64, we simply take the last positions of the previous segment. After we run and concat all the segments, we run the sequence through a 2-layer GRU layer. Since the GRU processes the concatted segments sequentially, it essentially reconnects all the segments.\n\n```\nB,L=input_ids.shape\nif L<=self.window_size:\nx=self.backbone(input_ids=input_ids,attention_mask=attention_mask,return_dict=False)[0]\nelse:\nsegments=(L-self.window_size)//self.inner_len\nif (L-self.window_size)%self.inner_len>self.edge_len:\nsegments+=1\nelif segments==0:\nsegments+=1\nx=self.backbone(input_ids=input_ids[:,:self.window_size],attention_mask=attention_mask[:,:self.window_size],return_dict=False)[0]\nfor i in range(1,segments+1):\nstart=self.window_size-self.edge_len+(i-1)*self.inner_len\nend=self.window_size-self.edge_len+(i-1)*self.inner_len+self.window_size\nend=min(end,L)\nx_next=input_ids[:,start:end]\nmask_next=attention_mask[:,start:end]\nx_next=self.backbone(input_ids=x_next,attention_mask=mask_next,return_dict=False)[0]\nif i==segments:\nx_next=x_next[:,self.edge_len:]\nelse:\nx_next=x_next[:,self.edge_len:self.edge_len+self.inner_len]\nx=torch.cat([x,x_next],1)\n```\n\n### Augmentation\nWe used 2 forms of augmentations:\n1. Masked aug, where we mask 15% of the tokens during training.\n2. Cutmix, similar to how cutmix works for images, we cut a portion of one sequence and paste it (and its labels) into another sequence in the same batch. Implementation is quite simple:\n```\nif np.random.uniform()<0.5:\ncut=0.25\nperm=torch.randperm(ids.shape[0]).cuda()\nrand_len=int(ids.shape[1]*cut)\nstart=np.random.randint(ids.shape[1]-int(ids.shape[1]*cut))\nids[:,start:start+rand_len]=ids[perm,start:start+rand_len]\nmask[:,start:start+rand_len]=mask[perm,start:start+rand_len]\nlabels[:,start:start+rand_len]=labels[perm,start:start+rand_len]\n```\n\n### Hyperparameters\n\nSince we use augmentations, we train for 7 epochs at learning rates of [2.5e-5, 2.5e-5, 2.5e-5, 2.5e-6, 2.5e-6, 2.5e-6, 2.5e-7] for longformer and deberta-l; for deberta-xl, we use the same schedule with 1/5 of the learnig rate. For longformer, we use a batch size/max_length of 4/2048, for deberta-large 3/2048, and for debrta xl 2/1536 (mostly due to memory constraints).\n\n### Training/inference tricks\nDuring training, instead of padding every sequence to a fixed max length, we pad sequences to the max length in its batch, which speeds up training considerably. During inference, we also sort all texts by their lengths before batching, thereby minimizing the amount of padding in each batch, which speeds up inference quite a bit.\n\n# Stacking framework\n\nOur stacking framework is the same as the one posted by chase bowers; we just made a lot of improvements to it. In short (for those who aren't aware of the notebook), for each discourse type, using out of fold predictions, we generate features for candidate spans based on a begin token probability threshold and a max span length (99.5 percentile for each discourse type), and train gradient boosting models that operate on these features and classify spans. Therefore, we have 7 binary classification models, one for each discourse type. During inference, we sort all candidate spans by predicted probability and take those as predictions until a low threshold, while removing spans that intersect more than 0.15/0.2 with existing predicted spans.  \n\nBelow I will discuss the improvements.\n\n### CV setup\n\nWe set up cross-validation which ended up being mostly consistent with public lb. As a result, most of our improvements locally observed translated to public lb improvements as well. In some cases, however, improvements in noisy classes (e.g. Rebuttal), we saw some inconsistencies, but that was to be expected.\n\n### Features\n\nFirst we fixed a minor error with calculations of probability that a word corresponds to either a 'B'-egin or 'I'-nside token for a class in the original stacking notebook, where B and I tokens happening for the same class are considered independent events. From:\n```\nprob_or = lambda word_preds: (1-(1-word_preds[:,disc_begin]) * (1-word_preds[:,disc_inside]))\n```\nto\n```\nprob_or = lambda word_preds: word_preds[:,disc_begin] + word_preds[:,disc_inside]\n```\n\nWe added more probabilities at the edges of the span as well as the probability of another B token for any class following the span. Additionally, we added the location of the max/min probabilities for the class in the span. Further, we added something we call instability, which is the average squared difference in prob_or from position to position:\n```\ns = prob_or(text_preds[pred_start:pred_end])\ninstability = 0\nif len(s) > 1:\ninstability = (np.diff(s)**2).mean()\n```\nAside from span specific features, we added global features of the average prob_or of every discourse type and the positions with the max B token probs of every disourse type.\n\nLast but not least, not all features are used for every discourse type, and instead we tune our feature selection based on CV. We have used around 25 features on average.\n\n### Increasing the amount of candidate spans\n\nFor some discourse types, we reduced the min begin token probability threshold so we have more candidate spans.\n\n### Gradient boosting models\n\nIn our best ensemble, we have both an lgbm and an xgb model, each with 5 folds trained on oofs. The predictions from both lgbm and xgb are weighted equally.lgbm is trained on dart mode. Since it is not possible to do early stopping on dart mode, first xgb is trained and its optimal number of trees x 1.4 is used for number of trees. We accelerated our gradient boosting models with RAPIDS ForestInference and got room for an extra deberta fold.\n\n### Decoding\nAll candidate spans are sorted by predicted probability and taken as predictions until a low threshold. The original notebook did not allow any intersection with existing predicted spans during decoding, but we were able to improve our score by allowing a certain level of intersection (normalized by span length) instead, such as 0.2.", "title": "Not provided", "competition_name": "Not provided", "task_category": "Sequence-to-Sequence Prediction", "field": "Modeling", "ranking": "Not provided", "score": "Not provided"}, {"content": "The overall design of this code is to train a model for a Kaggle competition on feedback effectiveness prediction. It uses a combination of transformer-based models, lightGBM, and a neural network stacker to make predictions on the test set.\n\nThe overall model architecture consists of three main components: a transformer-based model, a lightGBM model, and a neural network stacker.\n\n- The transformer-based model is based on the DeBERTa-v3-large architecture. It takes in the essay text as input and encodes it using the transformer model. It then uses a custom pooling layer called NLPAllclsTokenPooling to pool the hidden states of specific tokens related to discourse types. The pooled features are then passed through a linear layer to obtain logits for each class.\n\n- The lightGBM model takes in various features related to the discourse types, such as the discourse type itself, the predicted probabilities from the transformer-based model, the number of unique discourse types in an essay, the mean predicted probability of the \"Ineffective\" class, the length of the discourse text, and the number of paragraphs in the essay. It uses these features to make predictions on the effectiveness of the discourse.\n\n- The neural network stacker takes in the predicted probabilities from the transformer-based model, the lightGBM model, and the neural network stacker itself. It concatenates these predictions and passes them through a series of linear layers with PReLU activations. The final layer outputs logits for each class.\n\nThe important hyperparameters in this code are loaded from a YAML configuration file. The configuration file specifies the architecture of the transformer model, the maximum length of the input sequences, and the paths to the pre-trained models and tokenizers. These hyperparameters are used to initialize the transformer-based model and tokenizer.\n\nThe optimization objective of this code is to minimize the cross-entropy loss between the predicted probabilities and the true labels. The code uses the nn.CrossEntropyLoss() function as the loss function for both the transformer-based model and the neural network stacker.\n\nThe advanced machine learning technique used in this code is the transformer-based model. Transformers have revolutionized natural language processing tasks by capturing long-range dependencies and contextual information effectively. The DeBERTa-v3-large architecture used in this code is a state-of-the-art transformer model specifically designed for text classification tasks.\n\nSome important tricks that play a role in achieving high performance in this code include:\n- Data preprocessing: The code preprocesses the essay texts and discourse texts by adding special tokens to mark the start and end of each discourse type. This helps the model capture the discourse structure effectively.\n- Parallel processing: The code uses multiprocessing to parallelize the data loading and encoding steps, which can significantly speed up the training process.\n- Pooling strategy: The NLPAllclsTokenPooling layer in the transformer-based model pools the hidden states of specific tokens related to discourse types. This pooling strategy helps the model focus on the most relevant information for predicting the effectiveness of the discourse.\n- Ensemble learning: The code combines the predictions from multiple models, including the transformer-based model, lightGBM model, and neural network stacker, to make the final predictions. This ensemble approach helps improve the overall performance by leveraging the strengths of different models.", "title": null, "competition_name": "feedback effectiveness prediction", "task_category": "Classification", "field": "Modeling", "ranking": null, "score": null}, {"content": "High-ranking Kaggle notebooks or competition strategies: (1) The overall design of the code is to train multiple models using different pre-trained transformer models and then combine their predictions using weighted averaging to make the final prediction.\n\n(2) The overall model architecture consists of multiple transformer models, such as Electra, Deberta, BERT, Funnel, Roberta, and ERNIE. Each model is loaded from a pre-trained checkpoint using the AutoModelForSequenceClassification class. The models are then fine-tuned on the training data using a custom loss function (either MSELoss or BCEWithLogitsLoss) and the AdamW optimizer. The models take input sequences encoded by the tokenizer and output a single logit value. The final prediction is obtained by averaging the predictions of all models.\n\n(3) The important hyperparameters in this code are:\n- DEBUG: a boolean flag to control whether to run the code in debug mode or not.\n- SEED: the random seed for reproducibility.\n- MODEL_TYPE: the type of pre-trained transformer model to use.\n- MODEL_PATH: the path to the pre-trained transformer model checkpoint.\n- BATCH_SIZE: the batch size for training and inference.\n- DEVICE: the device to use for training and inference (either 'cuda' or 'cpu').\n- LR: the learning rate for the optimizer.\n- N_WARMUP: the number of warmup steps for the learning rate scheduler.\n- EPOCHS: the number of training epochs.\n\n(4) The optimization objective is to minimize the loss function, which is either the mean squared error (MSE) or the binary cross-entropy with logits (BCEWithLogitsLoss) depending on the training mode.\n\n(5) The advanced machine learning technique used in this code is transfer learning. The code utilizes pre-trained transformer models that have been trained on large-scale language modeling tasks. These models are then fine-tuned on the specific task of predicting a score for phrase-to-phrase matching.\n\n(6) Some important tricks that play a role in achieving high performance include:\n- Using multiple pre-trained transformer models and combining their predictions using weighted averaging.\n- Using different loss functions (MSE and BCEWithLogitsLoss) to train the models.\n- Using a learning rate scheduler (either get_linear_schedule_with_warmup or get_cosine_schedule_with_warmup) to adjust the learning rate during training.\n- Using a custom dataset class (TrainDataset) to preprocess and load the training data efficiently.\n- Using a custom model class (Model) to define the architecture of the transformer models and the loss function.\n- Using a validation function (val_fn) to evaluate the performance of the models on the validation data.\n- Setting random seeds for reproducibility.\n- Using tqdm for progress tracking during training and validation.\n- Saving and loading model checkpoints for later use.", "title": null, "competition_name": null, "task_category": "Regression", "field": "Modeling", "ranking": null, "score": null}, {"content": "High-ranking Kaggle notebooks or competition strategies: (1) The overall design of the code is to generate a high-performing solution for a Kaggle competition. It imports necessary libraries and modules, defines functions for data preprocessing and post-processing, and implements the training process using a combination of different models and techniques.\n\n(2) The overall model architecture consists of multiple models, including 'cp-deberta-xlarge-v2' and 'deberta-bs2'. Each model is loaded from a checkpoint file and fine-tuned for the specific task. The models are based on the DeBERTa architecture, which is a transformer-based model. The input data is tokenized using the AutoTokenizer from the transformers library. The tokenized data is then passed through the backbone model (AutoModel) to obtain the last hidden state. The last hidden state is then passed through dropout layers and a linear layer to obtain the final predictions. The model uses a combination of different dropout rates for regularization.\n\n(3) The important hyperparameters in this code are set in the YAML configuration files for each model. The configuration files specify the model architecture, batch size, maximum sequence length, stride, number of workers, weight, device, model paths, root directory, and other parameters. These hyperparameters can be modified in the configuration files to optimize the model performance.\n\n(4) The optimization objective of this code is to minimize the loss function during the training process. The specific loss function used is not mentioned in the code, but it is likely a standard loss function for multi-class classification tasks, such as cross-entropy loss.\n\n(5) The advanced machine learning technique used in this code is the use of transformer-based models, specifically the DeBERTa architecture. Transformers have been shown to be highly effective for natural language processing tasks, including text classification and sequence labeling. The code also uses techniques such as dropout regularization and data collation for efficient training.\n\n(6) Other important tricks that play a role in high performance include:\n- Thresholding: The code applies thresholding techniques to filter out predictions based on length and probability scores. This helps to improve the precision of the predictions.\n- Word-level predictions: The code processes the predictions at the word level, rather than at the character level, which can improve the accuracy of the predictions.\n- Model fusion: The code combines the predictions from multiple models using weighted fusion techniques, such as weighted boxes fusion (WBF). This helps to leverage the strengths of different models and improve the overall performance.\n- Data preprocessing: The code preprocesses the input data by tokenizing the text and converting it into a suitable format for the models. This ensures that the models can effectively process the data and make accurate predictions.\n- Post-processing: The code applies post-processing techniques, such as merging and thresholding, to refine the predictions and improve their quality.\n\nBy following the code and reproducing the steps described above, another data scientist should be able to exactly reproduce this high-performing solution for the Kaggle competition.", "title": "Not provided", "competition_name": "Not provided", "task_category": "Classification", "field": "Modeling", "ranking": "Not provided", "score": "Not provided"}, {"content": "High-ranking Kaggle notebooks or competition strategies: First of all, thanks to competition organizers for hosting this interesting competition and my teamate @emiria. I learn a lot from emiria's ideas and code. Congrats for emiria's fourth gold medal, a new GM is on the way. And this is my first gold medal of nlp competition.\n\nThe **key points** of our strategy:\n- Add \"prompt_text\" for inputs (0.03 boost on cv)\n- Freezing layers (0.01 boost on cv)\n- Different inputs for blending(0.01 boost on cv)\n- Blending with result of lightgbm(0.005 boost on cv)\n- Focus on local cv (LB only has 13% of data)\n\n**Did not work** for us:\n- AWP\n- SWA\n- Text preprocess\n- MLM\n\n### Models \nHere's the discription of our models we used for finall submissions. We use groupkfold with \"prompt_id\" for local validation, and used all prompts for training when inference.\n| id| backbone | inputs | maxlen| loss | cv |\n| --- | --- |\n| model1 | deberta-v3-large | text+sep+prompt_text+sep+prompt_question| 1280 | mseloss | 0.500|\n| model2 | deberta-v3-large | text+sep+prompt_title+sep+prompt_question+sep+prompt_text| 1280 | mseloss | 0.489|\n| model3 | deberta-v3-large | prompt_title+sep+prompt_question+sep+text+sep+prompt_text| 1280 | mseloss | 0.506|\n| model4 | deberta-v3-large+lgb | prompt_question+sep+text| 512 | mseloss | 0.520|\n| model5 | deberta-v3-large | text+sep+prompt_title+sep+prompt_question+sep+prompt_text| 768 | mseloss | -|\n| model6 | deberta-v3-large | text+sep+prompt_title+sep+prompt_question+sep+prompt_text| 768 | logloss | -|\n| model7 | deberta-large | text+sep+prompt_title+sep+prompt_question+sep+prompt_text| 1024 | mseloss | -|\n\n### Results\nAnd here's our models with best scores:\nEach model is average of 2 seeds, except the \"model4\"(with lightgbm).\n| PB | LB | Picked | models |\n| --- | --- | ---\n| 0.456 | 0.427 | Yes | 0.32\\*model1+0.32\\*model2+0.16\\*model3+0.2\\*model7 |\n| 0.453 | 0.428 | No | 0.32\\*model1+0.32\\*model2+0.16\\*model4+0.1\\*model5+0.1\\*model6|\n", "title": "High-ranking Kaggle notebooks or competition strategies", "competition_name": "Not explicitly mentioned", "task_category": "Classification", "field": "Modeling", "ranking": "Gold medal", "score": {"cv": {"model1": 0.5, "model2": 0.489, "model3": 0.506, "model4": 0.52}, "PB": {"picked_model": 0.456, "not_picked_model": 0.453}, "LB": {"picked_model": 0.427, "not_picked_model": 0.428}}}, {"content": "High-ranking Kaggle notebooks or competition strategies: (1) The overall design of the code is to make predictions on a test dataset using multiple pre-trained models. The code loads the test dataset, preprocesses the text data, and then uses each model to make predictions on the test data. The predictions from each model are then concatenated to form the final predictions.\n\n(2) The overall model architecture is a combination of multiple pre-trained models. Each model is loaded using the AutoModel class from the transformers library. The models are then fine-tuned using a custom model class that includes additional layers for classification. The input text is tokenized using the tokenizer associated with each model, and the tokenized input is passed through the model to obtain the final predictions.\n\n(3) The important hyperparameters in this code are:\n- num_workers: The number of worker processes for data loading.\n- path: The path to the directory containing the pre-trained models.\n- config_path: The path to the configuration file for each model.\n- model: The name of the pre-trained model to use.\n- batch_size: The batch size for inference.\n- fc_dropout: The dropout rate for the fully connected layer.\n- target_size: The size of the target variable.\n- max_len: The maximum length of the input text.\n- trn_fold: The list of fold numbers to use for inference.\n\n(4) The optimization objective is not explicitly mentioned in the code. However, based on the model architecture and the use of the sigmoid function in the inference function, it can be inferred that the optimization objective is binary classification.\n\n(5) The advanced machine learning technique used in this code is transfer learning. The code loads pre-trained models and fine-tunes them on the specific task of binary classification.\n\n(6) Some important tricks that play a role in high performance include:\n- Using multiple pre-trained models: The code uses multiple pre-trained models and combines their predictions to improve performance.\n- Attention mechanism: The code includes an attention mechanism to weight the importance of different parts of the input text.\n- Layer normalization: The code includes layer normalization to improve the stability and performance of the model.\n- Dropout regularization: The code includes dropout regularization to prevent overfitting and improve generalization.\n- Data preprocessing: The code preprocesses the input text by tokenizing it and applying various transformations such as trimming, min-max scaling, and reshaping. These preprocessing steps can help improve the performance of the models.", "title": null, "competition_name": null, "task_category": "Classification", "field": "Modeling", "ranking": null, "score": null}, {"content": "High-ranking Kaggle notebooks or competition strategies: (1) The overall design of the code is to make predictions on a given dataset using multiple pre-trained models and then perform ensemble predictions to improve the overall performance. The code uses different models with different hyperparameters and combines their predictions to generate the final output.\n\n(2) The overall model architecture consists of multiple transformer-based models, such as Longformer, Funnel Transformers, and DeBERTa. Each model is loaded with its pre-trained weights and fine-tuned on the given dataset. The models take input sequences, tokenize them using the AutoTokenizer, and pass them through the transformer layers. The output of the transformer is then passed through a linear layer with softmax activation to generate the final predictions for each token in the input sequence.\n\n(3) The important hyperparameters in this code are set through the `args` classes. These hyperparameters include the input path, model path, model weights, output path, batch size, maximum sequence length, and the folds to be used for training. These hyperparameters are set differently for each model, allowing for flexibility and experimentation.\n\n(4) The optimization objective of this code is to minimize the cross-entropy loss between the predicted labels and the ground truth labels. This is achieved by training the models using the DataLoader and backpropagating the gradients through the model layers. The models are optimized using the Adam optimizer with a learning rate of 1e-5.\n\n(5) The advanced machine learning technique used in this code is ensemble learning. The code combines the predictions of multiple models with different architectures and hyperparameters to improve the overall performance. The predictions from each model are weighted based on their performance and then combined to generate the final output.\n\n(6) Some important tricks that play a role in achieving high performance include:\n- Seed initialization: The `seed_everything` function is used to set the random seed for reproducibility.\n- Tokenization and padding: The input sequences are tokenized using the AutoTokenizer and padded to a maximum length of 4096 tokens.\n- Data parallelism: The code uses multiple workers and parallel processing to speed up the data loading and training process.\n- Gradient accumulation: The code accumulates gradients over multiple batches to reduce memory usage and improve training stability.\n- Half-precision training: The code uses mixed-precision training with automatic mixed precision (AMP) to speed up training and reduce memory usage.\n- Ensemble prediction: The code combines the predictions of multiple models using weighted averaging to improve the overall performance.\n- Post-processing: The code applies post-processing techniques, such as removing certain words and linking adjacent tokens, to refine the final predictions.", "title": null, "competition_name": null, "task_category": "Classification", "field": "Modeling", "ranking": null, "score": null}, {"content": "High-ranking Kaggle notebooks or competition strategies: # 9th Place Solution\n\nFirst and foremost, I'd like to extend my gratitude to the host for organizing this competition. Congratulations to the winners as well! I'd like to present a brief overview of my solution that secured the 9th position.\n\n## Cross-Validation\nThe wording of prompt_id 814d6b stood out, being notably different from other prompt_ids. When cross-validating with groupkfold using the prompt_id, predicting for this particular prompt_id didn't correlate with scores from other prompt_ids. Hypothetically, if there were any test ids with a distribution similar to 814d6b, having 814d6b in the training data might produce decent accuracy. However, there was no way to validate this. For this competition, I employed two methods of cross-validation and submitted for both:\nCross-validation 1: groupkfold (group = prompt_id), excluding 814d6b from evaluation.\nCross-validation 2: groupkfold (group = prompt_id), Including 814d6b in the evaluation.\nThe final private score was better for the model from cross-validation 2, so I'll delve into the details of that model. \nGiven that changing the seed alone resulted in variable CV scores, I performed cross-validation using three different seeds and evaluated the model based on their ensemble. The final submission was based on the predictions of models trained on all the data using three different seeds.\n\n## Training\nI tokenized the text as follows:\ntext1:  summary_text\ntext2: prompt_question + [SEP] + prompt_text\n```\n\ninputs = self.tokenizer.encode_plus(text1,\ntext2,\nadd_special_tokens=True,\nmax_length=self.max_len,\npadding='max_length',\ntruncation=True,\nreturn_token_type_ids=True)\n```\n\nModel: Consisted of two deberta-v3-large and one LSTM as described below:\n- The first deberta-v3-large was trained using the entire input text.\n- The second deberta-v3-large and LSTM were trained solely on the summary_text.\n\n```\n\nmodel_path = \"microsoft/deberta-v3-large\"\nclass CustomModel(nn.Module):\ndef __init__(self):\nsuper(CustomModel, self).__init__()\nself.model = AutoModel.from_pretrained(model_path)\nconfig = AutoConfig.from_pretrained(\nmodel_path, output_hidden_states=True)\nconfig.num_hidden_layers = 6\nself.model2 = DebertaV2Encoder(config)\nself.lstm = nn.LSTM(input_size=1024, hidden_size=1024,\nnum_layers=1, batch_first=True,\nbidirectional=True)\nself.linear1 = nn.Sequential(\nn.Linear(1024*2, 512),\nn.LayerNorm(512),\nn.ReLU(),\nn.Dropout(0.2),\nn.Linear(512, 2))\n\nself.pool = MeanPooling()\n\ndef forward(self, ids, mask, token_type_ids,\ns_mask):\nout = self.model(ids, attention_mask=mask,\ntoken_type_ids=token_type_ids)[\n'last_hidden_state']\ns_mask_len = s_mask.shape[1]\nout = out[:, :s_mask_len, :]\nout = out.contiguous()\nout = self.model2(out, s_mask)[\n'last_hidden_state']\nout_list = []\nfor s in range(len(s_mask)):\ns_mask_ = s_mask[s]\ns_mask_len = torch.sum(s_mask_)\nemb = out[[s], :s_mask_len, :]\ns_mask_ = s_mask_[:s_mask_len].unsqueeze(0)\nemb, _ = self.lstm(emb)\nemb = self.pool(emb, s_mask_)\nout_list.append(emb)\nout_concat = torch.cat(out_list,\naxis=0)\nout_concat = self.linear1(out_concat)\nreturn out_concat\n\n```\n\nTraining settings:\n\n- token_len: 1680\n- epochs: 3\n- Loss: SmoothL1Loss\n- lr: 8e-6\n- optimizer: AdamW\n- weight_decay: 0.01\n- beta: (0.9, 0.98)\n- scheduler: get_linear_schedule_with_warmup\n- num_warmup_steps: 10% of total training steps\n- EMA (Exponential Moving Average)\n- ema_decay: 0.995\n- Using EMA helped stabilize the training.\n\n## Inference\ntoken_len: 4200\n\n## Scores\n- CV: 0.495 (ensemble of 3 seeds)\n- 814d6b: 0.604982\n- ebad26: 0.431438\n- 3b9047: 0.49692\n- 39c16e: 0.483208\n- Public Score: 0.456\n- Private Score: 0.457\n\n## Inference Code", "title": "9th Place Solution", "competition_name": "Not explicitly mentioned", "task_category": "Not explicitly mentioned", "field": "Modeling", "ranking": "9th", "score": {"CV": "0.495 (ensemble of 3 seeds)", "814d6b": "0.604982", "ebad26": "0.431438", "3b9047": "0.49692", "39c16e": "0.483208", "Public Score": "0.456", "Private Score": "0.457"}}, {"content": "High-ranking Kaggle notebooks or competition strategies: First, thanks to all the organizers and kaggle staff and congrats to all the winners and thanks to my amazing teammates @kneroma and @tikutiku !  With this gold medal, @tikutiku and I finally become competition GMs. We have released our code/notebooks:\n\ncode: \n\n2nd logloss notebook: \n\n3rd place efficiency notebook: \n\nBelow is a summary of our solution. Our best private is 0.553 and our best selected private is 0.554. Please feel free to ask if you have any questions.\n\n# Transformer modeling\n\nEach of our team members has their own training pipeline for transformer models. On a high level, our transformer models look at the entirety of each essay and output predictions of effectiveness for each discourse either via pooling of discourse tokens or a classification token added to the front of the each discourse. Importantly, directly inputting essays results in a situation where the model is not 100% sure about where it needs to make predictions, so to circumvent this, we use either a prompt (i.e. concat ```f'({discourse_type} start)'``` and ```f'({discourse_type} end)'``` to the beginning and end of each discourse to signal where predictions need to be made) or simply concat special tokens added to the tokenizer instead (i.e. ```f'<{discourse_type}>'``` and ```f'<{discourse_type}\\>'```). You can find an example below with a highlighted segment.\n\n![example](\n\n## Encoders\n\nDeberta worked the best since (IMO) it supports unlimited input length and uses disentangled attention with relative positional embedding; in fact, our ensemble consists entirely of deberta variants. For me, it was also helpful to add a GRU/LSTM after pooling on the pooled discourse representations. Tom used my SlidingWindowTransformerModel ( from the last Feedback competiion, which stablized training for him.\n\n## Pretraining\n\nKkiller used pretrained weights from his solution in the last competiion ( and Tom and I found pretrained tascj0 models to be good starting points. We used some of the weights that tascj0 released after the last Feedback competition and Tom also pretrained some new ones on his own. Please checkout out tascj0's solution post if you'd like to learn more (\nIn addition, Tom used MLM for some of his models.  Further, some of our models simply used huggingface weights.\n## Max sequence length\n\nI used a max sequence length of 1280 in both training and inference, since I found that 99.9% of discourses fall within that range, whereas my teammates used up to around 1800 during inference and as low as 648 in training.\n\n# Pseudo labeling\nPseudo labeling is an integral part of all our solution. We use essays from the training set of last Feedback competition that are also not present in the training set of this competition. Our procedure is as follows:\n\n1. Train model with gt labels\n2. Make predictions for old data (around 11000 essays) with each fold model\n3. Retrain model with crossentropy on pseudo label probabilities (not discretized) generated by previous model trained on the same fold data: 3 epochs on pl labels only first and then 3 more epochs on gt labels only\n4. Repeat from step 2\n\nFor my pipeline, I saw improvement until 5 rounds of the above procedure. For Tom, it was only helpful for one round and kkiller did not have enough time to try multi-round pl.\n\n# Stacking\n\nStacking provides significantly improvement in both cv/lb (around 0.004). Our stacking framework is primarily inspired by my team's solution ( in the previous feedback competition. In addition to predicted probabilities outputted by the transformer models, we also utilized the token probabilities for each discourse, which we call prob_sequences. Compared to the previous Feedback competition, stacking is much faster since we don't have to deal with a huge amount of candidate sequences. Our features are as follows:\n\n```\n#make features\ndef get_xgb_features(train_df,prob_sequences):\nfeatures2calculate=[f\"instability_{i}\" for i in range(4)]+\\\n[f\"begin_{i}\" for i in range(3)]+\\\n[f\"end_{i}\" for i in range(3)]#+\\\n#[", "tmp=[]\n#quants = np.linspace(0,1,n_quan)\nprob_seq=np.array(prob_seq)\ninstability = []\n#all_quants=[]\ntmp.append(np.diff(prob_seq[:,:],0).mean(0))\ntmp.append([(np.diff(prob_seq[:,[1,2]].sum(1))**2).mean()])\n\ntmp.append(prob_seq[:5,:].mean(0))\ntmp.append(prob_seq[-5:,:].mean(0))\n\ncalculated_features.append(np.concatenate(tmp))\n\ntrain_df[features2calculate]=calculated_features\ntrain_df['len']=[len(s) for s in prob_sequences]\n\ncalculated_features=np.array(calculated_features)\ncalculated_features.shape\n\np_features=[]\nn_features=[]\nneighbor_features=['Ineffective','Adequate','Effective','discourse_type']\nneighbor_features_values=train_df[neighbor_features].values\nfor i in tqdm(range(len(train_df))):\nif i>1 and train_df['essay_id'].iloc[i]==train_df['essay_id'].iloc[i-1]:\np_features.append(neighbor_features_values[i-1])\nelse:\np_features.append(neighbor_features_values[i])\n\nif i<(len(train_df)-1) and train_df['essay_id'].iloc[i]==train_df['essay_id'].iloc[i+1]:\nn_features.append(neighbor_features_values[i+1])\nelse:\nn_features.append(neighbor_features_values[i])\n\ntrain_df[[f\"_previous\" for f in neighbor_features]]=p_features\ntrain_df[[f\"_next\" for f in neighbor_features]]=n_features\n\ntrain_df['mean_Ineffective']=train_df.groupby(\"essay_id\")['Ineffective'].transform(\"mean\")\ntrain_df['mean_Adequate']=train_df.groupby(\"essay_id\")['Adequate'].transform(\"mean\")\ntrain_df['mean_Effective']=train_df.groupby(\"essay_id\")['Effective'].transform(\"mean\")\n\ntrain_df['std_Ineffective']=train_df.groupby(\"essay_id\")['Ineffective'].transform(\"std\")\ntrain_df['std_Adequate']=train_df.groupby(\"essay_id\")['Adequate'].transform(\"std\")\ntrain_df['std_Effective']=train_df.groupby(\"essay_id\")['Effective'].transform(\"std\")\n\ntrain_df['discourse_count']=train_df.groupby(\"essay_id\")['discourse_type'].transform(\"count\")\n\ncnts=train_df.groupby('essay_id')['discourse_type'].apply(lambda x: x.value_counts())\n\n#new_df=[]\ndiscourse_types=['Claim','Evidence','Concluding Statement','Lead','Position','Counterclaim','Rebuttal']\nvalue_count_hash={}\nfor t in discourse_types:\nvalue_count_hash[t]={}\nfor key in cnts.keys():\nvalue_count_hash[key[1]][key[0]]=cnts[key]\n\ndiscourse_cnts=[]    \nfor essay_id in train_df['essay_id'].unique():\nrow=[essay_id]\nfor d in discourse_types:\ntry:\nrow.append(value_count_hash[d][essay_id])\nexcept:\nrow.append(0)\ndiscourse_cnts.append(row)\n\ndiscourse_cnts=pd.DataFrame(discourse_cnts,columns=['essay_id']+[f'{d}_count' for d in discourse types])    \n#discourse_cnts\n\ntrain_df=train_df.merge(discourse_cnts,how='left',on='essay_id')\ntrain_df\n\n#train_df\n\nreturn train_df\n```    \nSince stacking is fast, it works best when we use each fold predictions with xgb separately and then avg. For instance, because I have 6 folds of neural network models and 6 folds of xgb models, this way I have 6x6=36 preds to avg for each single model.\n\n# Best single models\nAll our best single models were deberta-large/deberta-v3-large variants. For Tom and Kkiller, their best single models came from 1st round PL, whereas for me it came from 4th round PL.\n|            | Shujun |  Tom  | Kkiller |\n|:----------:|:------:|:-----:|:-------:|\n|  Public LB |  0.560 | 0.566 |  0.562  |\n| Private LB |  0.558 | 0.571 |  0.562  |\n|  Local CV  |  0.571 |  N/A  |  0.572  |\n# Some more tips/tricks\nFor Tom AWP was useful, and he reported around 0.003 cv improvement with AWP (eps=1e-3 and lr=1e-2 for large models, 1e-4 for xlarge models).\nIt was also important to split the data with ```StratifiedGroupKFold``` instead of ```GroupKFold```. For me I started out with ```GroupKFold``` but found better correlation between cv/lb after switching to ```StratifiedGroupKFold```.\nFor ensembling models with the same cv split, we used GP_minimize to find optimal weights and otherwise weights were determined arbitrarily.\nGradient accumulation was useful since we had to deal with very long sequences.": "extracted title, if available", "competition_name": "Feedback Competition", "task_category": "Classification", "field": "Modeling", "ranking": "Gold Medal", "score": "Private LB: 0.553"}, {"content": "High-ranking Kaggle notebooks or competition strategies: (1) The overall design of this code is to perform inference and ensemble for a Kaggle competition. It consists of three parts: inference for three different models (Tom, Shujun, and Kkiller), and then ensemble the results from these models to generate the final submission.\n\n(2) The overall model architecture is not explicitly mentioned in the code. However, based on the code snippets, it can be inferred that each of the three models (Tom, Shujun, and Kkiller) uses different techniques and architectures for prediction. The code imports various libraries and dependencies, such as pandas, numpy, torch, transformers, and tokenizers, which are commonly used in deep learning and natural language processing tasks. The models might use techniques like transformer-based architectures, tokenization, and neural networks for text classification.\n\n(3) The important hyperparameters in this code are not explicitly mentioned. However, based on the code snippets, some possible hyperparameters that could be set are the weights for each model in the ensemble (sub_params), the version of the transformers library (v_transformers), and the weights assigned to each class in the final submission (cols).\n\n(4) The optimization objective of this code is to generate the best possible submission for the Kaggle competition. The code performs inference using three different models and then combines their predictions through ensemble techniques to generate the final submission. The objective is to maximize the effectiveness of the submission and minimize the errors or inaccuracies in the predictions.\n\n(5) The advanced machine learning technique used in this code is ensemble learning. The code combines the predictions from three different models (Tom, Shujun, and Kkiller) using weighted averaging. Each model's predictions are weighted based on their performance or importance, and the final submission is generated by combining these weighted predictions.\n\n(6) Some important tricks that might play a role in achieving high performance in this code include:\n- Using advanced transformer-based architectures for text classification.\n- Performing tokenization to convert text data into numerical representations.\n- Fine-tuning the pre-trained models on specific tasks or datasets.\n- Using weighted averaging in ensemble learning to combine the predictions from multiple models.\n- Handling missing values in the predictions by filling them with default values.\n- Ensuring that the sum of weights in the ensemble is equal to 1 to maintain the integrity of the final submission.", "title": null, "competition_name": null, "task_category": "Classification", "field": "Modeling", "ranking": null, "score": null}, {"content": "First of all, we would like to thank the competition organizers and the Kaggle platform for hosting such an exciting competition. And I also want to give thanks to my teammates. Without them, I would have given up a week ago and couldn't have leveraged my idea efficiently.\n\nI learned a lot from this competition and acquired some general knowledge that can be applied to other NLP tasks.\n\nWe ended up with 8th place (both on public/private LB) and I'd like to summarize our solution and share some trials that didn’t work for us.\n\nThe inference notebook is available [here](\n\n# Overview\n\nWe used 6 models trained with BCELoss and just averaged with different weights as the ensemble.\n![overview](\n\n# Model\n\n## Token Classification Model\n\n![token_classification_model](\n\nThis competition aims for estimating the semantic similarity between specific word pair (anchor and target) under specific context. There are multiple targets to compare with specific anchor.\n\nSo, we assumed that we could use three kinds of information to predict the similarity.\n\nThey are\n\n1. semantic relativity between anchor and target\n\n2. semantic relativity between word pair and context\n\n3. semantic relativity between targets that are supposed to be compared with same anchor and specific target\n\nWe wrack our brains over and defined the input as below and fed it to the model.\n\n![anchorwise_input](\n\n[TAR] is a special token that we added for letting model recognize the positions of each target tokens.\n\nThis approach made a huge improvement on the score and made train/inference time shorter because the model can infer multiple anchor-target pairs at once.\n\nPublic LB: 0.8380（out of medal zone） -> 0.8535(silver medal zone)\n\nPrivate LB: 0.8526（out of medal zone）  -> 0.8656(silver medal zone)\n\nEDIT: \nI published a notebook for training a token classification model.\n\n## Text Classification Model\n\n![text_classification_model](\n\nWe also trained models as a text classification task. Probably most of the competitors took this approach, but we added a little trick. We used only attention output corresponding to the CLS token. In our experiment, this made the model learn faster and improved the score. Although this model performs lower cv than the token classification model, it contributes the ensembling performance.\n\n# Train\n\n## CV Strategy\n\nWe used StratifiedGroupKFold(n_folds=4) and made train data stratified by score, grouped by anchor.\n\n## Target Shuffle Augmentation\n\nWe defined anchor-wise input that have multiple targets, so we augmented data by shuffling targets every sample. This can prevent the model from memorizing the train samples themselves.\n\n![target_shuffle_aug](\n\n## AWP(Adversarial Weight Perturbation)\n\nThis adversarial training method boosted our CV score. We modified the code of AWP made by @currypurin.\n\nThe hyper parameters are very important. The primary hyper parameter is `adv_lr`.  In past competitions, winners often adjusted `adv_eps`. However, after reading the original paper carefully, we concluded that `adv_lr` is more important.\n\nIn our understanding, `adv_eps` and `adv_lr` can be illustrated as the following figure. (However, we've had some experiences that are a little different from the expected behavior, so there may be a mistake somewhere.)\n\nAWP improved score about 0.005 in the text classification models and about 0.01 in the token classification models.\n\n![awp](\n\n## Hyper Parameters Tuning\n\nThe combination with small batch_size (like `2`) and medium lr (like `1e-5`) performs the best local CV in token classification model. The important combination of parameters was thoroughly explored as following figure.\n\nThis (almost) comprehensive hyper parameter tuning improved score about 0.002.\n\n![hyper_param_tuning1](\n\n![hyper_param_tuning2](\n\n# Inference\n\n## TTA(Test Time Augmentation)\n\nWe further improved the score with TTA. We shuffled the target positions for two times per anchor, just as we did during the training, and took mean value of the two predictions.\nFinally this led us to the gold medal zone; 8th place.\n\n0.8535(silver medal zone) -> 0.8555(gold medal zone)\n\nNote: \nThe scores shown above are accomplished by just a single deberta v3 large model.\n\n## Ensemble with Constrained Least Squares Method\n\nAt the end, we created about 20 trained models. This means we had to optimize the weights for the averaging ensemble. The problem was that we must search for the best weights in almost no time (in fact, we had just about 15 hours left for the deadline when we finally obtained the whole trained models ). Taking this problem into account, we used constrained least squares method. \n\n1.Suppose you want to find the best weights from the following data: y are labels, X are oofs.\n```\ny = np.array([0.5, 0.75, 0.25, 1.0, 0.5])\nX = np.array([\n[0.52, 0.9, 0.41, 0.99, 0.51],\n[0.52, 0.7, 0.41, 0.99, 0.51],\n[0.48, 0.73, 0.12, 0.97, 0.47],\n[0.45, 0.35, 0.25, 0.9, 0.49],\n])\n```\n2.First, let's simply look at the MSE for each row of X.\n```\nnp.square(X - y).mean(axis=1)\n#=> array([0.00974, 0.00574, 0.0039 , 0.03452])\nnp.square(X - y).mean(axis=0).mean(axis=0)\n#=> 0.013475\n```\n3.Then, compute the coefficients with linear regression.\n```\nfrom sklearn.linear_model import LinearRegression\nreg = LinearRegression().fit(X.T, y)\nreg.coef_\n#=> array([ 0.43575566, -0.05397578,  0.46076883,  0.21063718])\nX.T @ reg.coef_\n#=> array([0.51448131, 0.76448131, 0.26448131, 1.01448131, 0.51448131])\nnp.square(X.T @ reg.coef_ - y).mean(axis=0)\n#=> 0.00020970822203200185\n```\nVoila! Unfortunately, some coefficients can have negative values with the vanilla linear regression. Instead, we use the least-squares method with non-negative value constraints.\n4.Fortunately, scipy seems to have a solver for that. Let's find the weights as soon as possible.\n```\nweights, rnorm = scipy.optimize.nnls(X.T, y)\nweights\n# => array([0.29260857, 0.08404164, 0.52487508, 0.12761238])\nX.T @ weights\n# => array([0.50522372, 0.75      , 0.24931469, 0.99686367, 0.50131296])\nnp.square(X.T @ weights - y).mean(axis=0)\n# => 7.863453999510499e-06\n```\nThis method enabled us to easily find the optimal combined weights for ensembling, just within a minute!\n# What didn’t work well\n- increasing the number of TTA\n- adding multi sampled dropout layer\n- Custom Losses\n- optimizing Pearson Loss\n- optimizing MSE loss (although stable)\n- mixed above\n- MLM for patent texts (the size was about 4 million)\n- augmenting data\n- back translation(Japanese, Korean, Chinese, French, German, Spanish)\n- position swapping of anchor and target\n- adding special tokens that denote each context\n- pseudo labeling for the training data\n- increasing n_folds (It worked a little but too computational)\n- other pretrained models\n- AI-Growth-Lab/PatentSBERTa\n- microsoft/deberta-v2-xlarge\n- microsoft/deberta-v2-xxlarge", "title": "Not provided", "competition_name": "Not provided", "task_category": "Classification", "field": "Modeling", "ranking": "8th place", "score": {"public_lb": "0.8535", "private_lb": "0.8656"}}, {"content": "Thank you for hosting this awesome competition and congrats to the winners.\n\nThis problem is interesting and challenging. The data and annotations are high quality. It's a great learning and practicing experience working on this competition.\n\nI started this competition compeletely ignoring those shared NER baselines. I thought in an \"object detection\" task, segmentation + posprocess approaches can not do better than object detection approaches. I'm surprised by the postprocess ideas in top solutions.\n\nOverall, what I made is a YOLO-like text span detector. I share my code in [this notebook](\n\nCheckpoints are shared [here](\n\nTo reproduce the checkpoints, check the code and configs [here](\n\n\n## Modeling\n### Network\n\n```\nAutoModelForTokenClassification.from_pretrained(num_labels=1 + 2 + num_classes, ...)\n```\n\n1 for objectness (or span-ness?. fg/bg classification)\n\n2 for regression (distance from fg location to first and last index of corresponding span)\n\nnum_classes for discourse type classification\n\n### Aggregate tokens to words\n\nNetwork logits is in shape (num_tokens, 10). This is inconvenient (decoding output, ensembling models with different tokenizers). So I aggregate the logits to (num_words, 10) using RoIAlign.\n\n### Training target\n\nThe problem of this formulation is how to define positive for objectness training. In object detection, center of object is a natural choice of positve. In text span detection, I found the first word of span a good choice of positive.\n\nIn addition, I assign lowest cost word in each span as positive during training. This is inspired by YOLOX.\n\n### Augmentation, loss, decoding outputs, etc.\n\nI randomly replace tokens with mask token during training.\n\nFor other details, please check the code.\n\n### Post process\n\nThe only post process is nms.\n\n### Ensemble\n\nI used one cycle policy in training and averaged weights of the last few epochs.\nTo ensemble different models/folds, I simply averaged outputs of models.\nWBF ensemble does not work in local validation, and I didn't figure out why. I think I did something wrong here.\n\n## Results\n| backbone                                           | Validation | Public LB | Private LB |\n|----------------------------------------------------|------------|-----------|------------|\n| google/bigbird-roberta-base                        | 0.685~0.69 |           |            |\n| allenai/longformer-base-4096                       | 0.685~0.69 |           |            |\n| allenai/longformer-large-4096                      | 0.70~0.71  |           |            |\n| microsoft/deberta-base                             | 0.70~0.705 |           |            |\n| microsoft/deberta-large                            | 0.715~0.72 |           |            |\n| microsoft/deberta-xlarge                           | 0.715~0.72 |           |            |\n| microsoft/deberta-large + microsoft/deberta-xlarge | 0.723      | 0.714     | 0.732      |\n\nThe best combination is `deberta-large` + `deberta-xlarge`. Ensembling more does not help.\nIn the final submission, I used 2 weights (2/5 folds) each model. Submission time is around 2 hours.", "title": null, "competition_name": null, "task_category": "Object Detection", "field": "Modeling", "ranking": null, "score": {"Validation": {"google/bigbird-roberta-base": "0.685~0.69", "allenai/longformer-base-4096": "0.685~0.69", "allenai/longformer-large-4096": "0.70~0.71", "microsoft/deberta-base": "0.70~0.705", "microsoft/deberta-large": "0.715~0.72", "microsoft/deberta-xlarge": "0.715~0.72", "microsoft/deberta-large + microsoft/deberta-xlarge": "0.723"}, "Public LB": {"microsoft/deberta-large + microsoft/deberta-xlarge": "0.714"}, "Private LB": {"microsoft/deberta-large + microsoft/deberta-xlarge": "0.732"}}}, {"content": "High-ranking Kaggle notebooks or competition strategies: (1) The overall design of the code is to create a submission file for a Kaggle competition. The code reads in a test dataset, preprocesses the data, and then uses a trained model to make predictions on the test data. The predictions are then post-processed to create the final submission file. (2) The overall model architecture is a transformer-based model. The code uses the AutoModel class from the transformers library to load a pre-trained transformer model. The model is then fine-tuned on the training data using a custom head layer for multi-label classification. The model takes as input the tokenized text and outputs the predicted probabilities for each label. (3) The important hyperparameters in this code are the model checkpoint paths, the maximum length of the input text, the number of jobs for parallel processing, the seed for random number generation, and the probability thresholds and minimum token thresholds for post-processing. (4) The optimization objective is to minimize the loss function during training. The specific loss function used depends on the model architecture and the task being performed. In this code, the loss function is not explicitly defined, but it is likely a multi-label classification loss such as binary cross-entropy or focal loss. (5) The advanced machine learning technique used in this code is transfer learning. The code uses pre-trained transformer models from the Hugging Face transformers library and fine-tunes them on the training data for the specific task of multi-label classification. (6) Some important tricks that play a role in high performance include: - Using an ensemble of multiple models with different architectures and weights. - Using a combination of longformer and LED models for better performance on long texts. - Using LSTM layers in the model architecture to capture sequential information. - Applying post-processing techniques such as probability thresholding and minimum token thresholding to improve the quality of predictions. - Linking adjacent discourse segments to improve the coherence of the predicted labels. - Using a combination of different probability thresholds and minimum token thresholds for different classes to handle class-specific characteristics.", "title": null, "competition_name": null, "task_category": "Multi-label Classification", "field": "Modeling", "ranking": null, "score": null}, {"content": "High-ranking Kaggle notebooks or competition strategies: (1) The overall design of the code is to train a feedback prize effectiveness model using a transformer-based architecture. The code reads in the test data and essay texts, preprocesses the data, tokenizes the input, and creates a dataset for training. It then defines the model architecture, which includes a base transformer model, multi-head attention, and a classification layer. Finally, the code performs inference on the test dataset and saves the predictions.\n\n(2) The overall model architecture consists of a base transformer model, multi-head attention, and a classification layer. The base transformer model is loaded from a pre-trained model checkpoint. The input text is tokenized using the tokenizer, and the tokenized input is passed through the base transformer model to obtain the encoded representations. The encoded representations are then passed through the multi-head attention layer, which attends to different discourse elements in the text. The output of the multi-head attention layer is passed through a classification layer to obtain the final predictions.\n\n(3) The important hyperparameters in this code are specified in the `config` dictionary. These hyperparameters include the model directory, maximum sequence length, stride, number of labels, dropout rate, and batch size.\n\n(4) The optimization objective is to minimize the loss between the predicted labels and the ground truth labels. The loss function used is the cross-entropy loss.\n\n(5) The advanced machine learning technique used in this code is the transformer-based architecture. Transformers have been shown to be highly effective for natural language processing tasks, including text classification.\n\n(6) Some important tricks that play a role in high performance include:\n- Tokenizing the input text to capture the important discourse elements.\n- Using multi-head attention to attend to different discourse elements in the text.\n- Using a pre-trained base transformer model to leverage pre-trained representations.\n- Applying dropout regularization to prevent overfitting.\n- Using a data collator with padding to handle variable-length input sequences.\n- Using a sliding window approach for long input sequences to handle memory constraints.\n- Using a custom data loader to efficiently load and process the data.\n- Using a custom data collector to handle padding and batch processing.\n- Using the Accelerate library for distributed training and inference.\n- Using tqdm for progress tracking during training and inference.\n- Using joblib for parallel processing during data loading.\n- Using pickle for serialization and deserialization of Python objects.\n- Using the textblob library for text processing tasks such as separating POS tags.\n- Using the IPython library for interactive computing and debugging.\n- Using the tokenizers library for tokenization of input text.\n- Using the BERTopic library for topic modeling.\n- Using the BERTopic model for topic modeling.\n- Using the glob library for file path matching.\n- Using the pandas library for data manipulation and analysis.\n- Using the numpy library for numerical computations.\n- Using the torch library for deep learning.\n- Using the torch.nn library for building neural network models.\n- Using the torch.utils.data library for handling datasets.\n- Using the transformers library for pre-trained transformer models.\n- Using the DataCollatorWithPadding class for padding and collating data.\n- Using the LayerNorm class for layer normalization.\n- Using the tqdm.auto library for progress tracking.\n- Using the torch.cuda.empty_cache() function to clear GPU memory.\n- Using the gc.collect() function to perform garbage collection.", "title": "not provided", "competition_name": "Feedback Prize Effectiveness", "task_category": "Classification", "field": "Modeling", "ranking": "not provided", "score": "not provided"}, {"content": "High-ranking Kaggle notebooks or competition strategies: (1) The overall design of the code is to load pre-trained models and tokenizer, define the dataset and model architecture, perform inference on the test data, and post-process the predictions.\n\n(2) The overall model architecture consists of a pre-trained transformer model (such as Electra-Large-Discriminator, Deberta-V3-Large, or BERT-for-Patents) followed by a linear layer. The input to the model is a sequence of tokens, including the anchor text, target text, and context text. The anchor and target texts are concatenated with special tokens, and the context text is appended at the end. The model outputs a single score for each input sequence.\n\n(3) The important hyperparameters in this code are:\n- `num_workers`: Number of workers for data loading.\n- `path`: Path to the pre-trained model and tokenizer.\n- `config_path`: Path to the model configuration file.\n- `model`: Name of the pre-trained model.\n- `ckpt_name`: Name of the checkpoint file.\n- `batch_size`: Batch size for inference.\n- `target_size`: Size of the target variable.\n- `max_len`: Maximum length of the input sequence.\n- `seed`: Random seed for reproducibility.\n- `n_fold`: Number of folds for cross-validation.\n- `tar_token_id`: Token ID for the target token.\n- `tar_token`: Target token.\n- `trn_fold`: List of folds to use for training.\n- `n_augs`: Number of augmentations for test data.\n\n(4) The optimization objective is to minimize the mean squared error between the predicted scores and the ground truth scores.\n\n(5) The advanced machine learning technique used in this code is transfer learning. The code loads pre-trained transformer models (such as Electra-Large-Discriminator, Deberta-V3-Large, or BERT-for-Patents) and fine-tunes them on the given task of predicting scores for patent phrase matching.\n\n(6) Some important tricks that play a role in high performance are:\n- Data augmentation: The code performs data augmentation by shuffling the order of target phrases within each anchor-context pair.\n- Post-processing: The code applies post-processing techniques to the predictions, such as setting the score to 1.0 for anchor-target pairs that are exactly the same, normalizing the score to 1.0 for anchor-target pairs that have the same normalized form, and fitting the score to specific values near 0.0, 0.25, 0.5, 0.75, and 1.0. These post-processing techniques help improve the correlation between the predicted scores and the ground truth scores.", "title": null, "competition_name": "Patent Phrase Matching", "task_category": "Regression", "field": "Modeling", "ranking": null, "score": null}, {"content": "High-ranking Kaggle notebooks or competition strategies: (1) The overall design of the code is to train a model for predicting the content and wording scores of student summaries. It uses a combination of a pre-trained Deberta model and LightGBM for regression. The code also includes data preprocessing steps, feature engineering, and evaluation metrics.\n\n(2) The overall model architecture consists of two parts: a pre-trained Deberta model and LightGBM. The Deberta model is used for sequence classification and is fine-tuned on the training data. The input to the Deberta model is a concatenation of the prompt title, prompt question, and fixed summary text. The output of the Deberta model is then used as input features for the LightGBM model, which performs regression to predict the content and wording scores.\n\n(3) The important hyperparameters in this code are:\n- learning_rate: 1.5e-5\n- weight_decay: 0.02\n- hidden_dropout_prob: 0.007\n- attention_probs_dropout_prob: 0.007\n- num_train_epochs: 5\n- n_splits: 4\n- batch_size: 12\n- random_seed: 42\n- save_steps: 20\n- max_length: 512\n\n(4) The optimization objective is to minimize the root mean squared error (RMSE) between the predicted scores and the true scores.\n\n(5) The advanced machine learning technique used in this code is transfer learning. The Deberta model is pre-trained on a large corpus of text data and then fine-tuned on the specific task of predicting student summary scores.\n\n(6) Some important tricks that play a role in high performance are:\n- Data preprocessing: The code includes various preprocessing steps such as tokenization, spell checking, and feature engineering to improve the quality of the input data.\n- Feature engineering: The code includes several feature engineering techniques such as word overlap count, n-grams co-occurrence, quotes overlap, and grammar check to extract meaningful features from the text data.\n- Ensemble learning: The code combines the predictions of multiple models trained on different folds of the data to improve the overall performance.\n- Hyperparameter tuning: The code uses hyperparameter tuning techniques such as Optuna to find the best set of hyperparameters for the models.", "title": null, "competition_name": null, "task_category": "Regression", "field": "Modeling", "ranking": null, "score": null}]