[
    {
        "idea": "Lag Features with Rolling Means",
        "method": "Create lag features at 7 and 28 days and calculate rolling means over windows of 7 and 28 days.",
        "context": "The notebook creates lag features for sales data at 7 and 28 days and computes rolling means to capture trends and seasonality.",
        "hypothesis": {
            "problem": "Forecasting future sales based on historical sales data.",
            "data": "Sales data has strong seasonal patterns and trends.",
            "method": "Lag features help capture periodic patterns, and rolling means smooth out fluctuations.",
            "reason": "The scenario involves time-series data with seasonality, making lag features and rolling means effective in capturing relevant patterns."
        }
    },
    {
        "idea": "Hierarchical Forecasting",
        "method": "Use categorical features like 'item_id', 'dept_id', 'store_id', etc., to train models at different hierarchical levels.",
        "context": "The notebook uses categorical features in the LightGBM model, allowing it to learn at different hierarchical levels such as item, department, and store.",
        "hypothesis": {
            "problem": "Predicting sales for a hierarchical dataset with multiple levels of aggregation.",
            "data": "Data is structured hierarchically with multiple levels such as items, departments, and stores.",
            "method": "Hierarchical forecasting captures dependencies at different aggregation levels.",
            "reason": "Hierarchical structure in the data allows leveraging relationships across different levels to improve forecasting accuracy."
        }
    },
    {
        "idea": "Poisson Regression Objective",
        "method": "Train LightGBM model using Poisson regression objective for count data.",
        "context": "LightGBM is trained with a Poisson objective function to model sales counts effectively.",
        "hypothesis": {
            "problem": "Forecasting sales counts, which are non-negative integer values.",
            "data": "Sales data is count-based and non-negative.",
            "method": "Poisson regression models count data effectively.",
            "reason": "The count nature of sales data aligns well with the assumptions of Poisson regression, leading to better performance."
        }
    },
    {
        "idea": "Alpha Weighting in Prediction",
        "method": "Adjust predictions using a weighted sum of predictions with different alpha scalars.",
        "context": "The notebook decreases the alpha scalars slightly during prediction to account for trend changes from April to May.",
        "hypothesis": {
            "problem": "Forecasting sales with potential changes in trend patterns.",
            "data": "Sales trends may change over time, requiring adjustments in predictions.",
            "method": "Alpha weighting allows tuning predictions based on observed trend changes.",
            "reason": "Adjustments accommodate potential shifts in trends, which are common in time-series forecasting."
        }
    },
    {
        "idea": "Feature Engineering with Date Attributes",
        "method": "Extract various date attributes such as weekday, month, quarter, year, etc., for feature engineering.",
        "context": "Date attributes are extracted to enhance features for the LightGBM model.",
        "hypothesis": {
            "problem": "Incorporating temporal patterns in sales forecasting.",
            "data": "Sales data are influenced by temporal factors such as day of the week and month.",
            "method": "Date attributes capture temporal influences on sales.",
            "reason": "Temporal attributes help in understanding patterns associated with specific time periods, improving forecast accuracy."
        }
    },
    {
        "idea": "Random Sampling for Validation Set",
        "method": "Randomly sample a subset of training data as a fake validation set for model training.",
        "context": "A random sample of 2,000,000 records is used as a validation set during LightGBM training.",
        "hypothesis": {
            "problem": "Need for validation set when time-series split is not applicable.",
            "data": "Large dataset allows random sampling without significant loss of information.",
            "method": "Random sampling provides a quick way to get a validation set without strict time-series splitting.",
            "reason": "Random sampling is suitable when there's no strong temporal dependence that needs to be preserved during validation."
        }
    }
]