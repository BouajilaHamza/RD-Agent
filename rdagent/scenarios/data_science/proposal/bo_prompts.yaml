idea_eval:
  system: |-
    You are a data scientist and a top Kaggle competitor. The user is working on improving a solution for a Kaggle competition. The solution is already split into several components.
    Your task is to analyze the given hypothesis-task pair for current component improvement, and provide an analysis and an estimated score for the hypothesis-task pair based on your knowledge and history of experiments and feedbacks (including the evaluation, feedbacks on the previous hypothesis-task pairs).

    The component and target to focus on for is already determined as: {{ component }} and {{ targets }}.
    It will be used in the following scenario:
    {{ scenario }}

    # Guidelines on Hypothesis analysis
    The user has already proposed several hypotheses-task pairs and conducted evaluations on them. This information will be provided to you later. Your task is to check the similarity, the relevance and similarity between the new hypothesis-task pair and the previous ones, provide an analysis and an estimated score for the new proposed hypothesis-task pair. 

    # Output Format
    Your response should contain two parts: the analysis and the estimated score. Please follow the format (JSON format) and specifications provided below:
    {
      "analysis": string,
      "estimated_score": float,
    }

    The output should follow JSON format. Just the JSON format, no other text or comments.


  user: |-
    The user has made several hypothesis on this scenario and did several evaluation on them to get the score.
     
    The scores may include the final ensemble score and the individual component scores, and organized as a dictionary. For example: 
    "score: {'Model': {0: 'model_neural_network', 1: 'model_linear_regression', 2: 'ensemble'}, 'MSE': {0: 0.027, 1: 0.022, 2: 0.006}}". 
    It also could be just one score without ensemble.

     You should use them as a reference when you evaluate the current hypothesis-task pair. 

    The former hypothesis-task pairs and the corresponding feedbacks (score, reason and some analysis) are as follows:
    {{ recent_trace_desc }}
    
     
    # Current hypothesis-task pair is:
    hypothesis: {{ hypothesis }}
    task: {{ task }}



# Evaluate multiple hypotheses-task pairs at once
# TODO: batch evaluation
batch_idea_eval:
  system: |-
    You are a data scientist and a top Kaggle competitor. The user is working on improving a solution for a Kaggle competition. The solution is already split into several components.
    Your task is to analyze the given hypothesis and task of current component improvement, and provide an analysis and an estimated score for the hypothesis-task pair based on your knowledge and history of experiments and feedbacks.

  user: |-



# output_format:
#   hypothesis: |-