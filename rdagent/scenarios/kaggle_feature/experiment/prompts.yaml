kg_description_template:
  system: |-
    You are an assistant that extracts structured information from unstructured text.

  user: |-
    Based on the following competition description, please extract the following details:
    1. Competition Type
    2. Competition Description
    3. Target Description
    4. Competition Features

    Competition Description: {{ competition_descriptions }}

kg_feature_background: |-
  You are solving this data science tasks of {{ competition_type }}: 
  {{competition_description}}
  
  We provide an overall pipeline in train.py. Now fill in the provided train.py script to do the feature engineering to get a good performance on this task.
  
  The model is a machine learning or deep learning structure designed to predict {{ target_description }}. 
  The data is extracted from the competition dataset, focusing on relevant attributes like {{ competition_features }}.
  Data preprocessing is a crucial step in the data analysis pipeline, involving the transformation and preparation of raw data into a suitable format for further analysis or modeling.
  This process is essential to enhance the quality of data and to ensure the accuracy of the results obtained from analytical models
  Effective preprocessing improves data quality and model accuracy.
  Data preprocessing typically includes some of teh several key activities: Data Cleaning, Data Creation, Data Integration, Data Transformation, Data Reduction, Data Discretization and so on.
  
  The preprocessing method is defined in the following parts:
  1. Name: Unique identifier for the data preprocessing method.
  2. Description: The description of the method.
  3. Code: The code of the preprocessing method.
  4. Variables: The steps or functions used for this data preprocessing method.
  
  The method might not provide all the parts of the information above since some might not be applicable.
  Please specifically give all the hyperparameters in the method like Learning Rate, Regularization parameter, Threshold, etc., if needed. 
  One method should statically define one output with a fixed hyperparameter. 
  For example, a method with a learning rate of 0.01 and a method with a learning rate of 0.1 should be considered two different methods.

kg_feature_interface: |-
  Your python code should follow the interface to better interact with the user's system.
  You code should contain several parts:
  1. The import part: import the necessary libraries.
  2. A class that is a subclass of xgboost. This class should have an __init__ function and a forward function, which inputs a tensor and outputs a tensor.
  3. Set a variable called "model_cls" to the class you defined.

  The user will save your code into a python file called "model.py". Then the user imports model_cls in file "model.py" after setting the cwd into the directory:
  ```python
  from model import get_params, get_num_round
  ```
  So your python code should follow the pattern:
  ```python
  def get_params():
    params = {
      ...
    }
    return params
  def get_num_round():
    return xxx
  ```

  The model has one types,  "XGBoost" for XGBoost model.
  The XGBoost Model leverages two critical hyperparameters: "arams" and "num_round".
  "params": This hyperparameter encapsulates various settings that dictate the model's behavior and learning process.
  "num_round": This hyperparameter specifies the number of training iterations the model will undergo.
  User will initialize the XGBoost model with the following code:
  ```python
  params = get_params()
  num_round = get_num_round()
  ```
  No other parameters will be passed to the model so give other parameters a default value or just make them static.

  Don't write any try-except block in your python code. The user will catch the exception message and provide the feedback to you. Also, don't write main function in your python code. The user will call the forward method in the model_cls to get the output tensor.

  Please notice that your model should only use current features as input. The user will provide the input tensor to the model's forward function.


kg_feature_output_format: |-
  The output format should be tailored to the specific task at hand. Depending on the requirements:
  - The output can be a single feature table or a composite table consisting of multiple processed features.
  - Include necessary transformations, such as normalization or other adjustments, to ensure compatibility with the model.
  - The choice of output format should be based on the specific task's objectives and the nature of the data.
  
kg_feature_simulator: |-
  The data preprocessing method you provide will be used to prepare data by processing it, concatenating the results with other features, and removing unnecessary features before training the model. 
  The processed data will then be used for model training and prediction.
  The processed data will be sent into a model to train and predict.
  
  User will use your data preprocessing method to do the following steps:
  1. Execute your Python file to process the data.
  2. Concatenate the processed features with other features and the original data.
  3. Remove any unnecessary features before training the model.
  4. Train a model such as LightGBM, CatBoost, LSTM, or a simple PyTorch model using the processed data.
  5. Evaluate the performance of your preprocessing method and provide feedback.