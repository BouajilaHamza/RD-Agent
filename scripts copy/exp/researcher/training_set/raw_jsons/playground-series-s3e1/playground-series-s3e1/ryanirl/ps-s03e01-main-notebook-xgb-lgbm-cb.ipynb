{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import matplotlib.pyplot as plt\nfrom tqdm.notebook import tqdm\nimport pandas as pd\nimport numpy as np\nimport warnings\nimport glob\nimport math\nimport json\nimport sys\nimport os\n\nwarnings.filterwarnings(\"ignore\")\n\nfrom sklearn.datasets import fetch_california_housing\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import KFold\n\nfrom sklearn.metrics.pairwise import haversine_distances\nfrom sklearn.metrics import mean_squared_error\n\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.ensemble import IsolationForest\nfrom sklearn.neighbors import NearestNeighbors\nfrom sklearn.decomposition import PCA\n\nimport lightgbm as lgbm\nimport xgboost as xgb\nimport catboost\n\n%matplotlib inline","metadata":{"execution":{"iopub.status.busy":"2023-01-13T22:01:58.796468Z","iopub.execute_input":"2023-01-13T22:01:58.796993Z","iopub.status.idle":"2023-01-13T22:02:01.482036Z","shell.execute_reply.started":"2023-01-13T22:01:58.796863Z","shell.execute_reply":"2023-01-13T22:02:01.481107Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_dir = \"/kaggle/input/playground-series-s3e1/\"\ncity_dir = \"/kaggle/input/uscities/\"\n\nvalidation = False\n\nXGB = True\nLGBM = True\nCATBOOST = True\n\nFOLDS = 10\n\nprint(os.listdir(data_dir))","metadata":{"execution":{"iopub.status.busy":"2023-01-13T22:02:01.484003Z","iopub.execute_input":"2023-01-13T22:02:01.484635Z","iopub.status.idle":"2023-01-13T22:02:01.492523Z","shell.execute_reply.started":"2023-01-13T22:02:01.484599Z","shell.execute_reply":"2023-01-13T22:02:01.49099Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_test              = pd.read_csv(os.path.join(data_dir, \"test.csv\"))\ndf_train             = pd.read_csv(os.path.join(data_dir, \"train.csv\"))\ndf_sample_submission = pd.read_csv(os.path.join(data_dir, \"sample_submission.csv\"))","metadata":{"execution":{"iopub.status.busy":"2023-01-13T22:02:01.49463Z","iopub.execute_input":"2023-01-13T22:02:01.495037Z","iopub.status.idle":"2023-01-13T22:02:01.734699Z","shell.execute_reply.started":"2023-01-13T22:02:01.494991Z","shell.execute_reply":"2023-01-13T22:02:01.733365Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Load the original dataset.\noriginal = fetch_california_housing()\n\ndf_original = pd.DataFrame(\n    original[\"data\"], \n    columns = original[\"feature_names\"]\n)\n\ndf_original[\"MedHouseVal\"] = original[\"target\"]","metadata":{"execution":{"iopub.status.busy":"2023-01-13T22:02:01.737613Z","iopub.execute_input":"2023-01-13T22:02:01.738013Z","iopub.status.idle":"2023-01-13T22:02:05.933508Z","shell.execute_reply.started":"2023-01-13T22:02:01.737962Z","shell.execute_reply":"2023-01-13T22:02:05.932123Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Feature engineering functions.\n\ndf_cities = pd.read_csv(os.path.join(city_dir, \"uscities.csv\"))\n\ncolumns = [\"city\", \"lat\", \"lng\", \"density\", \"state_name\", \"population\"]\n\ndf_cities = df_cities[columns]\ndf_cities = df_cities[df_cities[\"state_name\"] == \"California\"].reset_index(drop = True)\n\ndf_cities = df_cities[df_cities[\"population\"] > 500_000]\n\ndef compute_distance(loc1, loc2):\n    loc1 = [math.radians(x) for x in loc1]\n    loc2 = [math.radians(x) for x in loc2]\n    \n    result = haversine_distances([loc1, loc2])\n    \n    return (result * (6371000 / 1000))[0][1]\n\ndef add_distance_features(df):\n    for city in tqdm(df_cities[\"city\"].unique()):\n        lon_lat = df_cities[df_cities[\"city\"] == city][[\"lng\", \"lat\"]].values.tolist()[0]\n        \n        df[f\"to_{city}\"] = df.apply(lambda t: compute_distance((t[\"Longitude\"], t[\"Latitude\"]), lon_lat), axis = 1) \n        \n    return df\n\ndef exp_features(df):\n    emb_size = 20\n    precision = 1e6 \n    \n    coordinates = df[[\"Latitude\", \"Longitude\"]]\n\n    latlon = np.expand_dims(coordinates, axis = -1) \n\n    m = np.exp(np.log(precision) / emb_size) \n    angle_freq = m ** np.arange(emb_size) \n    angle_freq = angle_freq.reshape(1, 1, emb_size) \n\n    latlon = latlon * angle_freq \n    latlon[..., 0::2] = np.cos(latlon[..., 0::2]) \n    latlon[..., 1::2] = np.sin(latlon[..., 1::2]) \n    latlon = latlon.reshape(-1, 2 * emb_size) \n\n    df[\"exp_latlon1\"] = [lat[0] for lat in latlon]\n    df[\"exp_latlon2\"] = [lat[1] for lat in latlon]\n    \n    return df\n\ndef distance_coastline_feature(df):\n    # Reads California coastline coordinates.\n    # (https://earthworks.stanford.edu/catalog/stanford-vx275xn8886) @kaivanbrunt\n    path = r\"/kaggle/input/coastlinedata/try.json\"\n    with open(path, \"r\") as f:\n        coastline = json.load(f)\n        features = coastline[\"features\"]\n\n    # Unpacks California coastline coordinates and builds a dataframe. shape = (25693, 2) \n    cstl_coords = [features[i][\"geometry\"][\"coordinates\"] for i in range(len(features))]\n    cstl_coords = np.hstack(cstl_coords).reshape((-1, 2))\n    cstl_df = pd.DataFrame(cstl_coords, columns = [\"Longitude\", \"Latitude\"])\n\n    # Maybe find the haversine distance.\n    # Finds the shortest distance to the coastline (Euclidian Distance).\n    def f(lat, lon, df):\n        return (((df.Latitude - lat) ** 2 + (df.Longitude - lon) ** 2) ** 0.5).min()\n\n    df[\"dist_to_cstl\"] = df.apply(lambda x: f(x.Latitude, x.Longitude, cstl_df), axis = 1)\n    \n    return df\n\ndef pca_coords(df):\n    coordinates = df[[\"Latitude\", \"Longitude\"]]\n    \n    pca_obj = PCA().fit(coordinates.values)\n    \n    df[\"pca_lat\"] = pca_obj.transform(coordinates)[:, 0]\n    df[\"pca_lon\"] = pca_obj.transform(coordinates)[:, 1]\n    \n    return df\n\ndef polar_coords(df):\n    df[\"r\"] = np.sqrt(df[\"Latitude\"] ** 2 + df[\"Longitude\"] ** 2)\n    df[\"theta\"] = np.arctan2(df[\"Latitude\"], df[\"Longitude\"])\n\n    return df\n\ndef rotate_coords(df): \n    \n    df[\"rot_15_x\"] = (np.cos(np.radians(15)) * df[\"Longitude\"]) + \\\n                     (np.sin(np.radians(15)) * df[\"Latitude\"])\n    \n    df[\"rot_15_y\"] = (np.cos(np.radians(15)) * df[\"Latitude\"]) - \\\n                     (np.sin(np.radians(15)) * df[\"Longitude\"])\n    \n    df[\"rot_30_x\"] = (np.cos(np.radians(30)) * df[\"Longitude\"]) + \\\n                     (np.sin(np.radians(30)) * df[\"Latitude\"])\n    \n    df[\"rot_30_y\"] = (np.cos(np.radians(30)) * df[\"Latitude\"]) - \\\n                     (np.sin(np.radians(30)) * df[\"Longitude\"])\n    \n    df[\"rot_45_x\"] = (np.cos(np.radians(45)) * df[\"Longitude\"]) + \\\n                     (np.sin(np.radians(45)) * df[\"Latitude\"])\n    \n    df[\"rot_45_y\"] = (np.cos(np.radians(45)) * df[\"Latitude\"]) - \\\n                     (np.sin(np.radians(45)) * df[\"Longitude\"])\n\n    return df\n","metadata":{"execution":{"iopub.status.busy":"2023-01-13T22:02:05.935786Z","iopub.execute_input":"2023-01-13T22:02:05.936287Z","iopub.status.idle":"2023-01-13T22:02:06.183258Z","shell.execute_reply.started":"2023-01-13T22:02:05.936243Z","shell.execute_reply":"2023-01-13T22:02:06.181981Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def build_features(df):\n    df = exp_features(df)\n    df = rotate_coords(df)\n    df = polar_coords(df)\n    df = pca_coords(df)\n    df = distance_coastline_feature(df)\n    df = add_distance_features(df)\n    \n    return df\n\n\ndf_original[\"is_generated\"] = 0\ndf_train[\"is_generated\"] = 1\ndf_test[\"is_generated\"] = 1\n\ndf_train = pd.concat([\n    df_train.drop(\"id\", axis = 1), \n    df_original\n]).reset_index(drop = True)\n\ndf_train = build_features(df_train)\ndf_test  = build_features(df_test)","metadata":{"execution":{"iopub.status.busy":"2023-01-13T22:02:06.185103Z","iopub.execute_input":"2023-01-13T22:02:06.18547Z","iopub.status.idle":"2023-01-13T22:04:03.429351Z","shell.execute_reply.started":"2023-01-13T22:02:06.185438Z","shell.execute_reply":"2023-01-13T22:04:03.428086Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"features = [column for column in df_train.columns if column not in [\"MedHouseVal\", \"id\"]]\n\ntarget = \"MedHouseVal\"","metadata":{"execution":{"iopub.status.busy":"2023-01-13T22:04:03.431045Z","iopub.execute_input":"2023-01-13T22:04:03.432219Z","iopub.status.idle":"2023-01-13T22:04:03.43866Z","shell.execute_reply.started":"2023-01-13T22:04:03.432155Z","shell.execute_reply":"2023-01-13T22:04:03.4371Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_X = df_train[features]\ndf_y = df_train[target]","metadata":{"execution":{"iopub.status.busy":"2023-01-13T22:04:03.440213Z","iopub.execute_input":"2023-01-13T22:04:03.44098Z","iopub.status.idle":"2023-01-13T22:04:03.462384Z","shell.execute_reply.started":"2023-01-13T22:04:03.440934Z","shell.execute_reply":"2023-01-13T22:04:03.461164Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if validation:\n    X_train, X_test, y_train, y_test = train_test_split(\n        df_X, \n        df_y, \n        train_size = 0.8, \n        test_size = 0.2, \n        random_state = 42,\n        shuffle = True\n    )\n    \n    indices = (X_test[\"is_generated\"] == 1)\n    X_test = X_test[indices]\n    y_test = y_test[indices]\nelse:\n    X_train = df_X\n    y_train = df_y","metadata":{"execution":{"iopub.status.busy":"2023-01-13T22:04:03.46446Z","iopub.execute_input":"2023-01-13T22:04:03.464902Z","iopub.status.idle":"2023-01-13T22:04:03.471731Z","shell.execute_reply.started":"2023-01-13T22:04:03.464866Z","shell.execute_reply":"2023-01-13T22:04:03.470728Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if XGB:\n    xgb_params = {\n        'max_depth': 9,\n        'eta': 0.01,\n        'colsample_bytree': 0.66,\n        'subsample': 0.76,\n        'min_child_weight': 22,\n        'lambda': 16, \n        'gamma': 1,\n\n        'tree_method': 'hist',\n        'booster': 'gbtree',\n        'predictor':'cpu_predictor',\n        'seed': 42,\n        'objective': 'reg:squarederror',\n        'eval_metric': 'rmse'\n    }\n    \n    skf = KFold(\n        n_splits = FOLDS, \n        random_state = 1, \n        shuffle = True\n    )\n\n    skf.get_n_splits(X_train, y_train)\n\n    xgb_scores = []\n    xgb_models = []\n    for i, (train_index, test_index) in enumerate(skf.split(X_train, y_train)):\n        valid_x = X_train.iloc[test_index]\n        valid_y = y_train.iloc[test_index]\n        \n        indices = (valid_x[\"is_generated\"] == 1)\n        valid_x = valid_x[indices]\n        valid_y = valid_y[indices]\n\n        xgb_train = xgb.DMatrix(\n            X_train.iloc[train_index], \n            label = y_train.iloc[train_index],\n        )\n\n        xgb_valid = xgb.DMatrix(\n            valid_x,\n            label = valid_y,   \n        )\n\n        watchlist = [(xgb_train, \"train\"), (xgb_valid, \"eval\")]\n\n        model = xgb.train(\n            params = xgb_params, \n            dtrain = xgb_train, \n            num_boost_round = 50000,\n            evals = watchlist, \n            verbose_eval = 1000,\n            callbacks = [\n                xgb.callback.EarlyStopping(\n                    rounds = 1000,\n                    data_name = \"eval\",\n                    maximize = False,\n                    save_best = True\n                )\n            ]\n        )\n\n        val_preds = model.predict(xgb_valid)\n        val_score = mean_squared_error(\n            valid_y, \n            val_preds, \n            squared = False\n        )\n        \n        print(\n            model.predict(\n                xgb.DMatrix(\n                    df_test.loc[:, (df_test.columns != \"id\")]\n                )\n            )\n        )\n\n        xgb_scores.append(val_score)\n        xgb_models.append(model)\n\n        print(f\"Score: {val_score}\")\n        print(\"-\" * 10)","metadata":{"execution":{"iopub.status.busy":"2023-01-13T22:04:03.475523Z","iopub.execute_input":"2023-01-13T22:04:03.476193Z","iopub.status.idle":"2023-01-13T22:19:31.573925Z","shell.execute_reply.started":"2023-01-13T22:04:03.47614Z","shell.execute_reply":"2023-01-13T22:19:31.572753Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if validation and XGB:\n    indices = (X_test[\"is_generated\"] == 1)\n    X_test = X_test[indices]\n    y_test = y_test[indices]\n    \n    xgb_test = xgb.DMatrix(\n        X_test\n    )\n\n    predictions = []\n    for model in xgb_models:\n        predictions.append(model.predict(xgb_test))\n\n    print(mean_squared_error(y_test, np.mean(predictions, axis = 0), squared = False))\n\n# 0.5380623336060028","metadata":{"execution":{"iopub.status.busy":"2023-01-13T22:19:31.578326Z","iopub.execute_input":"2023-01-13T22:19:31.579125Z","iopub.status.idle":"2023-01-13T22:19:31.589534Z","shell.execute_reply.started":"2023-01-13T22:19:31.57908Z","shell.execute_reply":"2023-01-13T22:19:31.588322Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if LGBM:\n    skf = KFold(\n        n_splits = FOLDS, \n        random_state = 1, \n        shuffle = True\n    )\n    \n    params = {\n        'n_estimators': 1000, \n        'reg_lambda': 0.8435272531761764, \n        'reg_alpha': 0.0047770992003183695, \n        'colsample_bytree': 0.5, \n        'learning_rate': 0.01, \n        'subsample': 0.8, \n        'max_depth': 100, \n        'min_child_samples': 194, \n        'num_leaves': 894\n    }\n    \n    skf.get_n_splits(X_train, y_train)\n\n    lgbm_scores = []\n    lgbm_models = []\n    for i, (train_index, test_index) in enumerate(skf.split(X_train, y_train)):\n        valid_x = X_train.iloc[test_index]\n        valid_y = y_train.iloc[test_index]\n        \n        indices = (valid_x[\"is_generated\"] == 1)\n        valid_x = valid_x[indices]\n        valid_y = valid_y[indices]\n\n        model = lgbm.LGBMRegressor(**params)\n        model.fit(\n            X_train.iloc[train_index], \n            y_train.iloc[train_index],\n            eval_set=[(\n                valid_x,\n                valid_y \n            )],\n            early_stopping_rounds = 100,\n            verbose = False\n        )\n        \n        preds = model.predict(valid_x)\n        \n        rmse = mean_squared_error(\n            valid_y, \n            preds,\n            squared = False\n        )\n        \n        print(rmse)\n        \n        lgbm_scores.append(rmse)\n        lgbm_models.append(model)","metadata":{"execution":{"iopub.status.busy":"2023-01-13T22:19:31.590794Z","iopub.execute_input":"2023-01-13T22:19:31.591424Z","iopub.status.idle":"2023-01-13T22:22:29.316684Z","shell.execute_reply.started":"2023-01-13T22:19:31.591389Z","shell.execute_reply":"2023-01-13T22:22:29.31577Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if validation and LGBM:\n    indices = (X_test[\"is_generated\"] == 1)\n    X_test = X_test[indices]\n    y_test = y_test[indices]\n    \n    predictions = []\n    for model in lgbm_models:\n        predictions.append(model.predict(X_test))\n        \n    rmse = mean_squared_error(\n        y_test, \n        np.mean(predictions, axis = 0), \n        squared = False\n    )\n    \n    print(rmse)\n    \n# 0.5424722699766628 | Hyperparameter opt with 5 folds. \n# | 0.5383166352453341","metadata":{"execution":{"iopub.status.busy":"2023-01-13T22:22:29.318154Z","iopub.execute_input":"2023-01-13T22:22:29.318806Z","iopub.status.idle":"2023-01-13T22:22:29.3259Z","shell.execute_reply.started":"2023-01-13T22:22:29.318769Z","shell.execute_reply":"2023-01-13T22:22:29.32487Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if CATBOOST:\n    params = {\n        \"random_seed\": 1234,    \n        \"iterations\": 15000,\n        \"early_stopping_rounds\": 1000,\n        \"use_best_model\": True,\n        \"eval_metric\": 'RMSE',\n        \"verbose\": 1000\n    }\n    \n    skf = KFold(\n        n_splits = FOLDS, \n        random_state = 1, \n        shuffle = True\n    )\n\n    skf.get_n_splits(X_train, y_train)\n\n    catboost_scores = []\n    catboost_models = []\n    for i, (train_index, test_index) in enumerate(skf.split(X_train, y_train)):\n        valid_x = X_train.iloc[test_index]\n        valid_y = y_train.iloc[test_index]\n        \n        indices = (valid_x[\"is_generated\"] == 1)\n        valid_x = valid_x[indices]\n        valid_y = valid_y[indices]\n\n        model = catboost.CatBoostRegressor(**params)\n        model.fit(\n            X_train.iloc[train_index], \n            y_train.iloc[train_index],\n            eval_set=[(\n                valid_x,\n                valid_y \n            )],\n            early_stopping_rounds = 100,\n            verbose = 1000\n        )\n        \n        preds = model.predict(valid_x)\n        \n        rmse = mean_squared_error(\n            valid_y, \n            preds,\n            squared = False\n        )\n        \n        print(rmse)\n        \n        catboost_scores.append(rmse)\n        catboost_models.append(model)","metadata":{"execution":{"iopub.status.busy":"2023-01-13T22:22:29.327534Z","iopub.execute_input":"2023-01-13T22:22:29.328773Z","iopub.status.idle":"2023-01-13T22:29:15.359882Z","shell.execute_reply.started":"2023-01-13T22:22:29.328658Z","shell.execute_reply":"2023-01-13T22:29:15.358623Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if validation and CATBOOST:\n    indices = (X_test[\"is_generated\"] == 1)\n    X_test = X_test[indices]\n    y_test = y_test[indices]\n    \n    predictions = []\n    for model in catboost_models:\n        predictions.append(model.predict(X_test))\n        \n    rmse = mean_squared_error(\n        y_test, \n        np.mean(predictions, axis = 0), \n        squared = False\n    )\n    \n    print(rmse)\n    \n# 0.5424722699766628 | Hyperparameter opt with 5 folds. \n# 0.5418564539103299","metadata":{"execution":{"iopub.status.busy":"2023-01-13T22:29:15.361526Z","iopub.execute_input":"2023-01-13T22:29:15.362007Z","iopub.status.idle":"2023-01-13T22:29:15.370051Z","shell.execute_reply.started":"2023-01-13T22:29:15.361958Z","shell.execute_reply":"2023-01-13T22:29:15.368714Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if validation and (CATBOOST and XGB and LGBM):\n    indices = (X_test[\"is_generated\"] == 1)\n    X_test = X_test[indices]\n    y_test = y_test[indices]\n    \n    predictions = []\n    for model in catboost_models:\n        predictions.append(model.predict(X_test))\n    \n    for model in xgb_models:\n        predictions.append(\n            model.predict(\n                xgb.DMatrix(X_test)\n            )\n        )\n    \n    for model in lgbm_models:\n        predictions.append(model.predict(X_test))\n        \n    rmse = mean_squared_error(\n        y_test, \n        np.mean(predictions, axis = 0), \n        squared = False\n    )\n    \n    print(rmse)\n    \n# 0.5424722699766628 | Hyperparameter opt with 5 folds. ","metadata":{"execution":{"iopub.status.busy":"2023-01-13T22:29:15.371477Z","iopub.execute_input":"2023-01-13T22:29:15.371829Z","iopub.status.idle":"2023-01-13T22:29:15.382865Z","shell.execute_reply.started":"2023-01-13T22:29:15.371788Z","shell.execute_reply":"2023-01-13T22:29:15.381748Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if not validation:\n    predictions = []\n    \n    if XGB:\n        xgb_test = xgb.DMatrix(\n            df_test.drop(\"id\", axis = 1)\n        )\n\n        xgb_predictions = []\n        for model in xgb_models:\n            pred = model.predict(xgb_test)\n            \n            print(pred[-5:])\n            \n            xgb_predictions.append(pred)\n        \n        predictions.append(np.mean(xgb_predictions, axis = 0))\n    \n    if LGBM:\n        lgbm_predictions = []\n        for model in lgbm_models:\n            pred = model.predict(\n                df_test.drop(\"id\", axis = 1)\n            )\n            \n            print(pred[-5:])\n            \n            lgbm_predictions.append(pred)\n        \n        predictions.append(np.mean(lgbm_predictions, axis = 0))\n        \n    if CATBOOST:\n        catboost_predictions = []\n        for model in catboost_models:\n            pred = model.predict(\n                df_test.drop(\"id\", axis = 1)\n            )\n            \n            print(pred[-5:])\n            \n            catboost_predictions.append(pred)\n        \n        predictions.append(np.mean(catboost_predictions, axis = 0))","metadata":{"execution":{"iopub.status.busy":"2023-01-13T22:29:15.384239Z","iopub.execute_input":"2023-01-13T22:29:15.384565Z","iopub.status.idle":"2023-01-13T22:29:41.610957Z","shell.execute_reply.started":"2023-01-13T22:29:15.384534Z","shell.execute_reply":"2023-01-13T22:29:41.610062Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if not validation:\n    preds = np.mean(predictions, axis = 0)\n    \n    print(preds)\n    \n    df_test[\"MedHouseVal\"] = preds\n        \n    submission = df_test[[\"id\", \"MedHouseVal\"]]\n    \n    # https://www.kaggle.com/competitions/playground-series-s3e1/discussion/376396\n    submission.MedHouseVal.clip(0, 5, inplace = True)\n\n    submission.to_csv(\"submission.csv\", index = False)\n    \n    print(submission.head())\n    print(submission.tail())","metadata":{"execution":{"iopub.status.busy":"2023-01-13T22:29:41.612251Z","iopub.execute_input":"2023-01-13T22:29:41.612733Z","iopub.status.idle":"2023-01-13T22:29:41.690366Z","shell.execute_reply.started":"2023-01-13T22:29:41.612702Z","shell.execute_reply":"2023-01-13T22:29:41.689001Z"},"trusted":true},"execution_count":null,"outputs":[]}]}