{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"##  Employee Attrition Prediction with DNN\nIn this notebook, I will create Employee Attrition Prediction Models using DNN with Employee Attrition Dataset in [Playground Series Season 3, Episode 3 Competition](https://www.kaggle.com/competitions/playground-series-s3e3) and [IBM HR Analytics Employee Attrition & Performance](https://www.kaggle.com/datasets/pavansubhasht/ibm-hr-analytics-attrition-dataset). I will do Exploratory Data Analaysis to divide these features into categorical features and numerical features and also select correlated features. I will train models for 5 folds using StratifiedKFold split strategy with different random seeds. To maximize CV, I will search best model using KerasTuner for different folds and retrain the model for more epochs and  select best model among them. ","metadata":{"papermill":{"duration":0.00636,"end_time":"2023-01-17T09:56:52.751802","exception":false,"start_time":"2023-01-17T09:56:52.745442","status":"completed"},"tags":[]}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.linear_model import LogisticRegression\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.preprocessing import StandardScaler\nimport warnings\nimport keras_tuner as kt\nimport tensorflow as tf\nfrom datetime import datetime\nimport math\nfrom tensorflow.keras.callbacks import LearningRateScheduler\nfrom tensorflow.keras.layers import Normalization\nwarnings.filterwarnings(\"ignore\")","metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"papermill":{"duration":1.545966,"end_time":"2023-01-17T09:56:54.30319","exception":false,"start_time":"2023-01-17T09:56:52.757224","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-01-19T19:49:43.568406Z","iopub.execute_input":"2023-01-19T19:49:43.569101Z","iopub.status.idle":"2023-01-19T19:49:43.577582Z","shell.execute_reply.started":"2023-01-19T19:49:43.569061Z","shell.execute_reply":"2023-01-19T19:49:43.576161Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Configuration","metadata":{"papermill":{"duration":0.00491,"end_time":"2023-01-17T09:56:54.313645","exception":false,"start_time":"2023-01-17T09:56:54.308735","status":"completed"},"tags":[]}},{"cell_type":"code","source":"class CFG:\n    TRAIN_DATA_URL = \"../input/playground-series-s3e3/train.csv\"\n    TEST_DATA_URL = \"../input/playground-series-s3e3/test.csv\"\n    id_field = \"id\"\n    target_field = \"Attrition\"\n    n_folds = 5\n    quick_experiment = False\n    tuning_epochs = 20\n    max_trials = 5 if quick_experiment else 10\n    epochs = 30 if quick_experiment else 100\n    use_correlated_columns = False","metadata":{"papermill":{"duration":0.01504,"end_time":"2023-01-17T09:56:54.333689","exception":false,"start_time":"2023-01-17T09:56:54.318649","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-01-19T19:49:52.064613Z","iopub.execute_input":"2023-01-19T19:49:52.065015Z","iopub.status.idle":"2023-01-19T19:49:52.072463Z","shell.execute_reply.started":"2023-01-19T19:49:52.064983Z","shell.execute_reply":"2023-01-19T19:49:52.070978Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Utils","metadata":{}},{"cell_type":"code","source":"def get_cosine_decay_learning_rate_scheduler(epochs, lr_start=0.001, lr_end=1e-6):\n    def cosine_decay(epoch):\n        if epoch <= CFG.tuning_epochs:\n            return lr_start\n        if epochs > 1:\n            w = (1 + math.cos(epoch / (epochs-1) * math.pi)) / 2\n        else:\n            w = 1\n        return w * lr_start + (1 - w) * lr_end\n    return LearningRateScheduler(cosine_decay, verbose=0)","metadata":{"execution":{"iopub.status.busy":"2023-01-19T19:49:55.1679Z","iopub.execute_input":"2023-01-19T19:49:55.168337Z","iopub.status.idle":"2023-01-19T19:49:55.175015Z","shell.execute_reply.started":"2023-01-19T19:49:55.168298Z","shell.execute_reply":"2023-01-19T19:49:55.173876Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Load data","metadata":{"papermill":{"duration":0.005254,"end_time":"2023-01-17T09:56:54.34432","exception":false,"start_time":"2023-01-17T09:56:54.339066","status":"completed"},"tags":[]}},{"cell_type":"code","source":"train = pd.read_csv(CFG.TRAIN_DATA_URL)\nexternal_train = pd.read_csv(\"../input/ibm-hr-analytics-attrition-dataset/WA_Fn-UseC_-HR-Employee-Attrition.csv\")\nexternal_train.rename(columns={\"EmployeeNumber\": \"id\"}, inplace=True)\nexternal_train[CFG.target_field] = external_train[CFG.target_field].apply(lambda attribution: 1 if attribution==\"Yes\" else 0)\ntrain = pd.concat([train, external_train])\ntrain.index = list(range(len(train)))\ntrain.head()","metadata":{"papermill":{"duration":0.070534,"end_time":"2023-01-17T09:56:54.420326","exception":false,"start_time":"2023-01-17T09:56:54.349792","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-01-19T19:49:59.355742Z","iopub.execute_input":"2023-01-19T19:49:59.356123Z","iopub.status.idle":"2023-01-19T19:49:59.447998Z","shell.execute_reply.started":"2023-01-19T19:49:59.35609Z","shell.execute_reply":"2023-01-19T19:49:59.446858Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test = pd.read_csv(CFG.TEST_DATA_URL)\ntest.head()","metadata":{"papermill":{"duration":0.043057,"end_time":"2023-01-17T09:56:54.469116","exception":false,"start_time":"2023-01-17T09:56:54.426059","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-01-19T19:50:02.38162Z","iopub.execute_input":"2023-01-19T19:50:02.382166Z","iopub.status.idle":"2023-01-19T19:50:02.43199Z","shell.execute_reply.started":"2023-01-19T19:50:02.382098Z","shell.execute_reply":"2023-01-19T19:50:02.430972Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## EDA","metadata":{}},{"cell_type":"markdown","source":"### Overall label distribution","metadata":{}},{"cell_type":"code","source":"sns.countplot(train[CFG.target_field])","metadata":{"execution":{"iopub.status.busy":"2023-01-19T19:50:04.794884Z","iopub.execute_input":"2023-01-19T19:50:04.795423Z","iopub.status.idle":"2023-01-19T19:50:05.021447Z","shell.execute_reply.started":"2023-01-19T19:50:04.795377Z","shell.execute_reply":"2023-01-19T19:50:05.020191Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Infer categorical columns and numeric columns automatically\nAs we can see, StandardHours, Over18 and EmployeeCount only have one unique value, doesn't make any difference. These columns can be removed.","metadata":{}},{"cell_type":"code","source":"categorical_columns = []\nnumeric_columns = []\nfor column in train.columns:\n    if train[column].dtype == object:\n        if len(train[column].unique()) == 1:\n            print(f\"{column} only have one unique value, omit this feature.\")\n        else:\n            categorical_columns.append(column)\n    elif column != CFG.target_field and column != CFG.id_field:\n        if len(train[column].unique()) == 1:\n            print(f\"{column} only have one unique value, omit this feature.\")\n        elif len(train[column].unique()) <= 10:\n            categorical_columns.append(column)\n        else:\n            numeric_columns.append(column)\nfeature_columns = numeric_columns + categorical_columns\nall_columns = feature_columns + [CFG.target_field]\nprint(f\"Categorical columns:{categorical_columns}.\")\nprint(f\"Numerical columns:{numeric_columns}.\")","metadata":{"execution":{"iopub.status.busy":"2023-01-19T19:50:07.144922Z","iopub.execute_input":"2023-01-19T19:50:07.146226Z","iopub.status.idle":"2023-01-19T19:50:07.165599Z","shell.execute_reply.started":"2023-01-19T19:50:07.146173Z","shell.execute_reply":"2023-01-19T19:50:07.164373Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Distribution of target in different categorical features","metadata":{}},{"cell_type":"code","source":"for column in categorical_columns:\n    sns.countplot(data=train, x=column, hue=CFG.target_field)\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2023-01-19T19:50:09.755228Z","iopub.execute_input":"2023-01-19T19:50:09.755609Z","iopub.status.idle":"2023-01-19T19:50:13.436168Z","shell.execute_reply.started":"2023-01-19T19:50:09.755579Z","shell.execute_reply":"2023-01-19T19:50:13.435024Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Distribution of target in different numerical features","metadata":{}},{"cell_type":"code","source":"for column in numeric_columns:\n    sns.pairplot(train[[column, CFG.target_field]], hue=CFG.target_field, diag_kind=\"kde\")\n    plt.figure(figsize=(10, 10))\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2023-01-19T19:50:21.501797Z","iopub.execute_input":"2023-01-19T19:50:21.502237Z","iopub.status.idle":"2023-01-19T19:50:24.924055Z","shell.execute_reply.started":"2023-01-19T19:50:21.5022Z","shell.execute_reply":"2023-01-19T19:50:24.922716Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test[CFG.target_field] = 0.0\ndata = pd.concat([train[all_columns], test[all_columns]])\ndata_dummy = pd.get_dummies(data, columns=categorical_columns)\ntrain_dummy = data_dummy.iloc[:len(train)]\ntest_dummy = data_dummy.iloc[len(train):]\ntrain_dummy.head()","metadata":{"execution":{"iopub.status.busy":"2023-01-19T19:50:27.80539Z","iopub.execute_input":"2023-01-19T19:50:27.806187Z","iopub.status.idle":"2023-01-19T19:50:27.862802Z","shell.execute_reply.started":"2023-01-19T19:50:27.806118Z","shell.execute_reply":"2023-01-19T19:50:27.861602Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Correlated features","metadata":{"papermill":{"duration":0.006513,"end_time":"2023-01-17T09:56:54.670049","exception":false,"start_time":"2023-01-17T09:56:54.663536","status":"completed"},"tags":[]}},{"cell_type":"code","source":"corr = train_dummy.corr()\ncorrelated_columns =  list(corr[CFG.target_field][corr[CFG.target_field].abs() > 0.05].index)\ncorrelated_columns.remove(CFG.target_field)\nif CFG.id_field in correlated_columns:\n    correlated_columns.remove(CFG.id_field)\nprint(f\"Correlated features:{correlated_columns}\")","metadata":{"execution":{"iopub.status.busy":"2023-01-19T19:50:31.818473Z","iopub.execute_input":"2023-01-19T19:50:31.818925Z","iopub.status.idle":"2023-01-19T19:50:31.916173Z","shell.execute_reply.started":"2023-01-19T19:50:31.818881Z","shell.execute_reply":"2023-01-19T19:50:31.915008Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"corr = train_dummy[correlated_columns + [CFG.target_field]].corr()\nplt.figure(figsize=(20, 20))\nsns.heatmap(corr, vmin=0, vmax=1.0,  cmap=\"PiYG\")\nplt.show()","metadata":{"papermill":{"duration":2.455986,"end_time":"2023-01-17T09:56:57.13308","exception":false,"start_time":"2023-01-17T09:56:54.677094","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-01-19T19:50:49.124799Z","iopub.execute_input":"2023-01-19T19:50:49.125214Z","iopub.status.idle":"2023-01-19T19:50:50.756531Z","shell.execute_reply.started":"2023-01-19T19:50:49.125179Z","shell.execute_reply":"2023-01-19T19:50:50.755269Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"corr[CFG.target_field].sort_values(key=lambda x: abs(x), ascending=False)","metadata":{"papermill":{"duration":0.026598,"end_time":"2023-01-17T09:56:57.169677","exception":false,"start_time":"2023-01-17T09:56:57.143079","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-01-19T19:50:55.744353Z","iopub.execute_input":"2023-01-19T19:50:55.744767Z","iopub.status.idle":"2023-01-19T19:50:55.756682Z","shell.execute_reply.started":"2023-01-19T19:50:55.744728Z","shell.execute_reply":"2023-01-19T19:50:55.755506Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if CFG.use_correlated_columns:\n    columns = correlated_columns\nelse:\n    columns = list(train_dummy.columns)\n    columns.remove(CFG.target_field)\nprint(columns)","metadata":{"execution":{"iopub.status.busy":"2023-01-19T19:51:39.644942Z","iopub.execute_input":"2023-01-19T19:51:39.645911Z","iopub.status.idle":"2023-01-19T19:51:39.65182Z","shell.execute_reply.started":"2023-01-19T19:51:39.645871Z","shell.execute_reply":"2023-01-19T19:51:39.650682Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Create Normalization Layer","metadata":{}},{"cell_type":"code","source":"nomalization = Normalization()\nwith tf.device(\"cpu\"):\n    nomalization.adapt(train_dummy[columns])","metadata":{"execution":{"iopub.status.busy":"2023-01-19T19:52:33.763453Z","iopub.execute_input":"2023-01-19T19:52:33.763951Z","iopub.status.idle":"2023-01-19T19:52:34.389351Z","shell.execute_reply.started":"2023-01-19T19:52:33.763911Z","shell.execute_reply":"2023-01-19T19:52:34.387949Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Hyperparameter Tuning","metadata":{}},{"cell_type":"code","source":"def build_model(hp):\n    use_dropout = hp.Choice(\"use_dropout\", [True, False])\n    dropout_value = hp.Float(\"dropout\", min_value=0.1, max_value=0.5)\n    learning_rate = hp.Float(\"learning_rate\", min_value=1e-5, max_value=1e-3, sampling=\"log\")\n    depth = 5\n    units = list(reversed(sorted([hp.Int(f\"unit_{i}\", min_value=16, max_value=128, step=16) for i in range(depth)])))\n    activation =  hp.Choice(\"activation\", [\"relu\", \"swish\"])\n    l2_factor = hp.Float(\"l2\", min_value=1e-6, max_value=1e-4, sampling=\"log\")\n    inputs = tf.keras.Input(shape=(len(columns)), dtype=tf.float32) \n    vector = nomalization(inputs)\n    for i in range(depth):\n        vector = tf.keras.layers.Dense(units[i], activation=activation, kernel_regularizer=tf.keras.regularizers.l2(l2_factor) if i == depth - 1 else None)(vector)\n    if use_dropout:\n        vector = tf.keras.layers.Dropout(dropout_value)(vector)\n    output = tf.keras.layers.Dense(1, activation=\"sigmoid\")(vector)\n    model = tf.keras.Model(inputs=inputs, outputs=output)\n    auc = tf.keras.metrics.AUC(name=\"auc\")\n    model.compile(loss=\"binary_crossentropy\", optimizer=tf.keras.optimizers.Adam(learning_rate), metrics=[auc, \"accuracy\"])\n    return model","metadata":{"execution":{"iopub.status.busy":"2023-01-19T19:53:04.459243Z","iopub.execute_input":"2023-01-19T19:53:04.459655Z","iopub.status.idle":"2023-01-19T19:53:04.471574Z","shell.execute_reply.started":"2023-01-19T19:53:04.459621Z","shell.execute_reply":"2023-01-19T19:53:04.470693Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Modeling\n\nNow train the model for using StratifiedKFold for 5 folds. I will search best model using KerasTuner for different folds. Since this dataset is very small, use different random seeds to stabilize the result. ","metadata":{"papermill":{"duration":0.009345,"end_time":"2023-01-17T09:56:57.227938","exception":false,"start_time":"2023-01-17T09:56:57.218593","status":"completed"},"tags":[]}},{"cell_type":"code","source":"%%time\nseeds = [42, 997]\nmodels = []\nscores = []\nfor seed in seeds:\n    kfold =StratifiedKFold(CFG.n_folds, shuffle=True, random_state=seed)\n    for fold, (train_indices, valid_indices) in enumerate(kfold.split(train_dummy, train_dummy[CFG.target_field])):\n        print(\"=\" * 100)\n        print(f\"Fold {fold}\")\n        print(\"=\" * 100)\n        X_train = train_dummy.iloc[train_indices]\n        y_train = X_train.pop(CFG.target_field)\n        X_val = train_dummy.iloc[valid_indices]\n        y_val = X_val.pop(CFG.target_field)\n        train_ds = tf.data.Dataset.from_tensor_slices((X_train[columns], y_train)).shuffle(1024).batch(128).cache().prefetch(tf.data.AUTOTUNE)\n        valid_ds = tf.data.Dataset.from_tensor_slices((X_val[columns], y_val)).batch(128).cache().prefetch(tf.data.AUTOTUNE)\n        \n        tuner = kt.BayesianOptimization(\n            build_model,\n            objective=kt.Objective(\"val_auc\", direction=\"max\"),\n            max_trials=CFG.max_trials,\n            overwrite=True\n        )\n        tuner.search(train_ds, epochs=CFG.tuning_epochs, validation_data=valid_ds, verbose=2)\n        tuner.results_summary()\n        best_hps = tuner.get_best_hyperparameters()\n        model = build_model(best_hps[0])\n        model_name = f\"model_seed_{seed}_fold_{fold}.tf\"\n        checkpoints = tf.keras.callbacks.ModelCheckpoint(\n            model_name, \n            monitor=\"val_auc\",\n            mode=\"max\",\n            save_best_only=True,\n            restore_best_weights=True\n        )\n        epochs = CFG.epochs\n        learning_rate = model.optimizer.learning_rate.numpy()\n        scheduler = get_cosine_decay_learning_rate_scheduler(epochs=epochs, lr_start=learning_rate, lr_end=learning_rate * 0.01)\n        \n        history = model.fit(train_ds, epochs=epochs, validation_data=valid_ds, callbacks=[checkpoints, scheduler], verbose=2)\n        model = tf.keras.models.load_model(model_name)\n        score = model.evaluate(valid_ds)[1]\n\n        best_model = tuner.get_best_models()[0]\n        score1 = best_model.evaluate(valid_ds)[1]\n        if score > score1:\n            models.append(model)\n            scores.append(score)\n        else:\n            models.append(best_model)\n            scores.append(score1)\nprint(\"Average AUC: %.5f\"%(np.mean(scores)))","metadata":{"papermill":{"duration":3.870933,"end_time":"2023-01-17T09:57:01.10846","exception":false,"start_time":"2023-01-17T09:56:57.237527","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-01-19T19:54:19.397348Z","iopub.execute_input":"2023-01-19T19:54:19.397749Z","iopub.status.idle":"2023-01-19T19:56:32.661996Z","shell.execute_reply.started":"2023-01-19T19:54:19.397717Z","shell.execute_reply":"2023-01-19T19:56:32.660569Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Submission ","metadata":{"papermill":{"duration":0.011857,"end_time":"2023-01-17T09:57:01.132249","exception":false,"start_time":"2023-01-17T09:57:01.120392","status":"completed"},"tags":[]}},{"cell_type":"code","source":"test[CFG.target_field]  = np.dot(np.array(scores), np.array([model.predict(test_dummy[columns]).reshape(-1) for model in models])) / np.sum(scores)\nsubmission = test[[CFG.id_field, CFG.target_field]]\nsubmission.to_csv(\"submission.csv\", index=False)\nsubmission.head()","metadata":{"papermill":{"duration":0.115933,"end_time":"2023-01-17T09:57:01.26017","exception":false,"start_time":"2023-01-17T09:57:01.144237","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-01-19T18:51:36.264648Z","iopub.execute_input":"2023-01-19T18:51:36.265118Z","iopub.status.idle":"2023-01-19T18:51:37.267852Z","shell.execute_reply.started":"2023-01-19T18:51:36.265079Z","shell.execute_reply":"2023-01-19T18:51:37.266733Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission[CFG.target_field].plot(kind=\"hist\")","metadata":{"papermill":{"duration":0.251888,"end_time":"2023-01-17T09:57:01.539221","exception":false,"start_time":"2023-01-17T09:57:01.287333","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-01-19T18:51:40.586868Z","iopub.execute_input":"2023-01-19T18:51:40.587258Z","iopub.status.idle":"2023-01-19T18:51:40.847828Z","shell.execute_reply.started":"2023-01-19T18:51:40.587225Z","shell.execute_reply":"2023-01-19T18:51:40.846532Z"},"trusted":true},"execution_count":null,"outputs":[]}]}