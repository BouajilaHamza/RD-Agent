{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"##### This is my 3rd place solution to Kaggle's AMPÂ®-Parkinson's Disease Progression Prediction competition.\n\n##### The discussion describing this solution is [here][1]\n\n[1]: https://www.kaggle.com/competitions/amp-parkinsons-disease-progression-prediction/discussion/411546","metadata":{}},{"cell_type":"markdown","source":"# 1. Preprocessing","metadata":{"papermill":{"duration":0.012787,"end_time":"2023-05-12T18:08:56.542112","exception":false,"start_time":"2023-05-12T18:08:56.529325","status":"completed"},"tags":[]}},{"cell_type":"code","source":"VER = \"v999\"","metadata":{"papermill":{"duration":0.031257,"end_time":"2023-05-12T18:08:56.585574","exception":false,"start_time":"2023-05-12T18:08:56.554317","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-05-24T16:13:50.491544Z","iopub.execute_input":"2023-05-24T16:13:50.491957Z","iopub.status.idle":"2023-05-24T16:13:50.497386Z","shell.execute_reply.started":"2023-05-24T16:13:50.491926Z","shell.execute_reply":"2023-05-24T16:13:50.496264Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import sys\nsys.path.append('/kaggle/input/amp-parkinsons-disease-progression-prediction')","metadata":{"papermill":{"duration":0.022595,"end_time":"2023-05-12T18:08:56.620095","exception":false,"start_time":"2023-05-12T18:08:56.5975","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-05-24T16:13:50.499818Z","iopub.execute_input":"2023-05-24T16:13:50.500279Z","iopub.status.idle":"2023-05-24T16:13:50.511545Z","shell.execute_reply.started":"2023-05-24T16:13:50.500236Z","shell.execute_reply":"2023-05-24T16:13:50.510295Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\npd.set_option('display.max_rows', 150)\npd.set_option('display.max_columns', None)\nimport numpy as np\nimport warnings\nwarnings.filterwarnings('ignore')","metadata":{"papermill":{"duration":0.022032,"end_time":"2023-05-12T18:08:56.654746","exception":false,"start_time":"2023-05-12T18:08:56.632714","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-05-24T16:13:50.513079Z","iopub.execute_input":"2023-05-24T16:13:50.514288Z","iopub.status.idle":"2023-05-24T16:13:50.527928Z","shell.execute_reply.started":"2023-05-24T16:13:50.514219Z","shell.execute_reply":"2023-05-24T16:13:50.526708Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# SMAPE: Metric for this competition\ndef smape(y_true, y_pred):\n    # 2023/3/19 add +1 \n    y_true = np.array(y_true) + 1\n    y_pred = np.array(y_pred) + 1\n\n    smap = np.zeros(len(y_true))\n    \n    num = np.abs(y_true - y_pred)\n    dem = ((np.abs(y_true) + np.abs(y_pred)) / 2)\n    \n    mask_not_zeros_ind = (y_true != 0) | (y_pred != 0)\n    smap[mask_not_zeros_ind] = num[mask_not_zeros_ind] / dem[mask_not_zeros_ind]\n    \n    return 100 * np.mean(smap)","metadata":{"papermill":{"duration":0.023083,"end_time":"2023-05-12T18:08:56.689893","exception":false,"start_time":"2023-05-12T18:08:56.66681","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-05-24T16:13:50.530617Z","iopub.execute_input":"2023-05-24T16:13:50.531316Z","iopub.status.idle":"2023-05-24T16:13:50.54593Z","shell.execute_reply.started":"2023-05-24T16:13:50.531275Z","shell.execute_reply":"2023-05-24T16:13:50.544731Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Missing value Completion\ndef kesson_hokan(df):\n    df['upd23b_clinical_state_on_medication'] = df['upd23b_clinical_state_on_medication'].replace('On', 0)\n    df['upd23b_clinical_state_on_medication'] = df['upd23b_clinical_state_on_medication'].replace('Off', 1)\n    df['upd23b_clinical_state_on_medication'] = df['upd23b_clinical_state_on_medication'].fillna(0)\n    df = df.set_index('visit_month').groupby('patient_id').apply(lambda group: group.interpolate(method='index')).reset_index()\n    return df","metadata":{"papermill":{"duration":0.024595,"end_time":"2023-05-12T18:08:56.749508","exception":false,"start_time":"2023-05-12T18:08:56.724913","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-05-24T16:13:50.547454Z","iopub.execute_input":"2023-05-24T16:13:50.547801Z","iopub.status.idle":"2023-05-24T16:13:50.558961Z","shell.execute_reply.started":"2023-05-24T16:13:50.547771Z","shell.execute_reply":"2023-05-24T16:13:50.557787Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 2. Read Data","metadata":{"execution":{"iopub.status.busy":"2023-05-20T14:26:07.482462Z","iopub.execute_input":"2023-05-20T14:26:07.482842Z","iopub.status.idle":"2023-05-20T14:26:07.488697Z","shell.execute_reply.started":"2023-05-20T14:26:07.482813Z","shell.execute_reply":"2023-05-20T14:26:07.487024Z"}}},{"cell_type":"code","source":"# Read data\ntrain_sup = pd.read_csv('../input/amp-parkinsons-disease-progression-prediction/supplemental_clinical_data.csv')\nprint(train_sup.shape)\ntrain_sup[\"add_flg\"] = 1\ntrain_sup['visit_month_max'] = train_sup.groupby('patient_id')['visit_month'].transform('max')\n# Patients with \"5 months\" are not normal\ntrain_sup = train_sup[train_sup[\"visit_month_max\"] >= 6].copy()\nprint(train_sup.shape)\ntrain_cli = pd.read_csv('../input/amp-parkinsons-disease-progression-prediction/train_clinical_data.csv')\nprint(train_cli.shape)\ntrain_pro = pd.read_csv('../input/amp-parkinsons-disease-progression-prediction/train_proteins.csv')\nprint(train_pro.shape)\ntrain_pep = pd.read_csv('../input/amp-parkinsons-disease-progression-prediction/train_peptides.csv')\nprint(train_pep.shape)\ntrain = pd.concat([train_cli, train_sup]).sort_values(by=[\"patient_id\", \"visit_month\"])\ntrain = kesson_hokan(train)\ntrain[\"add_flg\"] = train[\"add_flg\"].fillna(0)\ndic_monthkbn = {0:1, 6:2, 12:3, 18:4, 24:5, 36:6, 48:7, 60:8, 72:9, 84:10}\ndef get_diff(df):\n    df[\"visit_month_diff\"] = df.groupby([\"patient_id\"])[\"visit_month\"].diff()\n    df[\"visit_month_count\"] = df.groupby([\"patient_id\"])[\"patient_id\"].cumcount() + 1\n    df[\"visit_month_cummin\"] = df.groupby([\"patient_id\"])[\"visit_month_diff\"].cummin()\n    df[\"visit_month_cummin_group\"] = np.where(df[\"visit_month_cummin\"].isna(), 0, 1)\n    df[\"visit_month_cummin_group\"].mask(df[\"visit_month_cummin\"] >= 6, 2 ,inplace=True)\n    df[\"visit_month_cummin_group\"].mask(df[\"visit_month_cummin\"] >= 12, 3 ,inplace=True)\n    df[\"visit_month_cummin_group\"].mask(df[\"add_flg\"] == 1, 0 ,inplace=True)\n    return df\ndef get_diff_monthkbn(df, col):\n    df[f\"{col}monthkbn\"] = df[\"visit_month\"].map(dic_monthkbn)\n    df[f\"{col}monthkbn\"] = df.groupby([\"patient_id\"])[f\"{col}monthkbn\"].ffill()\n    df[f\"{col}monthkbn_diff\"] = df.groupby([\"patient_id\"])[f\"{col}monthkbn\"].diff()\n    df[f\"{col}monthkbn_cumcount\"] = df.groupby([\"patient_id\"])[\"visit_id\"].cumcount() + 1\n    df[f\"{col}monthkbn_cummax\"] = df.groupby([\"patient_id\"])[f\"{col}monthkbn_diff\"].cummax()\n    return df\ndef get_diff_monthkbn_merge(df, df_pro):\n    df = df.merge(df_pro, on=[\"patient_id\", \"visit_month\", \"visit_id\"], how=\"left\")\n    df[\"pro_monthkbn\"] = df.groupby([\"patient_id\"])[\"pro_monthkbn\"].ffill()\n    df[\"pro_monthkbn_cumcount\"] = df.groupby([\"patient_id\"])[\"pro_monthkbn_cumcount\"].ffill()\n    df[\"pro_monthkbn_cummax\"] = df.groupby([\"patient_id\"])[\"pro_monthkbn_cummax\"].ffill()\n    df[\"pro_monthkbn\"] = df[\"pro_monthkbn\"].fillna(0)\n    df[\"pro_monthkbn_diff\"] = df[\"pro_monthkbn_diff\"].fillna(0)\n    df[\"pro_monthkbn_cumcount\"] = df[\"pro_monthkbn_cumcount\"].fillna(0)\n    df[\"pro_monthkbn_cummax\"] = df[\"pro_monthkbn_cummax\"].fillna(0)\n    return df\ntrain1 = get_diff(train.reset_index(drop=True).copy())\ntrain1 = get_diff_monthkbn(train1.reset_index(drop=True).copy(), \"\")\ntrain_pro_diff_monthkbn = train_pro[[\"patient_id\", \"visit_month\", \"visit_id\"]].drop_duplicates().sort_values(by=[\"patient_id\", \"visit_month\"])\ntrain_pro_diff_monthkbn = get_diff_monthkbn(train_pro_diff_monthkbn.reset_index(drop=True).copy(), \"pro_\")\ntrain1 = get_diff_monthkbn_merge(train1, train_pro_diff_monthkbn)\ntrain1[\"total_month\"] = train1[\"visit_month\"]\ntrain1 = train1.sort_values(by=[\"patient_id\", \"visit_month\"]).reset_index(drop=True)\ntrain1[\"visit_id\"] = train1[\"patient_id\"].astype(str) + \"_\" + train1[\"visit_month\"].astype(str)\ntrain1[\"months\"] = train1[\"visit_month\"]\nprint(train1.shape)","metadata":{"papermill":{"duration":2.875005,"end_time":"2023-05-12T18:08:59.636614","exception":false,"start_time":"2023-05-12T18:08:56.761609","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-05-24T16:13:50.561181Z","iopub.execute_input":"2023-05-24T16:13:50.561924Z","iopub.status.idle":"2023-05-24T16:13:52.346348Z","shell.execute_reply.started":"2023-05-24T16:13:50.56188Z","shell.execute_reply":"2023-05-24T16:13:52.34514Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"targets = ['updrs_1', 'updrs_2', 'updrs_3', 'updrs_4']","metadata":{"papermill":{"duration":0.023794,"end_time":"2023-05-12T18:08:59.674424","exception":false,"start_time":"2023-05-12T18:08:59.65063","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-05-24T16:13:52.350616Z","iopub.execute_input":"2023-05-24T16:13:52.350936Z","iopub.status.idle":"2023-05-24T16:13:52.355782Z","shell.execute_reply.started":"2023-05-24T16:13:52.35091Z","shell.execute_reply":"2023-05-24T16:13:52.35462Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(train.shape)","metadata":{"papermill":{"duration":0.021571,"end_time":"2023-05-12T18:08:59.708343","exception":false,"start_time":"2023-05-12T18:08:59.686772","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-05-24T16:13:52.357669Z","iopub.execute_input":"2023-05-24T16:13:52.358092Z","iopub.status.idle":"2023-05-24T16:13:52.371197Z","shell.execute_reply.started":"2023-05-24T16:13:52.358051Z","shell.execute_reply":"2023-05-24T16:13:52.37039Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 3. Feature Engineering (Protein and Peptide)","metadata":{"papermill":{"duration":0.013298,"end_time":"2023-05-12T18:09:00.479586","exception":false,"start_time":"2023-05-12T18:09:00.466288","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# rank normalization\ndef get_count_rank(df, train_pro_count, train_pep_count):\n    months = sorted(df['visit_month'].unique())\n    list_df_y = []\n    train_pro_count[\"NPX_count_cummean\"] =  train_pro_count.groupby([\"patient_id\"])[\"NPX_count\"].transform(lambda x: x.expanding().mean())\n    train_pep_count[\"Pep_count_cummean\"] =  train_pep_count.groupby([\"patient_id\"])[\"Pep_count\"].transform(lambda x: x.expanding().mean())\n    for m in months:\n        df_tmp = df[df['visit_month'] == m].copy()\n        train_pro_count_for_rank = train_pro_count[train_pro_count['visit_month'] <= m].copy()\n        train_pep_count_for_rank = train_pep_count[train_pep_count['visit_month'] <= m].copy()\n        train_pro_count_for_rank[\"NPX_count_rank\"] = train_pro_count_for_rank[\"NPX_count\"].rank(method=\"average\", ascending=False, pct=True)\n        train_pro_count_for_rank[\"NPX_count_cummean_rank\"] = train_pro_count_for_rank[\"NPX_count_cummean\"].rank(method=\"average\", ascending=False, pct=True)\n        train_pep_count_for_rank[\"Pep_count_rank\"] = train_pep_count_for_rank[\"Pep_count\"].rank(method=\"average\", ascending=False, pct=True)\n        train_pep_count_for_rank[\"Pep_count_cummean_rank\"] = train_pep_count_for_rank[\"Pep_count_cummean\"].rank(method=\"average\", ascending=False, pct=True)\n        df_tmp = df_tmp.merge(train_pro_count_for_rank[['patient_id', 'visit_month', \"NPX_count_rank\", \"NPX_count_cummean\", \"NPX_count_cummean_rank\"]], on=['patient_id', 'visit_month'], how=\"left\")\n        df_tmp = df_tmp.merge(train_pep_count_for_rank[['patient_id', 'visit_month', \"Pep_count_rank\", \"Pep_count_cummean\", \"Pep_count_cummean_rank\"]], on=['patient_id', 'visit_month'], how=\"left\")\n        list_df_y.append(df_tmp)\n    df_y = pd.concat(list_df_y).sort_values(by=[\"patient_id\", \"visit_month\", \"total_month\"])\n    df_y[\"NPX_count_rank_cummean\"] = df_y.groupby([\"patient_id\"])[\"NPX_count_rank\"].transform(lambda x: x.expanding().mean())\n    df_y[\"NPX_count_rank_cummin\"] = df_y.groupby([\"patient_id\"])[\"NPX_count_rank\"].cummin()\n    df_y[\"NPX_count_rank_cummax\"] = df_y.groupby([\"patient_id\"])[\"NPX_count_rank\"].cummax()\n    df_y[\"Pep_count_rank_cummean\"] = df_y.groupby([\"patient_id\"])[\"Pep_count_rank\"].transform(lambda x: x.expanding().mean())\n    df_y[\"Pep_count_rank_cummin\"] = df_y.groupby([\"patient_id\"])[\"Pep_count_rank\"].cummin()\n    df_y[\"Pep_count_rank_cummax\"] = df_y.groupby([\"patient_id\"])[\"Pep_count_rank\"].cummax()\n    return df_y\n    \ndef get_count_rank_qcut(df, train_pro, train_pep):\n    train_pro_var = train_pro.groupby([\"patient_id\", \"visit_month\"])[\"NPX\"].std().rename('NPX_std').reset_index()\n    train_pro_var[\"NPX_std_qcut\"] = pd.qcut(train_pro_var[\"NPX_std\"], 10, labels=[i for i in range(1, 11, 1)], duplicates='drop')\n    train_pep_var = train_pep.groupby([\"patient_id\", \"visit_month\"])[\"PeptideAbundance\"].std().rename('Pep_std').reset_index()\n    train_pep_var[\"Pep_std_qcut\"] = pd.qcut(train_pep_var[\"Pep_std\"], 10, labels=[i for i in range(1, 11, 1)], duplicates='drop')\n    train_pro_count = train_pro.groupby([\"patient_id\", \"visit_month\"])[\"NPX\"].count().rename('NPX_count').reset_index()\n    train_pro_count[\"NPX_count_qcut\"] = pd.qcut(train_pro_count[\"NPX_count\"], 10, labels=[i for i in range(1, 11, 1)], duplicates='drop')\n    train_pep_count = train_pep.groupby([\"patient_id\", \"visit_month\"])[\"PeptideAbundance\"].count().rename('Pep_count').reset_index()\n    train_pep_count[\"Pep_count_qcut\"] = pd.qcut(train_pep_count[\"Pep_count\"], 10, labels=[i for i in range(1, 11, 1)], duplicates='drop')\n    df_y = df.merge(train_pro_count, on=['patient_id', 'visit_month'], how=\"left\")\n    df_y = df_y.merge(train_pep_count, on=['patient_id', 'visit_month'], how=\"left\")\n    df_y = df_y.merge(train_pro_var, on=['patient_id', 'visit_month'], how=\"left\")\n    df_y = df_y.merge(train_pep_var, on=['patient_id', 'visit_month'], how=\"left\")\n    df_y = df_y.sort_values(by=[\"patient_id\", \"visit_month\", \"total_month\"])\n    df_y = get_count_rank(df_y, train_pro_count, train_pep_count)\n    df_y['NPX_count_rank_ffill'] = df_y.groupby(['patient_id'])['NPX_count_rank'].ffill()\n    df_y['Pep_count_rank_ffill'] = df_y.groupby(['patient_id'])['Pep_count_rank'].ffill()\n    df_y['NPX_count_rank_cummean'] = df_y.groupby(['patient_id'])['NPX_count_rank_cummean'].ffill()\n    df_y['Pep_count_rank_cummean'] = df_y.groupby(['patient_id'])['Pep_count_rank_cummean'].ffill()\n    df_y['NPX_count_rank_cummin'] = df_y.groupby(['patient_id'])['NPX_count_rank_cummin'].ffill()\n    df_y['Pep_count_rank_cummin'] = df_y.groupby(['patient_id'])['Pep_count_rank_cummin'].ffill()\n    df_y['NPX_count_rank_cummax'] = df_y.groupby(['patient_id'])['NPX_count_rank_cummax'].ffill()\n    df_y['Pep_count_rank_cummax'] = df_y.groupby(['patient_id'])['Pep_count_rank_cummax'].ffill()\n    df_y['NPX_count_cummean_rank'] = df_y.groupby(['patient_id'])['NPX_count_cummean_rank'].ffill()\n    df_y['Pep_count_cummean_rank'] = df_y.groupby(['patient_id'])['Pep_count_cummean_rank'].ffill()\n    return df_y\n\nprint(train.shape)\ntrain2 = get_count_rank_qcut(train1, train_pro, train_pep)\nprint(train2.shape)","metadata":{"papermill":{"duration":1.16668,"end_time":"2023-05-12T18:09:01.659237","exception":false,"start_time":"2023-05-12T18:09:00.492557","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-05-24T16:13:52.372819Z","iopub.execute_input":"2023-05-24T16:13:52.373146Z","iopub.status.idle":"2023-05-24T16:13:53.522461Z","shell.execute_reply.started":"2023-05-24T16:13:52.373117Z","shell.execute_reply":"2023-05-24T16:13:53.521386Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Use SMAPE to normalize some features\ndef get_smape(df, df_moto, abs_flg):\n    for col in df.columns.tolist():\n        if col not in [\"visit_id\", 'patient_id', \"visit_month\"]:\n            df[col] = (df[col] - df_moto[col].mean()) / (df[col] + df_moto[col].mean())\n            if abs_flg:\n                df[col] = df[col].astype(float).abs()\n    return df.copy()\n\ndef get_propep_rank(df, col_rank, col_moto):\n    months = sorted(df['visit_month'].unique())\n    list_df_y = []\n    for m in months:\n        df_tmp = df[df['visit_month'] == m].copy()\n        df_for_rank = df[df['visit_month'] <= m].copy()\n        df_for_rank[col_rank] = df_for_rank[col_moto].rank(method=\"average\", ascending=False, pct=True)\n        df_tmp = df_tmp.merge(df_for_rank[['patient_id', 'visit_month', col_rank]], on=['patient_id', 'visit_month'], how=\"left\")\n        list_df_y.append(df_tmp)\n    return pd.concat(list_df_y).sort_values(by=[\"patient_id\", \"visit_month\"])\n\n# Protein and peptide were only partially effective\nfrom sklearn import preprocessing\ndef get_propep(train, train_pro, train_pep):\n    train_pep[\"UniProt_Pep\"] = train_pep[\"UniProt\"] + train_pep[\"Peptide\"]\n    le = preprocessing.LabelEncoder()\n    le.fit(train_pep[\"UniProt_Pep\"])\n    train_pep[\"le_Pep\"] = le.transform(train_pep[\"UniProt_Pep\"])\n    train_pep[\"le_Pep\"] = train_pep[\"UniProt\"].astype(str) + \"p\" + train_pep[\"le_Pep\"].astype(str).str.zfill(3)\n    unique_UniProt = train_pro['UniProt'].unique().tolist()\n    unique_ProtPep = train_pep['le_Pep'].unique().tolist()\n    train_pro2 = train_pro.pivot(index=['visit_id', 'patient_id', \"visit_month\"], columns='UniProt', values='NPX').sort_values(by=['patient_id', 'visit_month']).reset_index()\n    train_pep2 = train_pep.pivot(index=['visit_id', 'patient_id', \"visit_month\"], columns='le_Pep', values='PeptideAbundance').sort_values(by=['patient_id', 'visit_month']).reset_index()\n    df_y = train.copy().sort_values(by=['patient_id', 'visit_month']).reset_index(drop=True)\n    list_feat_propep_moto = []\n    for text, df, unique_cols in [[\"pro\", train_pro2, unique_UniProt], [\"pep\", train_pep2, unique_ProtPep]]:\n        df = get_smape(df.copy(), df.copy(), False)\n        df[f'{text}_var'] = df[unique_cols].var(axis=1)\n        df = get_propep_rank(df, f'{text}_var_rank', f'{text}_var')\n        df[f'{text}_std'] = df[unique_cols].std(axis=1)\n        df[f'{text}_abs_mean'] = np.abs(df[unique_cols]).mean(axis=1)\n        df[f'{text}_mean'] = df[unique_cols].mean(axis=1)\n        df[f'{text}_mean_clipupper0'] = df[unique_cols].clip(upper=0).mean(axis=1)\n        df[f\"{text}_mean_minus\"] = np.where(df[f\"{text}_mean\"] < 0, 1, 0)\n        df[f'{text}_sum'] = df[unique_cols].sum(axis=1)\n        df[f'{text}_sum_cummean'] = df.groupby([\"patient_id\"])[f'{text}_sum'].transform(lambda x: x.expanding().mean())\n        df = get_propep_rank(df, f'{text}_sum_cummean_rank',  f'{text}_sum_cummean')\n        df[f'{text}_sum_clipupper0'] = df[unique_cols].clip(upper=0).sum(axis=1)\n        df_diff = pd.concat([df[['visit_id', 'patient_id', 'visit_month']], df.groupby('patient_id')[unique_cols].diff()], axis=1)\n        df_diff[f'{text}_diff_var'] = df_diff[unique_cols].var(axis=1)\n        df_diff[f'{text}_diff_var_cummean'] = df_diff.groupby([\"patient_id\"])[f'{text}_diff_var'].transform(lambda x: x.expanding().mean())\n        df_diff = get_propep_rank(df_diff, f'{text}_diff_var_cummean_rank',  f'{text}_diff_var_cummean')\n        df_diff[f'{text}_diff_std'] = df_diff[unique_cols].std(axis=1)\n        df_diff[f'{text}_diff_abs_mean'] = np.abs(df_diff[unique_cols]).mean(axis=1)\n        df_diff[f'{text}_diff_mean'] = df_diff[unique_cols].mean(axis=1)\n        df_diff[f'{text}_diff_mean_clipupper0'] = df_diff[unique_cols].clip(upper=0).mean(axis=1)\n        df_diff[f'{text}_diff_sum'] = df_diff[unique_cols].sum(axis=1)\n        df_diff[f'{text}_diff_sum_clipupper0'] = df_diff[unique_cols].clip(upper=0).sum(axis=1)\n        list_feat_propep = [f\"{text}{i}\" for i in [\"_var\", \"_var_rank\", \"_std\", \"_abs_mean\", \"_mean\", \"_mean_clipupper0\", \"_mean_minus\", \"_sum\", \"_sum_cummean\", \"_sum_cummean_rank\", \"_sum_clipupper0\"]]\n        list_feat_prppep_diff = [f\"{text}_diff{i}\" for i in [\"_var\", \"_var_cummean\", \"_var_cummean_rank\", \"_std\", \"_abs_mean\", \"_mean\", \"_mean_clipupper0\", \"_sum\", \"_sum_clipupper0\"]]\n        df_y = df_y.merge(df[[\"visit_id\", \"patient_id\", \"visit_month\"] + list_feat_propep], on=['visit_id', 'patient_id', \"visit_month\"], how=\"left\")\n        df_y = df_y.merge(df_diff[[\"visit_id\"] + list_feat_prppep_diff], on=[\"visit_id\"], how=\"left\")\n        list_feat_propep_moto += list_feat_propep\n        list_feat_propep_moto += list_feat_prppep_diff\n    df_y[\"propep_mean_minus\"] = (df_y[\"pro_mean_minus\"] + df_y[\"pep_mean_minus\"]).clip(lower=0, upper=1)\n    df_y[\"propep_mean_minus_cummean\"] = df_y.groupby([\"patient_id\"])[\"propep_mean_minus\"].transform(lambda x: x.expanding().mean())\n    df_y[\"propep_mean_minus_cummax\"] = df_y.groupby([\"patient_id\"])[\"propep_mean_minus\"].cummax()\n    df_y[\"propep_mean_minus_cummax_cumsum\"] = df_y.groupby([\"patient_id\"])[\"propep_mean_minus_cummax\"].cumsum()\n    list_feat_propep_add = [\"propep_mean_minus_cummean\", \"propep_mean_minus_cummax\", \"propep_mean_minus_cummax_cumsum\"]\n    for i in list_feat_propep_moto + list_feat_propep_add:\n        df_y[i] = df_y.groupby('patient_id')[i].ffill()\n    df_y[\"propep_status\"] = 2\n    df_y[\"propep_status\"].mask(df_y[\"pro_diff_mean\"].isna() | df_y[\"pep_diff_mean\"].isna(), 1, inplace=True)\n    df_y[\"propep_status\"].mask(df_y[\"pro_mean\"].isna() | df_y[\"pep_mean\"].isna(), 0, inplace=True)\n    df_y[\"propep_status_cummin\"] = df_y.groupby([\"patient_id\"])[\"propep_status\"].cummin()\n    df_y[\"NPX_Pep_count_rank_cummean_harmean\"] = 3 / ((2 / df_y[\"NPX_count_rank_cummean\"]) + (1 / df_y[\"Pep_count_rank_cummean\"]))\n    df_y[\"NPX_Pep_count_rank_cummin_harmean\"] = 3 / ((2 / df_y[\"NPX_count_rank_cummin\"]) + (1 / df_y[\"Pep_count_rank_cummin\"]))\n    df_y[\"propep_sum_rank_harmean\"] = 3 / ((2 / df_y[\"pro_sum_cummean_rank\"]) + (1 / df_y[\"pep_sum_cummean_rank\"]))\n    df_y[\"propep_diff_var_rank_harmean\"] = 3 / ((2 / df_y[\"pro_diff_var_cummean_rank\"]) + (1 / df_y[\"pep_diff_var_cummean_rank\"]))\n    df_y[\"NPX_Pep_count_rank_harmean\"] = df_y[[\"NPX_Pep_count_rank_cummean_harmean\", \"NPX_Pep_count_rank_cummin_harmean\"]].mean(axis=1)\n    df_y[\"NPX_Pep_count_and_sum\"] = (2 / ((1 / df_y[\"NPX_Pep_count_rank_harmean\"]) + (1 / df_y[\"propep_sum_rank_harmean\"])))\n    df_y[\"feat_propep_worse\"] = df_y[[\"NPX_Pep_count_rank_harmean\", \"NPX_Pep_count_and_sum\"]].min(axis=1)\n    df_y[\"feat_propep_better\"] = (df_y[[\"propep_sum_rank_harmean\", \"propep_diff_var_rank_harmean\"]].mean(axis=1))\n    list_pro_monthkbn_cumcount = []\n    for i in [0, 6, 12, 18, 24]:\n        col0 = f\"pro_monthkbn_cumcount_month{i}_0\"\n        col1 = f\"pro_monthkbn_cumcount_month{i}_1\"\n        df_y[col0] = np.where(df_y[\"NPX_count\"].isna() & (df_y[\"visit_month\"] == i), 1, 0)\n        df_y[col1] = np.where(~df_y[\"NPX_count\"].isna() & (df_y[\"visit_month\"] == i), 1, 0)\n        list_pro_monthkbn_cumcount.extend([col0, col1])\n    for i in list_pro_monthkbn_cumcount:\n        df_y[i] = df_y.groupby([\"patient_id\"])[i].cumsum()\n    for i in [0, 6, 12, 18, 24]:\n        col0 = f\"pro_monthkbn_cumcount_month{i}_0\"\n        col1 = f\"pro_monthkbn_cumcount_month{i}_1\"\n        df_y[col0].mask((df_y[col0] + df_y[col1] == 0) & (df_y[\"visit_month\"] >= i), 1, inplace=True)\n    return df_y\n\nprint(train2.shape)\ntrain3 = get_propep(train2, train_pro, train_pep)\nprint(train3.shape)","metadata":{"papermill":{"duration":9.073019,"end_time":"2023-05-12T18:09:10.74578","exception":false,"start_time":"2023-05-12T18:09:01.672761","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-05-24T16:13:53.524561Z","iopub.execute_input":"2023-05-24T16:13:53.525412Z","iopub.status.idle":"2023-05-24T16:14:00.416987Z","shell.execute_reply.started":"2023-05-24T16:13:53.525371Z","shell.execute_reply":"2023-05-24T16:14:00.415707Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 4. Prediction (Const)","metadata":{}},{"cell_type":"code","source":"const_init1 = 4\nlist_const_increment1 = [3, 6, 18, 72, 84, 90, 96, 102, 108]\nconst_init2 = 3\nlist_const_increment2 = [1, 3, 6, 30, 42, 72, 84, 90, 96, 102, 108]\nconst_init3 = 17\nlist_const_increment3 = [1, 3, 6, 12, 24, 30, 36, 42, 48, 54, 60, 66, 72, 78, 84, 90, 96, 102, 108]\nconst_init4 = 0\nlist_const_increment4 = [72, 78, 84, 96, 108]\nestimates = {}\n\n# UnHealthy Group\nfor i in range(145):\n    for j in [0, 1, 2, 3]:\n        for target in targets:\n            if i >= 1:\n                estimates[(i, j, target)] = estimates[(i - 1, j, target)]\n            if target == 'updrs_1' and i == 0:\n                estimates[(i, j, target)] = const_init1\n            if target == 'updrs_1' and i in list_const_increment1:\n                estimates[(i, j, target)] += 1\n            if target == 'updrs_2' and i == 0:\n                estimates[(i, j, target)] = const_init2\n            if target == 'updrs_2' and i in list_const_increment2:\n                estimates[(i, j, target)] += 1\n            if target == 'updrs_3' and i == 0:\n                estimates[(i, j, target)] = const_init3\n            if target == 'updrs_3' and i in list_const_increment3:\n                estimates[(i, j, target)] += 1\n            if target == 'updrs_4' and i == 0:\n                estimates[(i, j, target)] = const_init4\n            if target == 'updrs_4' and i in list_const_increment4:\n                estimates[(i, j, target)] += 1\n\n# Healthy Group\nfor i in range(145):\n    for j in [3]:\n        for target in targets:\n            if target == 'updrs_1':\n                estimates[(i, j, target)] = 2\n            if target == 'updrs_1' and i >= 48:\n                estimates[(i, j, target)] = 3\n            if target not in ['updrs_1']:\n                estimates[(i, j, target)] = 0","metadata":{"papermill":{"duration":0.038597,"end_time":"2023-05-12T18:08:59.888617","exception":false,"start_time":"2023-05-12T18:08:59.85002","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-05-24T16:14:00.418212Z","iopub.execute_input":"2023-05-24T16:14:00.418561Z","iopub.status.idle":"2023-05-24T16:14:00.442528Z","shell.execute_reply.started":"2023-05-24T16:14:00.418533Z","shell.execute_reply":"2023-05-24T16:14:00.441212Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_df_estimates(x):\n    df = pd.DataFrame.from_dict(estimates, orient=\"index\").reset_index()\n    df.columns = ['month_updrs', 'value']\n    df['month'] = df['month_updrs'].map(lambda x: x[0])\n    df['month_sabun'] = df['month_updrs'].map(lambda x: x[1])\n    df['updrs'] = df['month_updrs'].map(lambda x: x[2])\n    return df\n\ndf_estimates = get_df_estimates(estimates)\ndf_estimates = df_estimates.pivot(index=['month', 'month_sabun'], columns='updrs', values='value').reset_index()\nfor i in [0, 1, 2, 3]:\n    print(df_estimates[df_estimates['month_sabun'] == i].head(1))\n    print(df_estimates[df_estimates['month_sabun'] == i].tail(1))","metadata":{"papermill":{"duration":0.074029,"end_time":"2023-05-12T18:09:00.00017","exception":false,"start_time":"2023-05-12T18:08:59.926141","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-05-24T16:14:00.444612Z","iopub.execute_input":"2023-05-24T16:14:00.444988Z","iopub.status.idle":"2023-05-24T16:14:00.49846Z","shell.execute_reply.started":"2023-05-24T16:14:00.444956Z","shell.execute_reply":"2023-05-24T16:14:00.497404Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Get const\nfor t in targets:\n    train3[f'{t}_const'] = train3[['total_month', 'visit_month_cummin_group']].apply(lambda x: (x[\"total_month\"], x[\"visit_month_cummin_group\"], t), axis=1).map(estimates).values","metadata":{"execution":{"iopub.status.busy":"2023-05-24T16:14:00.502808Z","iopub.execute_input":"2023-05-24T16:14:00.503172Z","iopub.status.idle":"2023-05-24T16:14:00.890146Z","shell.execute_reply.started":"2023-05-24T16:14:00.503144Z","shell.execute_reply":"2023-05-24T16:14:00.889136Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 5. Prediction (Slope)","metadata":{}},{"cell_type":"code","source":"list_feat_get_coef_rating = []\nlist_feat_get_coef_rating.append(\"pro_monthkbn_cumcount_month0_0\")\nlist_feat_get_coef_rating.append(\"pro_monthkbn_cumcount_month0_1\")\nlist_feat_get_coef_rating.append(\"pro_monthkbn_cumcount_month6_0\")\nlist_feat_get_coef_rating.append(\"pro_monthkbn_cumcount_month6_1\")\nlist_feat_get_coef_rating.append(\"pro_monthkbn_cumcount_month12_0\")\nlist_feat_get_coef_rating.append(\"pro_monthkbn_cumcount_month12_1\")\nlist_feat_get_coef_rating.append(\"pro_monthkbn_cumcount_month18_0\")\nlist_feat_get_coef_rating.append(\"pro_monthkbn_cumcount_month18_1\")\nlist_feat_get_coef_rating.append(\"pro_monthkbn_cumcount_month24_0\")\nlist_feat_get_coef_rating.append(\"pro_monthkbn_cumcount_month24_1\")\nlist_feat_get_coef_rating.append(\"feat_propep_worse\")\nlist_feat_get_coef_rating.append(\"feat_propep_better\")\ndef get_coef_rating(df):\n    df_y = df.copy()\n    df_y['feat1'] = np.where((df_y['visit_month_cummin_group'] <= 2)\n                             & (df_y['pro_monthkbn_cumcount_month6_0'] == 1), 1, 0)\n    df_y['feat2'] = np.where((df_y['visit_month_cummin_group'] <= 2)\n                             & (df_y['pro_monthkbn_cumcount_month6_1'] == 1)\n                             & (df_y['pro_monthkbn_cumcount_month12_0'] == 1), 1, 0)\n    df_y['feat3'] = np.where((df_y['visit_month_cummin_group'] <= 2) \n                             & (df_y['pro_monthkbn_cumcount_month6_1'] == 1), 1, 0)\n    df_y['feat4'] = np.where((df_y['visit_month_cummin_group'] <= 2)\n                             & (df_y['pro_monthkbn_cumcount_month6_1'] == 1)\n                             & (df_y['pro_monthkbn_cumcount_month12_1'] == 1), 1, 0)\n    df_y['feat5'] = np.where((df_y['visit_month_cummin_group'] <= 2)\n                             & (df_y['pro_monthkbn_cumcount_month6_0'] == 1)\n                             & (df_y['pro_monthkbn_cumcount_month18_1'] == 1), 1, 0)\n    df_y['feat6'] = np.where((df_y[\"visit_month_cummin_group\"] <= 2)\n                             & (df_y[\"feat_propep_worse\"] >= 0.7), 1, 0)\n    df_y['feat7'] = np.where((df_y[\"visit_month_cummin_group\"] <= 2)\n                             & (df_y[\"feat_propep_worse\"] >= 0.8), 1, 0)\n    df_y['feat7_2'] = np.where((df_y[\"visit_month_cummin_group\"] == 3)\n                               & (df_y[\"feat_propep_worse\"] >= 0.8), 1, 0)\n    df_y['feat8'] = np.where((df_y[\"visit_month_cummin_group\"] <= 2)\n                             & (df_y[\"feat_propep_better\"] <= 0.3), 1, 0)\n    df_y['feat9'] = np.where((df_y[\"visit_month_cummin_group\"] <= 2)\n                             & (df_y[\"feat_propep_better\"] <= 0.2), 1, 0)\n    dic_list_coef = dict(feat1=[0, -1, -2],\n                         feat2=[0, -1, 0],\n                         feat3=[0, 1, 2],\n                         feat4=[0, 0, 1],\n                         feat5=[-1, -1, -8],\n                         feat6=[0, 1, 1],\n                         feat7=[1, 1, 2],\n                         feat7_2=[1, 0, 0],\n                         feat8=[0, 0, -1],\n                         feat9=[0, -1, -1])\n    df_y[\"updrs_1_slope\"] = 0\n    df_y[\"updrs_2_slope\"] = 0\n    df_y[\"updrs_3_slope\"] = 0\n    for k, v in dic_list_coef.items():\n        df_y[\"updrs_1_slope\"] += df_y[k] * v[0]\n        df_y[\"updrs_2_slope\"] += df_y[k] * v[1]\n        df_y[\"updrs_3_slope\"] += df_y[k] * v[2]\n    df_y[\"updrs_1_hat\"] = df_y[\"updrs_1_slope\"] + df_y[\"updrs_1_const\"]\n    df_y[\"updrs_2_hat\"] = df_y[\"updrs_2_slope\"] + df_y[\"updrs_2_const\"]\n    df_y[\"updrs_3_hat\"] = df_y[\"updrs_3_slope\"] + df_y[\"updrs_3_const\"]\n    df_y[\"updrs_4_hat\"] = df_y[\"updrs_4_const\"]  # updrs_4 has only const\n    return df_y.copy()\n\n# Get final score\nprint(train3.shape)\ntrain4 = get_coef_rating(train3)\nprint(train4.shape)","metadata":{"papermill":{"duration":1.336499,"end_time":"2023-05-12T18:09:12.753426","exception":false,"start_time":"2023-05-12T18:09:11.416927","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-05-24T16:14:00.891631Z","iopub.execute_input":"2023-05-24T16:14:00.891923Z","iopub.status.idle":"2023-05-24T16:14:00.946433Z","shell.execute_reply.started":"2023-05-24T16:14:00.891898Z","shell.execute_reply":"2023-05-24T16:14:00.943985Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 6. CV Score","metadata":{}},{"cell_type":"code","source":"# CV Score\ndef calc_smape(df):\n    validation_x = []\n    validation_y = []\n    for id, row in df.iterrows():\n        for t in targets:\n            if row[f'{t}'] >= 0:\n                validation_x.append(row[f'{t}_hat'])\n                validation_y.append(row[f'{t}'])\n    return f\"{smape(validation_y, validation_x):.4f}\"\n\nprint(\"=== CV Score (shape) ===\")\ntrain_cv1 = train4[(train4[\"propep_status\"] >= 1) & (train4[\"add_flg\"] == 0)].copy().reset_index(drop=True)\nprint(train_cv1.shape)\ntrain_cv2 = train4[train4[\"add_flg\"] == 0].copy().reset_index(drop=True)\nprint(train_cv2.shape)\ntrain_cv3 = train4.copy()\nprint(train_cv3.shape)\nprint(\"=== CV Score ===\")\nsmape1 = calc_smape(train_cv1)\nsmape2 = calc_smape(train_cv2)\nsmape3 = calc_smape(train_cv3)\nprint(VER,\",\",smape1,\",\",smape2,\",\",smape3)","metadata":{"papermill":{"duration":0.616737,"end_time":"2023-05-12T18:09:11.376113","exception":false,"start_time":"2023-05-12T18:09:10.759376","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-05-24T16:14:00.948067Z","iopub.execute_input":"2023-05-24T16:14:00.948438Z","iopub.status.idle":"2023-05-24T16:14:02.181782Z","shell.execute_reply.started":"2023-05-24T16:14:00.948407Z","shell.execute_reply":"2023-05-24T16:14:02.180767Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 7. Time Series API","metadata":{"papermill":{"duration":0.013385,"end_time":"2023-05-12T18:09:12.864482","exception":false,"start_time":"2023-05-12T18:09:12.851097","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# import amp_pd_peptide (old)\nimport amp_pd_peptide_310\n\namp_pd_peptide_310.make_env.func_dict['__called__'] = False\nenv = amp_pd_peptide_310.make_env()   # initialize the environment\niter_test = env.iter_test()    # an iterator which loops over the test files\n\n# The API will deliver four dataframes in this specific order:\nlist_test = [train]\nlist_pro = [train_pro]\nlist_pep = [train_pep]\nfor (test, test_peptides, test_proteins, sample_submission) in iter_test:\n    list_test.append(test)\n    list_pro.append(test_proteins)\n    list_pep.append(test_peptides)\n    # This maps the correct value estimate to each line in sample_submission\n    sample_submission['patient_id'] = sample_submission['prediction_id'].str.split('_').apply(lambda x: int(x[0]))\n    sample_submission['visit_id'] = sample_submission['prediction_id'].str.split('_').apply(lambda x: '_'.join(x[0:2]))\n    sample_submission['targets_updrs'] = sample_submission['prediction_id'].str.split('_').apply(lambda x: '_'.join(x[2:4]))\n    sample_submission['months'] = sample_submission['prediction_id'].str.split('_').apply(lambda x: int(x[1]) + int(x[5]))\n    test_all = pd.concat(list_test).drop_duplicates([\"patient_id\", \"visit_month\", \"visit_id\"]).sort_values(by=[\"patient_id\", \"visit_month\"])\n    test_all[\"add_flg\"] = 0\n    test_all[\"total_month\"] = test_all[\"visit_month\"]\n    test_all = get_diff(test_all.copy())\n    test_pro = pd.concat(list_pro).sort_values(by=['patient_id', 'visit_month']).reset_index()\n    test_pep = pd.concat(list_pep).sort_values(by=['patient_id', 'visit_month']).reset_index()\n    test_all = get_diff_monthkbn(test_all.reset_index(drop=True).copy(), \"\")\n    test_pro_diff_monthkbn = test_pro[[\"patient_id\", \"visit_month\", \"visit_id\"]].drop_duplicates().sort_values(by=[\"patient_id\", \"visit_month\"])\n    test_pro_diff_monthkbn = get_diff_monthkbn(test_pro_diff_monthkbn.reset_index(drop=True).copy(), \"pro_\")\n    test_all1 = get_diff_monthkbn_merge(test_all, test_pro_diff_monthkbn)\n    test_all2 = get_count_rank_qcut(test_all1, test_pro, test_pep)\n    test_all3 = get_propep(test_all2, test_pro, test_pep)\n    list_feat_status = [\"visit_month_cummin_group\", \"propep_status\"]\n    sample_submission = sample_submission.merge(test_all3[[\"visit_id\"] + list_feat_status + list_feat_get_coef_rating], on=[\"visit_id\"], how=\"left\")\n    for i in list_feat_get_coef_rating:\n        sample_submission[i] = sample_submission[i].fillna(0)\n    targets_months_updrs = sample_submission[['months', \"visit_month_cummin_group\", 'targets_updrs']].apply(lambda x: (x[\"months\"], x[\"visit_month_cummin_group\"], x[\"targets_updrs\"]), axis=1)\n    sample_submission['updrs_1_const'] = targets_months_updrs.map(estimates).fillna(0)\n    sample_submission['updrs_2_const'] = targets_months_updrs.map(estimates).fillna(0)\n    sample_submission['updrs_3_const'] = targets_months_updrs.map(estimates).fillna(0)\n    sample_submission['updrs_4_const'] = targets_months_updrs.map(estimates).fillna(0)\n    sample_submission = get_coef_rating(sample_submission)\n    sample_submission['rating'] = sample_submission['updrs_1_hat']\n    sample_submission['rating'].mask((sample_submission[\"targets_updrs\"] == \"updrs_2\"), sample_submission['updrs_2_hat'], inplace=True)\n    sample_submission['rating'].mask((sample_submission[\"targets_updrs\"] == \"updrs_3\"), sample_submission['updrs_3_hat'], inplace=True)\n    sample_submission['rating'].mask((sample_submission[\"targets_updrs\"] == \"updrs_4\"), sample_submission['updrs_4_hat'], inplace=True)\n    \n    # debug\n    print(sample_submission[['prediction_id', 'rating']].head(1))\n    print(sample_submission[['prediction_id', 'rating']].tail(1))\n    \n    # Saves predictions to csv file\n    env.predict(sample_submission[['prediction_id', 'rating']])","metadata":{"papermill":{"duration":20.537161,"end_time":"2023-05-12T18:09:33.415582","exception":false,"start_time":"2023-05-12T18:09:12.878421","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-05-24T16:14:02.182964Z","iopub.execute_input":"2023-05-24T16:14:02.183303Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# check normal end\nsubmission = pd.read_csv('/kaggle/working/submission.csv')\nsubmission","metadata":{"papermill":{"duration":0.035958,"end_time":"2023-05-12T18:09:33.465642","exception":false,"start_time":"2023-05-12T18:09:33.429684","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"papermill":{"duration":0.014939,"end_time":"2023-05-12T18:09:33.495399","exception":false,"start_time":"2023-05-12T18:09:33.48046","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"papermill":{"duration":0.013998,"end_time":"2023-05-12T18:09:33.5241","exception":false,"start_time":"2023-05-12T18:09:33.510102","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"papermill":{"duration":0.014141,"end_time":"2023-05-12T18:09:33.552978","exception":false,"start_time":"2023-05-12T18:09:33.538837","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"papermill":{"duration":0.014727,"end_time":"2023-05-12T18:09:33.582638","exception":false,"start_time":"2023-05-12T18:09:33.567911","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"papermill":{"duration":0.014295,"end_time":"2023-05-12T18:09:33.611624","exception":false,"start_time":"2023-05-12T18:09:33.597329","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"papermill":{"duration":0.014659,"end_time":"2023-05-12T18:09:33.640878","exception":false,"start_time":"2023-05-12T18:09:33.626219","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"papermill":{"duration":0.014193,"end_time":"2023-05-12T18:09:33.669651","exception":false,"start_time":"2023-05-12T18:09:33.655458","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"papermill":{"duration":0.014175,"end_time":"2023-05-12T18:09:33.69925","exception":false,"start_time":"2023-05-12T18:09:33.685075","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"papermill":{"duration":0.015675,"end_time":"2023-05-12T18:09:33.729612","exception":false,"start_time":"2023-05-12T18:09:33.713937","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"papermill":{"duration":0.014309,"end_time":"2023-05-12T18:09:33.759173","exception":false,"start_time":"2023-05-12T18:09:33.744864","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]}]}