{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Idea:\n* Use month trend similar to [Only Trends](https://www.kaggle.com/code/vitalykudelya/only-trends)\n* Divide NPX values of a protein P05060 into several groups and find the best shift after month trend predicitons for each group\n* Sum predictions from the month trend and the corresponding NPX group shift\n\nProtein P05060 imporoved cross-validation score, public score and private score over Trend. <br>\nI'm not sure is it a pure luck or we have a real signal in P05060 protein.\n\nProtein P05060 was chosen as the best protein improving the score on the train dataset (for NPX groups top5 quantile and low5 quantile)","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom collections import defaultdict\nfrom tqdm.auto import tqdm\n\nimport plotly.express as px\n\nimport amp_pd_peptide\n\nfrom scipy.optimize import minimize","metadata":{"execution":{"iopub.status.busy":"2023-05-15T20:10:31.122161Z","iopub.execute_input":"2023-05-15T20:10:31.122514Z","iopub.status.idle":"2023-05-15T20:10:33.43951Z","shell.execute_reply.started":"2023-05-15T20:10:31.122484Z","shell.execute_reply":"2023-05-15T20:10:33.438499Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def smape_plus_1(y_true, y_pred):\n    y_true_plus_1 = y_true + 1\n    y_pred_plus_1 = y_pred + 1\n    metric = np.zeros(len(y_true_plus_1))\n    \n    numerator = np.abs(y_true_plus_1 - y_pred_plus_1)\n    denominator = ((np.abs(y_true_plus_1) + np.abs(y_pred_plus_1)) / 2)\n    \n    mask_not_zeros = (y_true_plus_1 != 0) | (y_pred_plus_1 != 0)\n    metric[mask_not_zeros] = numerator[mask_not_zeros] / denominator[mask_not_zeros]\n    \n    return 100 * np.nanmean(metric)","metadata":{"execution":{"iopub.status.busy":"2023-05-15T20:10:33.441052Z","iopub.execute_input":"2023-05-15T20:10:33.441382Z","iopub.status.idle":"2023-05-15T20:10:33.447255Z","shell.execute_reply.started":"2023-05-15T20:10:33.441351Z","shell.execute_reply":"2023-05-15T20:10:33.446396Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Generate Train Dataset","metadata":{}},{"cell_type":"code","source":"train_clinical_all = pd.read_csv('/kaggle/input/amp-parkinsons-disease-progression-prediction/train_clinical_data.csv')\nproteins = pd.read_csv('/kaggle/input/amp-parkinsons-disease-progression-prediction/train_proteins.csv')\nproteins_features = pd.pivot_table(proteins, values='NPX', index='visit_id', columns='UniProt', aggfunc='sum')\n\ntrain_clinical_all = train_clinical_all.merge(\n    proteins_features,\n    left_on='visit_id',\n    right_index=True,\n    how='left'\n)","metadata":{"execution":{"iopub.status.busy":"2023-05-15T20:10:33.448126Z","iopub.execute_input":"2023-05-15T20:10:33.449352Z","iopub.status.idle":"2023-05-15T20:10:33.841911Z","shell.execute_reply.started":"2023-05-15T20:10:33.449201Z","shell.execute_reply":"2023-05-15T20:10:33.840811Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_clinical_all[proteins_features.columns] = train_clinical_all.groupby('patient_id')[proteins_features.columns].\\\n                                                                                        fillna(method='ffill')","metadata":{"execution":{"iopub.status.busy":"2023-05-15T20:10:33.843653Z","iopub.execute_input":"2023-05-15T20:10:33.843947Z","iopub.status.idle":"2023-05-15T20:10:33.969827Z","shell.execute_reply.started":"2023-05-15T20:10:33.843922Z","shell.execute_reply":"2023-05-15T20:10:33.968616Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_clinical_all['pred_month'] = train_clinical_all['visit_month']\n\nfor plus_month in [6, 12, 24]:\n    train_shift = train_clinical_all[['patient_id', 'visit_month', 'pred_month', 'updrs_1', 'updrs_2', 'updrs_3', 'updrs_4']].copy()\n    train_shift['visit_month'] -= plus_month\n    train_shift.rename(columns={f'updrs_{i}': f'updrs_{i}_plus_{plus_month}' for i in range(1, 5)}, inplace=True)\n    train_shift.rename(columns={'pred_month': f'pred_month_plus_{plus_month}'}, inplace=True)\n    train_clinical_all = train_clinical_all.merge(train_shift, how='left', on=['patient_id', 'visit_month'])\n\ntrain_clinical_all.rename(columns={f'updrs_{i}': f'updrs_{i}_plus_0' for i in range(1, 5)}, inplace=True)\ntrain_clinical_all.rename(columns={'pred_month': f'pred_month_plus_0'}, inplace=True)\ntrain_clinical_all","metadata":{"execution":{"iopub.status.busy":"2023-05-15T20:10:33.970678Z","iopub.execute_input":"2023-05-15T20:10:33.970921Z","iopub.status.idle":"2023-05-15T20:10:34.048303Z","shell.execute_reply.started":"2023-05-15T20:10:33.970896Z","shell.execute_reply":"2023-05-15T20:10:34.047618Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def calculate_month_trend_predicitons(pred_month, trend, min_month_with_non_zero_median_u4):\n    if target == 'updrs_4': \n        result = trend[0] + pred_month * trend[1]\n        result[pred_month <= min_month_with_non_zero_median_u4] = 0\n        return result\n    \n    if len(trend) == 3:\n        return trend[0] + pred_month * trend[1] + pred_month**2 * trend[2]\n    else:\n        return trend[0] + pred_month * trend[1]\n\ntarget_to_trend = {\n    'updrs_1': {\n        'trend': [5.394793062665313, 0.027091086167821344],\n        'min_month_with_non_zero_median_u4': 72\n    },\n    'updrs_2': {\n        'trend': [5.469498130092747, 0.02824188329658148],\n        'min_month_with_non_zero_median_u4': 72\n    },\n    'updrs_3': {\n        'trend': [21.47671255789872, 0.030885385412370472, 0.00117880267326171],\n        'min_month_with_non_zero_median_u4': 72\n    },\n    'updrs_4': {\n        'trend': [2.2953201375507626, 0.002284573636684357],\n        'min_month_with_non_zero_median_u4': 72\n    }\n}","metadata":{"execution":{"iopub.status.busy":"2023-05-15T20:10:34.215237Z","iopub.execute_input":"2023-05-15T20:10:34.216562Z","iopub.status.idle":"2023-05-15T20:10:34.22371Z","shell.execute_reply.started":"2023-05-15T20:10:34.216522Z","shell.execute_reply":"2023-05-15T20:10:34.222921Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def calculate_predicitons_protein(protein, pred_month, protein_shift):\n    trend_pred_month = target_to_trend[target]\n    pred_month_trend = calculate_month_trend_predicitons(\n        pred_month=pred_month, \n        trend=trend_pred_month['trend'],\n        min_month_with_non_zero_median_u4=trend_pred_month['min_month_with_non_zero_median_u4']\n    )\n    return np.round(pred_month_trend + protein_shift)\n\ndef function_to_minimize(x):\n    metric = smape_plus_1(\n        y_true=y_true_array, \n        y_pred=calculate_predicitons_protein(\n            protein=protein_array,\n            pred_month=pred_month_array,\n            protein_shift=x[0]\n        )\n    )\n    return metric","metadata":{"execution":{"iopub.status.busy":"2023-05-15T20:10:38.344525Z","iopub.execute_input":"2023-05-15T20:10:38.344884Z","iopub.status.idle":"2023-05-15T20:10:38.351322Z","shell.execute_reply.started":"2023-05-15T20:10:38.344848Z","shell.execute_reply":"2023-05-15T20:10:38.350284Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def find_best_const(train_clinical_all_filtered, target):\n    columns_with_target = [f'{target}_plus_{plus_month}' for plus_month in [0, 6, 12, 24]]\n    columns_with_pred_month = [f'pred_month_plus_{plus_month}' for plus_month in [0, 6, 12, 24]]\n    global y_true_array\n    global pred_month_array\n    global protein_array\n    y_true_array = train_clinical_all_filtered[columns_with_target].values.ravel()\n    pred_month_array = train_clinical_all_filtered[columns_with_pred_month].values.ravel()\n    protein_array = np.concatenate([train_clinical_all_filtered[feature].values] * 4)\n    result = minimize(\n        fun=function_to_minimize,\n        x0=[0.0],\n        method='Powell'\n    ).x[0]\n    return result","metadata":{"execution":{"iopub.status.busy":"2023-05-15T20:10:41.808516Z","iopub.execute_input":"2023-05-15T20:10:41.80888Z","iopub.status.idle":"2023-05-15T20:10:41.815752Z","shell.execute_reply.started":"2023-05-15T20:10:41.808849Z","shell.execute_reply":"2023-05-15T20:10:41.814983Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Plot shifts","metadata":{"execution":{"iopub.status.busy":"2023-05-04T22:56:47.904667Z","iopub.execute_input":"2023-05-04T22:56:47.905208Z","iopub.status.idle":"2023-05-04T22:56:47.910904Z","shell.execute_reply.started":"2023-05-04T22:56:47.905165Z","shell.execute_reply":"2023-05-04T22:56:47.909989Z"}}},{"cell_type":"code","source":"feature = 'P05060'\nquantiles = [0, 0.025, 0.05, 0.15, 0.85, 0.95, 0.975, 1.0]\n\ndf_plot = []\nfor quantile_low, quantile_high in tqdm(zip(quantiles[:-1], quantiles[1:])):\n    item = {\n        'quantile_low': quantile_low,\n        'quantile_high': quantile_high,\n        'quantile_middle': (quantile_low + quantile_high) / 2\n    }\n    quantile_low_value = train_clinical_all[feature].quantile(quantile_low)\n    quantile_high_value = train_clinical_all[feature].quantile(quantile_high)\n    item['quantile_low_value'] = quantile_low_value\n    item['quantile_high_value'] = quantile_high_value\n    \n    if quantile_high == 1:\n        quantile_high_value += 0.00001\n        \n    train_clinical_all_filtered = train_clinical_all[\n        (train_clinical_all[feature] >= quantile_low_value)\n        & (train_clinical_all[feature] < quantile_high_value)\n    ]\n    for target in ['updrs_1', 'updrs_2', 'updrs_3', 'updrs_4']:\n        item[f'{target}_shift'] = find_best_const(train_clinical_all_filtered, target)\n    df_plot.append(item)\n    \ndf_plot = pd.DataFrame(df_plot)","metadata":{"execution":{"iopub.status.busy":"2023-05-15T20:10:58.161331Z","iopub.execute_input":"2023-05-15T20:10:58.161671Z","iopub.status.idle":"2023-05-15T20:10:58.398448Z","shell.execute_reply.started":"2023-05-15T20:10:58.161645Z","shell.execute_reply":"2023-05-15T20:10:58.397388Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for target in ['updrs_1', 'updrs_2', 'updrs_3', 'updrs_4']:\n    fig = px.line(\n        df_plot,\n        y=f'{target}_shift',\n        x='quantile_middle',\n        title=feature + ' ' + target\n    )\n    fig.show()","metadata":{"execution":{"iopub.status.busy":"2023-05-15T20:10:58.874386Z","iopub.execute_input":"2023-05-15T20:10:58.87476Z","iopub.status.idle":"2023-05-15T20:11:00.542583Z","shell.execute_reply.started":"2023-05-15T20:10:58.874725Z","shell.execute_reply":"2023-05-15T20:11:00.541526Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Find shifts","metadata":{}},{"cell_type":"code","source":"target_to_clip_max = {\n    'updrs_1': 6,\n    'updrs_2': 3,\n    'updrs_3': 6,\n    'updrs_4': 1\n}\n\ntarget_to_clips_025_low = {target: (0, target_to_clip_max[target]) for target in target_to_clip_max.keys()}\ntarget_to_clips_025_high = {target: (-target_to_clip_max[target], 0) for target in target_to_clip_max.keys()}\n\ntarget_to_clips_025_05_low = {target: (0, target_to_clip_max[target] / 4) for target in target_to_clip_max.keys()}\ntarget_to_clips_025__05_high = {target: (-target_to_clip_max[target] / 4, 0) for target in target_to_clip_max.keys()}\n\ntarget_to_clips_5_15_low = {target: (0, target_to_clip_max[target] / 5) for target in target_to_clip_max.keys()}\ntarget_to_clips_5_15_high = {target: (-target_to_clip_max[target] / 5, 0) for target in target_to_clip_max.keys()}\n\n\nnpx_groups = [\n    {'quantile_low': 0.0, 'quantile_high': 0.025, 'clip': target_to_clips_025_low},\n    {'quantile_low': 0.975, 'quantile_high': 1.0, 'clip': target_to_clips_025_high},\n\n    {'quantile_low': 0.025, 'quantile_high': 0.05, 'clip': target_to_clips_025_05_low},\n    {'quantile_low': 0.95, 'quantile_high': 0.975, 'clip': target_to_clips_025__05_high},\n\n    {'quantile_low': 0.05, 'quantile_high': 0.15, 'clip': target_to_clips_5_15_low},\n    {'quantile_low': 0.85, 'quantile_high': 0.95, 'clip': target_to_clips_5_15_high},\n]\ntarget_to_npx_groups_shift = defaultdict(list)\n\nfor target in ['updrs_1', 'updrs_2', 'updrs_3']:\n    for npx_group in npx_groups:\n        item = npx_group.copy()\n        item['feature'] = feature\n        \n        if item['quantile_low'] == 0:\n            item['quantile_low_value'] = -np.inf\n        else:\n            item['quantile_low_value'] = train_clinical_all[feature].quantile(item['quantile_low'])\n            \n        if item['quantile_high'] == 1:\n            item['quantile_high_value'] = np.inf\n        else: \n            item['quantile_high_value'] = train_clinical_all[feature].quantile(item['quantile_high'])\n\n        train_clinical_all_filtered = train_clinical_all[\n            (train_clinical_all[feature] >= item['quantile_low_value'])\n            & (train_clinical_all[feature] < item['quantile_high_value'])\n        ]\n        \n        item['shift'] = find_best_const(train_clinical_all_filtered, target).clip(*item['clip'][target])\n        target_to_npx_groups_shift[target].append(item)\n\ntarget_to_npx_groups_shift","metadata":{"execution":{"iopub.status.busy":"2023-05-15T20:11:51.33269Z","iopub.execute_input":"2023-05-15T20:11:51.333072Z","iopub.status.idle":"2023-05-15T20:11:51.53951Z","shell.execute_reply.started":"2023-05-15T20:11:51.333038Z","shell.execute_reply":"2023-05-15T20:11:51.538286Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Predictions","metadata":{}},{"cell_type":"code","source":"amp_pd_peptide.make_env.func_dict['__called__'] = False\nenv = amp_pd_peptide.make_env()   # initialize the environment\niter_test = env.iter_test()    # an iterator which loops over the test files\n\nproteins_features_all = pd.DataFrame()\n# The API will deliver four dataframes in this specific order:\nfor test_clinical_data, test_peptides, test_proteins, sample_submission in iter_test:\n    sample_submission['patient_id'] = sample_submission['prediction_id'].map(lambda x: int(x.split('_')[0]))\n    sample_submission['visit_month'] = sample_submission['prediction_id'].map(lambda x: int(x.split('_')[1]))\n    sample_submission['target_name'] = sample_submission['prediction_id'].map(lambda x: 'updrs_' + x.split('_')[3])\n    sample_submission['plus_month'] = sample_submission['prediction_id'].map(lambda x: int(x.split('_')[5]))\n    sample_submission['pred_month'] = sample_submission['visit_month'] + sample_submission['plus_month']\n    sample_submission['visit_id'] = sample_submission['patient_id'].astype(str) + '_' + sample_submission['visit_month'].astype(str)\n    \n    proteins_features = pd.pivot_table(test_proteins, values='NPX', index='visit_id', columns='UniProt', aggfunc='sum')\n    proteins_features['visit_id'] = proteins_features.index\n    proteins_features_all = pd.concat([proteins_features_all, proteins_features])\n    proteins_features_all['patient_id'] = proteins_features_all.index.map(lambda x: int(x.split('_')[0]))\n    proteins_features_all[proteins_features.columns] = proteins_features_all.groupby('patient_id')[proteins_features.columns].\\\n                                                                                                   fillna(method='ffill')\n    proteins_features = proteins_features_all.groupby('patient_id', as_index=False).last()\n    \n    sample_submission = sample_submission.merge(\n        proteins_features,\n        on='patient_id',\n        how='left'\n    )\n\n    for i in range(1, 5):\n        target = f'updrs_{i}'\n        mask_target = sample_submission['target_name'] == target\n        sample_submission.loc[mask_target, 'rating'] = calculate_month_trend_predicitons(\n            pred_month=sample_submission.loc[mask_target, 'pred_month'],\n            trend=target_to_trend[target]['trend'],\n            min_month_with_non_zero_median_u4=target_to_trend[target]['min_month_with_non_zero_median_u4']\n        )\n        \n        for item in target_to_npx_groups_shift[target]:\n            feature = item['feature']\n            mask_feature_range = mask_target & (\n                (sample_submission[feature] >= item['quantile_low_value'])\n                & (sample_submission[feature] < item['quantile_high_value'])\n            )\n            sample_submission.loc[mask_feature_range, 'rating'] += item['shift']\n\n        sample_submission.loc[mask_target, 'rating'] = np.round(sample_submission.loc[mask_target, 'rating']).clip(0, None)\n        \n    # call the env.predict for every iteration\n    env.predict(sample_submission[['prediction_id', 'rating']])","metadata":{"execution":{"iopub.status.busy":"2023-05-15T20:13:19.464241Z","iopub.execute_input":"2023-05-15T20:13:19.464623Z","iopub.status.idle":"2023-05-15T20:13:19.641832Z","shell.execute_reply.started":"2023-05-15T20:13:19.464589Z","shell.execute_reply":"2023-05-15T20:13:19.640807Z"},"trusted":true},"execution_count":null,"outputs":[]}]}