{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install \"/kaggle/input/pyspellchecker/pyspellchecker-0.7.2-py3-none-any.whl\"\n!pip install /kaggle/input/textstat-pypi/Pyphen-0.9.3-py2.py3-none-any.whl\n!pip install /kaggle/input/textstat-pypi/textstat-0.7.0-py3-none-any.whl","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","papermill":{"duration":65.838762,"end_time":"2023-08-27T11:10:31.641154","exception":false,"start_time":"2023-08-27T11:09:25.802392","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-10-10T17:18:31.063946Z","iopub.execute_input":"2023-10-10T17:18:31.065007Z","iopub.status.idle":"2023-10-10T17:20:12.516048Z","shell.execute_reply.started":"2023-10-10T17:18:31.064967Z","shell.execute_reply":"2023-10-10T17:20:12.514754Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import sys\n\nsys.path.append('/kaggle/input/autocorrect-1-1-1-mit/autocorrect/')","metadata":{"execution":{"iopub.status.busy":"2023-10-10T17:20:12.518499Z","iopub.execute_input":"2023-10-10T17:20:12.518942Z","iopub.status.idle":"2023-10-10T17:20:12.524187Z","shell.execute_reply.started":"2023-10-10T17:20:12.518905Z","shell.execute_reply":"2023-10-10T17:20:12.523206Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from typing import List\nimport gc\nimport numpy as np\nimport pandas as pd\nimport warnings\nimport logging\nimport os\nimport shutil\nimport json\nimport transformers\nfrom transformers import AutoModel, AutoTokenizer, AutoConfig, AutoModelForSequenceClassification\nfrom transformers import DataCollatorWithPadding\nfrom datasets import Dataset,load_dataset, load_from_disk\nfrom transformers import TrainingArguments, Trainer\nfrom datasets import load_metric, disable_progress_bar\nfrom sklearn.metrics import mean_squared_error\nimport torch\nfrom sklearn.model_selection import KFold, GroupKFold\nfrom tqdm import tqdm\n\nimport nltk\nfrom nltk.corpus import stopwords\nfrom nltk.tokenize import word_tokenize\nfrom nltk.tokenize.treebank import TreebankWordDetokenizer\nfrom collections import Counter\nimport spacy\nimport re\nfrom autocorrect import Speller\nfrom spellchecker import SpellChecker\nimport lightgbm as lgb\nimport textstat\n\n\nwarnings.simplefilter(\"ignore\")\nlogging.disable(logging.ERROR)\nos.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\nos.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \ndisable_progress_bar()\ntqdm.pandas()","metadata":{"papermill":{"duration":18.271344,"end_time":"2023-08-27T11:10:49.928337","exception":false,"start_time":"2023-08-27T11:10:31.656993","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-10-11T09:04:34.560762Z","iopub.execute_input":"2023-10-11T09:04:34.561807Z","iopub.status.idle":"2023-10-11T09:04:50.782634Z","shell.execute_reply.started":"2023-10-11T09:04:34.561766Z","shell.execute_reply":"2023-10-11T09:04:50.781646Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def seed_everything(seed: int):\n    import random, os\n    import numpy as np\n    import torch\n    \n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = True\n    \nseed_everything(seed=42)","metadata":{"papermill":{"duration":0.028463,"end_time":"2023-08-27T11:10:49.97308","exception":false,"start_time":"2023-08-27T11:10:49.944617","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-10-11T09:04:54.59529Z","iopub.execute_input":"2023-10-11T09:04:54.595615Z","iopub.status.idle":"2023-10-11T09:04:54.605673Z","shell.execute_reply.started":"2023-10-11T09:04:54.595541Z","shell.execute_reply":"2023-10-11T09:04:54.604719Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class CFG:\n    model_name=\"deberta-v3-large/deberta-v3-large\"\n    learning_rate=0.000016   #0.000015\n    weight_decay=0.02\n    hidden_dropout_prob=0.007\n    attention_probs_dropout_prob=0.007\n    num_train_epochs=5\n    n_splits=4\n    batch_size=4\n    random_seed=42\n    save_steps=100\n    max_length=512\n    target_cols=['cohesion', 'syntax', 'vocabulary', 'phraseology', 'grammar', 'conventions']\n    model = \"microsoft/deberta-v3-base\"\n    path = \"../input/0911-deberta-v3-base/\"\n    base = \"../input/fb3models/microsoft-deberta-v3-base/\"\n    config_path = base + \"config/config.json\"\n    tokenizer = AutoTokenizer.from_pretrained(base + 'tokenizer/')","metadata":{"papermill":{"duration":0.421041,"end_time":"2023-08-27T11:10:50.409927","exception":false,"start_time":"2023-08-27T11:10:49.988886","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-10-11T09:04:54.83571Z","iopub.execute_input":"2023-10-11T09:04:54.835978Z","iopub.status.idle":"2023-10-11T09:04:55.250506Z","shell.execute_reply.started":"2023-10-11T09:04:54.835952Z","shell.execute_reply":"2023-10-11T09:04:55.249635Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Dataload","metadata":{"papermill":{"duration":0.016267,"end_time":"2023-08-27T11:10:50.441892","exception":false,"start_time":"2023-08-27T11:10:50.425625","status":"completed"},"tags":[]}},{"cell_type":"code","source":"DATA_DIR = \"/kaggle/input/commonlit-evaluate-student-summaries/\"\n\ntrain = pd.read_csv('/kaggle/input/tr-no-correct/train.csv')\ndb_train = pd.read_csv('/kaggle/input/wts-squad/fold_train.csv')\n\nprompts_test = pd.read_csv(DATA_DIR + \"prompts_test.csv\")\nsummaries_test = pd.read_csv(DATA_DIR + \"summaries_test.csv\")\nsample_submission = pd.read_csv(DATA_DIR + \"sample_submission.csv\")","metadata":{"papermill":{"duration":0.154414,"end_time":"2023-08-27T11:10:50.611638","exception":false,"start_time":"2023-08-27T11:10:50.457224","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-10-11T09:04:55.550597Z","iopub.execute_input":"2023-10-11T09:04:55.551221Z","iopub.status.idle":"2023-10-11T09:04:57.070466Z","shell.execute_reply.started":"2023-10-11T09:04:55.551186Z","shell.execute_reply":"2023-10-11T09:04:57.069527Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train['iheb_pred_content_6'] = pd.read_csv('/kaggle/input/training-add-new-baseline/train.csv')['iheb_pred_content_6']\ntrain['iheb_pred_wording_6'] = pd.read_csv('/kaggle/input/training-add-new-baseline/train.csv')['iheb_pred_wording_6']","metadata":{"execution":{"iopub.status.busy":"2023-10-11T09:04:58.875471Z","iopub.execute_input":"2023-10-11T09:04:58.875762Z","iopub.status.idle":"2023-10-11T09:05:00.248484Z","shell.execute_reply.started":"2023-10-11T09:04:58.875734Z","shell.execute_reply":"2023-10-11T09:05:00.247531Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train['content_pred_squad'] = db_train['content_pred']\ntrain['wording_pred_squad'] = db_train['wording_pred']","metadata":{"execution":{"iopub.status.busy":"2023-10-11T09:05:01.144874Z","iopub.execute_input":"2023-10-11T09:05:01.14513Z","iopub.status.idle":"2023-10-11T09:05:01.150963Z","shell.execute_reply.started":"2023-10-11T09:05:01.145086Z","shell.execute_reply":"2023-10-11T09:05:01.149866Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Meta Data","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport spacy\nfrom sklearn.preprocessing import LabelEncoder\n\n\n# Load the SpaCy model\nnlp = spacy.load('en_core_web_sm')\n\ndef clean_lexile(lexile):\n    \"\"\"\n    Function to clean lexile feature\n    Args:\n        lexile (str or float): The lexile measure as a string or a float\n\n    Returns:\n        int or np.nan: The cleaned lexile measure as an integer, or np.nan for 'Non-Prose' or 'nan' values\n    \"\"\"\n    if pd.isnull(lexile):\n        return np.nan\n    elif isinstance(lexile, str):\n        if lexile == 'Non-Prose':\n            return np.nan\n        else:\n            # Remove the 'L' at the end and convert to integer\n            return int(lexile.rstrip('L'))\n    else:\n        # If lexile is a float (or any non-string data type), convert to int and return\n        return int(lexile)\n\n# Function to classify author type\ndef classify_author(author):\n    # Process the text\n    doc = nlp(author)\n    \n    # Check if any of the entities are labeled as 'PERSON'\n    for ent in doc.ents:\n        if ent.label_ == 'PERSON':\n            return 'person'\n            \n    # If no 'PERSON' entity is found, return 'org'\n    return 'org'\n\n\ndef encode_author_type(df):\n    \"\"\"\n    Function to encode author_type feature\n    Args:\n        df (pd.DataFrame): The DataFrame with 'author_type' column\n\n    Returns:\n        pd.DataFrame: The DataFrame with 'author_type' replaced with numerical values\n    \"\"\"\n    le = LabelEncoder()\n    df['author_type'] = le.fit_transform(df['author_type'])\n    return df\n\ndef clean_grade(df):\n    \"\"\"\n    Function to clean grade feature\n    Args:\n        df (pd.DataFrame): The DataFrame with 'grade' column\n\n    Returns:\n        pd.DataFrame: The DataFrame with 'grade' replaced with integer values\n    \"\"\"\n    df['grade'] = df['grade'].astype(str).str.replace('rd Grade', '')\n    df['grade'] = df['grade'].str.replace('th Grade', '')\n    df['grade'] = df['grade'].apply(lambda x: int(x) if x.isdigit() else 0)\n    return df\n\n\n\ndef group_and_encode_genre(df):\n    \"\"\"\n    Function to group and encode genre feature\n    Args:\n        df (pd.DataFrame): The DataFrame with 'genre' column\n\n    Returns:\n        pd.DataFrame: The DataFrame with 'genre' replaced with grouped and encoded values\n    \"\"\"\n    genre_map = {\n        'Fiction': ['Poem', 'Short Story', 'Folktale', 'Fantasy', 'Science Fiction', 'Allegory', 'Fiction - General', 'Fable', 'Myth', 'Historical Fiction', 'Magical Realism', 'Drama'],\n        'Non-Fiction': ['Informational Text', 'Non-Fiction - General', 'Biography', 'Essay', 'Memoir', 'Interview', 'Psychology', 'Primary Source Document', 'Autobiography'],\n        'News & Opinion': ['News', 'Opinion'],\n        'Historic & Legal': ['Historical Document', 'Legal Document', 'Letter'],\n        'Philosophy & Religion': ['Speech', 'Religious Text', 'Satire', 'Political Theory', 'Philosophy']\n    }\n\n    # Reverse the genre_map dictionary for mapping\n    reverse_genre_map = {genre: key for key, values in genre_map.items() for genre in values}\n\n    df['genre_big_group'] = df['genre'].map(reverse_genre_map)\n\n    # If the genre is not found in the map, assign it to 'Other'\n    df['genre_big_group'] = df['genre_big_group'].fillna('Other')\n\n    le = LabelEncoder()\n    df['genre_big_group_encode'] = le.fit_transform(df['genre_big_group'])\n    \n    return df\n","metadata":{"execution":{"iopub.status.busy":"2023-10-11T09:05:02.753963Z","iopub.execute_input":"2023-10-11T09:05:02.75423Z","iopub.status.idle":"2023-10-11T09:05:04.995876Z","shell.execute_reply.started":"2023-10-11T09:05:02.754204Z","shell.execute_reply":"2023-10-11T09:05:04.994845Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Usage\nprompt_grade = pd.read_csv(r'/kaggle/input/commonlit-texts/commonlit_texts.csv')\n# df = pd.read_csv(r'/kaggle/input/commonlit-texts/commonlit_texts.csv')\nprompt_grade['author_type'] = prompt_grade['author'].apply(classify_author)\nprompt_grade['lexile_md'] = prompt_grade['lexile'].apply(clean_lexile)\nprompt_grade = encode_author_type(prompt_grade)\nprompt_grade = clean_grade(prompt_grade)\nprompt_grade = group_and_encode_genre(prompt_grade)","metadata":{"execution":{"iopub.status.busy":"2023-10-11T09:05:04.997955Z","iopub.execute_input":"2023-10-11T09:05:04.998851Z","iopub.status.idle":"2023-10-11T09:05:18.818Z","shell.execute_reply.started":"2023-10-11T09:05:04.998816Z","shell.execute_reply":"2023-10-11T09:05:18.817058Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"prompt_grade.head()","metadata":{"execution":{"iopub.status.busy":"2023-10-11T09:05:18.819395Z","iopub.execute_input":"2023-10-11T09:05:18.82027Z","iopub.status.idle":"2023-10-11T09:05:18.84521Z","shell.execute_reply.started":"2023-10-11T09:05:18.820236Z","shell.execute_reply":"2023-10-11T09:05:18.844268Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def preprocess_and_join(df1, df2, df1_title_col, df2_title_col, grade_col):\n    # Copy dataframes to avoid modifying the originals\n    df1 = df1.copy()\n    df2 = df2.copy()\n\n    # Preprocess titles\n    df1[df1_title_col] = df1[df1_title_col].str.replace('\"', '').str.strip()\n    df2[df2_title_col] = df2[df2_title_col].str.replace('\"', '').str.strip()\n\n    # Remove duplicate grades\n    df2 = df2.drop_duplicates(subset=df2_title_col, keep='first')\n\n    # Join dataframes\n    merged_df = df1.merge(df2, how='left', left_on=df1_title_col, right_on=df2_title_col)\n    \n\n    # Postprocess grades\n    merged_df[grade_col] = merged_df[grade_col].fillna(0)\n    merged_df[grade_col] = merged_df[grade_col].astype(int).astype('category')\n\n \n    return merged_df\n\n# Usage\nDATA_DIR = \"/kaggle/input/commonlit-evaluate-student-summaries/\"\nprompts_train = pd.read_csv(DATA_DIR + \"prompts_train.csv\")\nprompts_test = pd.read_csv(DATA_DIR + \"prompts_test.csv\")\nsummaries_train = pd.read_csv(DATA_DIR + \"summaries_train.csv\")\nsummaries_test = pd.read_csv(DATA_DIR + \"summaries_test.csv\")\nsample_submission = pd.read_csv(DATA_DIR + \"sample_submission.csv\")\n# prompt_grade = pd.read_csv(r'/kaggle/input/litess-titles/all_titles.csv')\ntrain = preprocess_and_join(train, prompt_grade, 'prompt_title', 'title', 'grade')\nprompts_test = preprocess_and_join(prompts_test, prompt_grade, 'prompt_title', 'title', 'grade')","metadata":{"execution":{"iopub.status.busy":"2023-10-11T09:05:18.847608Z","iopub.execute_input":"2023-10-11T09:05:18.848449Z","iopub.status.idle":"2023-10-11T09:05:19.006778Z","shell.execute_reply.started":"2023-10-11T09:05:18.848409Z","shell.execute_reply":"2023-10-11T09:05:19.005813Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.head()","metadata":{"execution":{"iopub.status.busy":"2023-10-11T09:05:19.00816Z","iopub.execute_input":"2023-10-11T09:05:19.008699Z","iopub.status.idle":"2023-10-11T09:05:19.032907Z","shell.execute_reply.started":"2023-10-11T09:05:19.008661Z","shell.execute_reply":"2023-10-11T09:05:19.031785Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Label Encode","metadata":{}},{"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\nto_encode = ['genre', 'genre_big_group']\n\n\nfor c in to_encode:\n    mapper = dict(zip(train[c].unique(), range(train[c].nunique())))\n    train[c] = train[c].map(mapper)\n    prompts_test[c] = prompts_test[c].map(mapper)","metadata":{"execution":{"iopub.status.busy":"2023-10-11T09:05:19.034826Z","iopub.execute_input":"2023-10-11T09:05:19.035478Z","iopub.status.idle":"2023-10-11T09:05:19.052063Z","shell.execute_reply.started":"2023-10-11T09:05:19.035438Z","shell.execute_reply":"2023-10-11T09:05:19.050936Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Preprocess\n\n[Using features]\n\n- Text Length\n- Length Ratio\n- Word Overlap\n- N-grams Co-occurrence\n  - count\n  - ratio\n- Quotes Overlap\n- Grammar Check\n  - spelling: pyspellchecker\n","metadata":{"papermill":{"duration":0.028367,"end_time":"2023-08-27T11:10:50.667643","exception":false,"start_time":"2023-08-27T11:10:50.639276","status":"completed"},"tags":[]}},{"cell_type":"code","source":"class Preprocessor:\n    def __init__(self, \n                model_name: str,\n                ) -> None:\n        self.tokenizer = AutoTokenizer.from_pretrained(f\"/kaggle/input/{model_name}\")\n        self.twd = TreebankWordDetokenizer()\n        self.STOP_WORDS = set(stopwords.words('english'))\n        \n        self.spacy_ner_model = spacy.load('en_core_web_sm',)\n        self.speller = Speller(lang='en')\n        self.spellchecker = SpellChecker() \n        \n    def word_overlap_count(self, row):\n        \"\"\" intersection(prompt_text, text) \"\"\"        \n        def check_is_stop_word(word):\n            return word in self.STOP_WORDS\n        \n        prompt_words = row['prompt_tokens']\n        summary_words = row['summary_tokens']\n        if self.STOP_WORDS:\n            prompt_words = list(filter(check_is_stop_word, prompt_words))\n            summary_words = list(filter(check_is_stop_word, summary_words))\n        return len(set(prompt_words).intersection(set(summary_words)))\n            \n    def ngrams(self, token, n):\n        # Use the zip function to help us generate n-grams\n        # Concatentate the tokens into ngrams and return\n        ngrams = zip(*[token[i:] for i in range(n)])\n        return [\" \".join(ngram) for ngram in ngrams]\n\n    def ngram_co_occurrence(self, row, n: int) -> int:\n        # Tokenize the original text and summary into words\n        original_tokens = row['prompt_tokens']\n        summary_tokens = row['summary_tokens']\n\n        # Generate n-grams for the original text and summary\n        original_ngrams = set(self.ngrams(original_tokens, n))\n        summary_ngrams = set(self.ngrams(summary_tokens, n))\n\n        # Calculate the number of common n-grams\n        common_ngrams = original_ngrams.intersection(summary_ngrams)\n        return len(common_ngrams)\n    \n    def ner_overlap_count(self, row, mode:str):\n        model = self.spacy_ner_model\n        def clean_ners(ner_list):\n            return set([(ner[0].lower(), ner[1]) for ner in ner_list])\n        prompt = model(row['prompt_text'])\n        summary = model(row['text'])\n\n        if \"spacy\" in str(model):\n            prompt_ner = set([(token.text, token.label_) for token in prompt.ents])\n            summary_ner = set([(token.text, token.label_) for token in summary.ents])\n        elif \"stanza\" in str(model):\n            prompt_ner = set([(token.text, token.type) for token in prompt.ents])\n            summary_ner = set([(token.text, token.type) for token in summary.ents])\n        else:\n            raise Exception(\"Model not supported\")\n\n        prompt_ner = clean_ners(prompt_ner)\n        summary_ner = clean_ners(summary_ner)\n\n        intersecting_ners = prompt_ner.intersection(summary_ner)\n        \n        ner_dict = dict(Counter([ner[1] for ner in intersecting_ners]))\n        \n        if mode == \"train\":\n            return ner_dict\n        elif mode == \"test\":\n            return {key: ner_dict.get(key) for key in self.ner_keys}\n        \n    def quotes_count(self, row):\n        summary = row['text']\n        text = row['prompt_text']\n        \n        # Find all quotes in the summary\n        quotes_from_summary = re.findall(r'\"([^\"]*)\"', summary)\n        \n        if len(quotes_from_summary) > 0:\n            # Count the number of quotes from the summary that appear in the prompt text\n            quotes_found_in_prompt = [quote in text for quote in quotes_from_summary]\n            quotes_count = sum(quotes_found_in_prompt)\n            return quotes_count\n        else:\n            # If there are no quotes in the summary, return 0\n            return 0\n        \n    def quotes_presence_indicator(self, row):\n        summary = row['text']\n        text = row['prompt_text']\n        \n        # Find all quotes in the summary\n        quotes_from_summary = re.findall(r'\"([^\"]*)\"', summary)\n        \n        if len(quotes_from_summary) > 0:\n            # Check if any quotes from the summary exist in the prompt text\n            return int(any(quote in text for quote in quotes_from_summary))\n        else:\n            # If there are no quotes in the summary, return 0\n            return 0\n    \n    def quote_length_ratio(self, row):\n        summary = row['text']\n        \n        # Find all quotes in the summary\n        quotes_from_summary = re.findall(r'\"([^\"]*)\"', summary)\n        \n        if len(quotes_from_summary) > 0:\n            # Calculate the total length of quotes and the total length of the summary\n            total_quote_length = sum(len(quote) for quote in quotes_from_summary)\n            total_summary_length = len(summary)\n            \n            # Calculate the ratio of quote length to summary length\n            return total_quote_length / total_summary_length\n        else:\n            # If there are no quotes in the summary, return 0\n            return 0\n    \n    def quote_position(self, row):\n        summary = row['text']\n        \n        # Find all quotes in the summary\n        quotes_from_summary = re.findall(r'\"([^\"]*)\"', summary)\n        \n        if len(quotes_from_summary) > 0:\n            # Calculate the positions of quotes within the summary\n            positions = [match.start() for match in re.finditer(r'\"([^\"]*)\"', summary)]\n            \n            # Calculate the average position of quotes within the summary\n            average_position = sum(positions) / len(positions)\n            return average_position\n        else:\n            # If there are no quotes in the summary, return -1 to indicate no quotes\n            return -1  # You can choose a suitable placeholder value\n\n\n    def spelling(self, text):\n        \n        wordlist=text.split()\n        amount_miss = len(list(self.spellchecker.unknown(wordlist)))\n\n        return amount_miss\n    \n    def add_spelling_dictionary(self, tokens: List[str]) -> List[str]:\n        \"\"\"dictionary update for pyspell checker and autocorrect\"\"\"\n        self.spellchecker.word_frequency.load_words(tokens)\n        self.speller.nlp_data.update({token:1000 for token in tokens})\n    \n    def run(self, \n            prompts: pd.DataFrame,\n            summaries:pd.DataFrame,\n            mode:str\n        ) -> pd.DataFrame:\n        \n        # before merge preprocess\n        prompts[\"prompt_length\"] = prompts[\"prompt_text\"].apply(\n            lambda x: len(word_tokenize(x))\n        )\n        prompts[\"prompt_tokens\"] = prompts[\"prompt_text\"].apply(\n            lambda x: word_tokenize(x)\n        )\n\n        summaries[\"summary_length\"] = summaries[\"text\"].apply(\n            lambda x: len(word_tokenize(x))\n        )\n        summaries[\"summary_tokens\"] = summaries[\"text\"].apply(\n            lambda x: word_tokenize(x)\n        )\n        \n        # Add prompt tokens into spelling checker dictionary\n        prompts[\"prompt_tokens\"].apply(\n            lambda x: self.add_spelling_dictionary(x)\n        )\n        \n#         from IPython.core.debugger import Pdb; Pdb().set_trace()\n        # fix misspelling\n        summaries[\"fixed_summary_text\"] = summaries[\"text\"].progress_apply(\n            lambda x: self.speller(x)\n        )\n        \n        # count misspelling\n        summaries[\"splling_err_num\"] = summaries[\"text\"].progress_apply(self.spelling)\n        \n        # merge prompts and summaries\n        input_df = summaries.merge(prompts, how=\"left\", on=\"prompt_id\")\n\n        # after merge preprocess\n        input_df['length_ratio'] = input_df['summary_length'] / input_df['prompt_length']\n        \n        input_df['word_overlap_count'] = input_df.progress_apply(self.word_overlap_count, axis=1)\n        input_df['bigram_overlap_count'] = input_df.progress_apply(\n            self.ngram_co_occurrence,args=(2,), axis=1 \n        )\n        input_df['bigram_overlap_ratio'] = input_df['bigram_overlap_count'] / (input_df['summary_length'] - 1 + 0.001)\n        \n        input_df['trigram_overlap_count'] = input_df.progress_apply(\n            self.ngram_co_occurrence, args=(3,), axis=1\n        )\n        input_df['trigram_overlap_ratio'] = input_df['trigram_overlap_count'] / (input_df['summary_length'] - 2)\n        \n        input_df['quotes_count'] = input_df.progress_apply(self.quotes_count, axis=1)\n        \n        \n#         input_df['quote_presence_indicator'] = input_df.progress_apply(self.quotes_presence_indicator, axis=1)\n#         input_df['quote_length_ratio'] = input_df.progress_apply(self.quote_length_ratio, axis=1)\n#         input_df['quote_position'] = input_df.progress_apply(self.quote_position, axis=1)\n        \n        \n        return input_df.drop(columns=[\"summary_tokens\", \"prompt_tokens\"])\n    \npreprocessor = Preprocessor(model_name=CFG.model_name)","metadata":{"papermill":{"duration":3.022826,"end_time":"2023-08-27T11:10:53.714112","exception":false,"start_time":"2023-08-27T11:10:50.691286","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-10-10T17:20:47.542076Z","iopub.execute_input":"2023-10-10T17:20:47.542932Z","iopub.status.idle":"2023-10-10T17:20:49.354567Z","shell.execute_reply.started":"2023-10-10T17:20:47.542896Z","shell.execute_reply":"2023-10-10T17:20:49.353561Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test = preprocessor.run(prompts_test, summaries_test, mode=\"test\")","metadata":{"papermill":{"duration":704.199343,"end_time":"2023-08-27T11:22:37.928918","exception":false,"start_time":"2023-08-27T11:10:53.729575","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-10-10T17:20:49.356007Z","iopub.execute_input":"2023-10-10T17:20:49.356924Z","iopub.status.idle":"2023-10-10T17:20:49.463823Z","shell.execute_reply.started":"2023-10-10T17:20:49.356888Z","shell.execute_reply":"2023-10-10T17:20:49.462839Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test['genre_big_group']","metadata":{"execution":{"iopub.status.busy":"2023-10-10T17:20:49.465327Z","iopub.execute_input":"2023-10-10T17:20:49.46586Z","iopub.status.idle":"2023-10-10T17:20:49.475006Z","shell.execute_reply.started":"2023-10-10T17:20:49.465825Z","shell.execute_reply":"2023-10-10T17:20:49.474277Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Model Function Definition","metadata":{"papermill":{"duration":0.197061,"end_time":"2023-08-27T11:22:38.73599","exception":false,"start_time":"2023-08-27T11:22:38.538929","status":"completed"},"tags":[]}},{"cell_type":"code","source":"def compute_metrics(eval_pred):\n    predictions, labels = eval_pred\n    rmse = mean_squared_error(labels, predictions, squared=False)\n    return {\"rmse\": rmse}\n\ndef compute_mcrmse(eval_pred):\n    \"\"\"\n    Calculates mean columnwise root mean squared error\n    https://www.kaggle.com/competitions/commonlit-evaluate-student-summaries/overview/evaluation\n    \"\"\"\n    preds, labels = eval_pred\n\n    col_rmse = np.sqrt(np.mean((preds - labels) ** 2, axis=0))\n    mcrmse = np.mean(col_rmse)\n\n    return {\n        \"content_rmse\": col_rmse[0],\n        \"wording_rmse\": col_rmse[1],\n        \"mcrmse\": mcrmse,\n    }\n\ndef compt_score(content_true, content_pred, wording_true, wording_pred):\n    content_score = mean_squared_error(content_true, content_pred)**(1/2)\n    wording_score = mean_squared_error(wording_true, wording_pred)**(1/2)\n    \n    return (content_score + wording_score)/2","metadata":{"papermill":{"duration":0.194367,"end_time":"2023-08-27T11:22:39.119165","exception":false,"start_time":"2023-08-27T11:22:38.924798","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-10-10T17:20:49.476836Z","iopub.execute_input":"2023-10-10T17:20:49.477898Z","iopub.status.idle":"2023-10-10T17:20:49.487643Z","shell.execute_reply.started":"2023-10-10T17:20:49.47786Z","shell.execute_reply":"2023-10-10T17:20:49.486577Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## FB3 Features","metadata":{"papermill":{"duration":0.18286,"end_time":"2023-08-27T11:22:39.484188","exception":false,"start_time":"2023-08-27T11:22:39.301328","status":"completed"},"tags":[]}},{"cell_type":"code","source":"from torch import nn\n# ====================================================\n# Dataset\n# ====================================================\ndef prepare_input(cfg, text):\n    inputs = cfg.tokenizer.encode_plus(\n        text, \n        return_tensors=None, \n        add_special_tokens=True, \n        #max_length=CFG.max_len,\n        #pad_to_max_length=True,\n        #truncation=True\n    )\n    for k, v in inputs.items():\n        inputs[k] = torch.tensor(v, dtype=torch.long)\n    return inputs\n\n\n# new for CL\nclass CommonlitDataset(Dataset):\n    def __init__(self, cfg, df):\n        self.cfg = cfg\n        self.texts = df['text'].values\n\n    def __len__(self):\n        return len(self.texts)\n\n    def __getitem__(self, item):\n        inputs = prepare_input(self.cfg, self.texts[item])\n        return inputs\n    \n# ====================================================\n# Model\n# ====================================================\nclass MeanPooling(nn.Module):\n    def __init__(self):\n        super(MeanPooling, self).__init__()\n        \n    def forward(self, last_hidden_state, attention_mask):\n        input_mask_expanded = attention_mask.unsqueeze(-1).expand(last_hidden_state.size()).float()\n        sum_embeddings = torch.sum(last_hidden_state * input_mask_expanded, 1)\n        sum_mask = input_mask_expanded.sum(1)\n        sum_mask = torch.clamp(sum_mask, min=1e-9)\n        mean_embeddings = sum_embeddings / sum_mask\n        return mean_embeddings\n\nclass MaxPooling(nn.Module):\n    def __init__(self):\n        super(MaxPooling, self).__init__()\n        \n    def forward(self, last_hidden_state, attention_mask):\n        input_mask_expanded = attention_mask.unsqueeze(-1).expand(last_hidden_state.size()).float()\n        embeddings = last_hidden_state.clone()\n        embeddings[input_mask_expanded == 0] = -1e4\n        max_embeddings, _ = torch.max(embeddings, dim = 1)\n        return max_embeddings\n    \nclass MinPooling(nn.Module):\n    def __init__(self):\n        super(MinPooling, self).__init__()\n        \n    def forward(self, last_hidden_state, attention_mask):\n        input_mask_expanded = attention_mask.unsqueeze(-1).expand(last_hidden_state.size()).float()\n        embeddings = last_hidden_state.clone()\n        embeddings[input_mask_expanded == 0] = 1e-4\n        min_embeddings, _ = torch.min(embeddings, dim = 1)\n        return min_embeddings\n        \n\nclass CustomModel(nn.Module):\n    def __init__(self, cfg, config_path=None, pretrained=False):\n        super().__init__()\n        self.cfg = cfg\n        if config_path is None:\n            self.config = AutoConfig.from_pretrained(cfg.model, output_hidden_states=True)\n            self.config.hidden_dropout = 0.\n            self.config.hidden_dropout_prob = 0.\n            self.config.attention_dropout = 0.\n            self.config.attention_probs_dropout_prob = 0.\n            LOGGER.info(self.config)\n        else:\n            self.config = AutoConfig.from_pretrained(config_path, output_hidden_states=True)\n        if pretrained:\n            self.model = AutoModel.from_pretrained(cfg.model, config=self.config)\n        else:\n            self.model = AutoModel.from_config(self.config)\n        self.pool = MeanPooling()\n        self.fc = nn.Linear(self.config.hidden_size, 6)\n        self._init_weights(self.fc)\n        \n    def _init_weights(self, module):\n        if isinstance(module, nn.Linear):\n            module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n            if module.bias is not None:\n                module.bias.data.zero_()\n        elif isinstance(module, nn.Embedding):\n            module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n            if module.padding_idx is not None:\n                module.weight.data[module.padding_idx].zero_()\n        elif isinstance(module, nn.LayerNorm):\n            module.bias.data.zero_()\n            module.weight.data.fill_(1.0)\n        \n    def feature(self, inputs):\n        outputs = self.model(**inputs)\n        last_hidden_states = outputs[0]\n        feature = self.pool(last_hidden_states, inputs['attention_mask'])\n        return feature\n\n    def forward(self, inputs):\n        feature = self.feature(inputs)\n        output = self.fc(feature)\n        return output\n    \n# ====================================================\n# inference\n# ====================================================\ndef inference_fn(test_loader, model, device):\n    preds = []\n    model.eval()\n    model.to(device)\n    tk0 = tqdm(test_loader, total=len(test_loader))\n    for inputs in test_loader:\n        for k, v in inputs.items():\n            inputs[k] = v.to(device)\n        with torch.no_grad():\n            y_preds = model(inputs)\n        preds.append(y_preds.to('cpu').numpy())\n    predictions = np.concatenate(preds)\n    return predictions\n\ndef get_feedback_feat(data):\n    to_df = np.zeros((data.shape[0], len(CFG.target_cols)))\n    for _idx, CFG_ in enumerate([CFG]):\n        dataset = CommonlitDataset(CFG_, data)\n        loader = DataLoader(dataset,\n                            batch_size=CFG_.batch_size,\n                            shuffle=False,\n                            collate_fn=DataCollatorWithPadding(tokenizer=CFG.tokenizer, padding='longest'),\n                            num_workers=2, pin_memory=True, drop_last=False)\n\n        predictions = []\n        for fold in CFG.trn_fold:\n            print('='*10, f'started fold {fold}', '='*10)\n            model = CustomModel(CFG, config_path=CFG.config_path, pretrained=False)\n            state = torch.load(CFG.path+f\"{CFG.model.replace('/', '-')}_fold{fold}_best.pth\",\n                               map_location=torch.device('cpu'))\n            model.load_state_dict(state['model'])\n            prediction = inference_fn(loader, model, device)\n            predictions.append(prediction)\n            del prediction\n            torch.cuda.empty_cache()\n        to_df += np.mean(predictions, axis=0) \n        del model, dataset, loader; gc.collect()\n        torch.cuda.empty_cache() \n        \n    data[CFG.target_cols] = to_df\n    del predictions\n    return data","metadata":{"papermill":{"duration":0.233843,"end_time":"2023-08-27T11:22:39.901886","exception":false,"start_time":"2023-08-27T11:22:39.668043","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-10-10T17:20:49.4894Z","iopub.execute_input":"2023-10-10T17:20:49.490041Z","iopub.status.idle":"2023-10-10T17:20:49.514818Z","shell.execute_reply.started":"2023-10-10T17:20:49.490003Z","shell.execute_reply":"2023-10-10T17:20:49.513815Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tqdm.notebook import tqdm\n\ntqdm.pandas()\n\ndef get_stat_features(df, text_col=\"text\"):\n    df[\"num_unique_words\"] = df[text_col].apply(lambda x: len(set(x.split())))\n    df[\"num_words\"] = df[text_col].apply(lambda x: len(x.split()))\n    df[\"num_sentences\"] = df[text_col].apply(lambda x: len(x.split('.')))\n    #df[\"isupper\"] = df[text_col].apply(lambda x: x[0].isupper())\n    #df[\"mean_num_words\"] = df[text_col].apply(lambda x: np.mean([len(e.split()) for e in x.split('.')]))\n    #df[\"mean_num_unique_words\"] = df[text_col].apply(lambda x: np.mean([len(set(e.split())) for e in x.split('.')]))\n    #df[\"num_slash\"] = df[text_col].apply(lambda x: x.count(\"\\n\"))\n    #df[\"paragraph_count\"] = train[text_col].apply(lambda x: x.count(\"\\n\\n\"))\n    #df[\"upper_count\"] = df[text_col].apply(lambda x: np.sum([w.isupper() for w in x.split()])/len(x.split()))\n    df[\"syntax_count\"] = df[text_col].apply(lambda x: x.count(\",\") + x.count(\"-\") + x.count(\";\") + x.count(\":\"))\n        \n    #df['automated_readability_index'] = df[text_col].progress_apply(lambda x: textstat.automated_readability_index(x))\n    ##df['coleman_liau_index'] = df[text_col].progress_apply(lambda x: textstat.coleman_liau_index(x))\n    df['smog_index'] = df[text_col].progress_apply(lambda x: textstat.smog_index(x))\n    \n    #df['dale_chall_readability_score'] = df[text_col].progress_apply(lambda x: textstat.dale_chall_readability_score(x))\n    #df['linsear_write_formula'] = df[text_col].progress_apply(lambda x: textstat.linsear_write_formula(x))\n    #df['gunning_fog'] = df[text_col].progress_apply(lambda x: textstat.gunning_fog(x))\n    df['text_standard_float'] = df[text_col].progress_apply(lambda x: textstat.text_standard(x, float_output=True))\n    #df['spache_readability'] = df[text_col].progress_apply(lambda x: textstat.spache_readability(x))\n    #df['rix'] = df[text_col].progress_apply(lambda x: textstat.rix(x))\n   # df['lix'] = df[text_col].progress_apply(lambda x: textstat.lix(x))\n    \n    # new features \n    #df[\"stopwords_rel\"] = df[text_col].progress_apply(lambda x: get_stopwords_rel(x))\n    \n    return df\n    \ntest = get_stat_features(test)","metadata":{"papermill":{"duration":779.856951,"end_time":"2023-08-27T11:36:43.503511","exception":false,"start_time":"2023-08-27T11:23:43.64656","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-10-10T17:20:49.51639Z","iopub.execute_input":"2023-10-10T17:20:49.517044Z","iopub.status.idle":"2023-10-10T17:20:49.682146Z","shell.execute_reply.started":"2023-10-10T17:20:49.517008Z","shell.execute_reply":"2023-10-10T17:20:49.681223Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"CFG.n_fold=10\nCFG.trn_fold=list(range(CFG.n_fold))\nfrom torch.utils.data import Dataset,DataLoader\ndevice = 'cuda'\ntest = get_feedback_feat(test)","metadata":{"papermill":{"duration":890.52604,"end_time":"2023-08-27T11:51:34.221989","exception":false,"start_time":"2023-08-27T11:36:43.695949","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-10-10T17:20:49.683724Z","iopub.execute_input":"2023-10-10T17:20:49.684201Z","iopub.status.idle":"2023-10-10T17:22:50.490245Z","shell.execute_reply.started":"2023-10-10T17:20:49.684166Z","shell.execute_reply":"2023-10-10T17:22:50.489212Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Reacher Models","metadata":{"papermill":{"duration":0.19137,"end_time":"2023-08-27T11:51:35.563088","exception":false,"start_time":"2023-08-27T11:51:35.371718","status":"completed"},"tags":[]}},{"cell_type":"code","source":"class CustomDataset(Dataset) :\n    def __init__(self,df) :\n        self.df = df\n        self.tokenizer = tokenizer\n        \n        self.sep =self.tokenizer.sep_token\n        self.text = (self.df['prompt_title'] + self.sep\n        + self.df[\"prompt_question\"] + self.sep +\n        self.df[\"text\"]).values\n    \n    def __len__(self):\n        return len(self.df)\n    def __getitem__(self, index):\n        \n        text = self.text[index]\n        inputs = self.tokenizer.encode_plus(\n            text,\n            truncation=True,\n            add_special_tokens=True,\n            max_length=512,\n            #padding=\"max_length\", ## New\n           # is_split_into_words=True, ## New\n        )\n        feature_dict = {\n            'input_ids': inputs['input_ids'],\n            'attention_mask': inputs['attention_mask'],\n        }\n\n        return feature_dict\n\nfrom torch import nn\nclass MeanPooling(nn.Module):\n    def __init__(self):\n        super(MeanPooling, self).__init__()\n        \n    def forward(self, last_hidden_state, attention_mask):\n        input_mask_expanded = attention_mask.unsqueeze(-1).expand(last_hidden_state.size()).float()\n        sum_embeddings = torch.sum(last_hidden_state * input_mask_expanded, 1)\n        sum_mask = input_mask_expanded.sum(1)\n        sum_mask = torch.clamp(sum_mask, min=1e-9)\n        mean_embeddings = sum_embeddings / sum_mask\n        return mean_embeddings\n    \nclass GeMText(nn.Module):\n    def __init__(self, dim, cfg, p=3, eps=1e-6):\n        super(GeMText, self).__init__()\n        self.dim = dim\n        self.p = Parameter(torch.ones(1) * p)\n        self.eps = eps\n        self.feat_mult = 1\n\n    def forward(self, x, attention_mask, input_ids, cfg):\n        attention_mask_expanded = attention_mask.unsqueeze(-1).expand(x.shape)\n        x = (x.clamp(min=self.eps) * attention_mask_expanded).pow(self.p).sum(self.dim)\n        ret = x / attention_mask_expanded.sum(self.dim).clip(min=self.eps)\n        ret = ret.pow(1 / self.p)\n        return ret\n    \nclass Model(nn.Module):\n    def __init__(self,config_path):\n        super(Model, self).__init__()\n        self.config = torch.load(config_path)\n        self.model = AutoModel.from_config(self.config)\n        self.pool = MeanPooling()\n        self.fc = nn.Sequential(\n            nn.Linear(self.config.hidden_size, 2))\n        \n    def forward(self, ids, mask):        \n        out = self.model(input_ids=ids,attention_mask=mask,\n                         output_hidden_states=False)\n        out = self.pool(out.last_hidden_state, mask)\n        #out = self.drop(out)\n        out = self.fc(out)\n        return out\n# ====================================================\n# inference\n# ====================================================\ndef inference_fn(test_loader, model, device):\n    preds = []\n    model.eval()\n    tk0 = tqdm(test_loader, total=len(test_loader))\n    for data in tk0:\n        ids = data[\"input_ids\"].to(device, dtype=torch.long)\n        mask = data[\"attention_mask\"].to(device, dtype=torch.long)\n        with torch.no_grad():\n            y_preds = model(ids, mask)\n        preds.append(y_preds.to('cpu').numpy())\n    predictions = np.concatenate(preds)\n    return predictions","metadata":{"papermill":{"duration":0.221237,"end_time":"2023-08-27T11:51:35.977454","exception":false,"start_time":"2023-08-27T11:51:35.756217","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-10-10T17:22:50.492039Z","iopub.execute_input":"2023-10-10T17:22:50.492287Z","iopub.status.idle":"2023-10-10T17:22:50.511439Z","shell.execute_reply.started":"2023-10-10T17:22:50.492254Z","shell.execute_reply":"2023-10-10T17:22:50.510433Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Large","metadata":{"papermill":{"duration":0.202388,"end_time":"2023-08-27T11:51:36.37838","exception":false,"start_time":"2023-08-27T11:51:36.175992","status":"completed"},"tags":[]}},{"cell_type":"code","source":"test['iheb_pred_content_1'] = 0\ntest['iheb_pred_wording_1'] = 0\ntest['iheb_pred_content_2'] = 0\ntest['iheb_pred_wording_2'] = 0\n\ntest['iheb_pred_content_3'] = 0\ntest['iheb_pred_wording_3'] = 0\n\ntest['iheb_pred_content_6'] = 0\ntest['iheb_pred_wording_6'] = 0","metadata":{"papermill":{"duration":0.202065,"end_time":"2023-08-27T11:51:37.243324","exception":false,"start_time":"2023-08-27T11:51:37.041259","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-10-10T17:22:50.513249Z","iopub.execute_input":"2023-10-10T17:22:50.513766Z","iopub.status.idle":"2023-10-10T17:22:50.530713Z","shell.execute_reply.started":"2023-10-10T17:22:50.51373Z","shell.execute_reply":"2023-10-10T17:22:50.529675Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Infer\ntokenizer = AutoTokenizer.from_pretrained(\"/kaggle/input/deberta-v3-large-hf-weights\")\nconfig_path = \"/kaggle/input/commonlit-deberta-large-exp1/config.pth\"\ntest_dataset = CustomDataset(test)\ntest_loader = DataLoader(test_dataset,\n                         batch_size=16,\n                         shuffle=False,\n                         collate_fn=DataCollatorWithPadding(tokenizer=tokenizer),\n                         num_workers=2, pin_memory=True, drop_last=False)\n\npredictions = []\ndevice= 'cuda'\nimport gc\nfor fold in range(4):\n    model = Model(config_path).to(device)\n    \n    state = torch.load(f\"/kaggle/input/commonlit-deberta-large-exp1/fold_{fold}.bin\")\n    model.load_state_dict(state)\n    prediction = inference_fn(test_loader, model, device)\n    predictions.append(prediction)\n    del model, state, prediction; gc.collect()\n    torch.cuda.empty_cache()\npredictions = np.mean(predictions, axis=0)","metadata":{"papermill":{"duration":97.825082,"end_time":"2023-08-27T11:59:47.221461","exception":false,"start_time":"2023-08-27T11:58:09.396379","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-10-10T17:22:50.53239Z","iopub.execute_input":"2023-10-10T17:22:50.533011Z","iopub.status.idle":"2023-10-10T17:24:36.070786Z","shell.execute_reply.started":"2023-10-10T17:22:50.532974Z","shell.execute_reply":"2023-10-10T17:24:36.069642Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test['iheb_pred_content_1'] = predictions[:,0]\ntest['iheb_pred_wording_1'] = predictions[:,1]","metadata":{"papermill":{"duration":0.215044,"end_time":"2023-08-27T11:59:47.698281","exception":false,"start_time":"2023-08-27T11:59:47.483237","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-10-10T17:24:36.072774Z","iopub.execute_input":"2023-10-10T17:24:36.073063Z","iopub.status.idle":"2023-10-10T17:24:36.080185Z","shell.execute_reply.started":"2023-10-10T17:24:36.073022Z","shell.execute_reply":"2023-10-10T17:24:36.079069Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Base","metadata":{"papermill":{"duration":0.201207,"end_time":"2023-08-27T11:59:48.107811","exception":false,"start_time":"2023-08-27T11:59:47.906604","status":"completed"},"tags":[]}},{"cell_type":"code","source":"## Infer\ntokenizer = AutoTokenizer.from_pretrained(\"/kaggle/input/deberta-v3-base-commonlit/tokenizer\")\nconfig_path = \"/kaggle/input/deberta-config/config_base.pth\"\ntest_dataset = CustomDataset(test)\ntest_loader = DataLoader(test_dataset,\n                         batch_size=16,\n                         shuffle=False,\n                         collate_fn=DataCollatorWithPadding(tokenizer=tokenizer),\n                         num_workers=2, pin_memory=True, drop_last=False)\n\npredictions = []\ndevice= 'cuda'\nimport gc\nfor fold in range(4):\n    model = Model(config_path).to(device)\n    \n    state = torch.load(f\"/kaggle/input/baseline-training/fold_{fold}.bin\")\n    model.load_state_dict(state)\n    prediction = inference_fn(test_loader, model, device)\n    predictions.append(prediction)\n    del model, state, prediction; gc.collect()\n    torch.cuda.empty_cache()\npredictions = np.mean(predictions, axis=0)","metadata":{"papermill":{"duration":41.984142,"end_time":"2023-08-27T12:02:58.288322","exception":false,"start_time":"2023-08-27T12:02:16.30418","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-10-10T17:24:36.08205Z","iopub.execute_input":"2023-10-10T17:24:36.08291Z","iopub.status.idle":"2023-10-10T17:25:21.173547Z","shell.execute_reply.started":"2023-10-10T17:24:36.082863Z","shell.execute_reply":"2023-10-10T17:25:21.172411Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test['iheb_pred_content_2'] = predictions[:,0]\ntest['iheb_pred_wording_2'] = predictions[:,1]","metadata":{"papermill":{"duration":0.202219,"end_time":"2023-08-27T12:02:58.740913","exception":false,"start_time":"2023-08-27T12:02:58.538694","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-10-10T17:25:21.175268Z","iopub.execute_input":"2023-10-10T17:25:21.175571Z","iopub.status.idle":"2023-10-10T17:25:21.182904Z","shell.execute_reply.started":"2023-10-10T17:25:21.175535Z","shell.execute_reply":"2023-10-10T17:25:21.181381Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Custom","metadata":{}},{"cell_type":"code","source":"class Dataset(Dataset) :\n    def __init__(self,df,is_train = True) :\n        self.df = df\n        self.tokenizer = tokenizer\n        self.sep_token = self.tokenizer.sep_token\n        self.text = ( '[START_S]' + self.df['text'] + \"[END_S]\" +self.sep_token + '[START_P]' + self.df['prompt_question']+ self.sep_token+ self.df['prompt_text'] + \"[END_P]\" ).values\n        self.is_train = is_train\n    def __len__(self):\n        return len(self.df)\n    def __getitem__(self, index):\n        \n        text = self.text[index]\n        \n        inputs = self.tokenizer.encode_plus(\n            text,\n            truncation=True,\n            add_special_tokens=True,\n            max_length=816\n        )\n        feature_dict = {\n            'input_ids': inputs['input_ids'],\n            'attention_mask': inputs['attention_mask'],\n        }\n\n        return feature_dict\nclass CustomModelv2(nn.Module):\n    def __init__(self):\n        super(CustomModelv2, self).__init__()\n        self.drop = nn.Dropout(p=0)\n        \n        self.config = torch.load(\"/kaggle/input/commonlit-deberta-customv2-allfolds/config.pth\")\n\n        self.model = AutoModel.from_config(self.config)\n        self.mpool = \"\"#GeMText()\n        self.fc = nn.Sequential(\n            nn.Linear(self.config.hidden_size*2, 2),\n        )\n    def pool(self, x, attention_mask, input_ids):\n        input_ids_expanded = input_ids.clone().unsqueeze(-1).expand(x.shape)\n        attention_mask_expanded = torch.zeros_like(input_ids_expanded)\n        attention_mask_expanded[\n            (input_ids_expanded == tokenizer.convert_tokens_to_ids(\"[START_P]\"))\n            | (input_ids_expanded == tokenizer.convert_tokens_to_ids(\"[END_P]\"))\n        ] = 1\n        sum_features = (x * attention_mask_expanded).sum(1)\n        ret = sum_features / attention_mask_expanded.sum(1).clip(min=1e-8)\n        return ret\n    \n    def pool2(self, x, attention_mask, input_ids):\n        input_ids_expanded = input_ids.clone().unsqueeze(-1).expand(x.shape)\n        attention_mask_expanded = torch.zeros_like(input_ids_expanded)\n        attention_mask_expanded[\n            (input_ids_expanded == tokenizer.convert_tokens_to_ids(\"[START_S]\"))\n            | (input_ids_expanded == tokenizer.convert_tokens_to_ids(\"[END_S]\"))\n        ] = 1\n        sum_features = (x * attention_mask_expanded).sum(1)\n        ret = sum_features / attention_mask_expanded.sum(1).clip(min=1e-8)\n        return ret\n        \n    def forward(self, ids, mask):        \n        out = self.model(input_ids=ids,attention_mask=mask,\n                         output_hidden_states=False)\n   \n        prompt_embed = self.pool(out.last_hidden_state, mask, ids)\n        summ_embed = self.pool2(out.last_hidden_state, mask, ids)\n        feat = torch.cat(\n            (\n                prompt_embed,\n                summ_embed\n            ),\n            -1\n        )\n        out = self.fc(feat)\n        return out","metadata":{"execution":{"iopub.status.busy":"2023-10-10T17:25:21.191009Z","iopub.execute_input":"2023-10-10T17:25:21.191582Z","iopub.status.idle":"2023-10-10T17:25:21.207615Z","shell.execute_reply.started":"2023-10-10T17:25:21.191541Z","shell.execute_reply":"2023-10-10T17:25:21.206494Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## Infer\ntokenizer = AutoTokenizer.from_pretrained(\"/kaggle/input/commonlit-deberta-customv2-allfolds\")\nconfig_path = \"/kaggle/input/deberta-config/config_base.pth\"\ntest_dataset = Dataset(test)\ntest_loader = DataLoader(test_dataset,\n                         batch_size=16,\n                         shuffle=False,\n                         collate_fn=DataCollatorWithPadding(tokenizer=tokenizer),\n                         num_workers=2, pin_memory=True, drop_last=False)\n\npredictions = []\ndevice= 'cuda'\nimport gc\nfor fold in range(4):\n    model = CustomModelv2().to(device)\n    \n    state = torch.load(f\"/kaggle/input/commonlit-deberta-customv2-allfolds/content_fold_{fold}_seed_42.bin\")\n    model.load_state_dict(state, strict=False)\n    \n    prediction = inference_fn(test_loader, model, device)\n    predictions.append(prediction)\n    del model, state, prediction; gc.collect()\n    torch.cuda.empty_cache()\npredictions = np.mean(predictions, axis=0)\ntest['iheb_pred_content_3'] = predictions[:,0]\ntest['iheb_pred_wording_3'] = predictions[:,1]\ndel predictions\ngc.collect()","metadata":{"execution":{"iopub.status.busy":"2023-10-10T17:25:21.208945Z","iopub.execute_input":"2023-10-10T17:25:21.210168Z","iopub.status.idle":"2023-10-10T17:27:02.609614Z","shell.execute_reply.started":"2023-10-10T17:25:21.21013Z","shell.execute_reply":"2023-10-10T17:27:02.608584Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### New Baseline","metadata":{}},{"cell_type":"code","source":"class Dataset(Dataset) :\n    def __init__(self,df,is_train = True) :\n        self.df = df\n        self.tokenizer = tokenizer\n        self.sep_token = self.tokenizer.sep_token\n        self.text = ( '[START_S]' + self.df['text'] + \"[END_S]\" + self.sep_token +'[START_P]' + self.df['prompt_question']+ self.sep_token+  self.df['prompt_text'] + \"[END_P]\" ).values\n        self.is_train = is_train\n    def __len__(self):\n        return len(self.df)\n    def __getitem__(self, index):\n        \n        text = self.text[index]\n        \n        inputs = self.tokenizer.encode_plus(\n            text,\n            truncation=True,\n            add_special_tokens=True,\n            max_length=816\n        )\n        feature_dict = {\n            'input_ids': inputs['input_ids'],\n            'attention_mask': inputs['attention_mask'],\n        }\n\n        return feature_dict\n\nclass CustomPool(nn.Module):\n    def __init__(self, dim=1, p=3, eps=1e-6):\n        super(CustomPool, self).__init__()\n        self.dim = dim\n        self.p = Parameter(torch.ones(1) * p)\n        self.eps = eps\n        self.feat_mult = 1\n\n    def forward(self, x, attention_mask, input_ids, start_token, end_token):\n        input_ids_expanded = input_ids.clone().unsqueeze(-1).expand(x.shape)\n        attention_mask_expanded = torch.zeros_like(input_ids_expanded)\n        attention_mask_expanded[\n            (input_ids_expanded == tokenizer.convert_tokens_to_ids(start_token))\n            | (input_ids_expanded == tokenizer.convert_tokens_to_ids(end_token))\n        ] = 1\n        x = (x.clamp(min=self.eps) * attention_mask_expanded).pow(self.p).sum(self.dim)\n        ret = x / attention_mask_expanded.sum(self.dim).clip(min=self.eps)\n        ret = ret.pow(1 / self.p)\n        return ret\n    \nclass CustomModelv3(nn.Module):\n    def __init__(self):\n        super(CustomModelv3, self).__init__()\n        self.drop = nn.Dropout(p=0)\n        \n        self.config = torch.load(\"/kaggle/input/new-baseline-exp1/config.pth\")\n\n        self.model = AutoModel.from_config(self.config)\n        self.pool = CustomPool()\n\n        self.attention = nn.MultiheadAttention(self.config.hidden_size, num_heads=2)\n  \n        self.wording = nn.Linear(self.config.hidden_size, 1)\n        self.content = nn.Linear(self.config.hidden_size*2, 1)\n        \n\n\n        \n    def forward(self, ids, mask):        \n        out = self.model(input_ids=ids,attention_mask=mask,\n                         output_hidden_states=False)\n\n        prompt_embed = self.pool(out.last_hidden_state, mask, ids, \"[START_P]\", \"[END_P]\")\n        summ_embed = self.pool(out.last_hidden_state, mask, ids, \"[START_S]\", \"[END_S]\")\n        feat = torch.cat(\n            (\n                prompt_embed,\n                summ_embed\n            ),\n            -1\n        )\n        wor = self.wording(summ_embed)\n        con = self.content(feat)\n        return torch.cat((con,wor), -1)","metadata":{"execution":{"iopub.status.busy":"2023-10-10T17:27:02.611383Z","iopub.execute_input":"2023-10-10T17:27:02.6119Z","iopub.status.idle":"2023-10-10T17:27:02.626026Z","shell.execute_reply.started":"2023-10-10T17:27:02.611865Z","shell.execute_reply":"2023-10-10T17:27:02.625072Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## Infer\nfrom torch.nn import Parameter\ntokenizer = AutoTokenizer.from_pretrained(\"/kaggle/input/new-baseline-exp1\")\nconfig_path = \"/kaggle/input/deberta-config/config_base.pth\"\ntest_dataset = Dataset(test)\ntest_loader = DataLoader(test_dataset,\n                         batch_size=16,\n                         shuffle=False,\n                         collate_fn=DataCollatorWithPadding(tokenizer=tokenizer),\n                         num_workers=2, pin_memory=True, drop_last=False)\n\npredictions = []\ndevice= 'cuda'\nimport gc\nfor fold in range(4):\n    model = CustomModelv3().to(device)\n    \n    state = torch.load(f\"/kaggle/input/new-baseline-exp1/fold_{fold}.bin\")\n    model.load_state_dict(state, strict=False)\n    \n    prediction = inference_fn(test_loader, model, device)\n    predictions.append(prediction)\n    del model, state, prediction; gc.collect()\n    torch.cuda.empty_cache()\npredictions = np.mean(predictions, axis=0)\ntest['iheb_pred_content_6'] = predictions[:,0]\ntest['iheb_pred_wording_6'] = predictions[:,1]\ndel predictions\ngc.collect()","metadata":{"execution":{"iopub.status.busy":"2023-10-10T17:27:02.62784Z","iopub.execute_input":"2023-10-10T17:27:02.628471Z","iopub.status.idle":"2023-10-10T17:28:43.810034Z","shell.execute_reply.started":"2023-10-10T17:27:02.628434Z","shell.execute_reply":"2023-10-10T17:28:43.809038Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Deberta Regressor","metadata":{"papermill":{"duration":0.19673,"end_time":"2023-08-27T12:02:59.933652","exception":false,"start_time":"2023-08-27T12:02:59.736922","status":"completed"},"tags":[]}},{"cell_type":"code","source":"class ContentScoreRegressor:\n    def __init__(self, \n                model_name: str,\n                model_dir: str,\n                target: str,\n                hidden_dropout_prob: float,\n                attention_probs_dropout_prob: float,\n                max_length: int,\n                ):\n        self.inputs = [\"prompt_text\", \"prompt_title\", \"prompt_question\", \"fixed_summary_text\"]\n        self.input_col = \"input\"\n        \n        self.text_cols = [self.input_col] \n        self.target = target\n        self.target_cols = [target]\n\n        self.model_name = model_name\n        self.model_dir = model_dir\n        self.max_length = max_length\n        \n        self.tokenizer = AutoTokenizer.from_pretrained(f\"/kaggle/input/{model_name}\")\n        self.model_config = AutoConfig.from_pretrained(f\"/kaggle/input/{model_name}\")\n        \n        self.model_config.update({\n            \"hidden_dropout_prob\": hidden_dropout_prob,\n            \"attention_probs_dropout_prob\": attention_probs_dropout_prob,\n            \"num_labels\": 2,\n            \"problem_type\": \"regression\",\n        })\n        \n        seed_everything(seed=42)\n\n        self.data_collator = DataCollatorWithPadding(\n            tokenizer=self.tokenizer\n        )\n\n\n    def tokenize_function(self, examples: pd.DataFrame):\n        labels = [examples[self.target]]\n        tokenized = self.tokenizer(examples[self.input_col],\n                         padding=False,\n                         truncation=True,\n                         max_length=self.max_length)\n        return {\n            **tokenized,\n            \"labels\": labels,\n        }\n    \n    def tokenize_function_test(self, examples: pd.DataFrame):\n        tokenized = self.tokenizer(examples[self.input_col],\n                         padding=False,\n                         truncation=True,\n                         max_length=self.max_length)\n        return tokenized\n        \n    def train(self, \n            fold: int,\n            train_df: pd.DataFrame,\n            valid_df: pd.DataFrame,\n            batch_size: int,\n            learning_rate: float,\n            weight_decay: float,\n            num_train_epochs: float,\n            save_steps: int,\n        ) -> None:\n        \"\"\"fine-tuning\"\"\"\n        \n        sep = self.tokenizer.sep_token\n        train_df[self.input_col] = (\n                    train_df[\"prompt_title\"] + sep \n                    + train_df[\"prompt_question\"] + sep \n                    + train_df[\"fixed_summary_text\"]\n                  )\n\n        valid_df[self.input_col] = (\n                    valid_df[\"prompt_title\"] + sep \n                    + valid_df[\"prompt_question\"] + sep \n                    + valid_df[\"fixed_summary_text\"]\n                  )\n        \n        train_df = train_df[[self.input_col] + self.target_cols]\n        valid_df = valid_df[[self.input_col] + self.target_cols]\n        \n        model_content = AutoModelForSequenceClassification.from_pretrained(\n            f\"/kaggle/input/{self.model_name}\", \n            config=self.model_config\n        )\n\n        train_dataset = Dataset.from_pandas(train_df, preserve_index=False) \n        val_dataset = Dataset.from_pandas(valid_df, preserve_index=False) \n    \n        train_tokenized_datasets = train_dataset.map(self.tokenize_function, batched=False)\n        val_tokenized_datasets = val_dataset.map(self.tokenize_function, batched=False)\n\n        # eg. \"bert/fold_0/\"\n        model_fold_dir = os.path.join(self.model_dir, str(fold)) \n        \n        training_args = TrainingArguments(\n            output_dir=model_fold_dir,\n            load_best_model_at_end=True, # select best model\n            learning_rate=learning_rate,\n            per_device_train_batch_size=batch_size,\n            per_device_eval_batch_size=8,\n            num_train_epochs=num_train_epochs,\n            weight_decay=weight_decay,\n            report_to='none',\n            greater_is_better=False,\n            save_strategy=\"steps\",\n            evaluation_strategy=\"steps\",\n            eval_steps=save_steps,\n            save_steps=save_steps,\n            metric_for_best_model=\"rmse\",\n            save_total_limit=1\n        )\n\n        trainer = Trainer(\n            model=model_content,\n            args=training_args,\n            train_dataset=train_tokenized_datasets,\n            eval_dataset=val_tokenized_datasets,\n            tokenizer=self.tokenizer,\n            compute_metrics=compute_metrics,\n            data_collator=self.data_collator\n        )\n\n        trainer.train()\n        \n        model_content.save_pretrained(self.model_dir)\n        self.tokenizer.save_pretrained(self.model_dir)\n\n        \n    def predict(self, \n                test_df: pd.DataFrame,\n                fold: int,\n               ):\n        \"\"\"predict content score\"\"\"\n        \n        sep = self.tokenizer.sep_token\n        in_text = (\n                    test_df[\"prompt_title\"] + sep \n                    + test_df[\"prompt_question\"] + sep \n                    + test_df[\"fixed_summary_text\"]\n                  )\n        test_df[self.input_col] = in_text\n\n        test_ = test_df[[self.input_col]]\n    \n        test_dataset = Dataset.from_pandas(test_, preserve_index=False) \n        test_tokenized_dataset = test_dataset.map(self.tokenize_function_test, batched=False)\n\n        model_content = AutoModelForSequenceClassification.from_pretrained(\n            f\"/kaggle/input/{self.model_name}\", \n            config=self.model_config\n        )\n        model_content.load_state_dict(torch.load(self.model_dir))\n        model_content.eval()\n        \n        # e.g. \"bert/fold_0/\"\n        model_fold_dir = os.path.join('deberta_large', str(fold)) \n\n        test_args = TrainingArguments(\n            output_dir=model_fold_dir,\n            do_train = False,\n            do_predict = True,\n            per_device_eval_batch_size = 4,   \n            dataloader_drop_last = False,\n        )\n\n        # init trainer\n        infer_content = Trainer(\n                      model = model_content, \n                      tokenizer=self.tokenizer,\n                      data_collator=self.data_collator,\n                      args = test_args)\n\n        preds = infer_content.predict(test_tokenized_dataset)[0]\n\n        return preds","metadata":{"papermill":{"duration":0.22689,"end_time":"2023-08-27T12:03:00.356067","exception":false,"start_time":"2023-08-27T12:03:00.129177","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-10-10T17:28:43.812106Z","iopub.execute_input":"2023-10-10T17:28:43.812745Z","iopub.status.idle":"2023-10-10T17:28:43.83146Z","shell.execute_reply.started":"2023-10-10T17:28:43.812708Z","shell.execute_reply":"2023-10-10T17:28:43.830558Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train_by_fold(\n        train_df: pd.DataFrame,\n        model_name: str,\n        target:str,\n        save_each_model: bool,\n        n_splits: int,\n        batch_size: int,\n        learning_rate: int,\n        hidden_dropout_prob: float,\n        attention_probs_dropout_prob: float,\n        weight_decay: float,\n        num_train_epochs: int,\n        save_steps: int,\n        max_length:int\n    ):\n\n    # delete old model files\n    if os.path.exists(model_name):\n        shutil.rmtree(model_name)\n    \n    os.mkdir(model_name)\n        \n    for fold in range(CFG.n_splits):\n        print(f\"fold {fold}:\")\n        \n        train_data = train_df[train_df[\"fold\"] != fold]\n        valid_data = train_df[train_df[\"fold\"] == fold]\n        \n        if save_each_model == True:\n            model_dir =  f\"{target}/{model_name}/fold_{fold}\"\n        else: \n            model_dir =  f\"{model_name}/fold_{fold}\"\n\n        csr = ContentScoreRegressor(\n            model_name=model_name,\n            target=target,\n            model_dir = model_dir, \n            hidden_dropout_prob=hidden_dropout_prob,\n            attention_probs_dropout_prob=attention_probs_dropout_prob,\n            max_length=max_length,\n           )\n        \n        csr.train(\n            fold=fold,\n            train_df=train_data,\n            valid_df=valid_data, \n            batch_size=batch_size,\n            learning_rate=learning_rate,\n            weight_decay=weight_decay,\n            num_train_epochs=num_train_epochs,\n            save_steps=save_steps,\n        )\n\ndef validate(\n    train_df: pd.DataFrame,\n    target:str,\n    save_each_model: bool,\n    model_name: str,\n    hidden_dropout_prob: float,\n    attention_probs_dropout_prob: float,\n    max_length : int\n    ) -> pd.DataFrame:\n    \"\"\"predict oof data\"\"\"\n    for fold in range(CFG.n_splits):\n        print(f\"fold {fold}:\")\n        \n        valid_data = train_df[train_df[\"fold\"] == fold]\n        \n        model_dir = f'/kaggle/input/wts-deberta-single-model-2/deberta_large_{fold}.pth'\n        \n        csr = ContentScoreRegressor(\n            model_name=model_name,\n            target=target,\n            model_dir = model_dir,\n            hidden_dropout_prob=hidden_dropout_prob,\n            attention_probs_dropout_prob=attention_probs_dropout_prob,\n            max_length=max_length,\n           )\n        \n        pred = csr.predict(\n            test_df=valid_data, \n            fold=fold\n        )\n        \n        train_df.loc[valid_data.index, f\"content_pred\"] = pred[:, 0]\n        train_df.loc[valid_data.index, f\"wording_pred\"] = pred[:, 1]\n            \n    return train_df\n    \ndef predict(\n    test_df: pd.DataFrame,\n    target:str,\n    save_each_model: bool,\n    model_name: str,\n    hidden_dropout_prob: float,\n    attention_probs_dropout_prob: float,\n    max_length : int\n    ):\n    \"\"\"predict using mean folds\"\"\"\n\n    for fold in range(CFG.n_splits):\n        print(f\"fold {fold}:\")\n        \n        model_dir = f'/kaggle/input/wts-deberta-single-model-2/deberta_large_{fold}.pth'\n        \n        csr = ContentScoreRegressor(\n            model_name=model_name,\n            target=target,\n            model_dir = model_dir, \n            hidden_dropout_prob=hidden_dropout_prob,\n            attention_probs_dropout_prob=attention_probs_dropout_prob,\n            max_length=max_length,\n           )\n        \n        pred = csr.predict(\n            test_df=test_df, \n            fold=fold\n        )\n        \n        test_df[f\"content_pred_{fold}\"] = pred[:, 0]\n        test_df[f\"wording_pred_{fold}\"] = pred[:, 1]\n    \n    test_df[f\"content_pred\"] = test_df[[f\"content_pred_{fold}\" for fold in range(CFG.n_splits)]].mean(axis=1)\n    test_df[f\"wording_pred\"] = test_df[[f\"wording_pred_{fold}\" for fold in range(CFG.n_splits)]].mean(axis=1)\n        \n    return test_df","metadata":{"papermill":{"duration":0.215531,"end_time":"2023-08-27T12:03:00.765107","exception":false,"start_time":"2023-08-27T12:03:00.549576","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-10-10T17:28:43.834261Z","iopub.execute_input":"2023-10-10T17:28:43.834935Z","iopub.status.idle":"2023-10-10T17:28:43.851675Z","shell.execute_reply.started":"2023-10-10T17:28:43.834897Z","shell.execute_reply":"2023-10-10T17:28:43.850609Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"targets = ['content', 'wording']","metadata":{"papermill":{"duration":0.199858,"end_time":"2023-08-27T12:03:01.158614","exception":false,"start_time":"2023-08-27T12:03:00.958756","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-10-10T17:28:43.853215Z","iopub.execute_input":"2023-10-10T17:28:43.85357Z","iopub.status.idle":"2023-10-10T17:28:43.868086Z","shell.execute_reply.started":"2023-10-10T17:28:43.853536Z","shell.execute_reply":"2023-10-10T17:28:43.867123Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from datasets import Dataset,load_dataset, load_from_disk\n\n# for target in [\"content\", \"wording\"]:\ntarget = None\ntest = predict(\n    test,\n    target=target,\n    save_each_model=False,\n    model_name=CFG.model_name,\n    hidden_dropout_prob=CFG.hidden_dropout_prob,\n    attention_probs_dropout_prob=CFG.attention_probs_dropout_prob,\n    max_length=CFG.max_length\n)","metadata":{"papermill":{"duration":404.282051,"end_time":"2023-08-27T12:09:45.646086","exception":false,"start_time":"2023-08-27T12:03:01.364035","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-10-10T17:28:43.869633Z","iopub.execute_input":"2023-10-10T17:28:43.869882Z","iopub.status.idle":"2023-10-10T17:30:23.913136Z","shell.execute_reply.started":"2023-10-10T17:28:43.86985Z","shell.execute_reply":"2023-10-10T17:30:23.912184Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test.head()","metadata":{"papermill":{"duration":0.226604,"end_time":"2023-08-27T12:09:46.517374","exception":false,"start_time":"2023-08-27T12:09:46.29077","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-10-10T17:30:23.914712Z","iopub.execute_input":"2023-10-10T17:30:23.914955Z","iopub.status.idle":"2023-10-10T17:30:23.941574Z","shell.execute_reply.started":"2023-10-10T17:30:23.914922Z","shell.execute_reply":"2023-10-10T17:30:23.94059Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Squad","metadata":{}},{"cell_type":"code","source":"def predict(\n    test_df: pd.DataFrame,\n    target:str,\n    save_each_model: bool,\n    model_name: str,\n    hidden_dropout_prob: float,\n    attention_probs_dropout_prob: float,\n    max_length : int\n    ):\n    \"\"\"predict using mean folds\"\"\"\n\n    for fold in range(CFG.n_splits):\n        print(f\"fold {fold}:\")\n        \n        model_dir = f'/kaggle/input/wts-squad/deberta_large_{fold}.pth'\n        \n        csr = ContentScoreRegressor(\n            model_name=model_name,\n            target=target,\n            model_dir = model_dir, \n            hidden_dropout_prob=hidden_dropout_prob,\n            attention_probs_dropout_prob=attention_probs_dropout_prob,\n            max_length=max_length,\n           )\n        \n        pred = csr.predict(\n            test_df=test_df, \n            fold=fold\n        )\n        \n        test_df[f\"content_pred_squad{fold}\"] = pred[:, 0]\n        test_df[f\"wording_pred_squad{fold}\"] = pred[:, 1]\n    \n    test_df[f\"content_pred_squad\"] = test_df[[f\"content_pred_squad{fold}\" for fold in range(CFG.n_splits)]].mean(axis=1)\n    test_df[f\"wording_pred_squad\"] = test_df[[f\"wording_pred_squad{fold}\" for fold in range(CFG.n_splits)]].mean(axis=1)\n        \n    return test_df\n# for target in [\"content\", \"wording\"]:\ntarget = None\ntest = predict(\n    test,\n    target=target,\n    save_each_model=False,\n    model_name='squaddeb/squad_deberta',\n    hidden_dropout_prob=CFG.hidden_dropout_prob,\n    attention_probs_dropout_prob=CFG.attention_probs_dropout_prob,\n    max_length=CFG.max_length\n)","metadata":{"execution":{"iopub.status.busy":"2023-10-10T17:30:23.943531Z","iopub.execute_input":"2023-10-10T17:30:23.944199Z","iopub.status.idle":"2023-10-10T17:31:44.031856Z","shell.execute_reply.started":"2023-10-10T17:30:23.944161Z","shell.execute_reply":"2023-10-10T17:31:44.030867Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test.head()","metadata":{"execution":{"iopub.status.busy":"2023-10-10T17:31:44.033601Z","iopub.execute_input":"2023-10-10T17:31:44.03386Z","iopub.status.idle":"2023-10-10T17:31:44.05807Z","shell.execute_reply.started":"2023-10-10T17:31:44.033827Z","shell.execute_reply":"2023-10-10T17:31:44.056797Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## LGBM model","metadata":{"papermill":{"duration":0.196613,"end_time":"2023-08-27T12:09:46.918205","exception":false,"start_time":"2023-08-27T12:09:46.721592","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# FEATURES = train.columns","metadata":{"execution":{"iopub.status.busy":"2023-10-10T17:31:44.059486Z","iopub.execute_input":"2023-10-10T17:31:44.060442Z","iopub.status.idle":"2023-10-10T17:31:44.070467Z","shell.execute_reply.started":"2023-10-10T17:31:44.060377Z","shell.execute_reply":"2023-10-10T17:31:44.069562Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.description","metadata":{"execution":{"iopub.status.busy":"2023-10-11T09:06:00.195127Z","iopub.execute_input":"2023-10-11T09:06:00.195375Z","iopub.status.idle":"2023-10-11T09:06:00.20306Z","shell.execute_reply.started":"2023-10-11T09:06:00.195349Z","shell.execute_reply":"2023-10-11T09:06:00.20217Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test.select_dtypes(include=['object'])","metadata":{"execution":{"iopub.status.busy":"2023-10-11T09:06:20.794841Z","iopub.execute_input":"2023-10-11T09:06:20.795087Z","iopub.status.idle":"2023-10-11T09:06:20.813804Z","shell.execute_reply.started":"2023-10-11T09:06:20.795061Z","shell.execute_reply":"2023-10-11T09:06:20.812587Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train['grade'] = train.grade.astype(int)\ntest['grade'] = test.grade.astype(int)","metadata":{"execution":{"iopub.status.busy":"2023-10-11T09:06:22.102838Z","iopub.execute_input":"2023-10-11T09:06:22.103109Z","iopub.status.idle":"2023-10-11T09:06:22.109766Z","shell.execute_reply.started":"2023-10-11T09:06:22.103081Z","shell.execute_reply":"2023-10-11T09:06:22.10871Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"c_w = [ 0.1126 , 0.5324, -0.02550 , 0.2426 , 0.2235, 0.4235]\ncolumns = [\n    train.iheb_pred_content_6,\n    train.iheb_pred_content_3,\n    train.iheb_pred_content_1,\n    train.iheb_pred_content_2,\n    train.content_pred,\n    train.content_pred_squad\n]\ntest_columns = [\n    test.iheb_pred_content_6,\n    test.iheb_pred_content_3,\n    test.iheb_pred_content_1,\n    test.iheb_pred_content_2,\n    test.content_pred,\n    test.content_pred_squad\n]\ntrain['c_blend'] = sum((1/6)*c for w, c in zip(c_w, columns))\ntest['c_blend'] = sum((1/6)*c for w, c in zip(c_w, test_columns))","metadata":{"execution":{"iopub.status.busy":"2023-10-11T09:06:24.685283Z","iopub.execute_input":"2023-10-11T09:06:24.686132Z","iopub.status.idle":"2023-10-11T09:06:24.698391Z","shell.execute_reply.started":"2023-10-11T09:06:24.686093Z","shell.execute_reply":"2023-10-11T09:06:24.697255Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"c_w = [ 0.20779315,  0.46793504,  0.34587795, -0.06300992,  0.07636666, 0.27636666]\ncolumns = [\n    train.iheb_pred_wording_6,\n    train.iheb_pred_wording_3,\n    train.iheb_pred_wording_1,\n    train.iheb_pred_wording_2,\n    train.wording_pred,\n    train.wording_pred_squad\n]\ntest_columns = [\n    test.iheb_pred_wording_6,\n    test.iheb_pred_wording_3,\n    test.iheb_pred_wording_1,\n    test.iheb_pred_wording_2,\n    test.wording_pred,\n    test.wording_pred_squad\n]\ntrain['w_blend'] = sum((1/6)*c for w, c in zip(c_w, columns))\ntest['w_blend'] = sum((1/6)*c for w, c in zip(c_w, test_columns))","metadata":{"execution":{"iopub.status.busy":"2023-10-11T09:06:26.015871Z","iopub.execute_input":"2023-10-11T09:06:26.016135Z","iopub.status.idle":"2023-10-11T09:06:26.027858Z","shell.execute_reply.started":"2023-10-11T09:06:26.016108Z","shell.execute_reply":"2023-10-11T09:06:26.026661Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"targets = [\"content\", \"wording\"]\n\ndrop_columns = [\"fold\", \"student_id\", \"prompt_id\", \"text\", \"fixed_summary_text\",\n                \"prompt_question\", \"prompt_title\", \n                \"prompt_text\", 'description', 'author', 'title', 'path', 'date', 'intro', 'excerpt', 'license', 'notes',\n                'iheb_pred_content_6','iheb_pred_wording_6','iheb_pred_content_3','iheb_pred_wording_3','iheb_pred_content_1',\n                'iheb_pred_wording_1','iheb_pred_content_2'\n               ] + targets\nFEATURES = train.columns\nFEATURES = [x for x in FEATURES if x not in drop_columns]\n\n","metadata":{"papermill":{"duration":0.2087,"end_time":"2023-08-27T12:09:47.378611","exception":false,"start_time":"2023-08-27T12:09:47.169911","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-10-11T09:06:29.34305Z","iopub.execute_input":"2023-10-11T09:06:29.344022Z","iopub.status.idle":"2023-10-11T09:06:29.350703Z","shell.execute_reply.started":"2023-10-11T09:06:29.343979Z","shell.execute_reply":"2023-10-11T09:06:29.349609Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(FEATURES)","metadata":{"execution":{"iopub.status.busy":"2023-10-11T09:06:29.613306Z","iopub.execute_input":"2023-10-11T09:06:29.613596Z","iopub.status.idle":"2023-10-11T09:06:29.619608Z","shell.execute_reply.started":"2023-10-11T09:06:29.613545Z","shell.execute_reply":"2023-10-11T09:06:29.618649Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"FEATURES","metadata":{"execution":{"iopub.status.busy":"2023-10-11T09:06:29.935304Z","iopub.execute_input":"2023-10-11T09:06:29.935548Z","iopub.status.idle":"2023-10-11T09:06:29.942259Z","shell.execute_reply.started":"2023-10-11T09:06:29.935522Z","shell.execute_reply":"2023-10-11T09:06:29.941246Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from xgboost import XGBRegressor","metadata":{"execution":{"iopub.status.busy":"2023-10-11T09:06:32.314204Z","iopub.execute_input":"2023-10-11T09:06:32.314978Z","iopub.status.idle":"2023-10-11T09:06:32.474313Z","shell.execute_reply.started":"2023-10-11T09:06:32.314945Z","shell.execute_reply":"2023-10-11T09:06:32.473324Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from catboost import CatBoostRegressor\nfrom xgboost import XGBRegressor\nimport lightgbm as lgb\nimport gc\n\nmodel_dict = {}\n\nfor target in targets:\n    models = []      \n    \n    for fold in range(CFG.n_splits):\n        # Preparation phase\n        X_train_cv = train[train[\"fold\"] != fold][FEATURES]\n        y_train_cv = train[train[\"fold\"] != fold][target]\n        X_eval_cv = train[train[\"fold\"] == fold][FEATURES]\n        y_eval_cv = train[train[\"fold\"] == fold][target]\n        dtrain = lgb.Dataset(X_train_cv, label=y_train_cv)\n        dval = lgb.Dataset(X_eval_cv, label=y_eval_cv)\n        \n        # LGB Model\n        params = {\n            'boosting_type': 'gbdt',\n            'random_state': 42,\n            'objective': 'regression',\n            'metric': 'rmse',\n            'learning_rate': 0.048,\n            'max_depth': 5,\n            'lambda_l1': 0.0,\n            'lambda_l2': 0.011,\n            'n_estimators':5000,\n            'feature_fraction':0.5,\n        }\n        evaluation_results = {}\n        model_lgb = lgb.train(\n            params, train_set=dtrain, valid_sets=dval, num_boost_round=10000,\n            valid_names=['train', 'valid'], \n            callbacks=[\n                lgb.early_stopping(stopping_rounds=30, verbose=True),\n                lgb.log_evaluation(100),\n                lgb.callback.record_evaluation(evaluation_results)\n            ]\n        )\n        models.append(model_lgb)\n        del model_lgb, dtrain, dval, evaluation_results\n        gc.collect()\n\n        # CatBoost Model\n        model_cb = CatBoostRegressor(max_depth=4, learning_rate=0.01, iterations=5000)\n        model_cb.fit(X_train_cv, y_train_cv, eval_set=[(X_eval_cv, y_eval_cv)], early_stopping_rounds=90, verbose=100)\n        models.append(model_cb)\n        del model_cb\n        gc.collect()\n\n        # XGBoost Model\n        model_xgb = XGBRegressor(max_depth=4, learning_rate=0.01, n_estimators=5000, subsample=0.5)\n        model_xgb.fit(X_train_cv, y_train_cv, eval_set=[(X_eval_cv, y_eval_cv)], early_stopping_rounds=90, verbose=100)\n        models.append(model_xgb)\n        del model_xgb, X_train_cv, y_train_cv, X_eval_cv, y_eval_cv\n        gc.collect()\n\n    model_dict[target] = models","metadata":{"papermill":{"duration":11.111027,"end_time":"2023-08-27T12:09:59.501932","exception":false,"start_time":"2023-08-27T12:09:48.390905","status":"completed"},"tags":[],"scrolled":true,"execution":{"iopub.status.busy":"2023-10-11T09:06:58.66632Z","iopub.execute_input":"2023-10-11T09:06:58.666728Z","iopub.status.idle":"2023-10-11T09:08:44.018132Z","shell.execute_reply.started":"2023-10-11T09:06:58.666543Z","shell.execute_reply":"2023-10-11T09:08:44.017116Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\n\ndef compute_modes(train_target_series, target, bins, num):\n    \"\"\"\n    Compute the two most common values of the target for each bin from the training data.\n    Returns a dataframe with the bins and their corresponding 1st and 2nd modes.\n    \"\"\"\n    # Calculate the target bins for the training data with a distinct name\n    bins_col_name = f\"{target}_temp_bin\"\n    train_target_series[bins_col_name] = pd.cut(train_target_series, bins, labels=False)\n    \n    # Compute the two most common values of the target for each bin\n    top_two_modes = train_target_series.groupby(bins_col_name).apply(lambda x: x.value_counts().head(num).index.tolist())\n    \n    # Split the modes into separate columns\n    modes_df = pd.DataFrame(top_two_modes.tolist(), columns=[f\"{target}_mode_{x+1}\" for x in range(num)], index=top_two_modes.index).reset_index(drop=True)\n    return modes_df\n\ndef prepare_dataframe(df, target_series, target, bins, modes_df):\n    \"\"\"\n    Takes in a dataframe (features only) and a target Series.\n    Adds the 1st and 2nd mode features based on the target bin to the input dataframe.\n    Returns the modified dataframe.\n    \"\"\"\n    \n    # Calculate the target bins for the given dataframe\n    df_bins = pd.cut(target_series, bins, labels=False)\n    \n    # Merge the mode information with the given dataframe based on bins\n    df = pd.concat([df, modes_df.loc[df_bins].reset_index(drop=True)], axis=1)\n    \n    return df\n\n\n# Example usage:\n\nbins_dict = {'content': [-float('inf'), -1.5, -1.2, -1.05, -0.95, -0.50, -0.35, -0.1, 0.0, 0.1, 0.25, 0.3, 0.4, float('inf')],\n                 'wording': [-float('inf'), -1.46, -1, -0.5, 0, 0.2, 0.46 ,0.65, 0.9, 1.2, 2, float('inf')]}\nmodes = {'content': compute_modes(train['content'], 'content', bins_dict['content'], num=2),\n         'wording': compute_modes(train['wording'], 'wording', bins_dict['wording'], num=2)}","metadata":{"execution":{"iopub.status.busy":"2023-10-11T09:08:56.935717Z","iopub.execute_input":"2023-10-11T09:08:56.935984Z","iopub.status.idle":"2023-10-11T09:08:56.986954Z","shell.execute_reply.started":"2023-10-11T09:08:56.935957Z","shell.execute_reply":"2023-10-11T09:08:56.98597Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.linear_model import ElasticNet\nfrom sklearn.svm import SVR\nimport matplotlib.pyplot as plt\nfrom joblib import dump, load\n\nrmses = []\npred_dict = {}\npred_dict_oof = {}\n\nfig, axes = plt.subplots(nrows=1, ncols=2, figsize=(12, 5))\naxes = axes.ravel()\n\nfor idx, target in enumerate(targets):\n    models_list = model_dict[target]\n\n    all_oof_preds = []  # This will store OOF predictions from all models\n    trues = []\n    all_test_preds = []  # This will store test predictions from all models\n\n    for fold in range(len(models_list) // 3):  # Assuming 3 models per fold\n        X_eval_cv = train[train[\"fold\"] == fold][FEATURES]\n        y_eval_cv = train[train[\"fold\"] == fold][target]\n        trues.extend(y_eval_cv)\n\n        fold_oof_preds = []  \n        fold_test_preds = []  \n\n        for i in range(3):\n            model = models_list[fold * 3 + i]\n            if isinstance(model, lgb.Booster):  # Check if it's LGB Booster\n                fold_oof_preds.append(model.predict(X_eval_cv, raw_score=True))\n                fold_test_preds.append(model.predict(test[FEATURES], raw_score=True))\n            else:\n                fold_oof_preds.append(model.predict(X_eval_cv))\n                fold_test_preds.append(model.predict(test[FEATURES]))\n\n        # Stack predictions horizontally for this fold\n        all_oof_preds.append(np.column_stack(fold_oof_preds))\n        all_test_preds.append(np.column_stack(fold_test_preds))\n        \n        \n    import gc\n    import ctypes\n    libc = ctypes.CDLL(\"libc.so.6\")\n    _=gc.collect()\n    _=libc.malloc_trim(0)\n    _=torch.cuda.empty_cache()\n\n    # Vertical stack to get predictions for all folds\n    all_oof_preds = np.vstack(all_oof_preds)\n    all_test_preds = np.mean(np.array(all_test_preds), axis=0)\n\n    all_oof_preds = prepare_dataframe(pd.DataFrame(all_oof_preds),np.mean(all_oof_preds,axis=1), target, bins_dict[target],modes[target]).values\n    all_test_preds = prepare_dataframe(pd.DataFrame(all_test_preds),np.mean(all_test_preds,axis=1), target, bins_dict[target],modes[target]).values\n\n    # Prepare GroupKFold\n    gkf = GroupKFold(n_splits=4)\n    enet_oof_preds = np.zeros(all_oof_preds.shape[0])\n    enet_test_preds = []\n\n    for i, (train_idx, valid_idx) in enumerate(gkf.split(all_oof_preds, trues, groups=train['prompt_id'])):\n        X_train, X_valid = all_oof_preds[train_idx], all_oof_preds[valid_idx]\n        y_train, y_valid = np.array(trues)[train_idx], np.array(trues)[valid_idx]\n\n        enet = SVR(kernel='rbf', C=200)\n        enet.fit(X_train, y_train)\n\n        enet_oof_preds[valid_idx] = enet.predict(X_valid)\n        enet_test_preds.append(enet.predict(all_test_preds))\n\n        del enet\n\n    # Average the test predictions\n    test_preds_avg = np.mean(enet_test_preds, axis=0)\n    \n    enet_oof_preds = np.clip(enet_oof_preds,train[target].min(),train[target].max())\n    test_preds_avg = np.clip(test_preds_avg,train[target].min(),train[target].max())\n    \n    pred_dict[target] = test_preds_avg\n    pred_dict_oof[target] = enet_oof_preds\n    \n    \n    \n    # Train on Full Data + Psuedo Labeling for test set\n    all_test_preds = np.concatenate([all_test_preds,pred_dict[target].reshape(-1,1)],axis=1)\n    all_oof_preds = np.concatenate([all_oof_preds,pred_dict_oof[target].reshape(-1,1)],axis=1)\n    \n    enet = SVR(kernel='rbf', C=45,epsilon=0.15)\n    enet.fit(all_oof_preds, np.array(trues))\n    pred_dict[target] = np.clip(enet.predict(all_test_preds),train[target].min(),train[target].max())\n    \n    \n    rmse = np.sqrt(mean_squared_error(trues, enet_oof_preds))\n    rmses.append(rmse)\n    print(f\"{target}_rmse: {rmse}\")\n\n    # Plot histograms\n    axes[idx].hist(trues, bins=50, color='blue', alpha=0.7, label='True Values')\n    axes[idx].hist(enet_oof_preds, bins=50, color='red', alpha=0.7, label='Predictions')\n    axes[idx].set_title(f'Histogram for {target}')\n    axes[idx].set_xlabel('Value')\n    axes[idx].set_ylabel('Frequency')\n    axes[idx].legend()\n\n\nprint(f\"mcrmse: {sum(rmses) / len(rmses)}\")\n\nplt.tight_layout()\nplt.show()\n\n# content_rmse: 0.41092\n# wording_rmse: 0.55592\n# mcrmse: 0.483422","metadata":{"execution":{"iopub.status.busy":"2023-10-11T09:09:01.175144Z","iopub.execute_input":"2023-10-11T09:09:01.175412Z","iopub.status.idle":"2023-10-11T09:09:32.29013Z","shell.execute_reply.started":"2023-10-11T09:09:01.175386Z","shell.execute_reply":"2023-10-11T09:09:32.289241Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# remove 6\n# content_rmse : 0.42622270470069884\n# wording_rmse : 0.5620141385889237\n# mcrmse : 0.49411842164481123\n\n# remove 3 & 6\n# content_rmse : 0.4241196982233673\n# wording_rmse : 0.5587584707894322\n# mcrmse : 0.4914390845063997\n# remove 3 & 6 & 1\n# content_rmse : 0.41834440120904454\n# wording_rmse : 0.5613214137741236\n# mcrmse : 0.48983290749158404","metadata":{"execution":{"iopub.status.busy":"2023-10-10T17:32:57.474736Z","iopub.execute_input":"2023-10-10T17:32:57.474985Z","iopub.status.idle":"2023-10-10T17:32:57.479802Z","shell.execute_reply.started":"2023-10-10T17:32:57.474952Z","shell.execute_reply":"2023-10-10T17:32:57.478417Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test = test[['student_id']]\ntest[['content','wording']] = pd.DataFrame(pred_dict)\ndel pred_dict","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test","metadata":{"execution":{"iopub.status.busy":"2023-10-10T17:32:57.498611Z","iopub.execute_input":"2023-10-10T17:32:57.499558Z","iopub.status.idle":"2023-10-10T17:32:57.522957Z","shell.execute_reply.started":"2023-10-10T17:32:57.499504Z","shell.execute_reply":"2023-10-10T17:32:57.521781Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Create Submission file","metadata":{"papermill":{"duration":0.20231,"end_time":"2023-08-27T12:10:03.063101","exception":false,"start_time":"2023-08-27T12:10:02.860791","status":"completed"},"tags":[]}},{"cell_type":"code","source":"sample_submission","metadata":{"papermill":{"duration":0.22743,"end_time":"2023-08-27T12:10:03.495019","exception":false,"start_time":"2023-08-27T12:10:03.267589","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-10-10T17:32:57.524463Z","iopub.execute_input":"2023-10-10T17:32:57.525476Z","iopub.status.idle":"2023-10-10T17:32:57.538461Z","shell.execute_reply.started":"2023-10-10T17:32:57.525422Z","shell.execute_reply":"2023-10-10T17:32:57.537333Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"summary = pd.read_csv('/kaggle/input/commonlit-evaluate-student-summaries/summaries_train.csv')","metadata":{"execution":{"iopub.status.busy":"2023-10-10T17:32:57.5401Z","iopub.execute_input":"2023-10-10T17:32:57.541001Z","iopub.status.idle":"2023-10-10T17:32:57.638389Z","shell.execute_reply.started":"2023-10-10T17:32:57.540964Z","shell.execute_reply":"2023-10-10T17:32:57.637427Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def rounding(num):\n    global col\n    round_num, round_num2 = 0, 0\n    uniques = np.sort(np.unique(summary[col]))\n    for i,n in enumerate(uniques):\n        if n > num:\n            break\n        round_num = n\n        try:\n            round_num2 = uniques[i+1]\n        except:\n            round_num2 = uniques[i]\n    \n    return round_num if (abs(num - round_num) < abs(num - round_num2)) else round_num2","metadata":{"execution":{"iopub.status.busy":"2023-10-10T17:32:57.639757Z","iopub.execute_input":"2023-10-10T17:32:57.64019Z","iopub.status.idle":"2023-10-10T17:32:57.647888Z","shell.execute_reply.started":"2023-10-10T17:32:57.640157Z","shell.execute_reply":"2023-10-10T17:32:57.646898Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"col = 'content'\ntest[col] = test['content'].apply(rounding)\n\ncol = 'wording'\ntest[col] = test[col].apply(rounding)","metadata":{"execution":{"iopub.status.busy":"2023-10-10T17:32:57.649381Z","iopub.execute_input":"2023-10-10T17:32:57.649955Z","iopub.status.idle":"2023-10-10T17:32:57.666449Z","shell.execute_reply.started":"2023-10-10T17:32:57.649919Z","shell.execute_reply":"2023-10-10T17:32:57.665348Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test[[\"student_id\", \"content\", \"wording\"]].to_csv(\"submission.csv\", index=False)","metadata":{"papermill":{"duration":0.229089,"end_time":"2023-08-27T12:10:03.94389","exception":false,"start_time":"2023-08-27T12:10:03.714801","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-10-10T17:32:57.668038Z","iopub.execute_input":"2023-10-10T17:32:57.668581Z","iopub.status.idle":"2023-10-10T17:32:57.679565Z","shell.execute_reply.started":"2023-10-10T17:32:57.668544Z","shell.execute_reply":"2023-10-10T17:32:57.678535Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test[[\"student_id\", \"content\", \"wording\"]]","metadata":{"papermill":{"duration":0.220187,"end_time":"2023-08-27T12:10:04.369628","exception":false,"start_time":"2023-08-27T12:10:04.149441","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-10-10T17:32:57.681492Z","iopub.execute_input":"2023-10-10T17:32:57.682139Z","iopub.status.idle":"2023-10-10T17:32:57.694899Z","shell.execute_reply.started":"2023-10-10T17:32:57.682102Z","shell.execute_reply":"2023-10-10T17:32:57.693735Z"},"trusted":true},"execution_count":null,"outputs":[]}]}