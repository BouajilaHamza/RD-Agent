{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!rm -rf /library\n!mkdir '/library/'\n!cp -r ../input/commonlit-infer/ /library/commonlit_infer","metadata":{"execution":{"iopub.status.busy":"2023-10-22T13:50:48.304079Z","iopub.execute_input":"2023-10-22T13:50:48.304319Z","iopub.status.idle":"2023-10-22T13:50:51.409056Z","shell.execute_reply.started":"2023-10-22T13:50:48.304296Z","shell.execute_reply":"2023-10-22T13:50:51.407691Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nfrom pathlib import Path\nfrom collections import defaultdict\nimport sys\nsys.path.append('/library/')\nfrom commonlit_infer.preprocess import preprocess, clean_data, convert_data","metadata":{"execution":{"iopub.status.busy":"2023-10-22T13:50:51.411457Z","iopub.execute_input":"2023-10-22T13:50:51.412367Z","iopub.status.idle":"2023-10-22T13:50:53.512936Z","shell.execute_reply.started":"2023-10-22T13:50:51.412328Z","shell.execute_reply":"2023-10-22T13:50:53.511875Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%writefile /library/commonlit_infer/infer.py\nimport os\nimport sys\nimport datetime\nsys.path.append(os.path.join(os.path.dirname(__file__), '..'))\n\nfrom dataclasses import dataclass, field\nfrom typing import Optional\nfrom pathlib import Path\nimport pandas as pd\nimport torch\nimport transformers\nimport numpy as np\nfrom transformers import Trainer\nfrom commonlit_infer.models import Deberta\nfrom commonlit_infer.preprocess import preprocess, clean_data\nfrom commonlit_infer.dataset import get_data_module_fast\n\npd.pandas.set_option('mode.chained_assignment', None)\n\n\nbs_dict = {\n    'deberta_large': [\n        {'ge': 4096, 'le': None, 'bs': 1},\n        {'ge': 3584, 'le': 4096, 'bs': 3},\n        {'ge': 3072, 'le': 3584, 'bs': 4},\n        {'ge': 2560, 'le': 3072, 'bs': 6},\n        {'ge': 2048, 'le': 2560, 'bs': 10},\n        {'ge': 1536, 'le': 2048, 'bs': 12},\n        {'ge': 1280, 'le': 1536, 'bs': 24},\n        {'ge': 1024, 'le': 1280, 'bs': 32},\n        {'ge': None, 'le': 1024, 'bs': 48},\n    ],\n    'deberta_base': [\n        {'ge': 3072, 'le': None, 'bs': 1},\n        {'ge': 2048, 'le': 3072, 'bs': 2},\n        {'ge': 1024, 'le': 2048, 'bs': 24},\n        {'ge': None, 'le': 1024, 'bs': 64},\n    ],\n}\n\n@dataclass\nclass ModelArguments:\n    model_path: Optional[str] = field(default='decapoda-research/llama-7b-hf')\n\n\n@dataclass\nclass DataArguments:\n    df_path: str = field()\n    model_type: str = field(default='deberta_large')\n    max_token_len: int = field(default=None)\n\n\n@dataclass\nclass TrainingArguments(transformers.TrainingArguments):\n    cache_dir: Optional[str] = field(default=None)\n\n\ndef infer():\n    parser = transformers.HfArgumentParser((ModelArguments, DataArguments, TrainingArguments))\n    model_args, data_args, training_args = parser.parse_args_into_dataclasses()\n\n    model_path = Path(model_args.model_path)\n\n    directories = [entry for entry in model_path.iterdir() if entry.is_dir() and entry.stem.startswith('fold')]\n    tokenizer = transformers.DebertaV2Tokenizer.from_pretrained(\n        directories[0],\n        cache_dir=training_args.cache_dir,\n        model_max_length=4096,\n        padding_side=\"right\",\n        use_fast=False,\n    )\n\n    df = preprocess(Path(data_args.df_path), mode='test', tokenizer=tokenizer, max_token_len=data_args.max_token_len)\n    df = df.sort_values('total_len', ascending=False)\n\n    if training_args.fp16:\n        dtype = torch.float16\n    elif training_args.bf16:\n        dtype = torch.bfloat16\n    else:\n        dtype = torch.float32\n\n    for checkpoint_path in directories:\n        \n        model_kwargs = {\n            'pretrained_model_name_or_path': checkpoint_path,\n            'torch_dtype': dtype,\n            'low_cpu_mem_usage': True,\n            'cache_dir': training_args.cache_dir\n        }\n        model = Deberta.from_pretrained(**model_kwargs)  # .cuda().half()\n\n        data_module = get_data_module_fast(df=df, eval_fold=-1, tokenizer=tokenizer,\n                                           use_question_mask=True)\n\n        \n\n        for data_idx, data_params in enumerate(bs_dict[data_args.model_type]):\n            prefix = f'data_{data_idx}'\n            print(data_params)\n\n\n            data_module = get_data_module_fast(df=df, eval_fold=-1, tokenizer=tokenizer, pad_mul=8,\n                                               use_question_mask=True, le=data_params['le'], ge=data_params['ge'], return_test_df=True)\n            \n\n            if data_module is None:\n                continue\n                \n            print(datetime.datetime.now())\n            trainer = Trainer(model=model, tokenizer=tokenizer, args=training_args,\n                          data_collator=data_module['data_collator'])\n            print(datetime.datetime.now())\n            fold_name = f'{prefix}_{checkpoint_path.stem}'\n            save_dir = Path(training_args.output_dir) / model_path.stem / fold_name\n            print(save_dir)\n            save_dir.mkdir(parents=True, exist_ok=True)\n\n            predicted_df = data_module.pop('df')\n            print(predicted_df['total_len'].max())\n            \n            trainer.args.per_device_eval_batch_size = data_params['bs']\n            predictions = trainer.predict(data_module['test_dataset']).predictions\n\n            header = predicted_df['student_id'].to_frame()\n            header['content'] = predictions[:, 0]\n            header['wording'] = predictions[:, 1]\n            header['content'] = header['content'].astype(float)\n            header['wording'] = header['wording'].astype(float)\n            header.to_parquet(save_dir / \"preds.parquet\")\n            del predictions\n            del trainer\n            print(datetime.datetime.now())\n            torch.cuda.empty_cache()\n            print(datetime.datetime.now())\n            \n        del model\n#         return\n\n\nif __name__ == \"__main__\":\n    infer()","metadata":{"execution":{"iopub.status.busy":"2023-10-22T13:50:53.514664Z","iopub.execute_input":"2023-10-22T13:50:53.51519Z","iopub.status.idle":"2023-10-22T13:50:53.526635Z","shell.execute_reply.started":"2023-10-22T13:50:53.515162Z","shell.execute_reply":"2023-10-22T13:50:53.525212Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"clean_data_path = '/kaggle/working/cleaned_data'\nPath(clean_data_path).mkdir(parents=True, exist_ok=True)\nconvert_data(Path('/kaggle/input/commonlit-evaluate-student-summaries'), Path(clean_data_path), 'test')","metadata":{"execution":{"iopub.status.busy":"2023-10-22T13:50:53.529796Z","iopub.execute_input":"2023-10-22T13:50:53.530156Z","iopub.status.idle":"2023-10-22T13:50:53.577007Z","shell.execute_reply.started":"2023-10-22T13:50:53.530122Z","shell.execute_reply":"2023-10-22T13:50:53.575963Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"outname = 'final_0'\n!mkdir /kaggle/working/{outname}\n\nname = 'large-geom'\n!cp -r /kaggle/input/{name}/fold_0 /kaggle/working/{outname}/fold0geo\n\n\n!python /library/commonlit_infer/infer.py --df_path /kaggle/input/commonlit-evaluate-student-summaries  --model_path /kaggle/working/{outname} \\\n--fp16 True --output_dir /out --model_type deberta_large --fp16_full_eval True\n\n!rm -rf /kaggle/working/{outname}","metadata":{"execution":{"iopub.status.busy":"2023-10-22T13:50:53.578504Z","iopub.execute_input":"2023-10-22T13:50:53.57879Z","iopub.status.idle":"2023-10-22T13:51:47.097557Z","shell.execute_reply.started":"2023-10-22T13:50:53.578764Z","shell.execute_reply":"2023-10-22T13:51:47.096269Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"outname = 'final_0_1'\n!mkdir /kaggle/working/{outname}\n\nname = 'large-ema-min-lr-better'\n!cp -r /kaggle/input/{name}/fold_0 /kaggle/working/{outname}/fold0min\n\n\n!python /library/commonlit_infer/infer.py --df_path /kaggle/input/commonlit-evaluate-student-summaries  --model_path /kaggle/working/{outname} \\\n--fp16 True --output_dir /out --model_type deberta_large --fp16_full_eval True --max_token_len 1500\n\n!rm -rf /kaggle/working/{outname}","metadata":{"execution":{"iopub.status.busy":"2023-10-22T13:51:47.098948Z","iopub.execute_input":"2023-10-22T13:51:47.099222Z","iopub.status.idle":"2023-10-22T13:52:22.419164Z","shell.execute_reply.started":"2023-10-22T13:51:47.099196Z","shell.execute_reply":"2023-10-22T13:52:22.417968Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!cp -r /out/final_0_1/* /out/final_0\n!rm -rf /out/final_0_1/","metadata":{"execution":{"iopub.status.busy":"2023-10-22T13:52:22.420651Z","iopub.execute_input":"2023-10-22T13:52:22.421084Z","iopub.status.idle":"2023-10-22T13:52:24.337196Z","shell.execute_reply.started":"2023-10-22T13:52:22.421048Z","shell.execute_reply":"2023-10-22T13:52:24.335848Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"outname = 'final_1_0'\n!mkdir /kaggle/working/{outname}\n\nname = 'aug-flat'\n!cp -r /kaggle/input/{name}/fold_1 /kaggle/working/{outname}/fold1_aug\n\n!python /library/commonlit_infer/infer.py --df_path {clean_data_path}  --model_path /kaggle/working/{outname} \\\n--fp16 True --output_dir /out --model_type deberta_large --fp16_full_eval True --max_token_len 1500\n\n!rm -rf /kaggle/working/{outname}","metadata":{"execution":{"iopub.status.busy":"2023-10-22T13:52:24.339063Z","iopub.execute_input":"2023-10-22T13:52:24.340052Z","iopub.status.idle":"2023-10-22T13:53:00.045936Z","shell.execute_reply.started":"2023-10-22T13:52:24.339992Z","shell.execute_reply":"2023-10-22T13:53:00.044595Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"outname = 'final_1_1'\n!mkdir /kaggle/working/{outname}\n\nname = 'large-ema-min-lr-better'\n!cp -r /kaggle/input/{name}/fold_1 /kaggle/working/{outname}/fold1_bet\n\n\n!python /library/commonlit_infer/infer.py --df_path /kaggle/input/commonlit-evaluate-student-summaries  --model_path /kaggle/working/{outname} \\\n--fp16 True --output_dir /out --model_type deberta_large --fp16_full_eval True --max_token_len 1500\n\n!rm -rf /kaggle/working/{outname}","metadata":{"execution":{"iopub.status.busy":"2023-10-22T13:53:00.047546Z","iopub.execute_input":"2023-10-22T13:53:00.047877Z","iopub.status.idle":"2023-10-22T13:53:35.905713Z","shell.execute_reply.started":"2023-10-22T13:53:00.047847Z","shell.execute_reply":"2023-10-22T13:53:35.90444Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"outname = 'final_1_2'\n!mkdir /kaggle/working/{outname}\n\nname = 'large-ema-min-lr'\n!cp -r /kaggle/input/{name}/fold_1 /kaggle/working/{outname}/fold1min\n\n!python /library/commonlit_infer/infer.py --df_path /kaggle/input/commonlit-evaluate-student-summaries  --model_path /kaggle/working/{outname} \\\n--fp16 True --output_dir /out --model_type deberta_large --fp16_full_eval True --max_token_len 1500\n!rm -rf /kaggle/working/{outname}","metadata":{"execution":{"iopub.status.busy":"2023-10-22T13:53:35.910527Z","iopub.execute_input":"2023-10-22T13:53:35.910912Z","iopub.status.idle":"2023-10-22T13:54:12.671057Z","shell.execute_reply.started":"2023-10-22T13:53:35.910877Z","shell.execute_reply":"2023-10-22T13:54:12.669874Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!cp -r /out/final_1_1/* /out/final_1_0\n!rm -rf /out/final_1_1/\n!cp -r /out/final_1_2/* /out/final_1_0\n!rm -rf /out/final_1_2/","metadata":{"execution":{"iopub.status.busy":"2023-10-22T13:54:12.672591Z","iopub.execute_input":"2023-10-22T13:54:12.672974Z","iopub.status.idle":"2023-10-22T13:54:16.462975Z","shell.execute_reply.started":"2023-10-22T13:54:12.672934Z","shell.execute_reply":"2023-10-22T13:54:16.461395Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"outname = 'final_2'\n!mkdir /kaggle/working/{outname}\n\nname = 'large-ema-min-lr-better'\n!cp -r /kaggle/input/{name}/fold_2 /kaggle/working/{outname}/fold2_bet\n\nname = 'noema-geom'\n!cp -r /kaggle/input/{name}/fold_2 /kaggle/working/{outname}/fold2_geom\n\n!python /library/commonlit_infer/infer.py --df_path /kaggle/input/commonlit-evaluate-student-summaries  --model_path /kaggle/working/{outname} \\\n--fp16 True --output_dir /out --model_type deberta_large --fp16_full_eval True --max_token_len 1500\n\n!rm -rf /kaggle/working/{outname}","metadata":{"execution":{"iopub.status.busy":"2023-10-22T13:54:16.465008Z","iopub.execute_input":"2023-10-22T13:54:16.465345Z","iopub.status.idle":"2023-10-22T13:55:09.781703Z","shell.execute_reply.started":"2023-10-22T13:54:16.465315Z","shell.execute_reply":"2023-10-22T13:55:09.780413Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fold = 3\noutname = f'final_{fold}_0'\n!mkdir /kaggle/working/{outname}\n\nname = 'aug-flat'\n!cp -r /kaggle/input/{name}/fold_3 /kaggle/working/{outname}/fold3_aug\n\n!python /library/commonlit_infer/infer.py --df_path {clean_data_path}  --model_path /kaggle/working/{outname} \\\n--fp16 True --output_dir /out --model_type deberta_large --fp16_full_eval True --max_token_len 1500\n\n!rm -rf /kaggle/working/{outname}","metadata":{"execution":{"iopub.status.busy":"2023-10-22T13:55:09.783431Z","iopub.execute_input":"2023-10-22T13:55:09.783864Z","iopub.status.idle":"2023-10-22T13:55:46.756154Z","shell.execute_reply.started":"2023-10-22T13:55:09.783823Z","shell.execute_reply":"2023-10-22T13:55:46.754936Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"outname = f'final_{fold}_1'\n!mkdir /kaggle/working/{outname}\n\nname = 'geomv2'\n!cp -r /kaggle/input/{name}/fold_3 /kaggle/working/{outname}/fold3_geo\n\n\n!python /library/commonlit_infer/infer.py --df_path /kaggle/input/commonlit-evaluate-student-summaries  --model_path /kaggle/working/{outname} \\\n--fp16 True --output_dir /out --model_type deberta_large --fp16_full_eval True --max_token_len 1500\n\n!rm -rf /kaggle/working/{outname}","metadata":{"execution":{"iopub.status.busy":"2023-10-22T13:55:46.75773Z","iopub.execute_input":"2023-10-22T13:55:46.758114Z","iopub.status.idle":"2023-10-22T13:56:21.835241Z","shell.execute_reply.started":"2023-10-22T13:55:46.758081Z","shell.execute_reply":"2023-10-22T13:56:21.833803Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"outname = f'final_{fold}_2'\n!mkdir /kaggle/working/{outname}\n\nname = 'large-ema-min-lr-better'\n!cp -r /kaggle/input/{name}/fold_3 /kaggle/working/{outname}/fold3_bet\n\n\n!python /library/commonlit_infer/infer.py --df_path /kaggle/input/commonlit-evaluate-student-summaries  --model_path /kaggle/working/{outname} \\\n--fp16 True --output_dir /out --model_type deberta_large --fp16_full_eval True --max_token_len 1500\n\n!rm -rf /kaggle/working/{outname}","metadata":{"execution":{"iopub.status.busy":"2023-10-22T13:56:21.83716Z","iopub.execute_input":"2023-10-22T13:56:21.837571Z","iopub.status.idle":"2023-10-22T13:57:01.823427Z","shell.execute_reply.started":"2023-10-22T13:56:21.837534Z","shell.execute_reply":"2023-10-22T13:57:01.822264Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!cp -r /out/final_{fold}_1/* /out/final_{fold}_0\n!rm -rf /out/final_{fold}_1/\n!cp -r /out/final_{fold}_2/* /out/final_{fold}_0\n!rm -rf /out/final_{fold}_2/","metadata":{"execution":{"iopub.status.busy":"2023-10-22T13:57:01.824833Z","iopub.execute_input":"2023-10-22T13:57:01.825138Z","iopub.status.idle":"2023-10-22T13:57:05.680894Z","shell.execute_reply.started":"2023-10-22T13:57:01.825109Z","shell.execute_reply":"2023-10-22T13:57:05.679688Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"outdir = Path('/out/')","metadata":{"execution":{"iopub.status.busy":"2023-10-22T13:57:05.682297Z","iopub.execute_input":"2023-10-22T13:57:05.682622Z","iopub.status.idle":"2023-10-22T13:57:05.687473Z","shell.execute_reply.started":"2023-10-22T13:57:05.682592Z","shell.execute_reply":"2023-10-22T13:57:05.686405Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nmodels = {}\nfor path in outdir.glob('*'):\n    model_dir = path.stem\n    dfs = []\n    print(model_dir)\n    for fold in path.glob('*'):\n        print(f'{model_dir} ---->  {fold}')\n        dfs.append(pd.read_parquet(fold / f'preds.parquet'))\n    models[model_dir] = pd.concat(dfs).groupby('student_id')[['content', 'wording']].mean().reset_index(drop=False)","metadata":{"execution":{"iopub.status.busy":"2023-10-22T13:57:05.688872Z","iopub.execute_input":"2023-10-22T13:57:05.689226Z","iopub.status.idle":"2023-10-22T13:57:05.921955Z","shell.execute_reply.started":"2023-10-22T13:57:05.689191Z","shell.execute_reply":"2023-10-22T13:57:05.920983Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pd.concat(models.values()).groupby('student_id')[['content', 'wording']].mean().reset_index(drop=False).to_csv(\"submission.csv\", index=False)","metadata":{"execution":{"iopub.status.busy":"2023-10-22T13:57:05.923232Z","iopub.execute_input":"2023-10-22T13:57:05.923547Z","iopub.status.idle":"2023-10-22T13:57:05.933516Z","shell.execute_reply.started":"2023-10-22T13:57:05.923517Z","shell.execute_reply":"2023-10-22T13:57:05.932507Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}